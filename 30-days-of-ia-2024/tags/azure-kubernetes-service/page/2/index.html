<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-blog-30-days-of-ia-2024" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">21 posts tagged with &quot;azure-kubernetes-service&quot; | Build Intelligent Apps On Azure</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="og:title" content="#IntelligentApps start today | Microsoft Azure"><meta data-rh="true" name="og:description" content="Develop adaptive, responsive, and personalized experiences by building and modernizing intelligent applications with Azure!"><meta data-rh="true" name="og:url" content="https://aka.ms/FallForIA"><meta data-rh="true" name="twitter:site" content="@AzureAdvocates"><meta data-rh="true" name="awa-env" content="Production"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" property="og:url" content="https://azure.github.io/cloud-native/evaluate-with-ai"><meta data-rh="true" property="og:type" content="website"><meta data-rh="true" property="og:title" content="**Build Intelligent Apps | AI Apps on Azure"><meta data-rh="true" property="og:description" content="Today, we learn how to Evaluate that prototype using _AI-Assisted Evaluation_ with a larger set of test inputs."><meta data-rh="true" property="og:image" content="https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png"><meta data-rh="true" name="twitter:url" content="https://azure.github.io/Cloud-Native/evaluate-with-ai"><meta data-rh="true" name="twitter:title" content="**Build Intelligent Apps | AI Apps on Azure"><meta data-rh="true" name="twitter:description" content="Today, we learn how to Evaluate that prototype using _AI-Assisted Evaluation_ with a larger set of test inputs."><meta data-rh="true" name="twitter:image" content="https://azure.github.io/Cloud-Native/img/ogImage.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:creator" content="@devanshidiaries"><link data-rh="true" rel="icon" href="/Cloud-Native/img/favicon.ico"><link data-rh="true" rel="alternate" href="https://azure.github.io/Cloud-Native/30-days-of-ia-2024/tags/azure-kubernetes-service/page/2" hreflang="en"><link data-rh="true" rel="alternate" href="https://azure.github.io/Cloud-Native/30-days-of-ia-2024/tags/azure-kubernetes-service/page/2" hreflang="x-default"><link data-rh="true" rel="canonical" href="https://azure.github.io/Cloud-Native/evaluate-with-ai"><link rel="alternate" type="application/rss+xml" href="/Cloud-Native/blog/rss.xml" title="Build Intelligent Apps On Azure RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Cloud-Native/blog/atom.xml" title="Build Intelligent Apps On Azure Atom Feed">





<link rel="alternate" type="application/rss+xml" href="/Cloud-Native/cnny-2023/rss.xml" title="Build Intelligent Apps On Azure RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Cloud-Native/cnny-2023/atom.xml" title="Build Intelligent Apps On Azure Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/Cloud-Native/30DaysOfIA/rss.xml" title="Build Intelligent Apps On Azure RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Cloud-Native/30DaysOfIA/atom.xml" title="Build Intelligent Apps On Azure Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/Cloud-Native/60DaysOfIA/rss.xml" title="Build Intelligent Apps On Azure RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Cloud-Native/60DaysOfIA/atom.xml" title="Build Intelligent Apps On Azure Atom Feed">
<link rel="alternate" type="application/rss+xml" href="/Cloud-Native/30-days-of-ia-2024/rss.xml" title="Build Intelligent Apps On Azure RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Cloud-Native/30-days-of-ia-2024/atom.xml" title="Build Intelligent Apps On Azure Atom Feed">
<script>!function(t,e,n,c,a,r,s){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(r=e.createElement(c)).async=1,r.src="https://www.clarity.ms/tag/d61n997vq9",(s=e.getElementsByTagName(c)[0]).parentNode.insertBefore(r,s)}(window,document,"clarity","script")</script>

<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://js.monitor.azure.com/scripts/c/ms.analytics-web-3.min.js"></script><link rel="stylesheet" href="/Cloud-Native/assets/css/styles.fbc5305a.css">
<script src="/Cloud-Native/assets/js/runtime~main.ce045f40.js" defer="defer"></script>
<script src="/Cloud-Native/assets/js/main.36ad55fe.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><header><div></div></header><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/Cloud-Native/"></a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="announcementBarBackground_Iz1u"><div class="container"><div class="row"><div class="col col--8 col--offset-2 announcementBarContainer_QNjo"><div class="col-demo"><p class="announcementBarContent_tvcd">Learn to use <a class="announcementLink_qKCm" target="_blank" href="https://developer.microsoft.com/reactor/events/23599/?ocid=biafy25h1_cn_webpage_azuremktg" data-bi-area="AnnouncementBar" data-bi-name="Announcement">Azure Functions OpenAI to ingest your own content</a> | Give us a 🌟 <a class="announcementLink_qKCm" target="_blank" href="https://github.com/azure/cloud-native" data-bi-area="AnnouncementBar" data-bi-name="Give us a star on GitHub">on GitHub</a></p></div></div><div class="col col--2 announcementBarIconContainer_GQot"><div class="col-demo"><a href="https://github.com/azure/cloud-native" target="_blank" class="icon_QeTG" aria-label="Visit us on GitHub"><svg width="24" height="24" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="#FFFFFF"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a href="https://azure.github.io/Cloud-Native/60DaysOfIA/rss.xml" target="_blank" class="icon_QeTG" aria-label="Subscribe to RSS"><svg width="24" height="24" viewBox="0 0 333333 333333" xmlns="http://www.w3.org/2000/svg" fill="#f49c4f"><path d="M166667 0c92048 0 166667 74619 166667 166667s-74619 166667-166667 166667S0 258715 0 166667 74619 0 166667 0zm-57698 203357c-11551 0-20938 9418-20938 20897 0 11537 9386 20857 20938 20857 11587 0 20967-9320 20967-20857 0-11479-9378-20897-20967-20897zm-20918-61899v30148c19632 0 38081 7677 51977 21585 13883 13868 21548 32406 21548 52114h30276c0-57254-46585-103838-103801-103838v-9zm38-53431v30154c70007 0 126979 57031 126979 127116l30235 3c0-86697-70539-157270-157212-157270l-2-3z"></path></svg></a><svg viewBox="0 0 24 24" width="24" height="24" class="icon_Kj6K"><path fill="white" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg></div></div></div></div></div><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">#30Days Of IA 2024</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/deploy-with-aca">2.5 Deploy with ACA</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/evaluate-with-ai">2.4 Evaluate with AI!</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/ideate-with-prompty">2.3 Ideate with Prompty!</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/provision-with-azd">2.2 Provision With AZD!</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/kicking-off-azure-ai-week">2.1 Kicking Off Azure AI Week!</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/closing-summary">1.10 Closing Summary</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/how-it-works-behind-the-scenes-of-our-ai-based-content-generation-app">1.9 How it works: Behind the scenes of our AI-based content generation app</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/demo-our-ai-based-content-generation-app">1.8 Demo our AI-based content generation app</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/post-production-monitoring-scaling-and-optimization">1.7 Post-production monitoring, scaling, and optimization</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/setting-up-ci-cd-pipelines-for-azure-app-servicea-and-aks-using-azure-devops-2">1.6b Setting Up CI/CD Pipelines for Azure App Service and AKS Using Azure DevOps Part 2</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/setting-up-ci-cd-pipelines-for-azure-app-servicea-and-aks-using-azure-devops-1">1.6a Setting Up CI/CD Pipelines for Azure App Service and AKS Using Azure DevOps Part 1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/deploy-application-with-AKS-part-2">1.5b Deploy Application with AKS Part 2</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/deploy-application-with-AKS-part-1">1.5a Deploy Application with AKS Part 1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/deploy-application-with-azure-app-service-part-2">1.4b Deploy application with Azure App Service Part 2</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/deploy-application-with-azure-app-service-part-1">1.4a Deploy application with Azure App Service Part 1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/build-content-generation-app-part-2">1.3b Build Content Generation App Part 2</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/build-content-generation-app-part-1">1.3a Build Content Generation App Part 1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/setting-up-your-development-environment-2">1.2b Setting Up Your Development Environment Part 2</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/setting-up-your-development-environment-1">1.2a Setting up your development environment Part 1</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/use-generative-ai-to-build-intelligent-apps">1.1 Use Generative AI to build intelligent apps</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/Cloud-Native/30-days-of-ia-2024/kick-off">Kick-off #30Days of IA</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><header class="margin-bottom--xl"><h1>21 posts tagged with &quot;azure-kubernetes-service&quot;</h1><a href="/Cloud-Native/30-days-of-ia-2024/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Today, we learn how to Evaluate that prototype using _AI-Assisted Evaluation_ with a larger set of test inputs."><link itemprop="image" href="https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png"><meta itemprop="keywords" content="Cloud,Data,AI,AI/ML,intelligent apps,cloud-native,30-days-2024,30-days,enterprise apps,digital experiences,app modernization,serverless,ai apps"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/Cloud-Native/30-days-of-ia-2024/evaluate-with-ai">2.4 Evaluate with AI!</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-10-17T09:00:00.000Z" itemprop="datePublished">October 17, 2024</time> · <!-- -->16 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/nitya" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/nitya.png" alt="Nitya Narasimhan" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/nitya" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Nitya Narasimhan</span></a></div><small class="avatar__subtitle" itemprop="description">Senior AI Advocate</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/marlenezw" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/marlenezw.png" alt="Marlene Mhangami" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/marlenezw" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Marlene Mhangami</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Developer Advocate</small></div></div></div></div></header><div class="markdown" itemprop="articleBody">
<p>Welcome to Day 4️⃣ of Azure AI Week on the #30DaysOfIA series!</p>
<p>In this series, we are walking through this end-to-end developer workflow, to build <strong>2 separate application scenarios</strong> (<a href="https://aka.ms/aitour/contoso-chat" target="_blank" rel="noopener noreferrer">Contoso Chat</a> and <a href="https://aka.ms/aitour/contoso-creative-writer" target="_blank" rel="noopener noreferrer">Contoso Creative Writer</a>) code-first, using the <a href="https://ai.azure.com" target="_blank" rel="noopener noreferrer">Azure AI platform</a> with <a href="https://prompty.ai" target="_blank" rel="noopener noreferrer">Prompty</a> assets.</p>
<p>In our last post, we completed the third step in this diagram, learning about the Prompty asset and tooling, and its usage in implementing the RAG pattern (in Contoso Chat) and Multi-Agent pattern (in Contoso Creative Writer) - where we validated responses for a single sample input.</p>
<p><img loading="lazy" alt="Developer Workflow" src="/Cloud-Native/assets/images/04-developer-workflow-ea28bc208380d98a8041016271b8e50a.png" width="1433" height="448" class="img_ev3q"></p>
<p>Today, we learn how to <strong>Evaluate</strong> that prototype using <em>AI-Assisted Evaluation</em> with a larger set of test inputs. We assess quality by scoring the responses for criteria like fluency, coherence, relevance, and groundedness. We&#x27;ll use Prompty to build <strong>custom evaluators</strong> for this purpose, and use its built-in tracing for <strong>observability</strong>, giving us an intuitive sense for the execution flow and performance from initial prompt to final response.</p>
<p>Ready? Let&#x27;s get started!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-well-cover-today">What We&#x27;ll Cover Today<a href="#what-well-cover-today" class="hash-link" aria-label="Direct link to What We&#x27;ll Cover Today" title="Direct link to What We&#x27;ll Cover Today">​</a></h2>
<ul>
<li><strong>What is AI Assisted Evaluation</strong> - Evaluation dataset, Evaluation workflow</li>
<li><strong>Custom Evaluators</strong> - Coherence, Relevance, Groundedness, Fluency</li>
<li><strong>Evaluation in Action</strong> - Contoso Chat, Contoso Creative Writer</li>
<li><strong>Observability in Action</strong> - Prompty Tracer, Trace Viewer Analysis</li>
<li><strong>What&#x27;s Next</strong> - Let&#x27;s Deploy, Test &amp; Monitor</li>
</ul>
<hr>
<p><img loading="lazy" alt="Card Banner" src="/Cloud-Native/assets/images/04-evalute-trace-6c99da02ea65b63b74e88c1513fd55dc.png" width="960" height="403" class="img_ev3q"></p>
<br>
<p>In our previous post, we looked at how to create a Prompty asset with a default model, sample input, and prompt template - allowing us to rapidly iterate on prompt design till the response for that single input meets our manual assessment for quality.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-what-is-ai-assisted-evaluation">1. What is AI Assisted Evaluation?<a href="#1-what-is-ai-assisted-evaluation" class="hash-link" aria-label="Direct link to 1. What is AI Assisted Evaluation?" title="Direct link to 1. What is AI Assisted Evaluation?">​</a></h2>
<p>The challenge for us is that <em>natural language inputs</em> are non-deterministic by nature, meaning that we have an infinite number of possible test inputs that could be used with our prototype. How can we assess response quality in a way that scales to larger datasets, and can be automed for CI/CD pipelines?</p>
<p>This is where <a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-approach-gen-ai#ai-assisted-evaluations" target="_blank" rel="noopener noreferrer">AI-Assisted evaluation</a> comes into play. In simple terms, we use a second LLM (&quot;eval&quot; model) to grade the responses generated by the first LLM (&quot;chat&quot;) model - where the grading criteria is defined in an <em>evaluator</em> template which generates an <em>assessment score</em> as the output.</p>
<p>By default, Azure AI Studio provides <strong>built-in evaluators</strong> for both quality and safety metrics.</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-metrics-built-in?tabs=warning#generation-quality-metrics" target="_blank" rel="noopener noreferrer">AI-assisted Generation Quality Metrics</a> include Groundedness, Relevance, Coherence and Fluency, typically scored on a scale of 1 (low) to 5 (high).</li>
<li><a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-metrics-built-in?tabs=warning#risk-and-safety-metrics" target="_blank" rel="noopener noreferrer">AI-assisted Risk &amp; Safety Metrics</a> that identify the presence of Hateful &amp; unfair content, Sexual content, Violent content, Self-harm-related content, Indirect attack jailbreak, Direct attack jailbreak and Protected material content - on a severity scale of 0 (very low) to 7 (High).</li>
</ul>
<p>These built-in evaluators can be activated by using the <a href="https://learn.microsoft.com/en-us/azure/ai-studio/how-to/evaluate-generative-ai-app" target="_blank" rel="noopener noreferrer">evaluator library</a> in the Azure AI SDK. However, in today&#x27;s post, we&#x27;ll focus on <strong>custom evaluators</strong> that are <em>prompt-based</em> (as opposed to system-created) and focus primarily on assessing the quality of our application responses.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-what-are-custom-evaluators">2. What are Custom Evaluators?<a href="#2-what-are-custom-evaluators" class="hash-link" aria-label="Direct link to 2. What are Custom Evaluators?" title="Direct link to 2. What are Custom Evaluators?">​</a></h2>
<p><em>Custom evaluators</em> allow us to <strong>define our own evaluation metric</strong> for assessing the quality of our application. We may want to do this for two reasons:</p>
<ol>
<li>The default evaluation metrics (e.g., <em>coherence</em>) assesses scores based on broad guidelines and we want to refine or customize them further to reflect our specific application requirements.</li>
<li>The default evaluation metrics do not cover a specific application behavior (e.g., <em>friendliness</em>) that we want to assess for our application needs.</li>
</ol>
<p>Let&#x27;s take a quick look at the <a href="https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in?tabs=warning#generation-quality-metrics" target="_blank" rel="noopener noreferrer"><strong>default quality metrics</strong></a> defined by Azure AI Studio, and understand what the metric is, how it works, when to use it, and what input it requires for assessment.</p>
<table><thead><tr><th style="text-align:left">Metric</th><th style="text-align:left">What does it assess?</th><th style="text-align:left">How does it work?</th><th style="text-align:left">When should you use it?</th><th style="text-align:left">Inputs Needed</th></tr></thead><tbody><tr><td style="text-align:left"><strong>Groundedness</strong> <br> 1=ungrounded <br> 5=grounded</td><td style="text-align:left">How well does model&#x27;s generated answers align with information from source data (&quot;context&quot;)?</td><td style="text-align:left">Checks if response corresponds <em>verifiably</em> to source context</td><td style="text-align:left">When factual correctness and contextual accuracy are key - e.g., is it grounded in &quot;my&quot; product data?</td><td style="text-align:left">Question, Context, Generated Response</td></tr><tr><td style="text-align:left"><strong>Relevance</strong> <br> 1=bad <br> 5=good</td><td style="text-align:left">Are the model&#x27;s generated responses pertinent, and directly related, to the given queries?</td><td style="text-align:left">Assesses ability of responses to capture the key points of context that relate to the query</td><td style="text-align:left">When evaluating your application&#x27;s ability to understand the inputs and generate <em>contextually-relevant</em> responses</td><td style="text-align:left">Question, Answer</td></tr><tr><td style="text-align:left"><strong>Fluency</strong> 1=bad <br> 5=fluent</td><td style="text-align:left">How grammatically and linguistically correct the model&#x27;s predicted answer is.</td><td style="text-align:left">Checks quality of individual sentences in the ANSWER? Are they well-written and grammatically correct?</td><td style="text-align:left">When evaluating your application&#x27;s ability to generate <em>readable</em> responses</td><td style="text-align:left">Question, Answer</td></tr><tr><td style="text-align:left"><strong>Coherence</strong> <br> 1=bad <br> 5=good</td><td style="text-align:left">Measures the quality of all sentences in a model&#x27;s predicted answer and how they fit together naturally.</td><td style="text-align:left">Checks how well do all sentences in the ANSWER fit together? Do they sound natural when taken as a whole?</td><td style="text-align:left">When the <em>readability</em> of the response is important</td><td style="text-align:left">Question, Answer</td></tr></tbody></table>
<p>To create these custom evaluators, we need to do three things:</p>
<ol>
<li>Define the scoring criteria for that metrics, when evaluating our application responses.</li>
<li>Define a test prompt input that we can use to assess that the evaluator works correctly.</li>
<li>Understand the evaluation flow and integrate our custom evaluator into it, for real-world use.</li>
</ol>
<p>Let&#x27;s take a look at how these are done in our two application scenarios. But first, a quick review of how the evaluation flow works for AI-assisted evaluations with custom evaluators.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-how-is-evaluation-done">3. How is Evaluation Done?<a href="#3-how-is-evaluation-done" class="hash-link" aria-label="Direct link to 3. How is Evaluation Done?" title="Direct link to 3. How is Evaluation Done?">​</a></h2>
<p>Earlier, we talked about AI-assisted evaluation, which works with both built-in evaluators and custom evaluators, to assess quality and safety of your deployed application.</p>
<p><strong>Focus: Quality Evaluations</strong></p>
<p>In this section we focus on the <strong>quality</strong> assessment workflow, targeting the four quality metrics we identified above (along with additional custom metrics we may create). The evaluation flow consists of a sequence of 4 steps as shown in the figure. <a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-approach-gen-ai#ai-assisted-performance-and-quality-metrics" target="_blank" rel="noopener noreferrer">Read the docs</a> for more details.</p>
<ol>
<li>An evaluation <strong>dataset</strong> is created (by customer or AI), with a large set of representative prompts</li>
<li>The prompts are fed to the <strong>chat</strong> application, and resulting responses collected for assessment</li>
<li>Those responses are now fed to the <strong>evaluator</strong> application, which generates evaluation results</li>
<li>These results can now be delivered to a relevant <strong>dashboard</strong> (here, in Azure AI Studio) for analysis.</li>
</ol>
<p><img loading="lazy" alt="AI Assisted Eval" src="/Cloud-Native/assets/images/04-ai-assisted-flow-3041666caa88db26f6c75135eb963ef3.png" width="1785" height="1004" class="img_ev3q"></p>
<p>The <strong>key</strong> to good evaluations is to have <em>coverage</em> of the broad range of user inputs (test prompts) you may be likely to encounter in the real-world deployment of the application. This can come from the customer&#x27;s own dataset (based on their historical knowledge of customers) or be generated with AI assistance (to reflect the criteria you define). <em>In our scenarios below, we use sample test dataset with just a few inputs - in real-world contexts, this would likely be much larger and cover more edge cases</em>.</p>
<p><strong>Sidebar: Safety Evaluations</strong></p>
<p>Our samples do <strong>not</strong> contain custom evaluators for safety for a reason. Assessing safety requires a deep understanding of the potential harms and attacks possible, and should not be taken lightly. Azure AI Studio provides a safety system with built-in evaluations that is ideal for use in production. We encourage you to <a href="https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-approach-gen-ai#ai-assisted-risk-and-safety-metrics" target="_blank" rel="noopener noreferrer">read the docs</a> to learn more about the assessment criteria and how safety evaluations work in Azure AI Studio.</p>
<p><img loading="lazy" alt="AI Assisted Safety Eval" src="/Cloud-Native/assets/images/04-ai-assisted-safety-365f6441744735e67260f2ce296e47d3.png" width="1744" height="973" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-custom-evaluators-in-action">4. Custom Evaluators In Action<a href="#4-custom-evaluators-in-action" class="hash-link" aria-label="Direct link to 4. Custom Evaluators In Action" title="Direct link to 4. Custom Evaluators In Action">​</a></h2>
<p>Both Contoso Chat and Contoso Creative Writer use custom evaluators to assess application response quality. And just like we used prompty files to define our chat and agent applications, we can design prompty files that define the grading application - with a <strong>custom evaluator</strong> for each assessed metric. We will look at how to run evaluations for each sample.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="41-contoso-chat">4.1 Contoso Chat<a href="#41-contoso-chat" class="hash-link" aria-label="Direct link to 4.1 Contoso Chat" title="Direct link to 4.1 Contoso Chat">​</a></h2>
<p>If you are using Contoso Chat we will begin by viewing/running all evaluators.</p>
<ol>
<li>Navigate to the <code>src/api/evaluators/custom_evals</code> folder in VS Code.</li>
<li>Open each of the 4 <code>.prompty</code> files located there, in the VS Code editor.<!-- -->
<ul>
<li><code>fluency.prompty</code></li>
<li><code>coherence.prompty</code></li>
<li><code>groundedness.prompty</code></li>
<li><code>relevance.prompty</code></li>
</ul>
</li>
<li>Run each file and observe the output seen from Prompty execution.</li>
<li><strong>Check:</strong> You see prompty for Coherence, Fluency, Relevance and Groundedness.</li>
<li><strong>Check:</strong> Running the prompty assets gives scores between <code>1</code> and <code>5</code></li>
</ol>
<p>Let&#x27;s understand how this works, taking one of these custom evaluators as an example.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="411-view-coherence-prompty">4.1.1 View Coherence Prompty<a href="#411-view-coherence-prompty" class="hash-link" aria-label="Direct link to 4.1.1 View Coherence Prompty" title="Direct link to 4.1.1 View Coherence Prompty">​</a></h3>
<ol>
<li>
<p>Open the file <code>coherence.prompty</code> and look at its structure</p>
<ol>
<li>
<p>You should see: <strong>system</strong> task is</p>
<blockquote>
<p>You are an AI assistant. You will be given the definition of an evaluation metric for assessing the quality of an answer in a question-answering task. Your job is to compute an accurate evaluation score using the provided evaluation metric. You should return a single integer value between 1 to 5 representing the evaluation metric. You will include no other text or information.</p>
</blockquote>
</li>
<li>
<p>You should see: <strong>inputs</strong> expected are</p>
<ul>
<li><code>question</code> = user input to the chat model</li>
<li><code>answer</code> = response provided by the chat model</li>
<li><code>context</code> = support knowledge that the chat model was given</li>
</ul>
</li>
<li>
<p>You should see: <strong>meta-prompt</strong> guidance for the task:</p>
<blockquote>
<p>Coherence of an answer is measured by how well all the sentences fit together and sound naturally as a whole. Consider the overall quality of the answer when evaluating coherence. Given the question and answer, score the coherence of answer between one to five stars using the following rating scale:</p>
<ul>
<li>One star: the answer completely lacks coherence</li>
<li>Two stars: the answer mostly lacks coherence</li>
<li>Three stars: the answer is partially coherent</li>
<li>Four stars: the answer is mostly coherent</li>
<li>Five stars: the answer has perfect coherency</li>
</ul>
</blockquote>
</li>
<li>
<p>You should see: <strong>examples</strong> that provide guidance for the scoring.</p>
<blockquote>
<p>This rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.
(See examples for question-answer-context inputs that reflect 1,2,3,4 and 5 scores)</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="412-run-coherence-prompty">4.1.2 Run Coherence Prompty<a href="#412-run-coherence-prompty" class="hash-link" aria-label="Direct link to 4.1.2 Run Coherence Prompty" title="Direct link to 4.1.2 Run Coherence Prompty">​</a></h3>
<ol>
<li>
<p>You see: <strong>sample input</strong> for testing</p>
<table><thead><tr><th style="text-align:left">question</th><th style="text-align:left">What feeds all the fixtures in low voltage tracks instead of each light having a line-to-low voltage transformer?</th></tr></thead><tbody><tr><td style="text-align:left">answer</td><td style="text-align:left">The main transformer is the object that feeds all the fixtures in low voltage tracks.</td></tr><tr><td style="text-align:left">context</td><td style="text-align:left">Track lighting, invented by Lightolier, was popular at one period of time because it was much easier to install than recessed lighting, and individual fixtures are decorative and can be easily aimed at a wall. It has regained some popularity recently in low-voltage tracks, which often look nothing like their predecessors because they do not have the safety issues that line-voltage systems have, and are therefore less bulky and more ornamental in themselves. A master transformer feeds all of the fixtures on the track or rod with 12 or 24 volts, instead of each light fixture having its own line-to-low voltage transformer. There are traditional spots and floods, as well as other small hanging fixtures. A modified version of this is cable lighting, where lights are hung from or clipped to bare metal cables under tension</td></tr></tbody></table>
</li>
<li>
<p>Run the prompty file. You see output like this. This means the evaluator &quot;assessed&quot; this ANSWER as being very coherent (score=5).</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2024-09-16 21:35:43.602 [info] Loading /workspaces/contoso-chat/.env</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2024-09-16 21:35:43.678 [info] Calling ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2024-09-16 21:35:44.488 [info] 5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>
<p><strong>Observe:</strong> Recall that coherence is about how well the sentences fit together.</p>
<ul>
<li>Given the sample input, do you agree with the assessment?</li>
</ul>
</li>
<li>
<p><strong>Change Answer</strong></p>
<ul>
<li>replace sample answer with: <code>Lorem ipsum orci dictumst aliquam diam</code></li>
<li>run the prompty again. <em>How did the score change?</em></li>
<li>undo the change. Return the prompty to original state for the next step.</li>
</ul>
</li>
</ol>
<p>Repeat this exercise for the other evaluators on your own. Use this to build your intuition for each metric and how it defines and assesses response quality.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>&quot;Note the several examples given in the Prompty file of answers that represent each of the star ratings. This is an example of <a href="https://learn.microsoft.com/azure/ai-services/openai/concepts/advanced-prompt-engineering?pivots=programming-language-chat-completions#few-shot-learning" target="_blank" rel="noopener noreferrer">few-shot learning</a>, a common technique used to guide AI models.&quot;</p></div></div>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="413-run-batch-evaluation">4.1.3 Run Batch Evaluation<a href="#413-run-batch-evaluation" class="hash-link" aria-label="Direct link to 4.1.3 Run Batch Evaluation" title="Direct link to 4.1.3 Run Batch Evaluation">​</a></h3>
<p>In the previous section, we assessed a single answer for a single metric, running one Prompty at a time. In reality, we will need to run assessments automatically across a large set of test inputs, with all custom evaluators, before we can judge if the application is ready for production use. Here, we&#x27;ll run a batch evaluation on our Contoso Chat application, using a Jupyter notebook.</p>
<p>Navigate to the <code>src/api</code> folder in Visual Studio Code.</p>
<ul>
<li>Click: <code>evaluate-chat-flow.ipynb</code> - see: A Jupyter notebook</li>
<li>Click: Select Kernel - choose &quot;Python Environments&quot; - pick recommended <code>Python 3.11.x</code></li>
<li>Click: <code>Run all</code> - this kickstarts the multi-step evaluation flow.</li>
</ul>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>&quot;Troubleshooting: Evaluation gives an error message in the Notebook&quot;</p><p>On occasion, the evaluation notebook may throw an error after a couple of iterations. This is typically a transient error. To fix it, <code>Clear inputs</code> in the Jupyter Notebook, then <code>Restart</code> it. It should complete the run this time.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="42-contoso-creative-writer">4.2. Contoso Creative Writer<a href="#42-contoso-creative-writer" class="hash-link" aria-label="Direct link to 4.2. Contoso Creative Writer" title="Direct link to 4.2. Contoso Creative Writer">​</a></h2>
<p>If you are using Contoso Creative Writer we will begin by viewing/running all evaluators.</p>
<ol>
<li>Navigate to the <code>src/api/evaluate/custom_evals</code> folder in VS Code.</li>
<li>Open each of the 4 <code>.prompty</code> files located there, in the VS Code editor.<!-- -->
<ul>
<li><code>fluency.prompty</code></li>
<li><code>coherence.prompty</code></li>
<li><code>groundedness.prompty</code></li>
<li><code>relevance.prompty</code></li>
</ul>
</li>
<li>Run each file and observe the output seen from Prompty execution.</li>
<li><strong>Check:</strong> You see prompty for Coherence, Fluency, Relevance and Groundedness.</li>
<li><strong>Check:</strong> Running the prompty assets gives scores between <code>1</code> and <code>5</code></li>
</ol>
<p>Let&#x27;s understand how this works, taking a custom evaluators as an example.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="421-view-friendliness-prompty">4.2.1 View Friendliness Prompty<a href="#421-view-friendliness-prompty" class="hash-link" aria-label="Direct link to 4.2.1 View Friendliness Prompty" title="Direct link to 4.2.1 View Friendliness Prompty">​</a></h3>
<ol>
<li>
<p>Open the file <code>.prompty</code> and look at its structure</p>
<ol>
<li>
<p>You should see: <strong>system</strong> task is</p>
<blockquote>
<p>Friendliness assesses the warmth and approachability of the answer. Rate the friendliness of the response between one to five stars using the following scale:</p>
<p>One star: the answer is unfriendly or hostile</p>
<p>Two stars: the answer is mostly unfriendly</p>
<p>Three stars: the answer is neutral</p>
<p>Four stars: the answer is mostly friendly</p>
<p>Five stars: the answer is very friendly</p>
<p>Please assign a rating between 1 and 5 based on the tone and demeanor of the response.</p>
</blockquote>
</li>
<li>
<p>You should see: <strong>examples</strong> that provide guidance for the scoring.</p>
<blockquote>
<p>This rating value should always be an integer between 1 and 5. So the rating produced should be 1 or 2 or 3 or 4 or 5.
(See examples for question-answer-context inputs that reflect 1,2,3,4 and 5 scores)</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="422-run-friendliness-prompty">4.2.2 Run Friendliness Prompty<a href="#422-run-friendliness-prompty" class="hash-link" aria-label="Direct link to 4.2.2 Run Friendliness Prompty" title="Direct link to 4.2.2 Run Friendliness Prompty">​</a></h3>
<ol>
<li>
<p>To run see the friendliness prompty in action we will run it with python evaulating the simple input <code>I am happy to help you with that.</code></p>
<p>To evaulate the friendliness of this input run the following command in the terminal:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd ./src/api</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python -m evaluate.friendliness</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>
<p><strong>Observe:</strong> Read the system task above again and see if the score returned makes sense.</p>
<ul>
<li>Given the sample input, do you agree with the assessment?</li>
</ul>
</li>
<li>
<p><strong>Change Answer</strong></p>
<ul>
<li>open the <code>./src/api/evaluate/friendliness.py</code> file and scroll to the bottom of the file and look for where the input <code>I am happy to help you with that.</code> is passed.</li>
<li>replace the input with: <code>Lorem ipsum orci dictumst aliquam diam</code></li>
<li>run the prompty again. <em>How did the score change?</em></li>
<li>undo the change. Return the prompty to original state for the next step.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="423-run-batch-evaluation">4.2.3 Run Batch Evaluation<a href="#423-run-batch-evaluation" class="hash-link" aria-label="Direct link to 4.2.3 Run Batch Evaluation" title="Direct link to 4.2.3 Run Batch Evaluation">​</a></h3>
<p>In the previous section, we assessed a single answer for a single metric, running one Prompty at a time. In reality, we will need to run assessments automatically across a large set of test inputs, with all custom evaluators, before we can judge if the application is ready for production use. Here, we&#x27;ll run a batch evaluation on our Contoso Creative Writer application, using a Python script.</p>
<p>If you are using Contoso Creative Writer a custom <code>evaluate.py</code> script has been written to run all evaulations for you.</p>
<ol>
<li>
<p>Navigate to the <code>src/api/evaluate/</code> folder in VS Code.</p>
</li>
<li>
<p>Open the <code>src/api/evaluate/eval_inputs.jsonl</code> file. Observe that 3 examples of research, product and assignment context are stored in this file. This data will be sent to the orchestrator so that each example will have:</p>
<ul>
<li>research returned from the internet based on research context.</li>
<li>products returned from the Azure AI Seacrh vector store based on semantic similarity to the product context.</li>
<li>A final generated article that incroperates the research and products into an article based on the assignment context.</li>
</ul>
</li>
<li>
<p>The evaluations run when using the <code>evaluate.py</code> script will incoperate all of the context, research, products, and final article when grading the response.</p>
</li>
<li>
<p>To run the script run the following commands:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd ./src/api</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python -m evaluate.evaluate</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li>
<p><strong>Check:</strong> You see scores for Coherence, Fluency, Relevance and Groundedness.</p>
</li>
<li>
<p><strong>Check:</strong> The scores are between <code>1</code> and <code>5</code></p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-observability-in-action">6. Observability in Action<a href="#6-observability-in-action" class="hash-link" aria-label="Direct link to 6. Observability in Action" title="Direct link to 6. Observability in Action">​</a></h2>
<p>One of the benefits of using Prompty is the built-in <code>Tracer</code> feature that captures execution traces for the entire workflow. These trace <em>runs</em> are stored in  <code>.tracy</code> files in the <code>api/.runs/</code> folder as shown in the figure below.</p>
<p><img loading="lazy" alt="Eval" src="/Cloud-Native/assets/images/eval_tracing-16bddf17e2ebfe252b730279d14d24db.png" width="1908" height="707" class="img_ev3q"></p>
<p>Click on any of these <code>.tracy</code> files to launch the <em>Trace Viewer</em> window.</p>
<ul>
<li>Note that this may take a while to appear.</li>
<li>You may need to click several runs before seeing a full trace.</li>
</ul>
<p>Once the trace file is displayed, explore the panel to get an intuition for usage</p>
<ul>
<li>See: sequence of steps in orchestrated flow (left)</li>
<li>See: prompt files with <code>load-prepare-run</code> sub-traces</li>
<li>See: Azure OpenAIExecutor traces on model use</li>
<li>Click: any trace to see its timing and details in pane (right)</li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>&quot;Want to learn more about Prompty Tracing? <a href="https://github.com/microsoft/prompty/tree/main/runtime/prompty#using-tracing-in-prompty" target="_blank" rel="noopener noreferrer">Explore the documentation</a> to learn how to configure your application for traces, and how to view and publish traces for debugging and observability.&quot;</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-where-next">7. Where Next<a href="#7-where-next" class="hash-link" aria-label="Direct link to 7. Where Next" title="Direct link to 7. Where Next">​</a></h2>
<p>In this section, you saw how Prompty-based custom evaluators work with AI-Assisted evaluation, to assess the quality of your application using defined metrics like coherence, fluency, relevance, and groundedness. You got a sense for how these custom evaluators are crafted. In tomorrow&#x27;s post we&#x27;ll learn how to deploy, test and monitor our application.</p>
<p><img loading="lazy" alt="Developer Workflow" src="/Cloud-Native/assets/images/04-developer-workflow-ea28bc208380d98a8041016271b8e50a.png" width="1433" height="448" class="img_ev3q"></p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/build-intelligent-apps">Build-Intelligent-Apps</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/30-days-of-ia-2024">30-days-of-IA-2024</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/learn-live">learn-live</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/demo-bytes">demo-bytes</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/community-gallery">community-gallery</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/azure-kubernetes-service">azure-kubernetes-service</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/azure-functions">azure-functions</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/azure-openai">azure-openai</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/azure-container-apps">azure-container-apps</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/azure-cosmos-db">azure-cosmos-db</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/github-copilot">github-copilot</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/github-codespaces">github-codespaces</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/Cloud-Native/30-days-of-ia-2024/tags/github-actions">github-actions</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/Cloud-Native/30-days-of-ia-2024/tags/azure-kubernetes-service"><div class="pagination-nav__label">Newer Entries</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Cloud-Native/30-days-of-ia-2024/tags/azure-kubernetes-service/page/3"><div class="pagination-nav__label">Older Entries</div></a></nav></main></div></div></div><footer><div></div></footer></div>
</body>
</html>