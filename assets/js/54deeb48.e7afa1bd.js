"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[30554],{64861:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"kick-off","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/kick-off","source":"@site/blog-60daysofIA/2024-02-15/kickoff-blog.md","title":"Kick-off #60Days of IA","description":"Combine the power of AI, cloud-scale data, and cloud-native app development to create highly differentiated digital experiences. Develop adaptive, responsive, and personalized experiences by building and modernizing intelligent applications with Azure.","date":"2024-02-15T09:00:00.000Z","formattedDate":"February 15, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":4.69,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-02-15T09:00","slug":"kick-off","title":"Kick-off #60Days of IA","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["Cloud-Scale","Data","AI","AI/ML","intelligent apps","cloud-native","60-days","enterprise apps","digital experiences","app modernization"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"Combine the power of AI, cloud-scale data, and cloud-native app development to create highly differentiated digital experiences. Develop adaptive, responsive, and personalized experiences by building and modernizing intelligent applications with Azure.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"nextItem":{"title":"1. Harnessing the power of Intelligent Apps","permalink":"/Cloud-Native/60DaysOfIA/harnessing-the-power-of-intelligent-apps"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/kick-off\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"Join us on a learning journey to build intelligent apps on Azure. Read all about the upcoming #BuildIntelligentApps initiative on this post!\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/kick-off\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" /> \\r\\n  <meta name=\\"twitter:description\\" content=\\"Join us on a learning journey to build intelligent apps on Azure. Read all about the upcoming #BuildIntelligentApps initiative on this post!\\" /> \\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/kick-off\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\nLet\u2019s ride the buzz of AI with the focus on building intelligent apps using cloud-native technologies. Build \'#IntelligentApps\' brings to you a learning journey to build your skills on creating differentiated experiences while modernizing your applications. It\u2019s time to \'learn it all\'. \\r\\n\\r\\n## What We\u2019ll Cover\\r\\n\\r\\n* What is Build Intelligent Apps?\\r\\n* How Can I *participate*?\\r\\n* How Can I *skill up*? (in just 60 Days)\\r\\n* **Exercise:** Take the [Build Intelligent Apps Skills Challenge](https://aka.ms/build-ia/csc)\\r\\n\\r\\n![Build intelligent apps](../../static/img/60-days-of-ia/60-days-of-ia-cloud-skills-banner.jpg)\\r\\n\\r\\n## Get Ready To Build #IntelligentApps starting February 19!\\r\\n\\r\\nToday, we kick off with content and activities for you to skill up on all things Intelligent Apps or AI Apps on Azure with content, events, and community interactions! Read on to learn about what is coming!\\r\\n\\r\\n## Explore Our Initiatives\\r\\n\\r\\nWe have a number of initiatives planned for the month to help you learn and skill up on relevant technologies. Click on the links to visit the relevant pages for each.\\r\\n\\r\\n* [#60Days of IA](https://aka.ms/build-ia/60days) - 8 themed weeks of blogs on AI led application development\\r\\n* [Learn Live Series](https://aka.ms/FallForIA/LearnLive) \u2013 8 weekly live episodes on \'Kubernetes\' and \'Serverless\'\\r\\n* [Ask The Expert](https://aka.ms/build-ia/ATE-series) \u2013 join live Q&A sessions with Product Engineering and Advocacy teams\\r\\n* [Cloud Skills Challenge](https://aka.ms/build-ia/csc) \u2013 skill up by competing with peers to complete modules\\r\\n\\r\\n![Build intelligent apps](../../static/img/60-days-of-ia/60-days-of-ia-cloud-skills-modules.png)\\r\\n\\r\\n:::info\\r\\n## Register for the events!\\r\\n\\r\\nWhat are 4 things you can do today, to jumpstart your learning journey?\\r\\n\\r\\n* **Register** for live Q&A sessions (free, online) \\r\\n  * February 29 \u2013 [Ask The Expert: Intelligent Apps with Azure Kubernetes Service](https://aka.ms/intelligent-apps/ate-aks/?ocid=buildia24_60days_blogs)\\r\\n  * March 7 \u2013 [Ask The Expert: Intelligent Apps with Azure Cosmos DB](https://aka.ms/intelligent-apps/ate-cosmos/?ocid=buildia24_60days_blogs)\\r\\n  * March 21 - [Ask The Expert: Intelligent Apps with Azure AI](https://aka.ms/intelligent-apps/ate-ai/?ocid=buildia24_60days_blogs) \\r\\n  * April 4 \u2013 [Ask The Expert: Intelligent Apps with Azure Functions](https://aka.ms/intelligent-apps/ate-functions/?ocid=buildia24_60days_blogs)\\r\\n* **Register** for the [Learn Live Series: Kubernetes Edition](https://aka.ms/intelligent-apps/aks-learnlive?ocid=buildia24_LL_website&ocid=buildia24_60days_blogs) \u2013 weekly live learning \\r\\n  * February 21 \u2013 [Episode 1: Deploying Intelligent Apps with OpenAI on AKS](https://aka.ms/learn-live-building-intelligent-apps-aks-ep1?ocid=buildia24_60days_blogs) \\r\\n  * February 28 \u2013 [Episode 2: Bring Your Own AI Models to Intelligent Apps on AKS with KAITO](https://aka.ms/learn-live-building-intelligent-apps-aks-ep2?ocid=buildia24_60days_blogs)\\r\\n  * March 6 \u2013 [Episode 3: Enhance Observability of Your Intelligent Apps on AKS](https://aka.ms/learn-live-building-intelligent-apps-aks-ep3?ocid=buildia24_60days_blogs)\\r\\n  * March 13 \u2013 [Episode 4: Taking Your Intelligent App Global with AKS](https://aka.ms/learn-live-building-intelligent-apps-aks-ep4?ocid=buildia24_60days_blogs)\\r\\n* **Register** for the [Azure Kubernetes Day at KubeCon, EU](https://aka.ms/aks-day?ocid=buildia24_60days_blogs) to meet the product engineering teams in-person and learn about the new product capabilities for intelligent apps.\\r\\n* **Complete** the [Cloud Skills Challenge](https://aka.ms/intelligent-apps/apps-csc?ocid=buildia24_60days_blogs) to earn a Microsoft Learn badge \u2013 ends on *April 15*!\\r\\n:::\\r\\n\\r\\n## #60Days Of Intelligent Apps\\r\\n\\r\\n[#60Days of IA](https://aka.ms/build-ia/60days) is a series of blog posts grouped into themed weeks - taking you from core concepts to end-to-end solution examples in 60 days. Each blog will provide conceptual lessons paired with exercises and resources to help you reinforce learnings and take next steps.\\r\\n\\r\\nThis series takes you through learning journey in\u202f**eight stages**, each building on the previous week to help you skill up in a beginner-friendly way:\\r\\n\\r\\n* **Week 1**: Power of [Intelligent Applications](https://azure.microsoft.com/en-us/blog/build-next-generation-ai-powered-applications-on-microsoft-azure/?ocid=buildia24_60days_blogs)\\r\\n* **Week 2**: [Azure Kubernetes Service](https://learn.microsoft.com/en-us/azure/aks/?ocid=buildia24_60days_blogs) is the platform of choice for intelligent apps\\r\\n* **Week 3**: [Azure Cosmos DB](https://learn.microsoft.com/en-us/azure/cosmos-db/introduction?ocid=buildia24_60days_blogs) is the database of choice for intelligent apps\\r\\n* **Week 4**: [Azure AI](https://learn.microsoft.com/en-us/azure/ai-services/ai-services-and-ecosystem?ocid=buildia24_60days_blogs) is your choice for [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai?ocid=buildia24_60days_blogs)\\r\\n* **Week 5**: Building an intelligent [serverless](https://azure.microsoft.com/en-us/solutions/serverless/?ocid=buildia24_60days_blogs) event driven [functions app](https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview?pivots=programming-language-csharp?ocid=buildia24_60days_blogs)\\r\\n* **Week 6**: Build intelligent microservices with [serverless containers](https://learn.microsoft.com/en-us/azure/container-apps/overview?ocid=buildia24_60days_blogs)\\r\\n* **Week 7**: [Platform engineering](https://learn.microsoft.com/en-us/platform-engineering/?ocid=buildia24_60days_blogs) needs for your intelligent apps\\r\\n* **Week 8**: Managing cost for your intelligent apps \\r\\n\\r\\nWe will start with defining intelligent apps and then expand on how to build with cloud-native technologies like [Azure Kubernetes Service](https://azure.microsoft.com/en-us/products/kubernetes-service/?WT.mc_id=javascript-99907-ninarasi&ocid=buildia24_60days_blogs), [Azure Container Apps](https://azure.microsoft.com/en-us/products/container-apps/?WT.mc_id=javascript-99907-ninarasi&?ocid=buildia24_60days_blogs) and [Azure Functions](https://azure.microsoft.com/en-us/products/functions?WT.mc_id=javascript-99907-ninarasi&?ocid=buildia24_60days_blogs), as well as integrate AI and cloud-scale data. You will learn how to build end-to-end scenarios for real world application development based on [reference architectures](https://learn.microsoft.com/en-us/azure/architecture/??ocid=buildia24_60days_blogs). Before we dive deep on intelligent apps, here is a high-level overview of the **Intelligent Apps** landscape on Azure for you to leverage the most comprehensive, trusted cloud to prime the customer and employee experiences.\\r\\n\\r\\n![intelligent apps on Azure](../../static/img/60-days-of-ia/blogs/2024-02-15/intelligent-apps-on-azure.png)\\r\\n\\r\\nBring your applications to a modern application platform in the cloud, which leverages a cloud data platform at scale and agile development methods with DevOps is the best way to prime the customer and employee experiences. Azure offers the latest apps, data, AI and is the most comprehensive, trusted cloud.\\r\\n\\r\\n![intelligent apps](../../static/img/60-days-of-ia/blogs/2024-02-15/intelligent-apps.png)\\r\\n\\r\\n**Containers on Azure**\u202fservices offer you a wide range of capabilities, from simplicity to control to suit your different needs.\\r\\n\\r\\n![containers on azure](../../static/img/fallforia/blogs/2023-09-17/Containers-on-Azure.jpg)\\r\\n\\r\\n![containers on azure](../../static/img/fallforia/blogs/2023-09-17/Containers-on-Azure-2.jpg)\\r\\n\\r\\nTo start with the basics for developing [Kubernetes](https://azure.microsoft.com/en-us/products/kubernetes-service/?WT.mc_id=javascript-99907-ninarasi&ocid=buildia24_60days_blogs) applications, explore [#30Days of CloudNative](https://azure.github.io/Cloud-Native/cnny-2023).\\r\\n\\r\\nCloud-native development when paired with **serverless computing** enhances your solution architecture for building cost optimized, resilient applications.\\r\\n\\r\\n![serverless on Azure](../../static/img/60-days-of-ia/blogs/2024-02-15/serverless-on-azure.jpg)\\r\\n\\r\\nTo start with the basics for [serverless computing](https://azure.microsoft.com/solutions/serverless/?WT.mc_id=javascript-99907-ninarasi&?ocid=buildia24_60days_blogs), explore [#30DaysOfServerless](https://azure.github.io/Cloud-Native/blog).\\r\\n\\r\\n## Let\u2019s Get Started\\r\\n\\r\\nNow you know everything! We hope you are as excited as we are to dive into a full month of active learning and doing! Don\'t forget to\u202f[subscribe](https://azure.github.io/Cloud-Native/60DaysOfIA/rss.xml)\u202ffor updates in your favorite feed reader.\u202f**And, look out for our first Intelligent Apps blog on Monday, February 19!**"},{"id":"harnessing-the-power-of-intelligent-apps","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/harnessing-the-power-of-intelligent-apps","source":"@site/blog-60daysofIA/2024-02-19/harnessing-the-power-of-intelligent-apps.md","title":"1. Harnessing the power of Intelligent Apps","description":"Combine the power of AI, cloud-scale data, and cloud-native app development to create highly differentiated digital experiences. Develop adaptive, responsive, and personalized experiences by building and modernizing intelligent applications with Azure.","date":"2024-02-19T09:00:00.000Z","formattedDate":"February 19, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":6.185,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-02-19T09:00","slug":"harnessing-the-power-of-intelligent-apps","title":"1. Harnessing the power of Intelligent Apps","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["Cloud-Scale","Data","AI","AI/ML","intelligent apps","cloud-native","60-days","enterprise apps","digital experiences","app modernization"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"Combine the power of AI, cloud-scale data, and cloud-native app development to create highly differentiated digital experiences. Develop adaptive, responsive, and personalized experiences by building and modernizing intelligent applications with Azure.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"Kick-off #60Days of IA","permalink":"/Cloud-Native/60DaysOfIA/kick-off"},"nextItem":{"title":"2. Power Up: Crafting an Intelligent Energy Forecasting Application Using Azure Kubernetes Service","permalink":"/Cloud-Native/60DaysOfIA/power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/harnessing-the-power-of-intelligent-apps\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"In this article, we\u2019ll spotlight the success stories of some organizations that have leveraged Microsoft Azure to create and deploy intelligent apps in their workflows and products.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/harnessing-the-power-of-intelligent-apps\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"In this article, we\u2019ll spotlight the success stories of some organizations that have leveraged Microsoft Azure to create and deploy intelligent apps in their workflows and products.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/harnessing-the-power-of-intelligent-apps\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n![intelligent apps on Azure](../../static/img/60-days-of-ia/blogs/2024-02-19/harnessing-the-power-of-intelligent-apps.jpg)\\r\\n\\r\\n## Harnessing the Power of Intelligent Apps\\r\\n\\r\\nOrganizations are increasingly adopting advanced technologies to drive innovation and elevate operational efficiency. Intelligent apps\u2014applications that integrate machine learning (ML), data analytics, and predictive or generative artificial intelligence (AI) to create differentiated digital experiences\u2014are one way to achieve this. According to Gartner\xae, \u201cby 2026, 30% of new applications will use AI to drive personalized adaptive user interfaces, up from less than 5% today\u201d<sup>1</sup>.\\r\\n\\r\\nIntelligent apps tend to fall into one of three categories:\\r\\n\\r\\n* **Outcome-based apps** \u2014 These apps focus on user intent, predictions, and task automation to enable better decision-making.\\r\\n* **Functionality-based apps** \u2014 These apps use ML, AI, or APIs to generate content. They examine user patterns to provide personalized recommendations or feedback.\\r\\n* **Feature-based apps** \u2014 These apps have AI or ML components built in, which means they rely on neural networks and internal LLMs to run advanced algorithms.\\r\\n\\r\\nBecause Intelligent apps help organizations leverage business intelligence and other data to drive and automate organizational decision-making, they\u2019re becoming a pivotal part of modern business strategies. In this article, we\u2019ll spotlight the success stories of some organizations that have leveraged Microsoft Azure to create and deploy intelligent apps in their workflows and products.\\r\\n\\r\\n___\\r\\n\\r\\n## Intelligent Apps in Action\\r\\n\\r\\nIntelligent Apps offer tangible business outcomes by automating complex processes, enhancing decision-making, and providing personalized experiences. By leveraging Azure services, the organizations discussed below have experienced a paradigm shift in their operations \u2014 and a boost in productivity and agility.\\r\\n\\r\\n### How Intelligent Apps Power the Ultimate LEGO Experience\\r\\n\\r\\nDenmark\u2019s ultimate LEGO experience center, LEGO House, found challenges in maintaining its on-premises data center. To keep serving its custom-built digital experiences, the business upgraded its facilities with [Azure Kubernetes Service](https://azure.microsoft.com/en-us/products/kubernetes-service/?ocid=buildia24_60days_blogs) (AKS) in 2023.\\r\\n\\r\\nThis shift in approach to the cloud was a boon for responsiveness \u2014 LEGO House could take on visitor feedback to swiftly update experiences and develop new ones. The containerized, component-based setup on AKS also allowed LEGO House\u2019s digital tech stack to become more scalable and flexible, transforming development efficiency and maintenance.\\r\\n\\r\\nLEGO House continued its partnership with Microsoft to launch experiences like City Architect \u2014 powered by [Azure IoT Edge Device](https://azure.microsoft.com/en-us/products/iot-edge?ocid=buildia24_60days_blogs) \u2014 and Robo Lab. These innovations allowed visitors to interact with digitally projected landscapes and build robots, fostering principles of programming. AKS streamlines integration and supports element reuse, enhancing efficiency and creativity.\\r\\n\\r\\nThe results were remarkable \u2014 improved stability, higher uptime, and positive visitor feedback. Azure services made life easier for LEGO House\u2019s developers and gave the entire LEGO ecosystem a strong foundation for growth. Specifically, by allowing the reuse of elements, AKS provides a common foundation for all LEGO experience builds. The organization\u2019s next move is to rebuild the entire House on the [Azure AI](https://azure.microsoft.com/en-us/solutions/ai?ocid=buildia24_60days_blogs) platform and AKS. Read more about how LEGO [modernized interactive experiences across LEGO House with Azure Kubernetes Service](https://customers.microsoft.com/en-us/story/1703088157691224129-lego-house-azure-kubernetes-service-media-and-entertainment-denmark?ocid=buildia24_60days_blogs).\\r\\n\\r\\n### Using Intelligent Apps to Make Cars Smarter With TomTom\\r\\n\\r\\nTomTom\u2019s navigation solutions have a proven track record of innovating the driving experience. Today, the company continues to adapt to drivers\u2019 evolving needs. Using [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service/?ocid=buildia24_60days_blogs), [Azure Cosmos DB](https://learn.microsoft.com/en-us/azure/cosmos-db/introduction?ocid=buildia24_60days_blogs), and [AKS](https://azure.microsoft.com/en-us/products/kubernetes-service/?ocid=buildia24_60days_blogs) to develop Digital Cockpit, TomTom has created smarter, AI-powered vehicles, facilitating huge advancements in user experience.\\r\\n\\r\\nDigital Cockpit is an AI-driven, conversational in-car infotainment system that allows drivers to interact naturally with the vehicle. It can perform tasks like navigation, controlling onboard systems, and even managing work tasks during electric vehicle recharging.\\r\\n\\r\\nLet\u2019s look closer at the Azure services that drive Digital Cockpit:\\r\\n\\r\\n* **Azure OpenAI Service** \u2014 The Azure OpenAI Service supports generative AI chatbots that provide natural-sounding voices and accurate transcription of spoken audio.\\r\\n* **Azure Cosmos DB** \u2014 Azure Cosmos DB, a globally distributed database, retains customer conversations and preferences, allowing the system to continuously learn and tailor driver experiences.\\r\\n* **AKS** \u2014 AKS accelerates service deployment and scaling, enhancing overall architecture efficiency.\\r\\n\\r\\nInternally, integrating Azure services resulted in a significant improvement in TomTom\u2019s development efficiency. For example, the team working on the prototype no longer required ten engineers \u2014 three team members were sufficient to complete the task. Additionally, response times decreased from 12 to 2.5 seconds, and the system demonstrated a 95 percent success rate in understanding complex driver requests. Read more about how [TomTom brings AI-powered, talking cars to life with Azure](https://customers.microsoft.com/en-us/story/1723808815413508250-tomtom-azure-netherlands?ocid=buildia24_60days_blogs).\\r\\n\\r\\n:::info\\r\\nTry the [Intelligent Apps Skills Challenges](https://aka.ms/intelligent-apps/apps-csc?ocid=buildia24_60days_blogs) to compete for the leaderboard and earn a Microsoft Learn Badge.\\r\\n:::\\r\\n\\r\\n### How Gluwa Leverages Intelligent Apps to Make Banking More Accessible\\r\\n\\r\\nSan Francisco-based startup Gluwa is on a mission to address the financial gap for the unbanked and underbanked, estimated at 1.4 billion people globally. Combining blockchain technology and Azure services, Gluwa connects investors with individuals in emerging markets. \\r\\n\\r\\nGluwa harnesses the capabilities of various Azure services to power its blockchain services. [Azure Container Instances](https://azure.microsoft.com/en-us/products/container-instances?ocid=buildia24_60days_blogs) and AKS play a pivotal role in peer-to-peer discovery, fostering a dynamic and efficient environment. [Azure App Configuration](https://azure.microsoft.com/en-us/products/app-configuration?ocid=buildia24_60days_blogs) streamlines the centralization of app configurations, ensuring seamless control and adaptability.\\r\\n\\r\\nFor secure media delivery, Gluwa relies on the powerful combination of [Azure Content Delivery Network](https://azure.microsoft.com/en-us/products/cdn?ocid=buildia24_60days_blogs) and [Azure Storage](https://learn.microsoft.com/en-us/azure/storage/common/storage-introduction?ocid=buildia24_60days_blogs), which bolsters reliability and safeguards sensitive data. Using [Azure DevOps](https://azure.microsoft.com/en-us/products/devops?ocid=buildia24_60days_blogs) to manage intricate lifecycle builds, Gluwa streamlined the development process. [Azure App Services](https://azure.microsoft.com/en-us/products/app-service?ocid=buildia24_60days_blogs) serve as the backbone for Gluwa\u2019s APIs, complemented by [Azure Redis](https://azure.microsoft.com/en-us/products/cache?ocid=buildia24_60days_blogs) for optimal cache distribution, to enhance overall performance. Finally, [Azure SQL](https://azure.microsoft.com/en-us/products/azure-sql/database?ocid=buildia24_60days_blogs) and Azure Cosmos DB are scalable database solutions that support Gluwa\u2019s infrastructure, ensuring adaptability and responsiveness in meeting evolving demands within the blockchain landscape.\\r\\n\\r\\nGluwa\u2019s decentralized financial platform, Gluwa Invest, encourages stable coin investments, while the Creditcoin blockchain records loans, providing transparency and immutability. Together, they\u2019ve facilitated nearly 4.27 million loan transactions, totaling over $79.7 million. Gluwa turned to Azure\u2019s reliable, scalable cloud foundation to make these innovative and socially impactful initiatives a reality. Read more about how [Gluwa uses blockchain to help investors fund loans to the unbanked](https://customers.microsoft.com/en-us/story/1709609183358710412-gluwa-azure-banking-and-capital-markets-usa?ocid=buildia24_60days_blogs).\\r\\n\\r\\n___\\r\\n\\r\\n## Summary\\r\\n\\r\\nAzure services have empowered organizations developing intelligent apps by offering scalability, flexibility, and seamless integration of ML, data analytics, and AI.\\r\\n\\r\\nAzure\u2019s impact extends beyond immediate efficiency gains, empowering developers to iterate, learn, and keep creating new experiences. Businesses that build with Azure services can streamline collaboration across ecosystems, unlocking collective vision and applied creativity.\\r\\n\\r\\nExplore Microsoft [Customer Stories](https://customers.microsoft.com/en-us/home?sq=aks&ff=&p=1&so=story_publish_date%20desc&ocid=buildia24_60days_blogs) for deeper insights into transformative, AI-powered solutions. Finally, don\u2019t forget to mark your calendar for [Azure Kubernetes Day](https://aka.ms/aks-day?ocid=buildia24_60days_blogs) at [KubeCon EU 2024](https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/) to get the latest on cutting-edge developments in cloud technology.\\r\\n\\r\\n<sup>1</sup> Source: [Gartner, Demand Grows for Intelligent Applications Powered by AI, September 27, 2023](https://www.gartner.com/en/articles/demand-grows-for-intelligent-applications-powered-by-ai). GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved."},{"id":"power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service","source":"@site/blog-60daysofIA/2024-02-27/power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service.md","title":"2. Power Up: Crafting an Intelligent Energy Forecasting Application Using Azure Kubernetes Service","description":"In this article, we\u2019ll will guide you through creating an intelligent app that leverages Azure technologies, including Azure Kubernetes Service (AKS), to build an application that forecasts energy usage and pricing.","date":"2024-02-27T09:00:00.000Z","formattedDate":"February 27, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":5.885,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-02-27T09:00","slug":"power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service","title":"2. Power Up: Crafting an Intelligent Energy Forecasting Application Using Azure Kubernetes Service","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["Cloud-Scale","Data","AI","AI/ML","intelligent apps","cloud-native","60-days","enterprise apps","digital experiences","app modernization"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"In this article, we\u2019ll will guide you through creating an intelligent app that leverages Azure technologies, including Azure Kubernetes Service (AKS), to build an application that forecasts energy usage and pricing.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"1. Harnessing the power of Intelligent Apps","permalink":"/Cloud-Native/60DaysOfIA/harnessing-the-power-of-intelligent-apps"},"nextItem":{"title":"2.1 Forecasting Energy Usage with Intelligent Apps Part 1: Laying the Groundwork with AKS, KAITO, and LLaMA","permalink":"/Cloud-Native/60DaysOfIA/forecasting-energy-usage-with-intelligent-apps-1"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"In this article, we\u2019ll spotlight the success stories of some organizations that have leveraged Microsoft Azure to create and deploy intelligent apps in their workflows and products.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"In this article, we\u2019ll spotlight the success stories of some organizations that have leveraged Microsoft Azure to create and deploy intelligent apps in their workflows and products.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\nAt the forefront of recent technological innovation are intelligent apps: apps that use machine learning (ML), artificial intelligence (AI), and data analytics. These apps support smarter, data-driven decisions, making them particularly useful in sectors like energy management, where efficiency and long-term planning are critical.\\r\\n\\r\\nOur upcoming series will guide you through creating an intelligent app that leverages Azure technologies, including [Azure Kubernetes Service](https://azure.microsoft.com/products/kubernetes-service?ocid=buildia24_60days_blogs) (AKS), to build an application that forecasts energy usage and pricing. \\r\\n\\r\\nYour app will harness AKS for hosting and AI to analyze historical energy consumption data. Then, you\u2019ll integrate the Kubernetes AI Toolchain Operator (KAITO) with advanced analytical tools\u2014such as LLaMA 2, Langchain, and pandas\u2014to build an intelligent app that underscores the importance of green energy practices and demonstrates the versatility and efficacy of Azure services.\\r\\n\\r\\nWe invite you to join us on this three-part educational series, where you\u2019ll learn the skills needed to construct your own intelligent apps. This series is more than a technical walkthrough: It\u2019s an opportunity to engage with cutting-edge technologies and contribute to meaningful advancements in energy management.\\r\\n\\r\\nWhether you\u2019re an experienced developer or new to the AI and ML sphere, this series will give you a glimpse into the future of application development and the strategic impact of cloud technologies in driving forward-thinking solutions.\\r\\n\\r\\n## The Synergy of Azure Kubernetes Service and Intelligent Apps\\r\\n\\r\\nUsing AKS as the backbone of intelligent apps has numerous benefits \u2014 especially when deploying your AI-driven application. AKS provides a managed, cloud-based container orchestration service that simplifies deploying, managing, and scaling AI-backed applications, making it ideal for a project like the one you\u2019ll create in this series.\\r\\n\\r\\nOne of the primary advantages of AKS is its ability to handle distributed applications with evolving demands. For AI-driven apps, the ability to scale resources based on computational demands is crucial. Because AKS allows for automatic scaling, intelligent apps have the necessary resources during peak analysis times without wasting resources during quieter periods. But this dynamic scalability isn\u2019t just about handling loads efficiently: It\u2019s also cost-effective, ensuring that you pay only for the resources you use.\\r\\n\\r\\nIntegrating the Kaito operator with AKS further enhances the deployment of AI models like LLaMA 2 by simplifying the complexities of managing AI workloads. Kaito, designed specifically for Kubernetes environments, acts as a bridge between the advanced AI models and the scalable, managed infrastructure provided by AKS. It offers custom resource definitions (CRDs) tailored for AI applications, facilitating the deployment, updating, and management of AI models within the Kubernetes ecosystem.\\r\\n\\r\\nThis seamless integration enables developers to focus more on the application logic and less on the underlying infrastructure, accelerating the development cycle and reducing the time to market for innovative AI solutions.\\r\\n\\r\\nAKS and KAITO create a robust, flexible, and efficient environment for developing and deploying intelligent applications. This combination not only leverages the cloud\u2019s power and scalability but also optimizes the deployment of AI models, making it easier for developers to bring complex, data-driven applications to life.\\r\\n\\r\\n:::info\\r\\nRegister for **[Intelligent Apps on AKS: Episode 2](https://developer.microsoft.com/en-us/reactor/events/21815/?ocid=buildia24_60days_blogs)**, a live hands-on training with an expert on how to use AKS to run your own AI models with KAITO.\\r\\n:::\\r\\n\\r\\n## Laying the Groundwork with Azure Kubernetes Service\\r\\n\\r\\nIn the [first installment of this series](https://azure.github.io/Cloud-Native/60DaysOfIA/forecasting-energy-usage-with-intelligent-apps-1), you\u2019ll roll up your sleeves and set up an AKS environment. This step is foundational to the rest of the series, laying the groundwork for deploying and managing your application \u2014 and accessing the full scalability and flexibility that AKS offers.\\r\\n\\r\\nThe article starts with a straightforward step-by-step guide on establishing the AKS environment, ensuring you have a solid base for the exciting journey ahead. This tutorial is succinct to maintain clarity and speedy development, offering links to additional resources for well-documented steps. \\r\\n\\r\\nNext, you\u2019ll meet KAITO, a tool that streamlines deploying AI applications in Kubernetes environments. The core of this article is configuring [the KAITO operator](https://github.com/Azure/kaito) to work seamlessly with the LLaMA 2 model, providing hands-on instructions, code samples, and screenshots to guide you through each step.\\r\\n\\r\\n## Adding Intelligence to the App\\r\\n\\r\\nThe second part of this series dives into the more practical aspects of building the Intelligent App. You\u2019ll leverage an open-source energy dataset alongside powerful tools like LangChain and a pandas Python agent to craft a forecasting model that predicts future energy demands with speed and precision.\\r\\n\\r\\nIntegrating these tools with AKS highlights the high-impact relationship between robust data processing capabilities and scalable cloud infrastructure. Hands-on examples and streamlined code will guide you through setting up the environment, processing the dataset, and deploying the forecasting model.\\r\\n\\r\\nThis practical application reinforces the theoretical foundations laid in Part 1 and sets the stage for advanced analytics and AI-driven predictions. As you progress through the tutorial, the focus will remain on simplicity and efficiency, ensuring that even complex AI-related processes become accessible.\\r\\n\\r\\n:::info\\r\\nComplete the **[Intelligent Apps Skills Challenge](https://aka.ms/intelligent-apps/apps-csc?ocid=buildia24_60days_blogs)** to compete for the leaderboard and earn a Microsoft Learn Badge.\\r\\n:::\\r\\n\\r\\n## Building a Web Interface\\r\\n\\r\\nAs the concluding installment of our series, part 3 assembles all the pieces by introducing a user-friendly web interface. Here, users can input or upload their energy usage data and parameters, after which the Intelligent App will generate future predictions on usage and pricing.\\r\\n\\r\\nThis web front end serves as the direct point of interaction with your AKS-hosted application, seamlessly displaying the reports and predictions the AI model produces.\\r\\n\\r\\nAfter deploying this interface in the AKS environment established in [part 1](https://azure.github.io/Cloud-Native/60DaysOfIA/forecasting-energy-usage-with-intelligent-apps-1), you\u2019ll experience the complete cycle of developing an intelligent, data-driven application and appreciate how straightforward it is to engineer intelligent apps that can deliver tangible, user-centric outcomes.\\r\\n\\r\\n## Ready to Get Started?\\r\\n\\r\\nTogether, these three articles guide you through creating an innovative, AI-driven energy forecasting app. Setting up a scalable AKS environment with integrated cutting-edge AI models, processing open-source energy data for insightful predictions, and deploying a user-friendly web interface will equip you with the tools you need to build your own Intelligent Apps.\\r\\n\\r\\nStay tuned for each part of the series and get ready to dive into the world of Azure, AI, and application development with us. Join us in this exciting venture and harness the power of technology to make a difference. Register for the **[Intelligent Apps on AKS: Episode 2](https://aka.ms/learn-live-building-intelligent-apps-aks-ep2?ocid=buildia24_60days_blogs)**\u202f to experience live hands-on training with an expert on how to use AKS to run your own AI models with KAITO."},{"id":"forecasting-energy-usage-with-intelligent-apps-1","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/forecasting-energy-usage-with-intelligent-apps-1","source":"@site/blog-60daysofIA/2024-03-05/forecasting-energy-usage-with-intelligent-apps-1.md","title":"2.1 Forecasting Energy Usage with Intelligent Apps Part 1: Laying the Groundwork with AKS, KAITO, and LLaMA","description":"In this series, you\u2019ll create an Intelligent App powered by Azure Kubernetes Service (AKS) to forecast energy usage and cost.","date":"2024-03-05T09:00:00.000Z","formattedDate":"March 5, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":6.21,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-03-05T09:00","slug":"forecasting-energy-usage-with-intelligent-apps-1","title":"2.1 Forecasting Energy Usage with Intelligent Apps Part 1: Laying the Groundwork with AKS, KAITO, and LLaMA","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["Cloud-Scale","Data","AI","AI/ML","intelligent apps","cloud-native","60-days","enterprise apps","digital experiences","app modernization"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"In this series, you\u2019ll create an Intelligent App powered by Azure Kubernetes Service (AKS) to forecast energy usage and cost.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"2. Power Up: Crafting an Intelligent Energy Forecasting Application Using Azure Kubernetes Service","permalink":"/Cloud-Native/60DaysOfIA/power-up-crafting-an-intelligent-energy-forecasting-application-using-azure-kubernetes-service"},"nextItem":{"title":"3. Cosmos DB and Intelligent Apps: A Match Made for Innovation","permalink":"/Cloud-Native/60DaysOfIA/cosmos-db-and-intelligent-apps-a-match-made-for-innovation"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/forecasting-energy-usage-with-intelligent-apps-1\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"In this series, you\'ll create an Intelligent App powered by Azure Kubernetes Service (AKS) to forecast energy usage and cost.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/forecasting-energy-usage-with-intelligent-apps-1\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"In this series, you\'ll create an Intelligent App powered by Azure Kubernetes Service (AKS) to forecast energy usage and cost.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/forecasting-energy-usage-with-intelligent-apps-1\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n![Forecasting Energy Usage with Intelligent Apps: Laying the Groundwork with AKS, KAITO, and LLaMA](../../static/img/60-days-of-ia/blogs/2024-03-05/2-1-1.jpg)\\r\\n\\r\\n*This three-part series demonstrates how to create an Intelligent App that forecasts future energy consumption and pricing based on historical data. In this first article, you\u2019ll set up an Azure Kubernetes Service (AKS) environment, install KAITO, and set up KAITO to work with the LLaMA 2 model.*\\r\\n\\r\\n## Forecasting Energy Usage with Intelligent Apps Part 1: Laying the Groundwork with AKS, KAITO, and LLaMA\\r\\n\\r\\nIntelligent Apps leverage artificial intelligence (AI) and machine learning (ML) technologies to enhance traditional applications with advanced capabilities. They enable businesses to make smarter decisions, automate tasks, and drive innovation by extracting actionable insights from vast amounts of data.\\r\\n\\r\\nIn this series, you\u2019ll create an Intelligent App powered by [Azure Kubernetes Service](https://azure.microsoft.com/en-ca/products/kubernetes-service) (AKS) to forecast energy usage and cost. Each article will demonstrate the use of core Azure technologies, particularly AKS, to build an application that generates forecasts based on AI capabilities applied to user input and historical data analysis.\\r\\n\\r\\nLet\u2019s get started!\\r\\n\\r\\n### Prerequisites\\r\\n\\r\\nTo follow this tutorial, ensure you have the following:\\r\\n\\r\\n- An [Azure Subscription](https://azure.microsoft.com/en-us/free/search) that supports the GPU-enabled [Standard_NC12s_v3 instance type](https://learn.microsoft.com/en-us/azure/virtual-machines/ncv3-series) in the selected region. You might need to request an increase in vCPU quota.\\r\\n - Basic understanding of [AKS](https://azure.microsoft.com/en-us/products/kubernetes-service) and Kubernetes\\r\\n\\r\\n### Building an Intelligent App with Azure Kubernetes Service and KAITO\\r\\n\\r\\nThis first article walks you through setting up an AKS environment and the Kubernetes AI Toolchain Operator (KAITO) to automate AI/ML model deployment in the AKS cluster.\\r\\n\\r\\n#### Downloading the LLaMA 2 Model\\r\\n\\r\\nA fundamental piece in your Intelligent App\u2019s architecture is the target model. Here, you\u2019ll use LLaMA 2, an open-source project developed by Meta in partnership with Microsoft.\\r\\n\\r\\nLLaMA 2 is a large-scale training and inference framework for ML models. It provides a distributed computing infrastructure that enables executing ML tasks across multiple nodes or clusters, using parallelism and optimization techniques to improve performance.\\r\\n\\r\\nTo configure your model, download LLaMA 2 by following the instructions in [this document](https://github.com/Azure/kaito/tree/main/presets/models/llama2). Ensure you download the **llama2-7b** model.\\r\\n\\r\\n#### Configuring the AKS Cluster and KAITO\\r\\n\\r\\n![engergy-usage-aks model](../../static/img/60-days-of-ia/blogs/2024-03-05/2-1-2.jpg)\\r\\n\\r\\nCreating an AKS environment is the first step for onboarding large AI inference models onto Kubernetes. Later, you\u2019ll integrate the node provisioner controller with AKS APIs, letting you dynamically add GPU nodes to the cluster to promote scalability and optimal resource use.\\r\\n\\r\\nAdditionally, AKS facilitates testing service endpoints within the cluster, providing a reliable environment for validating and fine-tuning AI inference services.\\r\\n\\r\\nKAITO is an open-source operator that transforms how you deploy AI models on Kubernetes. It streamlines the process, automating critical tasks like infrastructure provisioning and resource optimization. It intelligently selects the optimal hardware configuration for your specific model, using available CPU and GPU resources on AKS. KAITO eliminates the manual setup complexities, accelerating your deployment time and reducing associated costs.\\r\\n\\r\\nTo set up an AKS cluster and install KAITO, follow [this tutorial](https://github.com/Azure/kaito/blob/main/docs/installation.md), adjusting the KAITO installation steps to match the **llama2-7b** model you downloaded earlier.\\r\\n\\r\\n:::info\\r\\nRegister for **[Intelligent Apps on AKS: Episode 3](https://aka.ms/learn-live-building-intelligent-apps-aks-ep3?ocid=buildia24_60days_blogs)**, a live hands-on training with an expert on how OpenCost, Prometheus, and Grafana with AKS can improve intelligent apps. \\r\\n:::\\r\\n\\r\\n#### Pushing LLaMA 2 Model to Azure Container Registry\\r\\n\\r\\nNow that you have AKS with the KAITO installation, you need to push the local model image to the AKS cluster.\\r\\n\\r\\nCreate an Azure Container Registry (ACR) resource using Azure CLI with the following command, replacing `<YOUR-ACR-NAME>` with a new ACR name:\\r\\n\\r\\n```\\r\\naz acr create --name <YOUR-ACR-NAME> --resource-group $RESOURCE_GROUP --sku Standard --location $LOCATION\\r\\n```\\r\\n\\r\\nNow, push your local LLaMA 2 model\u2019s Docker image to the ACR hosted at `<YOUR-ACR-NAME>.azurecr.io` by running:\\r\\n\\r\\n```\\r\\ndocker push <YOUR-ACR-NAME>.azurecr.io/llama2_model:latest\\r\\n```\\r\\n\\r\\nFinally, run the command to update the AKS cluster to attach it to your ACR, allowing the cluster to pull the model container image from `<YOUR-ACR-NAME>.azurecr.io`:\\r\\n\\r\\n```\\r\\naz aks update -g $RESOURCE_GROUP -n $MY_CLUSTER --attach-acr <YOUR-ACR-NAME>\\r\\n```\\r\\n\\r\\n#### Starting the Inference Service\\r\\n\\r\\nAfter installing KAITO, run the following command to start a `llama-2-7b` inference service, replacing `<YOUR-ACR-NAME>` with the ACR name you created previously:\\r\\n\\r\\n```\\r\\n$ cat examples/kaito_workspace_llama2_7b.yaml\\r\\napiVersion: kaito.sh/v1alpha1\\r\\nkind: Workspace\\r\\nmetadata:\\r\\n  name: workspace-llama-2-7b\\r\\nresource:\\r\\n  instanceType: \\"Standard_NC12s_v3\\"\\r\\n  labelSelector:\\r\\n    matchLabels:\\r\\n      apps: llama-2-7b\\r\\ninference:\\r\\n  preset:\\r\\n    name: \\"llama-2-7b\\"\\r\\n    accessMode: private\\r\\n    presetOptions:\\r\\n      image: <YOUR-ACR-NAME>.azurecr.io/llama2_model:latest\\r\\n\\r\\n$ kubectl apply -f examples/kaito_workspace_llama2_7b.yaml\\r\\n```\\r\\n\\r\\nKubernetes uses this YAML code to instantiate a workspace resource with the specified configurations. This enables deploying and managing inference workloads within the cluster.\\r\\n\\r\\nYou can monitor the workspace status by executing the command below. The model deployment has been completed once the `WORKSPACEREADY` column becomes `True`:\\r\\n\\r\\n```\\r\\n$ kubectl get workspace workspace-llama-2-7b \\r\\n| NAME | INSTANCE | RESOURCEREADY | INFERENCEREADY | WORKSPACEREADY | AGE |\\r\\n| workspace-llama-2-7b | Standard_NC12s_v3 | True | True | True | 10m |\\r\\n```\\r\\n\\r\\n**Note**: Achieving machine and workspace readiness may take up to 20 minutes.\\r\\n\\r\\nNow, run the command below to find the inference service\u2019s cluster IP:\\r\\n\\r\\n```\\r\\n$ kubectl get svc workspace-llama-2-7b \\r\\n| NAME | TYPE | CLUSTER-IP | EXTERNAL-IP | PORT(S) | AGE |\\r\\n| workspace-llama-2-7b | ClusterIP | <CLUSTERIP> | <none> | 80/TCP,29500/TCP | 10m |\\r\\n```\\r\\n\\r\\nFinally, run a curl pod to test the service endpoint in the cluster:\\r\\n\\r\\n```\\r\\nexport CLUSTERIP=$(kubectl get svc workspace-llama-2-7b -o jsonpath=\\"{.spec.clusterIPs[0]}\\")\\r\\n\\r\\n$ kubectl run -it --rm --restart=Never curl --image=curlimages/curl -- curl -X POST http://$CLUSTERIP/generate -H \\"accept: application/json\\" -H \\"Content-Type: application/json\\" -d \\"{\\\\\\"prompts\\\\\\":[\\\\\\"What is the capital of India?\\\\\\"],\\\\\\"parameters\\\\\\": {\\\\\\"temperature\\\\\\": 0, \\\\\\"max_gen_len\\\\\\": 64 }}\\"\\r\\n```\\r\\n\\r\\nYou should receive these results:\\r\\n\\r\\n```\\r\\n{\\"results\\":[{\\"prompt\\":\\"What is the capital of India?\\",\\"response\\":\\"\\\\nWhat is the capital of India? New Delhi is the capital of India. It is located in the northern part of the country. It is also the home of the President of India.\\\\nWhat is the\\"}]}\\r\\n```\\r\\n\\r\\n**Note**: You can test with your own questions, but there may be inaccuracies within the response. This is because AKS hasn\u2019t fine-tuned the model for your scenario.\\r\\n\\r\\nThat\u2019s it! You\u2019ve successfully established your AKS environment and familiarized yourself with setting up KAITO to deploy the LLaMA 2 model within your Kubernetes environment. You\u2019re now ready to analyze a model and make predictions using Azure\u2019s AI services.\\r\\n\\r\\n## Next Steps\\r\\n\\r\\nIn this article, you established an AKS cluster and configured KAITO to integrate with the LLaMA 2 model for advanced ML capabilities. In part 2, you\u2019ll use AKS and KAITO to analyze historical energy consumption data with advanced ML models. You\u2019ll create a dynamic web interface for users to input data, generate predictions, and visualize results seamlessly.\\r\\n\\r\\nBe sure to join the [Cloud Skill Challenge](https://azure.github.io/Cloud-Native/Build-IA/CloudSkills) to level up your cloud computing skills and gain hands-on experience. You can also register for the [next episode](https://aka.ms/learn-live-building-intelligent-apps-aks-ep3?ocid=buildia24_60days_blogs) on **Intelligent Apps with Azure Kubernetes Service**, an instructor led live learning experience to deploy your app on AKS. And, join the AKS product and engineering team at *KubeCon EU 2024*\u2014the premier conference for cloud-native technologies, for **AKS [Customer](https://aka.ms/aks-day) and [Lab](https://aka.ms/aks-lab-day) Days**."},{"id":"cosmos-db-and-intelligent-apps-a-match-made-for-innovation","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/cosmos-db-and-intelligent-apps-a-match-made-for-innovation","source":"@site/blog-60daysofIA/2024-03-07/cosmos-db-and-intelligent-apps-a-match-made-for-innovation.md","title":"3. Cosmos DB and Intelligent Apps: A Match Made for Innovation","description":"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.","date":"2024-03-07T09:00:00.000Z","formattedDate":"March 7, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":5.8,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-03-07T09:00","slug":"cosmos-db-and-intelligent-apps-a-match-made-for-innovation","title":"3. Cosmos DB and Intelligent Apps: A Match Made for Innovation","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["Cloud-Scale","Data","AI","AI/ML","intelligent apps","cloud-native","60-days","enterprise apps","digital experiences","app modernization"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"2.1 Forecasting Energy Usage with Intelligent Apps Part 1: Laying the Groundwork with AKS, KAITO, and LLaMA","permalink":"/Cloud-Native/60DaysOfIA/forecasting-energy-usage-with-intelligent-apps-1"},"nextItem":{"title":"3.1 Dynamic Repricing of Products Using Intelligent Apps Part 1","permalink":"/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-1"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/cosmos-db-and-intelligent-apps-a-match-made-for-innovation\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/cosmos-db-and-intelligent-apps-a-match-made-for-innovation\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/cosmos-db-and-intelligent-apps-a-match-made-for-innovation\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n![Cosmos DB and Intelligent Apps: A Match Made for Innovation](../../static/img/60-days-of-ia/blogs/2024-03-07/3-1.jpeg)\\r\\n\\r\\n## Cosmos DB and Intelligent Apps: A Match Made for Innovation\\r\\n\\r\\nIntelligent Apps represent the next frontier in application development. Merging machine learning (ML), data analytics, and artificial intelligence (AI), Intelligent Apps help drive and automate informed decisions within everyday workflows. These applications can offer predictive insights and personalized experiences by understanding user intent, making predictions, and automating tasks.\\r\\n\\r\\nThe core of Intelligent Apps lies in their ability to harness vast amounts of data, analyze it for patterns, and use these insights to improve decision-making processes, enhance user experiences, and streamline operations.\\r\\n\\r\\n[Azure Cosmos DB](https://azure.microsoft.com/free/cosmos-db?ocid=buildia24_60days_blogs) plays an instrumental role in building these advanced applications. Its scalability, multi-model support, and seamless integration with Azure AI Services make it a solid foundation for Intelligent Apps. Using Cosmos DB, you can manage and analyze large volumes of diverse data worldwide with minimal latency, ensuring the apps you build are intelligent, highly responsive, and globally available. Moreover, the service\u2019s ability to handle real-time data updates and queries empowers Intelligent Apps to deliver dynamic, up-to-the-minute insights and actions.\\r\\n\\r\\nOur three-part series demonstrates how to use Cosmos DB alongside Azure AI Services to create an Intelligent App that forecasts price fluctuations based on historical pricing and product data. In completing this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.\\r\\n\\r\\nJoin us as we embark on this journey to unlock the potential of Intelligent Apps with Cosmos DB!\\r\\n\\r\\n:::info\\r\\nComplete the **[Intelligent Apps Data Skills Challenge](https://aka.ms/intelligent-apps/data-csc?ocid=buildia24_60days_blogs)** to compete for the leaderboard and earn a Microsoft Learn Badge. \\r\\n:::\\r\\n\\r\\n### Building an Intelligent Forecasting Demo for E-Commerce\\r\\n\\r\\nIn the competitive e-commerce landscape, the ability to adapt pricing in real time based on demand and historical data is a valuable asset. So, this project focuses on developing a forecasting model that leverages AI/ML capabilities to predict future price changes. By integrating this model into your projects, you can enhance your applications with data-driven decision-making tools that respond effectively to market trends.\\r\\n\\r\\nAt the heart of this project is Azure Cosmos DB, chosen for its robust data management and analysis features. Cosmos DB facilitates the handling of large datasets required for accurate forecasting, providing a scalable, globally distributed database environment that supports real-time updates and queries. This capability is crucial for applying AI algorithms to historical price data, enabling the app to generate timely predictions that can inform pricing strategies.\\r\\n\\r\\n### Laying the Groundwork with Cosmos DB\\r\\n\\r\\n[Part 1 of our series](https://azure.github.io/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-1) starts with the foundation: setting up an Azure Cosmos DB environment tailored for the intelligent forecasting application. We\u2019ll guide you through the initial steps of creating and configuring your Cosmos DB instance to ensure it\u2019s ready to handle the complexities of historical pricing data.\\r\\n\\r\\nThis installment reviews how to populate your database with relevant data that will serve as the backbone for the dynamic repricing model. Once the Cosmos DB environment is established and filled with historical pricing data, you\u2019ll be in a strong position to start leveraging Azure AI Services to analyze this data and predict future price trends.\\r\\n\\r\\nBut the first article isn\u2019t just about setting up a database: It\u2019s about preparing the stage for a sophisticated application that can dynamically adjust e-commerce prices. Through this exercise, you\u2019ll learn the importance of a well-structured data foundation and how it enables the creation of more responsive and intelligent e-commerce platforms.\\r\\n\\r\\n### Analyzing Data with Azure AI Services\\r\\n\\r\\nIn part 2 of this series, the spotlight turns to Azure AI Services. You\u2019ll explore how to harness Azure\u2019s powerful AI capabilities to sift through the dataset, identifying patterns and trends that are key to understanding future price fluctuations.\\r\\n\\r\\nThis stage is all about bridging the gap between raw data and actionable insights, demonstrating how to apply AI capabilities to accurately forecast prices. We\u2019ll walk step-by-step through integrating Azure AI Services with Cosmos DB, helping you create a seamless workflow that brings the dynamic repricing model to life.\\r\\n\\r\\nThis hands-on exploration will equip you with the skills to implement intelligent forecasting within your own e-commerce platforms\u2014something that helps you make data-driven decisions on inventory pricing. By the end of part 2, you\u2019ll have a fully operational forecasting model capable of predicting price trends based on historical data.\\r\\n\\r\\n### Building the Web Interface\\r\\n\\r\\nIn part 3 of this series, you\u2019ll create a simple, yet effective web interface for the Intelligent App. This interface will serve as the window through which you can easily view and interact with the results of the dynamic repricing tool. We\u2019ll guide you through the development process, showcasing how to use popular web technologies to build an interface.\\r\\n\\r\\nThis web interface is critical in making the Intelligent App not just a powerful analytical tool but also a practical solution for e-commerce businesses. By providing a clear and intuitive way to access and understand the pricing forecasts, you can efficiently make informed decisions about pricing.\\r\\n\\r\\nThis final piece of the series ties together all the components of the project and highlights the importance of user experience in the deployment of Intelligent Apps.\\r\\n\\r\\n:::info\\r\\nCheck out the [Azure Cosmos DB Ask The Expert](https://aka.ms/intelligent-apps/ate-cosmos?ocid=buildia24_60days_blogs) session to learn how to build RAG solutions, manage chat history by seamlessly connecting with Azure OpenAI, as well as explore the power of Azure Cosmos DB\'s copilot. The experts will also cover how to seamlessly integrate your operational and transactional data with AI frameworks and sdks like Semantic Kernel, Langchain, and LlamaIndex.\\r\\n:::\\r\\n\\r\\n### Harnessing Cosmos DB for Intelligent Apps\\r\\n\\r\\nIn this exploration of how to build an Intelligent App with Cosmos DB, you\u2019ll have completed a project that showcases the power of Azure services and demonstrates the practical applications of these technologies in forecasting for e-commerce. And by walking through the steps needed to use Cosmos DB alongside Azure AI Services, you\u2019re walking away with a blueprint for building apps that can dynamically adjust pricing based on historical data and market trends.\\r\\n\\r\\nStay tuned for our series to dive deeper into the creation of this forecasting tool. Whether you\u2019re looking to enhance your technical skills or implement intelligent solutions in your own projects, following along will shine light onto the value of using Cosmos DB for Intelligent Apps."},{"id":"dynamic-repricing-of-products-using-intelligent-apps-part-1","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-1","source":"@site/blog-60daysofIA/2024-03-08/dynamic-repricing-of-products-using-intelligent-apps-part-1.md","title":"3.1 Dynamic Repricing of Products Using Intelligent Apps Part 1","description":"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable. In the first article of this series, you\u2019ll set up and populate the Cosmos DB database with data to use in the later parts of the series.","date":"2024-03-08T09:00:00.000Z","formattedDate":"March 8, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":7.14,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-03-08T09:00","slug":"dynamic-repricing-of-products-using-intelligent-apps-part-1","title":"3.1 Dynamic Repricing of Products Using Intelligent Apps Part 1","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["Cloud-Scale","Data","AI","AI/ML","intelligent apps","cloud-native","60-days","enterprise apps","digital experiences","app modernization"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable. In the first article of this series, you\u2019ll set up and populate the Cosmos DB database with data to use in the later parts of the series.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"3. Cosmos DB and Intelligent Apps: A Match Made for Innovation","permalink":"/Cloud-Native/60DaysOfIA/cosmos-db-and-intelligent-apps-a-match-made-for-innovation"},"nextItem":{"title":"3.2 Dynamic Repricing of Products Using Intelligent Apps Part 2","permalink":"/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-2"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/dynamic-repricing-of-products-using-intelligent-apps-part-1\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable. In the first article of this series, you\u2019ll set up and populate the Cosmos DB database with data to use in the later parts of the series.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/dynamic-repricing-of-products-using-intelligent-apps-part-1\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable. In the first article of this series, you\u2019ll set up and populate the Cosmos DB database with data to use in the later parts of the series.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/dynamic-repricing-of-products-using-intelligent-apps-part-1\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n![Cosmos DB and Intelligent Apps: A Match Made for Innovation](../../static/img/60-days-of-ia/blogs/2024-03-08/3-1-1.jpeg)\\r\\n\\r\\n*This three-part series demonstrates how to use Azure Cosmos DB to build an Intelligent App that uses historical pricing and product data to forecast future price fluctuations for specific products. In the first article of this series, you\u2019ll set up and populate the Cosmos DB database with data to use in the later parts of the series.*\\r\\n\\r\\n## Dynamic Repricing of Products Using Intelligent Apps Part 1: Setting Up and Populating Cosmos DB with Data\\r\\n\\r\\nIntelligent Apps leverage data and artificial intelligence (AI) to provide smart, personalized, and adaptive experiences for users. AI and machine learning (ML) techniques like natural language processing (NLP), computer vision, and deep learning help understand context, intent, and user preferences to deliver relevant and timely insights and actions.\\r\\n\\r\\nSome examples of Intelligent Apps include:\\r\\n\\r\\n- **Virtual assistants**\u2014Interactive applications that understand and execute user commands\\r\\n- **Chatbots**\u2014Automated messaging systems that provide information or assistance\\r\\n- **Recommendation** systems\u2014Algorithms that suggest relevant items based on user preferences and behavior\\r\\n\\r\\nIn this three-part series, you\u2019ll create an Intelligent App powered by Azure Cosmos DB and AI/ML capabilities that dynamically suggests changes to product prices based on demand and historical trends. This app will help optimize revenue and customer satisfaction by adjusting product prices according to market conditions and customer behavior.\\r\\n\\r\\n### Laying the Groundwork for an Intelligent App with Cosmos DB\\r\\n\\r\\nFirst, you\u2019ll set up an Azure Cosmos DB database and populate it with product data and historical information about sales and demand. In part 2, you\u2019ll analyze this data using AI and ML to forecast and suggest price changes.\\r\\n\\r\\n#### Prerequisites\\r\\n\\r\\nTo follow this tutorial, ensure you have the following:\\r\\n\\r\\n- [An Azure account](https://azure.microsoft.com/free/?ocid=buildia24_60days_blogs)\\r\\n- A [Kaggle account](https://www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2F) to download the [dataset](https://www.kaggle.com/datasets/sujaykapadnis/price-quote-data/data) this tutorial uses\\r\\n\\r\\n#### Create an Azure Cosmos DB Account\\r\\n\\r\\nAzure Cosmos DB is a fully managed multi-model database that ensures fast access to data, easy scalability, reliable uptime, and strong data consistency. Cosmos DB supports various data models and APIs, including SQL, MongoDB, Cassandra, Gremlin, and table storage, making it easy to query and manipulate data using familiar tools and languages.\\r\\n\\r\\nAlthough you already have an Azure account, you also need to create an Azure Cosmos DB account by following the steps below:\\r\\n\\r\\n1. Sign in to the [Azure portal](https://portal.azure.com/).\\r\\n\\r\\n2. Click **Create a resource** on the upper-left side of the page.\\r\\n\\r\\n3. Search for \u201cAzure Cosmos DB\u201d and select it. On the **Azure Cosmos DB** page, select **Create**.\\r\\n\\r\\n4. Enter the settings for your new account:\\r\\n\\r\\n    - Select your desired subscription.\\r\\n\\r\\n    - Create a new resource group or select an existing one if you have one you\u2019d like to use.\\r\\n\\r\\n    - Enter a unique account name.\\r\\n\\r\\n    - Select **SQL (Core)** as the API. This is the default API for Azure Cosmos DB and allows you to use SQL syntax to query and manage your data.\\r\\n\\r\\n    - Select a **Location** for the account.\\r\\n\\r\\n    - Click **Review + create**.\\r\\n\\r\\n5. Review your account settings and click **Create** to create the account.\\r\\n\\r\\n:::info\\r\\nComplete the **[Data Skills Challenge](https://aka.ms/intelligent-apps/data-csc?ocid=buildia24_60days_blogs)** to compete for the leaderboard and earn a Microsoft Learn Badge.\\r\\n:::\\r\\n\\r\\n#### Create a Database and a Container\\r\\n\\r\\nNext, you\u2019ll create a database and container within Azure Cosmos DB. Databases facilitate management, billing, and scaling, while a container is a schema-agnostic grouping of items (documents) with a partition key and a provisioned throughput. The partition property determines how the data is distributed across physical partitions for scalability and performance.\\r\\n\\r\\nTo create a database and container, follow the steps below:\\r\\n\\r\\n1. From the Azure portal, navigate to your Azure Cosmos DB account and select **Data Explorer** on the left menu. In the **Data Explorer**, select **New Database** on the top menu.\\r\\n\\r\\n2. In the **Add Database** panel, enter a name for the new database, like \u201cProductsDB.\u201d\\r\\n\\r\\n3. Check **Provision database throughput** if you want to enable shared throughput for the database. This shares the throughput (RU/s) you provision among all containers in the database. You can also activate or deactivate autoscale, which automatically adjusts the throughput based on your application\u2019s usage patterns.\\r\\n\\r\\n4. Select **OK** to create the database.\\r\\n\\r\\n5. In **Data Explorer**, expand the **ProductsDB** database and select **New Container** on the top menu. Then, open the **Add Container** panel and create a new container:\\r\\n\\r\\n    - Enter \u201cProducts\u201d as the container name.\\r\\n\\r\\n    - Enter \u201c/ITEM_ID\u201d as the container\u2019s partition key. This will [partition](https://learn.microsoft.com/en-us/azure/cosmos-db/partitioning-overview) the data by its `ITEM_ID` property, since columns with a wide range of values make excellent partition keys.\\r\\n\\r\\n    - Use the default value of 400 throughput units. If you\u2019d like, you can also deactivate autoscale for the container.\\r\\n\\r\\n6. Select **OK** to create the container.\\r\\n\\r\\n#### Populate the Container\\r\\n\\r\\nNow that you\u2019ve created your database and container, you need to populate them with some data. For this demonstration, you\u2019ll use a CSV file that contains [UK inflation data](https://www.ons.gov.uk/economy/inflationandpriceindices/datasets/consumerpriceindicescpiandretailpricesindexrpiitemindicesandpricequotes). The dataset contains over 100,000 rows of data representing 600 products sold in UK shops over 12 months.\\r\\n\\r\\nTo populate the container with this data, follow these steps:\\r\\n\\r\\n1. Download the [CSV file](https://www.kaggle.com/datasets/sujaykapadnis/price-quote-data/data).\\r\\n\\r\\n2. In the Azure portal, navigate to your Azure Cosmos DB account and select **Data Explorer** on the left menu.\\r\\n\\r\\n3. In **Data Explorer**, expand the **ProductsDB** database and the **Products** container, and select **Items**.\\r\\n\\r\\n##### *Upload the CSV File*\\r\\n\\r\\nNow, upload the CSV file:\\r\\n\\r\\n1. From the top menu, select **Upload Item**.\\r\\n\\r\\n2. In the **Upload Item** panel, select **Browse**, and choose the CSV file you downloaded previously.\\r\\n\\r\\n3. Select **Upload** to upload the file to the container.\\r\\n\\r\\n4. After the upload finishes, you should see the items in the container, each representing a row in the CSV file. You can select an item to view its properties and values in JSON format.\\r\\n\\r\\n##### *Verify the Data in the Container*\\r\\n\\r\\nTo verify that the data in the container is correct and consistent, you can use the SQL query editor in the Data Explorer.\\r\\n\\r\\n1. Select **New SQL Query**.\\r\\n\\r\\n2. The query editor lets you execute SQL queries against the data in the container. For example, run the following query to get the container\u2019s item count:\\r\\n\\r\\n    ```SELECT VALUE COUNT(1) FROM c```\\r\\n\\r\\n    You should get a result of `10000`, which matches the number of rows in the CSV file.\\r\\n\\r\\n  3. You can also run queries to check the data quality and integrity, like the following:\\r\\n      - **Get the distinct values of ITEM_ID** \u2014 `SELECT DISTINCT VALUE c.ITEM_ID FROM c`\\r\\n      \\r\\n      - **Get the average price of each product** \u2014 `SELECT c.ITEM_ID, c.ITEM_DESC, AVG(c.PRICE) AS avg_price FROM c GROUP BY c.ITEM_ID, c.ITEM_DESC`\\r\\n      - **Get the price trend of a product over time** \u2014 `SELECT c.QUOTE_DATE, c.PRICE FROM c WHERE c.ITEM_ID = \'210102\' ORDER BY c.QUOTE_DATE`\\r\\n4. You can also use the built-in charts to visualize the query results. In the top-right corner of the query editor, select **Chart** and choose the chart type you want to use, such as line, bar, or pie.\\r\\n\\r\\n### Next Steps\\r\\n\\r\\nIn this article, you configured an Azure Cosmos DB database and populated it with data about product price changes. You also verified the data in the container using SQL queries and charts.\\r\\n\\r\\nIn the [next part of the series](https://azure.github.io/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-2), you\u2019ll learn how to use Azure\u2019s AI and ML capabilities to analyze the data and suggest product price forecasts. \\r\\n\\r\\nIf you want to challenge yourself and learn more about Azure, Cosmos DB, and AI/ML, we encourage you to participate in the **[Data Cloud Skill Challenge](https://azure.github.io/Cloud-Native/Build-IA/CloudSkills)**. You can also register for **AKS [Customer](https://aka.ms/aks-day) and [Lab](https://aka.ms/aks-lab-day) Days** at the premier conference for cloud-native technologies, *KubeCon EU 2024*."},{"id":"dynamic-repricing-of-products-using-intelligent-apps-part-2","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-2","source":"@site/blog-60daysofIA/2024-03-08/dynamic-repricing-of-products-using-intelligent-apps-part-2.md","title":"3.2 Dynamic Repricing of Products Using Intelligent Apps Part 2","description":"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.","date":"2024-03-08T09:01:00.000Z","formattedDate":"March 8, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":6.785,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-03-08T09:01","slug":"dynamic-repricing-of-products-using-intelligent-apps-part-2","title":"3.2 Dynamic Repricing of Products Using Intelligent Apps Part 2","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["Cloud-Scale","Data","AI","AI/ML","intelligent apps","cloud-native","60-days","enterprise apps","digital experiences","app modernization"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"3.1 Dynamic Repricing of Products Using Intelligent Apps Part 1","permalink":"/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-1"},"nextItem":{"title":"4. Fuel Your Intelligent Apps with Azure AI","permalink":"/Cloud-Native/60DaysOfIA/fuel-your-intelligent-apps-with-azure-ai"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/dynamic-repricing-of-products-using-intelligent-apps-part-2\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/dynamic-repricing-of-products-using-intelligent-apps-part-2\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"In this series, you\u2019ll learn why Cosmos DB is an ideal choice for powering such applications\u2014and how it makes building Intelligent Apps accessible and approachable.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/dynamic-repricing-of-products-using-intelligent-apps-part-2\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n![Dynamic Repricing of Products Using Intelligent Apps Part 2: Price Forecasting with AI/ML](../../static/img/60-days-of-ia/blogs/2024-03-08/3-2-1.jpeg)\\r\\n\\r\\n*This three-part series demonstrates how to use Azure Cosmos DB to build an Intelligent App that uses historical pricing and product data to forecast future price fluctuations for specific products. In this installment, you\u2019ll use artificial intelligence and machine learning to build the price forecasting model.*\\r\\n\\r\\n## Dynamic Repricing of Products Using Intelligent Apps Part 2: Price Forecasting with AI/ML\\r\\n\\r\\n[In Part 1 of this series](https://azure.github.io/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-1), you set up and populated an [Azure Cosmos DB](https://azure.microsoft.com/free/cosmos-db?ocid=buildia24_60days_blogs) database, laying the groundwork for your Intelligent Application. You also imported your data to a Cosmos DB instance.\\r\\n\\r\\nIn this second article, you\u2019ll use this data alongside Azure\u2019s machine learning (ML) and artificial intelligence (AI) capabilities to build a model that analyzes pricing trends and predicts future prices for a fictional e-commerce business.\\r\\n\\r\\n### Analyzing Price Trends to Predict Future Prices\\r\\n\\r\\nThe ability to forecast pricing is a game-changer. With the power of foresight, businesses can preemptively adjust their pricing strategies in line with market expectations.\\r\\n\\r\\nIn this tutorial, we\u2019ll give you a step-by-step guide to generating a predictive ML model for an e-commerce business, using Azure\u2019s suite of ML tools.\\r\\n\\r\\n#### Prerequisites\\r\\n\\r\\nBefore you begin, make sure you have the following:\\r\\n\\r\\n- An active [Azure Account](https://azure.microsoft.com/free/?ocid=buildia24_60days_blogs)\\r\\n- A Cosmos DB instance with the [pricing data](https://www.kaggle.com/datasets/sujaykapadnis/price-quote-data/data) you set up in Part 1\\r\\n- Access to [Azure Machine Learning Studio](https://studio.azureml.net/)\\r\\n- An [Azure Machine Learning workspace](https://learn.microsoft.com/azure/machine-learning/tutorial-azure-ml-in-a-day?view=azureml-api-2&ocid=buildia24_60days_blogs)\\r\\n- A [Jupyter notebook set up](https://learn.microsoft.com/azure/machine-learning/quickstart-create-resources?view=azureml-api-2#create-a-new-notebook&ocid=buildia24_60days_blogs) in your workspace\\r\\n- Familiarity with [Azure Machine Learning](https://azure.microsoft.com/products/machine-learning?ocid=buildia24_60days_blogs) concepts\\r\\n- Basic Python programming knowledge and understanding of ML concepts\\r\\n\\r\\n**Note**: You should add and run all code in this article into your Jupyter Notebook in the order in which it appears.\\r\\n\\r\\n:::info\\r\\nCheck out the Azure **[Cosmos DB Ask The Expert](https://aka.ms/intelligent-apps/ate-cosmos?ocid=buildia24_60days_blogs)** session to learn how to build RAG solutions, manage chat history by seamlessly connecting with *Azure OpenAI*, as well as explore the power of *Azure Cosmos DB\'s copilot*. The experts will also cover how to seamlessly integrate your operational and transactional data with AI frameworks and sdks like Semantic Kernel, Langchain, and LlamaIndex. \\r\\n:::\\r\\n\\r\\n#### Extract Historical Pricing Data from Cosmos DB\\r\\n\\r\\nStart by extracting historical pricing data from Cosmos DB, where you stored it in Part 1. For this tutorial, you\u2019ll extract items with names ending in `JACKET`. Because the dataset is relatively small, a simple `like` query will do. However, when working with larger data sets, you should consider additional upfront data cleaning and categorizing, to ensure you can query your database efficiently.\\r\\n\\r\\nRun the code below to extract the data:\\r\\n\\r\\n```\\r\\nfrom azure.cosmos import CosmosClient, exceptions\\r\\nimport pandas as pd\\r\\n```\\r\\n```\\r\\n# Initialize a Cosmos client\\r\\nendpoint = \\"your_cosmos_db_endpoint\\"\\r\\nkey = \'your_cosmos_db_key\'\\r\\nclient = CosmosClient(endpoint, key)\\r\\n```\\r\\n```\\r\\n# Connect to the database and container\\r\\ndatabase_name = \'your_database_name\'\\r\\ncontainer_name = \'your_container_name\'\\r\\ndatabase = client.get_database_client(database_name)\\r\\ncontainer = database.get_container_client(container_name)\\r\\n```\\r\\n```\\r\\n# Query these items using the SQL query syntax\\r\\nquery = \\"SELECT * FROM c where ITEM_DESC like \'%JACKET\'\\"\\r\\nitems = list(container.query_items(query=query, enable_cross_partition_query=True))\\r\\n```\\r\\n```\\r\\n# Convert the query result to a DataFrame\\r\\npricing_data = pd.DataFrame(items)\\r\\n```\\r\\n\\r\\n#### Preprocess Data and Split into Training and Testing\\r\\n\\r\\nBefore feeding the data into an ML model, preprocess it and split it into training and testing sets using the code below:\\r\\n\\r\\n```\\r\\nfrom sklearn.model_selection import train_test_split\\r\\n```\\r\\n```\\r\\n# Assume the DataFrame `pricing_data` has columns: \'quote_date\', \'price\', \'price_relative\', \'item_id\', etc.\\r\\n```\\r\\n```\\r\\n# Convert \'quote_date\' from string to datetime for proper chronological splitting\\r\\npricing_data[\'QUOTE_DATE\'] = pd.to_datetime(pricing_data[\'QUOTE_DATE\'], format=\'%Y%m\')\\r\\n```\\r\\n```\\r\\n# Selecting the features and target for the model\\r\\nX = pricing_data[[\'QUOTE_DATE\', \'ITEM_ID\', \'PRICE_RELATIVE\',\'STRATUM_WEIGHT\', \'SHOP_WEIGHT\']]\\r\\ny = pricing_data[\'price\']\\r\\n```\\r\\n```\\r\\n# Split the data into training and testing sets\\r\\n# We\'ll use a chronological split rather than a random split to maintain the time series integrity\\r\\nsplit_date = pd.Timestamp(\'YYYY-MM-DD\')  # replace with the appropriate date\\r\\ntrain = pricing_data.loc[pricing_data[\'QUOTE_DATE\'] <= split_date]\\r\\ntest = pricing_data.loc[pricing_data[\'QUOTE_DATE\'] > split_date]\\r\\n```\\r\\n```\\r\\nX_train, y_train = train[[\'ITEM_ID\', \'PRICE_RELATIVE\', \'STRATUM_WEIGHT\', \'SHOP_WIGHT\']], train[\'PRICE\']\\r\\nX_test, y_test = test[[\'ITEM_ID\', \'PRICE_RELATIVE\', \'STRATUM_WEIGHT\', \'SHOP_WEIGHT\']], test[\'PRICE\']\\r\\n```\\r\\n\\r\\n#### Train a Forecasting Model Using Azure Machine Learning\\r\\n\\r\\nNext, you\u2019ll build and train the forecasting model using Azure Machine Learning. Note that in the code below, you\u2019re using a local compute target, which works on simple datasets like the one used for this tutorial. However, Azure Machine Learning offers more powerful compute targets for more complex models.\\r\\n\\r\\n```\\r\\nfrom azureml.core import Workspace, Experiment, Environment\\r\\nfrom azureml.train.automl import AutoMLConfig\\r\\n```\\r\\n```\\r\\n# Connect to your Azure ML workspace\\r\\nws = Workspace.from_config()\\r\\n```\\r\\n```\\r\\n# Define your experiment\\r\\nexperiment_name = \'price_forecasting_experiment\'\\r\\nexperiment = Experiment(ws, experiment_name)\\r\\n```\\r\\n```\\r\\n# Configure the automated ML job \\r\\n\\r\\nautoml_config = AutoMLConfig(\\r\\n    task=\'forecasting\',\\r\\n    primary_metric=\'normalized_root_mean_squared_error\',\\r\\n    experiment_timeout_minutes=30,\\r\\n    training_data=train,\\r\\n    label_column_name=\'PRICE\',\\r\\n    n_cross_validations=5,\\r\\n    enable_early_stopping=True,\\r\\n    verbosity=logging.INFO,\\r\\n    compute_target=\'local\'\\r\\n) \\r\\n```\\r\\n```\\r\\n# Submit the experiment\\r\\nrun = experiment.submit(automl_config, show_output=True)\\r\\n```\\r\\n\\r\\n#### Evaluate and Integrate the Model\\r\\n\\r\\nNext, check the results of the model by running the following:\\r\\n\\r\\n```\\r\\nfrom azureml.widgets import RunDetails\\r\\n```\\r\\n```\\r\\n# Show run details while running\\r\\nRunDetails(run).show()\\r\\n```\\r\\n```\\r\\n# Wait for the run to complete\\r\\nrun.wait_for_completion()\\r\\n```\\r\\n```\\r\\n# Retrieve the best model from the AutoML run\\r\\nbest_run, fitted_model = run.get_output()\\r\\nprint(best_run)\\r\\nprint(fitted_model)\\r\\n```\\r\\n```\\r\\n# Evaluate the best model\'s accuracy using the test data\\r\\n# Assuming test data is a Pandas DataFrame with the same structure as the training data\\r\\nX_test = test_data.drop(\'PRICE\', axis=1)  # Features (drop the target column)\\r\\ny_test = test_data[\'PRICE\']  # True values of the target column\\r\\n```\\r\\n```\\r\\n# Predict using the fitted model\\r\\ny_pred = fitted_model.predict(X_test)\\r\\n```\\r\\n```\\r\\n# Calculate the accuracy or any other performance metrics\\r\\nfrom sklearn.metrics import mean_squared_error, r2_score\\r\\nmse = mean_squared_error(y_test, y_pred)\\r\\nr2 = r2_score(y_test, y_pred)\\r\\n```\\r\\n```\\r\\nprint(f\\"Mean Squared Error: {mse}\\")\\r\\nprint(f\\"R-squared: {r2}\\")\\r\\n```\\r\\n\\r\\nWith the performance metrics calculated, you can now determine whether the model\u2019s predictions are accurate enough for your needs. If they are, you can integrate the model with a hypothetical e-commerce platform. The easiest way to integrate a model is to deploy it using an Azure Machine Learning endpoint:\\r\\n\\r\\n```\\r\\nws = Workspace.from_config() \\r\\n```\\r\\n```\\r\\n# Register the model from the best run\\r\\nmodel = best_run.register_model(model_name=\'price_forecast_model\', model_path=\'outputs/model.pkl\') \\r\\n```\\r\\n```\\r\\n# Download the scoring file produced by AutoML\\r\\nbest_run.download_file(\'outputs/scoring_file_v_1_0_0.py\', \'score.py\')\\r\\n```\\r\\n```\\r\\n# Download the environment file produced by AutoML\\r\\nbest_run.download_file(constants.CONDA_ENV_FILE_PATH, \'environment.yml\')\\r\\n```\\r\\n```\\r\\n# Create the environment\\r\\nenv = Environment.from_conda_specification(name=\'forecasting_environment\', file_path=\'environment.yml\')\\r\\n```\\r\\n```\\r\\n# Create the inference configuration\\r\\ninference_config = InferenceConfig(entry_script=\'score.py\', environment=env)\\r\\n```\\r\\n```\\r\\n# Create the deployment configuration\\r\\ndeployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\\r\\n```\\r\\n```\\r\\n# Deploy the model as a web service\\r\\nservice_name = \'price-forecast-service\'\\r\\nservice = Model.deploy(ws, service_name, [model], inference_config, deployment_config) \\r\\nservice.wait_for_deployment(show_output=True)\\r\\n```\\r\\n```\\r\\n# The web service endpoint URL\\r\\nprint(service.scoring_uri)\\r\\n```\\r\\n\\r\\nAnd with that, you\u2019ve deployed your Azure ML endpoint and are ready for Part 3!\\r\\n\\r\\n### Conclusion\\r\\n\\r\\nIn this tutorial, you extracted data from Cosmos DB, preprocessed it, performed a train/test split, initiated a model training pipeline using Azure Machine Learning, and, finally, tested and deployed the model. These are crucial steps to building a system that can intelligently forecast product prices.\\r\\n\\r\\nIn the third and final article of this series, you\u2019ll build a web interface that displays the generated price forecasts using approachable, simple graphs that help businesses easily make data-informed decisions.\\r\\n\\r\\nTo challenge yourself, learn more about Azure\u2019s AI and ML tooling, and put the skills you\u2019ve learned in this tutorial to work, participate in the [Data Cloud Skill Challenge](https://azure.github.io/Cloud-Native/Build-IA/CloudSkills). You can also register for **AKS [Customer](https://aka.ms/aks-day) and [Lab](https://aka.ms/aks-lab-day) Days** at the premier conference for cloud-native technologies, *KubeCon EU 2024*."},{"id":"fuel-your-intelligent-apps-with-azure-ai","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/fuel-your-intelligent-apps-with-azure-ai","source":"@site/blog-60daysofIA/2024-03-11/fuel-your-intelligent-apps-with-azure-ai.md","title":"4. Fuel Your Intelligent Apps with Azure AI","description":"In this kickoff post, we\'ll set the stage for the week of posts by describing the application scenario (motivation) and introducing core terminology (LLM Ops), developer tools (Azure AI Studio, frameworks) and design patterns (RAG) to help you jumpstart your journey building and deploying generative AI solutions in the enterprise. By the end of this week, you should have a good understanding of how to build a copilot app end-to-end on the Azure AI platform, how to deploy it for integration with real-world applications, and how to incorporate responsible AI principles into your development workflow.","date":"2024-03-11T09:00:00.000Z","formattedDate":"March 11, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":9.09,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-03-11T09:00","slug":"fuel-your-intelligent-apps-with-azure-ai","title":"4. Fuel Your Intelligent Apps with Azure AI","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["promptflow","azure","aistudio","generativeai","e2e","llmops"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"In this kickoff post, we\'ll set the stage for the week of posts by describing the application scenario (motivation) and introducing core terminology (LLM Ops), developer tools (Azure AI Studio, frameworks) and design patterns (RAG) to help you jumpstart your journey building and deploying generative AI solutions in the enterprise. By the end of this week, you should have a good understanding of how to build a copilot app end-to-end on the Azure AI platform, how to deploy it for integration with real-world applications, and how to incorporate responsible AI principles into your development workflow.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"3.2 Dynamic Repricing of Products Using Intelligent Apps Part 2","permalink":"/Cloud-Native/60DaysOfIA/dynamic-repricing-of-products-using-intelligent-apps-part-2"},"nextItem":{"title":"4.1 Build Contoso Chat End-to-End","permalink":"/Cloud-Native/60DaysOfIA/build-contoso-chat-end-to-end"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/fuel-your-intelligent-apps-with-azure-ai\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"In this kickoff post, we\'ll set the stage for the week of posts by describing the application scenario (motivation) and introducing core terminology (LLM Ops), developer tools (Azure AI Studio, frameworks) and design patterns (RAG) to help you jumpstart your journey building and deploying generative AI solutions in the enterprise. By the end of this week, you should have a good understanding of how to build a copilot app end-to-end on the Azure AI platform, how to deploy it for integration with real-world applications, and how to incorporate responsible AI principles into your development workflow.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/fuel-your-intelligent-apps-with-azure-ai\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"In this kickoff post, we\'ll set the stage for the week of posts by describing the application scenario (motivation) and introducing core terminology (LLM Ops), developer tools (Azure AI Studio, frameworks) and design patterns (RAG) to help you jumpstart your journey building and deploying generative AI solutions in the enterprise. By the end of this week, you should have a good understanding of how to build a copilot app end-to-end on the Azure AI platform, how to deploy it for integration with real-world applications, and how to incorporate responsible AI principles into your development workflow.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/fuel-your-intelligent-apps-with-azure-ai\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n# Kicking Off Azure AI Week!\\r\\n\\r\\nWelcome to the `Azure AI` week on **#60Days Of IA**. Over the next 5 days, we\'ll share a series of blog posts that give you a comprehensive look at the tools and end-to-end development workflow reequired to build intelligent applications [code-first on the Azure AI platform](https://techcommunity.microsoft.com/t5/ai-ai-platform-blog/a-code-first-experience-for-building-a-copilot-with-azure-ai/ba-p/4058659?ocid=buildia24_60days_blogs). \\r\\n\\r\\nIn this kickoff post, we\'ll set the stage for the week of posts by describing the application scenario (motivation) and introducing core terminology (LLM Ops), developer tools (Azure AI Studio, frameworks) and design patterns (RAG) to help you jumpstart your journey building and deploying generative AI solutions in the enterprise. By the end of this week, you should have a good understanding of how to build a copilot app end-to-end on the Azure AI platform, how to deploy it for integration with real-world applications, and how to incorporate responsible AI principles into your development workflow.\\r\\n\\r\\nReady? Let\'s get started!\\r\\n\\r\\n## What We\'ll Cover Today\\r\\n * **Application Scenario |** What is Contoso Chat?\\r\\n * **Paradigm Shift |** What is LLM Ops?\\r\\n * **Unified Platform |** What is Azure AI Studio?\\r\\n * **Copilot Experience |** What is the development workflow?\\r\\n * **The Week Ahead |** What will we cover?\\r\\n * **Resources:** [Explore the Code-First Azure AI Collection](https://aka.ms/ai-studio/collection?ocid=buildia24_60days_blogs)\\r\\n\\r\\n---\\r\\n\\r\\n![Roadmap](../../static/img/60-days-of-ia/blogs/2024-03-11/banner.png)\\r\\n\\r\\n<br/>\\r\\n\\r\\nGenerative AI applications are transforming the user experience and accelerating adoption of AI tools and solutions in the enterprise. But as developers, we face new challenges in building solutions **end-to-end** - from prompt engineering to LLM Ops. We need new tools, frameworks, and guidance to help us navigate and streamline a fast-growing ecosystem. \\r\\n\\r\\nIn [a recent blog post](https://techcommunity.microsoft.com/t5/ai-ai-platform-blog/a-code-first-experience-for-building-a-copilot-with-azure-ai/ba-p/4058659?ocid=buildia24_60days_blogs) we described how the Azure AI platform is addressing these challanges with a _code-first experience for building a copilot application end-to-end_ with your data and APIs. This week, we unpack that post in more detail - walking you through a end-to-end application sample, and several _quickstart_ options, to get you started on your own generative AI solutions.\\r\\n\\r\\nTo kick things off, let\'s set the stage by describing a common generative AI application scenario (\\"Contoso Chat\\") and introduce core terminology, tools and processes that we will be using throughout the week, on our development journey.\\r\\n\\r\\n## 1 | The Application Scenario\\r\\n\\r\\nSay hello to _Contoso Outdoor Company_ - an online retailer of outdoor adventuring equipment with a loyal and growing customer base. Your website has a rich catalog of items organized into categories like _tents_, _backpacks_, _hiking boots_ and more. Customers visit the site looking to find the best gear for their next adventure, and often have questions about the products, or how they might fit with their previous purchases.\\r\\n\\r\\n![Contoso Outdoors site](../../static/img/60-days-of-ia/blogs/2024-03-11/app-contoso-outdoors.png)\\r\\n\\r\\nThe company has a customer support line, but it is getting overwhelmed with calls and you don\'t have the resources to meet the demand. You hear about generative AI applications and decide to build a _customer support chat AI_ agent that knows your catalog and customers. You can then integrate it into the site as shown, to improve customer satisfaction and drive follow-up actions.\\r\\n\\r\\n![Contoso Chat concept](../../static/img/60-days-of-ia/blogs/2024-03-11/app-contoso-chat-concept.png)\\r\\n\\r\\nYou identify three requirements for your chat AI application:\\r\\n - **Custom Data**. The application responses must prioritize your catalog data.\\r\\n - **Responsible AI**. The application must follow responsible AI principles.\\r\\n - **LLM Ops**. The end-to-end development workflow must be operationalizable.\\r\\n\\r\\n## 2 | The Paradigm Shift\\r\\n\\r\\nBuilding generative AI applications requires a different mindset from traditional ML applications. The latter are trained on finite custom data, deploying an endpoint that makes _predictions_. By contrast, generative AI applications are trained on massive amounts of data, using large language models (LLM) and natural language processing (NLP) to _generate_ new content.\\r\\n\\r\\nThe focus now moves from **MLOps** (workflow for building ML apps) to **LLMOps** (workflow for building generative AI apps) - starting with _prompt engineering_, a process where we refine the inputs to the LLM (\\"prompts\\") through a process of trial-and-error (build-run-evaluate) till the responses meet our quality, cost and performance requirements. The generative AI application lifecycle now looks more like this:\\r\\n\\r\\n![LLM App Lifecyle](../../static/img/60-days-of-ia/blogs/2024-03-11/llm-app-lifecycle.png)\\r\\n\\r\\n1. **Ideation Phase**: Start by building the basic AI application (copilot) for your scenario. At this stage, you define the architectural elements (AI resources, design patterns) and language models (chat completion, chat evaluation, text embeddings) that you will need to build-run-evaluate the basic experience. And have sample data to test against.\\r\\n2. **Augmentation Phase**: Iteratively refine the quality and performance of your application by _engineering_ the prompts, _tuning_ the models, and _evaluating_ the responses with sample data (smal) and batch runs (large). Use relevant metrics (groundedness, coherence, relevance, fluency) to guide decisions on what to change, and when to stop iterating.\\r\\n3. **Operationalization Phase:** Now, you\'re ready to deploy the application to a production environment so that the endpoint can be accessed by others, for integrating into user-facing experiences. This is also a good time to review the entire workflow for responsible AI practices, and explore automation and monitoring solutions for efficiency and performance.\\r\\n\\r\\n## 3 | The Azure AI Platform\\r\\n\\r\\nImplementing this end-to-end workflow and managing the various phases of the application lifecycle can be challenging for developers. Azure AI Studio addresses these challenges with a [**unified platform**](https://ai.azure.com?ocid=buildia24_60days_blogs) for building generative AI applications and custom copilot experiences. \\r\\n\\r\\nUse the platform to **explore** language models from Microsoft and the broader community, and experiment with them in a built-in playground. Then **build** your \\r\\nAI project by seamlessly integrating with deployed models and built-in AI services - and **manage** your AI resources (for compute, access, billing and more) from the unified UI. \\r\\n\\r\\n![Azure AI Studio](../../static/img/60-days-of-ia/blogs/2024-03-11/azure-ai.png)\\r\\n\\r\\nAs a developer, you have both low-code and code-first options for engaging with the platform. Use the [Azure AI Studio UI](https://ai.azure.com?ocid=buildia24_60days_blogs) for a browser-based low-code experience, and the [Azure AI SDK](https://learn.microsoft.com/azure/ai-studio/how-to/sdk-generative-overview?ocid=buildia24_60days_blogs) for a Python-based code-first experience. In our posts this week, we\'ll focus on the code-first experience, and show you how to build a copilot app on Azure AI using the Python SDK and popular frameworks.\\r\\n\\r\\n\\r\\n## 4 | The Copilot Experience\\r\\n\\r\\nSo how do we get started on the end-to-end development journey using the Azure AI platform? Let\'s start by defining what we mean by a _copilot_ experience for enterprise-grade generative AI applications. A copilot is:\\r\\n - a generative AI application that uses large language models (LLM) and natural language processing (NLP) \\r\\n - to assist customers in completing complex cognitive tasks **using your data** \\r\\n - typically using conversational \u201cchat\u201d interactions (request-reponse)\\r\\n\\r\\nThe copilot (generative AI application) is deployed in the cloud to expose an interaction endpoint (API) that can be integrated into customer-facing experiences (e.g,, web or mobile apps) for real-world use. For our specific application scenario, the implementation will involve two components:\\r\\n - Contoso Chat (copilot API) as the backend component with the chat AI\\r\\n - Contoso Outdoors (web App) as the frontend component with the chat UI\\r\\n\\r\\n![Azure Copilot](../../static/img/60-days-of-ia/blogs/2024-03-11/copilot-architecture.png) \\r\\n\\r\\nThe figure shows the high-level application architecture for [building generative AI applications using custom code with Azure AI](https://www.youtube.com/watch?v=UbJg7RNLi7E), where the **App** represents the front-end component and the blue box encloses the components of the **Copilot** implementation exposed through the managed online endpoint (API). The copilot experience now involves the following steps:\\r\\n - The user (customer) asks a question from the chat UI (web app)\\r\\n - The web app sends the question to the chat API (copilot endpoint)\\r\\n - The chat API invokes our custom Python code (chat function) which:\\r\\n    - converts the user question (prompt) into a machine-friendly format (vector)\\r\\n    - uses the vectorized prompt to find matches in our custom data (search index)\\r\\n    - combines the user question with custom results for an enhanced prompt\\r\\n    - sends this prompt to the chat model to get the completion (answer)\\r\\n - The chat API now returns the answer as a response to the chat UI request\\r\\n\\r\\nTo build this workflow requires us to complete the following steps:\\r\\n 1. Provision the necessary resources on Azure\\r\\n 1. Create the search index using our custom data\\r\\n 1. Deploy chat and embedding models for use by the chat function\\r\\n 1. Configure connections between chat function and models, resources\\r\\n 1. Write the code to _orchestrate_ the steps for the chat function\\r\\n 1. Deploy our chat function to expose the API endpoint online\\r\\n 1. Integrate the API endpoint with our front-end application for usage\\r\\n\\r\\nFrom an LLM Ops perspective, we also need to consider two additional steps:\\r\\n 1. Evaluation of the chat function using sample data - to assess quality\\r\\n 1. Automation of the workflow steps - for iteration and operationalization\\r\\n\\r\\nThis is a non-trivial set of requirements for building, running, evaluating, and deploying a generative AI application. Thankfully, the Azure AI platform and related ecosystem of tools and services, helps streamline the process for developers - allowing us to focus on our chat function logic and user experience.\\r\\n\\r\\n## 5 | The Week Ahead!\\r\\n\\r\\nIn the upcoming week, we\'ll dive into the implementation details of these processes in the context of a signature reference sample (Contoso Chat) and as quickstart templates that showcase usage with popular frameworks. Here\'s what we\'ll cover:\\r\\n- [**Day 1:**](https://azure.github.io/Cloud-Native/60DaysOfIA/build-contoso-chat-end-to-end) Build the Contoso Chat app on Azure AI (end-to-end reference sample)\\r\\n- **Day 2:** Build a Copilot app on Azure AI with the Python SDK (quickstart)\\r\\n- **Day 3:** Build a Copilot app on Azure AI with promptflow (framework)\\r\\n- **Day 4:** Build a Copilot app on Azure AI with LangChain (framework)\\r\\n- **Day 5:** Deploy your Copilot app responsibly on Azure AI (advanced topics)"},{"id":"build-contoso-chat-end-to-end","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/build-contoso-chat-end-to-end","source":"@site/blog-60daysofIA/2024-03-11/build-contoso-chat-end-to-end.md","title":"4.1 Build Contoso Chat End-to-End","description":"Building generative AI applications poses new challenges for streamlining end-to-end application development - from prompt engineering, to LLM Ops. In this post we introduce Contoso Chat, a sample application for building a copilot with your data - using the Azure AI platform with prompt flow.","date":"2024-03-11T09:01:00.000Z","formattedDate":"March 11, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":9.93,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-03-11T09:01","slug":"build-contoso-chat-end-to-end","title":"4.1 Build Contoso Chat End-to-End","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["promptflow","azure","aistudio","generativeai","e2e","llmops"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"Building generative AI applications poses new challenges for streamlining end-to-end application development - from prompt engineering, to LLM Ops. In this post we introduce Contoso Chat, a sample application for building a copilot with your data - using the Azure AI platform with prompt flow.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"4. Fuel Your Intelligent Apps with Azure AI","permalink":"/Cloud-Native/60DaysOfIA/fuel-your-intelligent-apps-with-azure-ai"},"nextItem":{"title":"4.2 Build A Copilot Code-First with the Azure AI Python SDK","permalink":"/Cloud-Native/60DaysOfIA/build-a-copilot-code-first-with-the-azure-ai-python-sdk"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/build-contoso-chat-end-to-end\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"Building generative AI applications poses new challenges for streamlining end-to-end application development - from prompt engineering, to LLM Ops. In this post we introduce Contoso Chat, a sample application for building a copilot with your data - using the Azure AI platform with prompt flow.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/build-contoso-chat-end-to-end\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"Building generative AI applications poses new challenges for streamlining end-to-end application development - from prompt engineering, to LLM Ops. In this post we introduce Contoso Chat, a sample application for building a copilot with your data - using the Azure AI platform with prompt flow.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/build-contoso-chat-end-to-end\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n**Welcome to Day 1\ufe0f\u20e3 of Azure AI week on ##60Days Of IA** \\r\\n\\r\\nIn today\'s post, we\'ll introduce you to the [Contoso Chat](https://aka.ms/aitour/contoso-chat) sample - a comprehensive end-to-end reference sample that walks you through the journey of building the customer support AI application we talked about in our kickoff post yesterday. By the end of this tutorial, you will be able to:\\r\\n - explain how to build a copilot app end-to-end on Azure AI\\r\\n - explain what Retrieval Augmented Generation does for copilot apps\\r\\n - explain what prompt flow is and how it streamlines your workflow\\r\\n - describe the Azure AI platform and Azure AI SDK capabilities\\r\\n\\r\\n_Ready? Let\'s go!_\\r\\n\\r\\n## What You\'ll Learn Today\\r\\n * **Contoso Chat Sample**: Building a copilot with Azure AI and Prompt flow\\r\\n * **Retrieval Augmented Generation**: Design pattern for using custom data\\r\\n * **Prompt flow**: Open-source tooling for orchestrating end-to-end workflow\\r\\n * **Azure resources**: Provisioning Azure for the Contoso Chat AI project\\r\\n * **Hands-on lab**: Step-by-step tutorial to build & deploy Contoso Chat\\r\\n * **Exercise**: [_Fork the sample_](https://aka.ms/aitour/contoso-chat) then work through the hands-on tutorial.\\r\\n * **Resources**: [_Explore this collection_](https://aka.ms/ai-studio/collection?ocid=buildia24_60days_blogs) for samples, docs and training resources.\\r\\n\\r\\n<br/>\\r\\n\\r\\n![Build Contoso Chat - from prompt-engineering to LLM Ops](../../static/img/60-days-of-ia/blogs/2024-03-11/banner.png)\\r\\n\\r\\n---\\r\\n\\r\\n## Contoso Chat Sample\\r\\n\\r\\nThe [Contoso Chat](https://aka.ms/aitour/contoso-chat) sample provides a comprehensive end-to-end reference example for using Azure AI Studio and Prompt flow, to build a copilot application end-to-end. The sample implements a _customer support chat AI_ experience - allowing customers on the Contoso Outdoors website to ask questions about related products and receive relevant responses based on their query and purchase history. The illustrated guide below gives you a high-level overview of the steps involved in building the application - from provisioning Azure resources to deploying and using the chat AI endpoint. To learn more about the application scenario, refer to our [kickoff post](https://azure.github.io/Cloud-Native/60DaysOfIA/fuel-your-intelligent-apps-with-azure-ai) for this week.\\r\\n\\r\\n![Sketchnote](../../static/img/60-days-of-ia/blogs/2024-03-11/contoso-chat-sketchnote.png)\\r\\n\\r\\n## RAG Design Pattern\\r\\n\\r\\nOur first step is to define the application architecture for Contoso Chat. We know we want to have our copilot _grounded in our data_ so that customer queries return responses that reflect the product catalog or customer purchase history.\\r\\n\\r\\nThe challenge is that Large Language Models (LLM) are trained on massive datasets so the default responses may not be _relevant_ or _accurate_ with respect to your data. This is where prompt engineering and design patterns like Retrieval Augmented Generation (RAG) come in. RAG is a design pattern that uses an information _retrieval_ component to get data relevant to the user prompt, then _augments_ the prompt with that context before sending it to the LLM, as illustrated below.\\r\\n\\r\\n![RAG](../../static/img/60-days-of-ia/blogs/2024-03-11/rag.png)\\r\\n\\r\\nWe can break down the workflow into the following steps:\\r\\n 1. User asks a question (\\"User prompt\\")\\r\\n 1. The question is sent to an information retrieval component (\\"AI Search\\")\\r\\n 1. This vectorizes the query (\\"Embedding Model\\")\\r\\n 1. And uses the vector to retrieve relevant results (\\"Product Index\\")\\r\\n 1. Results are used to augment User prompt (\\"Model prompt\\")\\r\\n 1. The enhanced prompt is sent to the LLM (\\"Chat completion\\")\\r\\n\\r\\nThe answer is then returned to the user, who now sees a response that is more relevant to the products in your catalog, and personalized to their purchase history. Note that this basic copilot workflow requires us to deploy two large language models:\\r\\n 1. Text-Embedding model (e.g., `text-embedding-ada-002`) that vectories the user query \\r\\n 1. Text-Generation model (e.g., `gpt-35-turbo`) that generates the final response\\r\\n\\r\\n## Prompt flow Orchestration\\r\\n\\r\\nImplementing the RAG pattern requires a number of interactions between the language model deployments and the data sources used (e.g., search index for products, cusomer database for purchase history), and _coordination_ of intermediate steps before the final response can be delivered. This is where frameworks like Prompt flow, LangChain and Semantic kernel come in.\\r\\n\\r\\n\\r\\nThe Contoso Chat sample makes extensive use of Prompt flow - an [open-source project](https://github.com/microsoft/promptflow) on GitHub, with its own SDK and VS Code extension. Prompt flow provides a comprehensive solution that simplifies the process of prototyping, experimenting, iterating, and deploying your AI applications. It is [recommended for use as a feature within Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/how-to/prompt-flow?ocid=buildia24_60days_blogs), making it a natural first choice for building our Contoso Chat application. The figure shows a high-level architecture diagram showcasing the Azure components used with Prompt flow as the orchestration layer.\\r\\n\\r\\n![Prompt Flow Architecture](../../static/img/60-days-of-ia/blogs/2024-03-11/contoso-chat-flow.png)\\r\\n\\r\\nWith Prompt flow, your application is defined as a a directed acyclic graph of _nodes_ (`flow.dag.yaml`) that connect _input_ (prompt) and final _output_ (response) - with intermediate nodes implemented as Python _functions_ (tools) that process or transform the data flowing through them. The Prompt flow extension in VS Code provides a rich _visual editor_ capability as shown below, making it easy to define, debug, run, and test, your application in a local development environment. _This view also helps us see how the RAG pattern is implemented in practice, in our copilot_.\\r\\n\\r\\n![Contoso Chat Flow](../../static/img/60-days-of-ia/blogs/2024-03-11//promptflow-visual.png)\\r\\n\\r\\n## Azure Provisioning\\r\\n\\r\\nThe Contoso Chat sample comes with a [`provision.sh`](https://github.com/Azure-Samples/contoso-chat/blob/main/provision.sh) script that will pre-provision many of the Azure resources for you, for use in the development workflow. To get started with the implementation, follow the instructions in the [README](https://github.com/Azure-Samples/contoso-chat/blob/main/README.md) file in the repo by doing the following:\\r\\n 1. [Fork the sample](https://github.com/Azure-Samples/contoso-chat/fork) to your own GitHub account\\r\\n 2. [Setup development environment](https://github.com/Azure-Samples/contoso-chat/blob/main/README.md#3-development-environment) using GitHub Codespaces\\r\\n 3. [Authenticate](https://github.com/Azure-Samples/contoso-chat/tree/main#41-authenticate-with-azure) with your Azure subscription\\r\\n 4. [Run the Provisioning script](https://github.com/Azure-Samples/contoso-chat/tree/main#42-run-provisioning-script) and verify your setup is complete\\r\\n\\r\\nAt this point, you should have an Azure resource group created for your project with the following resources created for your application. Note that in order to complete this step, you must have a valid Azure subscription that has been given access to the relevant Azure OpenAI services. You must also have available quota for model deployments in the specific regions that we use in the provisioning script.\\r\\n\\r\\n![Provisioning Azure](../../static/img/60-days-of-ia/blogs/2024-03-11//provision-azure.png)\\r\\n\\r\\n## Hands-on Lab\\r\\n\\r\\nYou can now complete the step-by-step tutorial in the [README](https://github.com/Azure-Samples/contoso-chat/blob/main/README.md) to build, evaluate and deploy the application. Let\'s quickly review the main steps involved in the end-to-end workflow.\\r\\n\\r\\n| Stage | Description |\\r\\n|:---|:---|\\r\\n| 1. Build a Copilot. | Get familiar with the application codebase. Check out the `data/` folder to see the data we will be using for customer order (history) and product catalog (index). |\\r\\n| 2. Provision Azure. | Run the `./provision.sh` script or manually provision the required resources. This should setup an Azure AI hub (manage), an Azure AI project (build), an Azure Cosmos DB resource  (customer data) and an Azure AI Search resource (product index). Verify you have a `config.json` created (for local Azure configuration) and an `.env` file (for relevant keys and endpoints for access). |\\r\\n| 3. Add Models & Data. | The provisioning script does the model deployments - but review them now. Make sure you have a chat completion model (gpt-35-turbo), a chat evaluation model (gpt-4) and a text-embeddings model (text-embedding-ada-02). Use the provided notebooks to populate the data in Azure Cosmos DB and Azure AI Search. |\\r\\n| 4. Add Connections | The `devcontainer` configuration ensures you have the Prompt flow extension installed in VS Code, and the `pf` too for command-line, by default. Use the provided notebooks to setup _connection configurations_ from prompt flow to key services (Azure OpenAI, Azure AI Search, Azure Cosmos DB) for use in related notes of the prompt flow graph. Use the `pf` tool to validate these were setup correctly (on VS Code). The provision script may have setup some of these for you in the cloud (Azure) for use in later stages (deploy) - take a minute to verify and correct these as described in README. |\\r\\n| 5. Build Prompt Flow| You are all set to run the prompt flow with your data in Azure.  Explore the components of the prompt flow. Click the _stylized P_ icon in the sidebar to see the Prompt Flow extension activity menu. Open the `contoso-chat/flow.dag.yaml` file in VS Code, then click the _Visual Editor_ option to see the view shown in the earlier screeshot above. Run it to validate it works - then explore the nodes, outputs and code.|\\r\\n| 6. Evaluate Prompt Flow| You can complete a local evaluation by opening the relevant notebook and running it _cell-by-cell_. Review the code in each cell of the notebook, then analyze the output to understand what the relevant metrics are telling you about the quality of the basic flow. The _batch run_ step takes a while and requires Azure connection setup so consider that an optional step. Switch periodically to the _Azure AI Studio_ website view to see how the relevant Azure AI project pages are updated to show the status of various activities or configurations. |\\r\\n| 7. Deploy Prompt Flow| Deploying the prompt flow is a 2-step process. First, we need to upload the flow (code, assets) to Azure AI Studio. Do this using the provided notebook, or you can try to do this manually using the _import_ option in Azure AI Studio under the _Prompt Flow_ section. Once uploaded, you need to select a runtime (\\"automatic\\") and start it to get a compute instance provisioned to execute your flow. Use that to _test_ that your flow was imported successfully. Then click the _Deploy_ option to deploy the flow. This will take a while - refresh the _Deployments_ page to get updates. Once deployment is successful, use the built-in testing feature to try a simple question against the hosted API endpoint. **Congratulations** Your chat AI endpoint is ready for use! |\\r\\n| 8. Summary & Clean up | This was a lot. Note that almost every step of this process can be achieved using code (SDK), command-line (CLI) or UI (Studio website) so explore the documentation. _Note that Azure AI Studio is in preview_ so the features are constantly evolving and things may break unexpectedly - send feedback if so! Finally, don\'t forget to **delete your codespaces and your Azure resources for this lab** to avoid unnecessary charges. And watch the sample repo for updates on workshop content and exercises to extend this further. |\\r\\n| | |\\r\\n\\r\\nCompleting this workshop can take 60-90 minutes based on your level of familiarity with the tools. In the _next_ blog post, we\'ll dive a bit deeper into the process with specific focus on the **Azure AI SDK** to understand _how_ you can implement core steps of the workflow from your Python application. And, in the _final_ post of this week, we\'ll return to the Contoso Chat sample to explore deployment and evaluation in more detail - with additional guidance for ensuring responsible AI usage in your generative AI applications.\\r\\n\\r\\n\\r\\n## Exercise\\r\\n\\r\\nCongratulations! You made it to the end of this whirlwind tour of the Contoso Chat sample. Now it\'s time for you to do the hard work of building this yoursel!! Start by [_forking the sample_](https://aka.ms/aitour/contoso-chat) - then follow the step-by-step instructions in the README.\\r\\n\\r\\n\\r\\n## Resources\\r\\n\\r\\nWe\'ve referenced a number of links and samples in this post. Bookmark the [_Azure AI Studio: Code-First Collection_](https://aka.ms/ai-studio/collection?ocid=buildia24_60days_blogs) and revisit it regularly for an updated list of resources for code-first development of generative AI applications on Azure."},{"id":"build-a-copilot-code-first-with-the-azure-ai-python-sdk","metadata":{"permalink":"/Cloud-Native/60DaysOfIA/build-a-copilot-code-first-with-the-azure-ai-python-sdk","source":"@site/blog-60daysofIA/2024-03-12/build-a-copilot-code-first-with-the-azure-ai-python-sdk.md","title":"4.2 Build A Copilot Code-First with the Azure AI Python SDK","description":"Have a generative AI application you want to build, but don\'t know where to start? In this blog post, we introduce the Azure AI Studio Python Quickstart Sample, explain the end-to-end development workflow, then show you how you can get started customizing it, to explore your own application requirements.","date":"2024-03-12T09:00:00.000Z","formattedDate":"March 12, 2024","tags":[{"label":"Build-Intelligent-Apps","permalink":"/Cloud-Native/60DaysOfIA/tags/build-intelligent-apps"},{"label":"60-days-of-IA","permalink":"/Cloud-Native/60DaysOfIA/tags/60-days-of-ia"},{"label":"learn-live","permalink":"/Cloud-Native/60DaysOfIA/tags/learn-live"},{"label":"hack-together","permalink":"/Cloud-Native/60DaysOfIA/tags/hack-together"},{"label":"community-buzz","permalink":"/Cloud-Native/60DaysOfIA/tags/community-buzz"},{"label":"ask-the-expert","permalink":"/Cloud-Native/60DaysOfIA/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-kubernetes-service"},{"label":"azure-functions","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-functions"},{"label":"azure-openai","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-openai"},{"label":"azure-container-apps","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-container-apps"},{"label":"azure-cosmos-db","permalink":"/Cloud-Native/60DaysOfIA/tags/azure-cosmos-db"},{"label":"github-copilot","permalink":"/Cloud-Native/60DaysOfIA/tags/github-copilot"},{"label":"github-codespaces","permalink":"/Cloud-Native/60DaysOfIA/tags/github-codespaces"},{"label":"github-actions","permalink":"/Cloud-Native/60DaysOfIA/tags/github-actions"}],"readingTime":11.26,"hasTruncateMarker":false,"authors":[{"name":"#60Days Of IA","title":"BuildIA Content Team","url":"https://azure.github.io/Cloud-Native/Build-IA/","imageURL":"https://azure.github.io/Cloud-Native/img/logo-2024.png","key":"cnteam"}],"frontMatter":{"date":"2024-03-12T09:00","slug":"build-a-copilot-code-first-with-the-azure-ai-python-sdk","title":"4.2 Build A Copilot Code-First with the Azure AI Python SDK","authors":["cnteam"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","azureai","copilot","aisdk"],"image":"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png","description":"Have a generative AI application you want to build, but don\'t know where to start? In this blog post, we introduce the Azure AI Studio Python Quickstart Sample, explain the end-to-end development workflow, then show you how you can get started customizing it, to explore your own application requirements.","tags":["Build-Intelligent-Apps","60-days-of-IA","learn-live","hack-together","community-buzz","ask-the-expert","azure-kubernetes-service","azure-functions","azure-openai","azure-container-apps","azure-cosmos-db","github-copilot","github-codespaces","github-actions"]},"unlisted":false,"prevItem":{"title":"4.1 Build Contoso Chat End-to-End","permalink":"/Cloud-Native/60DaysOfIA/build-contoso-chat-end-to-end"}},"content":"<head> \\r\\n  <meta property=\\"og:url\\" content=\\"https://azure.github.io/cloud-native/60daysofia/build-a-copilot-code-first-with-the-azure-ai-python-sdk\\"/>\\r\\n  <meta property=\\"og:type\\" content=\\"website\\"/> \\r\\n  <meta property=\\"og:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\"/> \\r\\n  <meta property=\\"og:description\\" content=\\"Have a generative AI application you want to build, but don\'t know where to start? In this blog post, we introduce the Azure AI Studio Python Quickstart Sample, explain the end-to-end development workflow, then show you how you can get started customizing it, to explore your own application requirements.\\"/> \\r\\n  <meta property=\\"og:image\\" content=\\"https://github.com/Azure/Cloud-Native/blob/main/website/static/img/ogImage.png\\"/> \\r\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/60daysofIA/build-a-copilot-code-first-with-the-azure-ai-python-sdk\\" /> \\r\\n  <meta name=\\"twitter:title\\" content=\\"Build Intelligent Apps | AI Apps on Azure\\" />\\r\\n <meta name=\\"twitter:description\\" content=\\"Have a generative AI application you want to build, but don\'t know where to start? In this blog post, we introduce the Azure AI Studio Python Quickstart Sample, explain the end-to-end development workflow, then show you how you can get started customizing it, to explore your own application requirements.\\" />\\r\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/img/ogImage.png\\" /> \\r\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" /> \\r\\n  <meta name=\\"twitter:creator\\" content=\\"@devanshidiaries\\" /> \\r\\n  <link rel=\\"canonical\\" href=\\"https://azure.github.io/Cloud-Native/60daysofIA/build-a-copilot-code-first-with-the-azure-ai-python-sdk\\" /> \\r\\n</head> \\r\\n\\r\\n\x3c!-- End METADATA --\x3e\\r\\n\\r\\n**Welcome to Day 2\ufe0f\u20e3 of the Azure AI week on #60Days Of IA** \\r\\n\\r\\nLet\'s recap what we learned so far. In our _kickoff_ post we set the stage by describing our application scenario (Contoso Chat), the paradigm shift for generative AI apps (LLM Ops) and the unified platform for streamlining development (Azure AI Studio). In the next post we walked through the signature [Contoso Chat](https://aka.ms/aitour/contoso-chat) application sample to understand how we can implement that scenario using Azure AI Studio and Prompt flow - from building the chat function, to evaluating it, deploying it to a hosted endpoint, then testing that API in a chat client.\\r\\n\\r\\nBut what if you want to get started building your own application scenario? Over the next three posts, we\'ll look at _starter samples_ that will get you from ideation (define chat function) to operationalization (deploy chat API) using different tools and frameworks to simplify orchestration.\\r\\n\\r\\nReady? Let\'s go!\\r\\n\\r\\n## What You\'ll Learn Today\\r\\n * What is the copilot architecture?\\r\\n * What is the Azure AI SDK?\\r\\n * What is the Quickstart sample?\\r\\n * How can I customize and extend this for my scenario?\\r\\n * **Challenge:** Fork [this quickstart](https://github.com/Azure-Samples/aistudio-python-quickstart-sample) and build it, then extend it with your data.\\r\\n * **Resources:** Bookmark [this collection](https://aka.ms/ai-studio/collection?ocid=buildia24_60days_blogs) for training & documentation.\\r\\n\\r\\n<br/>\\r\\n\\r\\n\\r\\n![Build a Copilot on Azure Code-First with Azure AI SDK](../../static/img/60-days-of-ia/blogs/2024-03-12/banner.png)\\r\\n\\r\\n---\\r\\n\\r\\n\x3c!-- ************************************** --\x3e\\r\\n\x3c!--  AUTHORS: WRITE BLOG POST CONTENT HERE --\x3e\\r\\n\x3c!-- ************************************** --\x3e\\r\\n\\r\\n\\r\\n## 1 | Learning Objectives\\r\\n\\r\\nThe [copilot ai-sdk quickstart](https://github.com/Azure-Samples/aistudio-python-quickstart-sample) is a Python-based starter sample for a code-first approach to building a copilot experience on the Azure AI platform. Since this is the foundational sample, we\'ll use it to explore some of the details of the implementation and set the stage for you to explore customizing it further for your application requirements.\\r\\n\\r\\nBy the end of this tutorial you should be able to:\\r\\n\\r\\n1. Explain the functional components of the copilot architecture\\r\\n1. Explain the Azure resources required to implement a copilot\\r\\n1. Explain the core functionality provided by the Azure AI SDK\\r\\n1. Build, run, evaluate, and deploy, a basic copilot with Azure AI Studio.\\r\\n1. Explore the Azure AI curated VS Code environment to customize the sample\\r\\n\\r\\nKeep in mind that this is a _quickstart sample_ and is **not meant for production use**. We encourage you to extend and customize the sample to understand the platform capabilities and end-to-end development workflow. Make sure to validate the responses yourself and evaluate its suitability for your application needs in context.\\r\\n\\r\\n## 2| Copilot Architecture\\r\\n\\r\\nLet\'s first revisit the high-level application architecture for our copilot and familiarize ourselves with the core functional components. Our goal is to **build the chat function** component and deploy it to get a hosted **Copilot API** endpoint that we can integrate into front-end applications to provide a conversational chatbot capability grounded in our data.\\r\\n![Copilot architecture](../../static/img/60-days-of-ia/blogs/2024-03-12/copilot-architecture.png)\\r\\n\\r\\nLet\'s review what we will need to implement this architecture:\\r\\n\\r\\n1. **Model Deployments** - we need deployed models for chat and embeddings.\\r\\n1. **Search Index** - we need a search index populated with our product data.\\r\\n1. **Azure Resources** - we need to setup and configure our Azure AI project.\\r\\n1. **App Evaluation** - we need to evaluate copilot quality for responsible AI.\\r\\n1. **App Deployment** - we need to deploy the copilot for a hosted API endpoint.\\r\\n\\r\\nThe [copilot ai-sdk quickstart](https://github.com/Azure-Samples/aistudio-python-quickstart-sample) provides a starter codebase that implements this chat function using the Retrieval Augmented Generation (RAG) pattern with custom data. The implementation makes use of Azure AI Studio and the [Azure AI SDK (Python)](https://aka.ms/aistudio/docs/sdk?ocid=buildia24_60days_blogs) for a code-first approach. Since these technologies are currently in preview, we expect the sample to keep evolving quickly and **recommend following the README-based tutorial there** for the latest instructions.\\r\\n\\r\\n## 3 | Azure AI SDK\\r\\n\\r\\nBefore we dive into the sample, let\'s take a moment to learn about the [Azure AI SDK for Python (preview)](https://learn.microsoft.com/python/api/overview/azure/ai?view=azure-python-preview?ocid=buildia24_60days_blogs). The SDK consists of two packages:\\r\\n - [azure-ai-generative](https://pypi.org/project/azure-ai-generative/) - which provides the functionality needed for building, evaluating and deploying Generative AI applications. This has extra packages (index, evaluate, promptflow) you can use for enhanced local development capabilities - or optionally, remove if unused.\\r\\n - [azure-ai-resources](https://pypi.org/project/azure-ai-resources/) - which provides the functionality for connecting to, and managing, your Azure AI projects and resources. Use this for control plane operations to create and manage data, indexes, models and deployments.\\r\\n\\r\\nThe generative package makes use of the resources package to [create an `AIClient` instance](https://learn.microsoft.com/azure/ai-studio/how-to/sdk-generative-overview#connecting-to-projects?ocid=buildia24_60days_blogs) that can be used for connecting to the Azure AI project resources.\\r\\n\\r\\n```python\\r\\nfrom azure.ai.resources.client import AIClient\\r\\nfrom azure.identity import DefaultAzureCredential\\r\\n\\r\\nai_client = AIClient(\\r\\n    credential=DefaultAzureCredential(),\\r\\n    subscription_id=\'subscription_id\',\\r\\n    resource_group_name=\'resource_group\',\\r\\n    project_name=\'project_name\'\\r\\n)\\r\\n```\\r\\n\\r\\nOnce connected, you can use the generative package to build an index, run a local evaluation, or deploy chat functions and prompt flows, using the imports shown:\\r\\n\\r\\n```python\\r\\nfrom azure.ai.generative.index import build_index\\r\\nfrom azure.ai.generative.evaluate import evaluate\\r\\nfrom azure.ai.resources.entities.deployment import Deployment\\r\\n```\\r\\n\\r\\nTo get started, you will need to [install the SDK](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/sdk-install?ocid=buildia24_60days_blogs) in your local development environment. When you use the quickstart sample with GitHub Codespaces or the Azure AI curated VS Code environment, the SDK comes pre-installed and ready to use. \\r\\n\\r\\n## 4 | Using the Quickstart Sample\\r\\n\\r\\nThe [copilot ai-sdk quickstart](https://github.com/Azure-Samples/aistudio-python-quickstart-sample) provides a comprehensive **README.md** document that describes the step-by-step process for building, running, evaluating, and deploying, a starter copilot sample.\\r\\n\\r\\n### 4.1 | Pre-Requisites\\r\\n\\r\\nTo get started, you will need an active Azure subscription and have access to the Azure OpenAI service to create and deploy the required models for chat completion, chat evaluation and embedddings. You will also need a GitHub account. \\r\\n\\r\\n### 4.2 | Setup Dev Environment\\r\\n\\r\\nThe fastest way to get started exploring the sample is to fork the repo to your personal profile, then launch GitHub Codespaces by navigating to the \\"Codespaces\\" tab under the \\"Code\\" dropdown and creating a new codespace. Active codespaces are listed as shown below. \\r\\n\\r\\n![Launch](../../static/img/60-days-of-ia/blogs/2024-03-12/01-launch-codespaces.png)\\r\\n\\r\\nOnce the Codespace is ready, you will see the Visual Studio Code editor view in your browser tab. Open the **README.md** in the editor, then follow the instructions to complete the tutorial.\\r\\n\\r\\n![Run](../../static/img/60-days-of-ia/blogs/2024-03-12/03-running-codespaces.png)\\r\\n\\r\\n### 4.3 | Initialize Azure AI Resources\\r\\n\\r\\nTo build the copilot, we need to provision the Azure resources listed below. \\r\\n - An [Azure AI hub resource](https://learn.microsoft.com/azure/ai-studio/concepts/ai-resources?ocid=buildia24_60days_blogs) to provide a working _team_ environment and manage resource access, billing and more.\\r\\n - An [Azure AI project resource](https://learn.microsoft.com/azure/ai-studio/how-to/create-projects?ocid=buildia24_60days_blogs) to organize the data, models, and deployments for _an application_, and save its state for future use.\\r\\n - An [Azure AI Search resource](https://learn.microsoft.com/en-us/azure/search/?ocid=buildia24_60days_blogs) to host the search index for our product data.\\r\\n - An [Azure OpenAI resource](https://learn.microsoft.com/azure/openai?ocid=buildia24_60days_blogs) to deploy the models for chat completion, chat evaluation and embeddings.\\r\\n\\r\\nFor now, we will be creating these resources from the [Azure AI Studio UI](https://ai.azure.com?ocid=buildia24_60days_blogs) and [Azure Portal](https://portal.azure.com?ocid=buildia24_60days_blogs) UI in the browser. However, we expect future support for a command-line (CLI) based approach for efficiency and automation. Refer to the sample README for the step-by-step guidance.\\r\\n\\r\\n### 4.4 | Initialize Azure Configuration\\r\\n\\r\\nOnce we\'ve created the Azure resources, we need to configure our Visual Studio Code environment to connect to the cloud.  The repo comes with a `config.sample.json` that shows you the properties that need to be configured. The easiest way to set these is to download the `config.json` file from your Azure AI project resource and place it in the root folder. This information is then used to initialize the`AIClient` in the code, to support interactions with those resources, as explained earlier.\\r\\n\\r\\n```json\\r\\n{\\r\\n    \\"subscription_id\\": \\"your_subscription_id\\",\\r\\n    \\"resource_group\\": \\"your_resource_group\\",\\r\\n    \\"project_name\\": \\"your_project_name\\"\\r\\n}\\r\\n```\\r\\n\\r\\n### 4.5 | Configure Environment Variables\\r\\n\\r\\nThe codebase comes with a sample `.env.sample` file that shows the environment variables you will need to configure, to run the sample. Copy this to `.env` then replace the placeholder strings with the values from the respective Azure resources you provisioned earlier. These environment variables will be used by the Azure AI SDK, to connect to relevant services (by endpoint) with required authentication (key) when implementing the chat function.\\r\\n\\r\\n```bash\\r\\nAZURE_SUBSCRIPTION_ID=replace_with_azure_subscription_id\\r\\nOPENAI_API_TYPE=azure\\r\\nOPENAI_API_KEY=replace_with_openai_key\\r\\nOPENAI_API_BASE=replace_with_openai_base\\r\\nOPENAI_API_VERSION=replace_with_openai_version\\r\\nAZURE_AI_SEARCH_ENDPOINT=replace_with_aisearch_target\\r\\nAZURE_AI_SEARCH_KEY=replace_with_aisearch_key\\r\\nAZURE_AI_SEARCH_INDEX_NAME=replace_with_aisearch_index_name\\r\\nAZURE_OPENAI_CHAT_MODEL=gpt-35-turbo-16k\\r\\nAZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo-16k-0613\\r\\nAZURE_OPENAI_EVALUATION_MODEL=gpt-35-turbo-16k\\r\\nAZURE_OPENAI_EVALUATION_DEPLOYMENT=\\"gpt-35-turbo-16k-0613\\"\\r\\nAZURE_OPENAI_EMBEDDING_MODEL=text-embedding-ada-002\\r\\nAZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-ada-embedding-002-2\\r\\n```\\r\\n\\r\\n### 4.6 | Explore Custom Data\\r\\n\\r\\nAt this point, the base system configuration is done and we just need to populate the data (for the search index) and then run, evaluate, and iterate, the chat function till the response quality is acceptable. Let\'s take a minute to explore the codebase `data/` folder to see the sample data we provide in the starter. We only use the product catalog data (to build the index) in _this_ sample but you can explore usage of the other data types for advanced features or integrations later.\\r\\n\\r\\n| Data Folder | Data Description |\\r\\n| --- | --- |\\r\\n| `data/0-misc` | General information - e.g., customer policies for org. |\\r\\n| `data/1-customer-info`| Customer purchase records  - for 13 fictional customers |\\r\\n| `data/2-chat-history`| Customer conversation history - for a subset of customers |\\r\\n| `data/3-product-info` | Product catalog data - for 20 items in 7 categories |\\r\\n| `data/4-scores` | Test data - for use in evaluations  |\\r\\n| `data/5-prompt-templates` | Example templates - for different contexts |\\r\\n\\r\\n### 4.7 | Explore The Codebase\\r\\n\\r\\nHere are the main files you need to be aware of:\\r\\n\\r\\n| File | Description |\\r\\n| --- | --- |\\r\\n| `src/run.py` | The main entry point for executing core operations |\\r\\n| `src/streaming_utils.py` | Functions for use in interactive conversation |\\r\\n| `src/copilot_aisdk/chat.py` | The chat function implementation. |\\r\\n| `src/system-message.jinja2` | The prompt template with system context (assistant) |\\r\\n\\r\\nYou can now execute the various steps of the end-to-end workflow as follows:\\r\\n- `python src/run.py --build-index` - to build the search index\\r\\n- `python src/run.py --question \\"which tent is the most waterproof?\\"` - to test the chat function\\r\\n- `python src/run.py --evaluate` - to evaluate the chat function\\r\\n- `python src/run.py --deploy` - to deploy the chat function\\r\\n- `python src/run.py --invoke` - to test the deployed chat API endpoint\\r\\n\\r\\nNote that the exact syntax and parameters used in these commands may evolve over time - so check the README in the sample for the latest instructions.\\r\\n\\r\\n### 4.8 | Explore The Chat Function\\r\\n\\r\\nLet\'s briefly talk about the custom code for the copilot, found in the `src/chat.py` file. \\r\\n- The main entry point is the `chat_completion` function that takes a list of messages representing the conversation history.\\r\\n- The `get_documents` function extracts the last message (\\"user question\\") and uses it to retrieve relevant search results using the OpenAI embeddings model and the Azure AI Search client respectively, in a _retrieval augmented generation_ (RAG) pattern.\\r\\n- The `chat_completion` function then takes the returned response and crafts an enhanced prompt (with the system context template, initial user message, and returned search results) and sends the request to the OpenAI chat model for completion.\\r\\n- The returned response is then returned to the user either interactively, or by adding it to the conversation thread (in stream mode).\\r\\n\\r\\n## 5 | Operationalization\\r\\n\\r\\nThe starter sample provides a simple sequence of command-line operations to build, run, evaluate, deploy, and test, the chat function. However, in a real-world scenario, you would integrate the deployed app with a front-end chat UI (like the Contoso Outdoors website) - and use the Azure AI Studio platform to further evaluate the chat function (batch runs), configure content filters (content safety), and monitor usage (performance) for iterative improvement. We\'ll discuss some of these tools and practices in the final post of this series.\\r\\n\\r\\n\\r\\n## 6 | Customizing the Sample\\r\\n\\r\\nThe quickstart sample is a great starting point for exploring your own application scenarios using your own data. Note that the sample is not designed for production use - you will need to do your own validation and evaluation of responses to determine if the chat function is suitable for your application needs. \\r\\n\\r\\nHowever, this is a great time to introduce you to the _cloud development environment_ provided by the [Azure AI curated Visual Studio Code environment](https://learn.microsoft.com/azure/ai-studio/how-to/develop-in-vscode?ocid=buildia24_60days_blogs).This allows you to open your fork of the sample directly from Azure AI Studio, creating a compute instance with a development environment that has the Azure AI SDK and other dependencies pre-installed. Watch this video from the Azure AI Studio team to see how that works - then replicate the process to jumpstart your application exploration journey. \\r\\n\\r\\n<iframe width=\\"600\\" height=\\"400\\" src=\\"https://www.youtube.com/embed/UbJg7RNLi7E\\" title=\\"Build generative AI applications using custom code with Azure AI\\" frameborder=\\"0\\" allowfullscreen></iframe>\\r\\n\\r\\n## Resources\\r\\n\\r\\nWe\'ve referenced a number of links and samples in this post. Bookmark the [_Azure AI Studio: Code-First Collection_](https://aka.ms/ai-studio/collection?ocid=buildia24_60days_blogs) and revisit it regularly for an updated list of resources for code-first development of generative AI applications on Azure."}]}')}}]);