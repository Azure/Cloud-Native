"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[83508],{91650:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"29-awesome-azd","metadata":{"permalink":"/Cloud-Native/blog/29-awesome-azd","source":"@site/blog/2022-10-06/index.md","title":"Oct | `awesome-azd` Templates","description":"What\'s new in Azure Developer CLI October 2022 release?","date":"2022-10-06T00:00:00.000Z","formattedDate":"October 6, 2022","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/blog/tags/cloud-native"},{"label":"devtools","permalink":"/Cloud-Native/blog/tags/devtools"},{"label":"hacktoberfest","permalink":"/Cloud-Native/blog/tags/hacktoberfest"},{"label":"azure-developer-cli","permalink":"/Cloud-Native/blog/tags/azure-developer-cli"}],"readingTime":4.665,"hasTruncateMarker":false,"authors":[{"name":"Savannah Ostrowski","title":"Senior Product Manager @Microsoft","url":"https://twitter.com/savostrowski","imageURL":"https://github.com/savannahostrowski.png","key":"savannah"}],"frontMatter":{"slug":"29-awesome-azd","title":"Oct | `awesome-azd` Templates","authors":["savannah"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","serverless","devtools","azd"],"image":"./img/banner.png","description":"What\'s new in Azure Developer CLI October 2022 release?","tags":["cloud-native","devtools","hacktoberfest","azure-developer-cli"]},"nextItem":{"title":"Serverless September - In a Nutshell","permalink":"/Cloud-Native/blog/serverless-status-post"}},"content":"\x3c!-- FIXME --\x3e\\n<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/29-awesome-azd\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Cloud to Community with `awesome-azd`\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Cloud to Community with `awesome-azd`\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@savostrowski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/29-awesome-azd\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Beyond #30DaysOfServerless!` in October!\\n\\nYes, it\'s October!! And since we ended #ServerlessSeptember with a focus on **End-to-End Development** for Serverless on Azure, we thought it would be good to share updates in October that can help you skill up even further.\\n\\nToday, we\'re following up on the **[Code to Cloud with `azd`](./../2022-09-29/index.md)** blog post (Day #29) where we introduced the Azure Developer CLI (`azd`), an open-source tool for streamlining your end-to-end developer experience going from local development environment to Azure cloud. In today\'s post, we celebrate the _October 2022_ release of the tool, with three cool new features. \\n\\nAnd if it\'s October, it must be **#Hacktoberfest**!! Read on to learn about how you can take advantage of one of the new features, to contribute to the `azd` open-source community and ecosystem!\\n\\nReady? Let\'s go!\\n\\n---\\n\\n## What We\'ll Cover\\n * **Azure Friday**: Introducing the Azure Developer CLI (Video)\\n * **October 2022 Release**: What\'s New in the Azure Developer CLI? \\n    * **Azure Pipelines for CI/CD**: [Learn more](https://learn.microsoft.com/azure/developer/azure-developer-cli/configure-devops-pipeline?tabs=azdo)\\n    * **Improved Infrastructure as Code structure via Bicep modules:** [Learn more](https://devblogs.microsoft.com/azure-sdk/azure-developer-cli-azd-october-2022-release/#improved-infrastructure-as-code-structure-via-bicep-modules)\\n    * **A new `azd` template gallery**: The new `azd-templates` gallery for community use! [Learn more](https://devblogs.microsoft.com/azure-sdk/azure-developer-cli-azd-october-2022-release/#new-template-gallery-awesome-azd)\\n  * **Awesome-Azd**: The new `azd-templates` gallery for Community use\\n    * Features: discover, create, contribute, request - templates\\n    * Hacktoberfest: opportunities to contribute in October - and beyond!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Azure Friday\\n\\nThis post is a follow-up to our #ServerlessSeptember post on **[Code to Cloud with Azure Developer CLI](./../2022-09-29/index.md)** where we introduced `azd`, a new open-source tool that makes it quick and simple for you to move your application from a _local development environment_ to Azure, streamlining your _end-to-end developer workflow_ in the process. \\n\\nPrefer to watch a video overview? I have you covered! Check out my recent conversation with Scott Hanselman on [Azure Friday](https://learn.microsoft.com/Shows/Azure-Friday/) where we:\\n - talked about the code-to-cloud developer journey\\n - walkthrough the ins and outs of an `azd` template\\n - explored Azure Developer CLI commands in the terminal and VS Code, and\\n - (probably most importantly) got a web app up and running on Azure with a database, Key Vault and monitoring all in a couple of minutes\\n\\n<iframe width=\\"500\\" height=\\"300\\" src=\\"https://www.youtube.com/embed/VTk-FhJyo7s\\" title=\\"Introducing the Azure Developer CLI (azd) | Azure Friday\\"></iframe>\\n\\n---\\n\\n## October Release\\n\\nWe\'re pleased to announce the October 2022 release of the Azure Developer CLI (currently `0.3.0-beta.2`). Read [the release announcement](https://devblogs.microsoft.com/azure-sdk/azure-developer-cli-azd-october-2022-release/#new-template-gallery-awesome-azd) for more details. Here are the highlights:\\n  * **Azure Pipelines for CI/CD**: This addresses [azure-dev#101](https://github.com/Azure/azure-dev/issues/101), adding support for Azure Pipelines (alongside GitHub Actions) as a CI/CD provider. [Learn more](https://learn.microsoft.com/azure/developer/azure-developer-cli/configure-devops-pipeline?tabs=azdo) about usage and related documentation.\\n  * **Improved Infrastructure as Code structure via Bicep modules**: This addresses [azure-dev#543](https://github.com/Azure/azure-dev/issues/543), which recognized the complexity of using a single `resources.bicep` file for all resources. With this release, `azd` templates now come with Bicep modules organized by purpose making it easier to edit and understand. [Learn more](https://devblogs.microsoft.com/azure-sdk/azure-developer-cli-azd-october-2022-release/#improved-infrastructure-as-code-structure-via-bicep-modules) about this structure, and how to use it.\\n  * **New Templates Gallery - awesome-azd**: This addresses [azure-dev#398](https://github.com/Azure/azure-dev/issues/398), which aimed to make templates more discoverable and easier to contribute. [Learn more](https://devblogs.microsoft.com/azure-sdk/azure-developer-cli-azd-october-2022-release/#new-template-gallery-awesome-azd) about how the new gallery improves the template discovery experience.\\n\\n\\nIn the next section, we\'ll dive briefly into the last feature, introducing the new [`awesome-azd`](https://aka.ms/awesome-azd) site and resource for templates discovery and contribution. And, since it\'s #Hacktoberfest season, we\'ll talk about the **Contributor Guide** and the many ways you can contribute to this project - with, or without, code.\\n\\n---\\n\\n## It\'s `awesome-azd`\\n\\nWelcome to `awesome-azd` a new template gallery hosted on GitHub Pages, and meant to be a destination site for discovering, requesting, and contributing `azd-templates` for community use! \\n\\nIn addition, it\'s **README** reflects the [awesome-list](https://github.com/topics/awesome-list) resource format, providing a location for the community to share \\"best of\\" resources for Azure Developer CLI - from blog posts and videos, to full-scale tutorials and templates.\\n\\n * Visit the [awesome-azd Gallery](https://azure.github.io/awesome-azd/)\\n * Browse the [awesome-azd README](https://github.com/Azure/awesome-azd/blob/main/README.md)\\n\\n\\n![](./img/gallery.gif)\\n\\nThe Gallery is organized into three main areas:\\n - [Gallery](https://azure.github.io/awesome-azd/) page hosting templates.\\n - [Contributor Guide](https://azure.github.io/awesome-azd/docs/intro) with an FAQ for contributors.\\n - [Custom Issues](https://github.com/Azure/awesome-azd/issues/new/choose) for the types of contributions you can make\\n\\nTake a minute to explore the Gallery and note the features:\\n - **Search** for templates by name\\n - **Requested** Templates - indicating asks from the community\\n - **Featured** Templates - highlighting high-quality templates\\n - **Filters** - to discover templates by and/or query combinations\\n\\nCheck back often to see the latest contributed templates and requests!\\n\\n---\\n\\n## Hacktoberfest\\n\\nSo, why is this a good time to talk about the Gallery? Because October means it\'s time for [#Hacktoberfest](https://hacktoberfest.com/) - a month-long celebration of open-source projects and their maintainers, and an opportunity for **first-time contributors** to get support and guidance making their first pull-requests! Check out the [#Hacktoberfest](https://github.com/topics/hacktoberfest) topic on GitHub for projects you can contribute to.\\n\\nAnd we hope you think of `awesome-azd` as another possible project to contribute to. \\n * Explore [Custom Issues](https://azure.github.io/awesome-azd/docs/intro#our-custom-issues) for actionable ways to contribute code.\\n * Explore [Other Ways To Help](https://azure.github.io/awesome-azd/docs/intro#other-ways-to-help) for equally important non-code contributions.\\n \\nCheck out the FAQ section to learn how to [create](https://azure.github.io/awesome-azd/docs/faq/create-template), [discover](https://azure.github.io/awesome-azd/docs/faq/discover-azd), and [contribute](https://azure.github.io/awesome-azd/docs/faq/contribute-template) templates. Or take a couple of minutes to watch this video walkthrough from [Jon Gallant](https://twitter.com/jongallant):\\n\\n<iframe width=\\"350\\" height=\\"500\\" src=\\"https://www.youtube.com/embed/vJa0K0TDvdM\\" title=\\"Awesome-azd\\"></iframe>\\n\\n\\nAnd don\'t hesitate to reach out to us - either via Issues on the repo, or in the [Discussions](https://github.com/Azure/Cloud-Native/discussions) section of this site, to give us feedback!\\n\\nHappy Hacking! \ud83c\udf83\\n\\n---"},{"id":"serverless-status-post","metadata":{"permalink":"/Cloud-Native/blog/serverless-status-post","source":"@site/blog/2022-10-04/index.md","title":"Serverless September - In a Nutshell","description":"A wrap-up post from Serverless September, referencing the many initiatives and resources","date":"2022-10-04T00:00:00.000Z","formattedDate":"October 4, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"azure-event-grid","permalink":"/Cloud-Native/blog/tags/azure-event-grid"},{"label":"azure-logic-apps","permalink":"/Cloud-Native/blog/tags/azure-logic-apps"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"}],"readingTime":6.89,"hasTruncateMarker":false,"authors":[{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://github.com/devanshidiaries.png","key":"devanshi"}],"frontMatter":{"slug":"serverless-status-post","title":"Serverless September - In a Nutshell","authors":["devanshi"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","serverless","event grid","logic apps","cloudevents"],"image":"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png","description":"A wrap-up post from Serverless September, referencing the many initiatives and resources","tags":["serverless-september","azure-container-apps","dapr","azure-event-grid","azure-logic-apps","azure-functions"]},"prevItem":{"title":"Oct | `awesome-azd` Templates","permalink":"/Cloud-Native/blog/29-awesome-azd"},"nextItem":{"title":"29. Code to Cloud with `azd`","permalink":"/Cloud-Native/blog/29-azure-developer-cli"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/serverless-status-post\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ServerlessSeptember: In A Nutshell\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ServerlessSeptember: In A Nutshell\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/21-cloudevents-via-event-grid\\" />\\n</head>\\n\\n---\\n\\nIt\'s `Serverless September` in a Nutshell! Join us as we unpack our month-long learning journey exploring the core technology pillars for Serverless architectures on Azure. Then end with a look at next steps to build your Cloud-native applications on Azure.\\n\\n---\\n\\n## What We\'ll Cover\\n * Functions-as-a-Service (FaaS)\\n * Microservices and Containers\\n * Serverless Integrations\\n * End-to-End Solutions\\n * Developer Tools & #Hacktoberfest\\n\\n![Banner for Serverless September](./img/banner.png)\\n\\n---\\n\\n## Building Cloud-native Apps\\n\\nBy definition, _cloud-native technologies empower organizations to **build and run scalable applications** in modern, dynamic environments such as public, private, and hybrid clouds._ You can learn more about cloud-native in Kendall Roden\'s #ServerlessSeptember post on [Going Cloud-native with Azure Container Apps](/blog/zero2hero-aca-01).\\n\\nServeless technologies accelerate productivity and minimize costs for deploying applications at cloud scale. So, what can we build with serverless technologies in cloud-native on Azure? _Anything that is event-driven_ - examples include:\\n - **Microservices** - scaled by KEDA-compliant triggers\\n - **Public API Endpoints** - scaled by #concurrent HTTP requests\\n - **Event-Driven Applications** - scaled by length of message queue\\n - **Web Applications** - scaled by #concurrent HTTP requests\\n - **Background Process** - scaled by CPU and Memory usage\\n\\n![](./img/cloud-native.png)\\n\\nGreat - but as developers, we really want to know **_how_ we can get started building and deploying serverless solutions on Azure**. That was the focus of our #ServerlessSeptember journey. Let\'s take a quick look at the four key themes.\\n\\n\\n## Functions-as-a-Service (FaaS)\\n\\n_Functions-as-a-Service_ (FaaS) is the epitome of developer productivity for full-stack modern apps. As developers, you don\'t manage infrastructure and focus only on business logic and application code. And, with **Serverless Compute** you _only pay for when your code runs_ - making this the simplest first step to begin migrating your application to cloud-native.\\n\\nIn Azure, FaaS is provided by Azure Functions. Check out our [Functions + Serverless on Azure](./../2022-09-08/index.md) to go from learning core concepts, to building your first Functions app in your programming language of choice. Azure functions support multiple programming languages including C#, F#, Java, JavaScript, Python, Typescript, and PowerShell. \\n\\nWant to get extended language support for languages like Go, and Rust? You can [Use Custom Handlers](/blog/zero2hero-func-03) to make this happen! But what if you want to have long-running functions, or create complex workflows involving more than one function? Read our [post on Durable Entities](/blog/zero2hero-func-02) to learn how you can _orchestrate_ this with Azure Functions.\\n\\nCheck out this recent [AskTheExpert](https://aka.ms/ATEonDemand) Q&A session with the Azure Functions team to get answers to popular community questions on Azure Functions features and usage.\\n\\n<iframe src=\\"https://learn-video.azurefd.net/vod/player?show=ask-the-expert&ep=serverless-september-azure-functions\\" width=\\"600\\" height=\\"400\\"></iframe>\\n\\n## Microservices and Containers \\n\\nFunctions-as-a-Service is an ideal first step towards serverless development. But Functions are just _one of the 5 pillars_ of [cloud-native](https://azure.github.io/Cloud-Native/blog/zero2hero-aca-01). This week we\'ll look at two of the other pillars: **microservices** and **containers** - with specific focus on two core technologies: Azure Container Apps and Dapr (Distributed Application Runtime).\\n\\nIn this 6-part series of posts, we walk through each technology independently, before looking at the value of building Azure Container Apps **with Dapr**.\\n\\n * In [Hello Container Apps](https://azure.github.io/Cloud-Native/blog/09-aca-fundamentals) we learned core concepts & deployed our first ACA.\\n * In [Microservices Communication](https://azure.github.io/Cloud-Native/blog/microservices-10) we learned about ACA environments and virtual networks, and how microservices communicate in ACA with a hands-on tutorial.\\n * In [Scaling Your Container Apps](https://azure.github.io/Cloud-Native/blog/11-scaling-container-apps) we learned about KEDA (Kubernetes Event-Driven Autoscaler) and configuring ACA for autoscaling with KEDA-compliant triggers.\\n * In [Build with Dapr](https://azure.github.io/Cloud-Native/blog/12-build-with-dapr) we introduced the Distributed Application Runtime (Dapr), exploring its Building Block APIs and sidecar architecture for working with ACA.\\n * In [Secure ACA Access](https://azure.github.io/Cloud-Native/blog/13-aca-managed-id) we learned how to secure ACA access to external services with - and without - Dapr, covering Secret Stores and Managed Identity.\\n * Finally, [Build ACA with Dapr](https://azure.github.io/Cloud-Native/blog/14-dapr-aca-quickstart) tied it all together with a enterprise app scenario where an orders processor (ACA) uses Dapr APIs (PubSub, State Management) to receive and store order messages from Azure Service Bus.\\n\\n\\n![Build ACA with Dapr](https://github.com/Azure/Cloud-Native/blob/41cc0890acd204a9069836dfcc5727c48d5fca97/website/blog/2022-09-14/img/ACA-Tutorial-AsyncComm-0922.jpg)\\n\\nCheck out this recent [AskTheExpert](https://aka.ms/ATEonDemand) Q&A session with the Azure Container Apps team for answers to popular community questions on core features and usage.\\n\\n<iframe src=\\"https://learn-video.azurefd.net/vod/player?show=ask-the-expert&ep=serverless-september-azure-container-apps\\" width=\\"640\\" height=\\"360\\"></iframe>\\n\\n\\n## Serverless Integrations\\n\\nIn the first half of the month we looked at _compute_ resources for building and deploying serverless applications. In the second half, we look at _integration_ tools and resources that automate developer workflows to streamline the end-to-end developer experience.\\n\\nIn Azure, this is enabled by services like [Azure Logic Apps](https://learn.microsoft.com/azure/logic-apps/logic-apps-overview) and [Azure Event Grid](https://learn.microsoft.com/azure/event-grid/overview). Azure Logic Apps provides a visual designer to _create and automate workflows_ with little or no code involved. Azure Event Grid provides a _highly-scable event broker_ with support for pub/sub communications to drive async event-driven architectures. \\n\\n * In [Tracking Weather Data Changes With Logic Apps](https://azure.github.io/Cloud-Native/blog/17-integrate-cosmosdb) we look at how you can use Logic Apps to  integrate the MSN weather service with Azure CosmosDB, allowing automated collection of weather data on changes.\\n * In [Teach the Cloud to Read & Categorize Mail](https://azure.github.io/Cloud-Native/blog/18-cloudmail) we take it a step further, using Logic Apps to automate a workflow that includes a Computer Vision service to \\"read\\" images and store the results to CosmosDB.\\n * In [Integrate with Microsoft Graph](https://azure.github.io/Cloud-Native/blog/20-events-graph) we explore a multi-cloud scenario (Azure + M365) where change notifications from Microsoft Graph can be integrated using Logic Apps and Event Hubs to power an onboarding workflow.\\n * In [Cloud Events with Event Grid](https://azure.github.io/Cloud-Native/blog/21-cloudevents-via-event-grid) we learn about the CloudEvents specification (for consistently describing event data) - and learn how Event Grid brokers events in this format. Azure Logic Apps can be an Event handler (subscriber) that uses the event to trigger an automated workflow on receipt.\\n\\n ![Azure Event Grid And Logic Apps](https://azure.github.io/Cloud-Native/assets/images/21-cloudevents-via-event-grid-01-694e11ff4422f7f4f28ae03f08580170.png)\\n\\nWant to explore other such integrations? Browse [Azure Architectures](https://learn.microsoft.com/azure/architecture/browse/?filter-products=Logic%20A&products=azure-event-grid%2Cazure-logic-apps) and filter by selected Azure services for more real-world scenarios.\\n\\n---\\n\\n## End-to-End Solutions\\n\\nWe\'ve covered serverless _compute_ solutions (for building your serverless applications) and serverless _integration_ services to automate end-to-end workflows in synchronous or asynchronous event-driven architectures. In this final week, we want to leave you with a sense of _end-to-end_ development tools and use cases that can be enabled by Serverless on Azure. Here are some  key examples:\\n\\n| Article | Description |\\n|:---|:---|\\n|![](https://azure.github.io/Cloud-Native/assets/images/architecture-a2d16c0719ab5f90fe9e4b66a40198bc.png)| In [**this tutorial**](https://azure.github.io/Cloud-Native/blog/24-aca-dotnet), you\'ll learn to deploy a containerized ASP.NET Core 6.0 application to Azure Container Apps - with a Blazor front-end and two Web API projects|\\n|![Deploy Java containers to cloud](https://azure.github.io/Cloud-Native/assets/images/acr-portal-01-56ad80e74d4597e32bb2bb534148d10d.png) | In [**this tutorial**](https://azure.github.io/Cloud-Native/blog/24-aca-dotnet) you learn to build and deploy a Java application running on Spring Boot, by publishing it in a container to Azure Container Registry, then deploying to Azure Container Apps,, from ACR, via the Azure Portal.|\\n|![**Where am I? My GPS Location with Serverless Power Platform Custom Connector**](https://azure.github.io/Cloud-Native/assets/images/28-serverless-power-platform-custom-connector-01-d6fac44727880dd526e03e2010938f0a.png) | In [**this step-by-step tutorial**](https://azure.github.io/Cloud-Native/blog/28-where-am-i) you learn to integrate a serverless application (built on Azure Functions and OpenAPI) with Power Platforms custom connectors via Azure API Management (API-M).This pattern can empower a new ecosystem of _fusion apps_ for cases like inventory management.|\\n| ![](https://microsoft.github.io/WhatTheHack/015-Serverless/images/preferred-solution.png) | And in our [**Serverless Hacks**](https://microsoft.github.io/WhatTheHack/015-Serverless/images/preferred-solution.png) initiative, we walked through an 8-step hack to build a serverless tollbooth. Check out [**this 12-part video walkthrough**](https://aka.ms/serverless-september/videos) of a reference solution using .NET.  |\\n\\n## Developer Tools\\n\\nBut wait - there\'s more. Those are a sample of the end-to-end application scenarios that are built on serverless on Azure. But what about the **developer experience**? In [**this article**](https://azure.github.io/Cloud-Native/blog/29-azure-developer-cli), we say hello to the _Azure Developer CLI_ - an open-source tool that streamlines your develop-deploy workflow, with simple commands that map to core stages of your development journey. **Go from code to cloud with one CLI**\\n\\n![](https://azure.github.io/Cloud-Native/assets/images/azd-workflow-163d61cf5c6aa44a23dd4dda9858a296.png)\\n\\nAnd **watch this space for more such tutorials and content through October**, including a special #Hacktoberfest focused initiative to encourage and support first-time contributors to open-source. Here\'s a sneak peek at the project we plan to share - the new [awesome-azd templates](https://aka.ms/awesome-azd) gallery.\\n\\n![](./../2022-10-06/img/gallery.gif)\\n\\n---\\n\\n## Join us at Microsoft Ignite!\\n\\nWant to continue your learning journey, and learn about what\'s next for Serverless on Azure? \\n**Microsoft Ignite** happens Oct 12-14 this year and has multiple sessions on relevant technologies and tools. Check out the [Session Catalog](https://ignite.microsoft.com/sessions?q=cloud%2520native%2520architectures&f=%255B%257B%2522name%2522%253A%2522Breakout%2522%252C%2522facetName%2522%253A%2522sessionType%2522%257D%255D&s=%257B%2522name%2522%253A%2522translate.refine.label.sort.relevance%2522%252C%2522type%2522%253A0%257D&t=%257B%2522from%2522%253A%25222022-10-12T00%253A00%253A00-07%253A00%2522%252C%2522to%2522%253A%25222022-10-13T23%253A59%253A59-07%253A00%2522%257D&g=%255B%257B%2522name%2522%253A%2522live-now-and-upcoming%2522%252C%2522enabled%2522%253Afalse%257D%255Dl) and [register here](https://ignite.microsoft.com/sessions/8950b2b1-62eb-48f9-90ef-5ad779ce8e22?source=sessions) to attend online."},{"id":"29-azure-developer-cli","metadata":{"permalink":"/Cloud-Native/blog/29-azure-developer-cli","source":"@site/blog/2022-09-29/index.md","title":"29. Code to Cloud with `azd`","description":"<FIXME>","date":"2022-09-29T00:00:00.000Z","formattedDate":"September 29, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"},{"label":"azd","permalink":"/Cloud-Native/blog/tags/azd"},{"label":"azure-developer-cli","permalink":"/Cloud-Native/blog/tags/azure-developer-cli"}],"readingTime":8.895,"hasTruncateMarker":false,"authors":[{"name":"Savannah Ostrowski","title":"Senior Product Manager @Microsoft","url":"https://twitter.com/savostrowski","imageURL":"https://github.com/savannahostrowski.png","key":"savannah"}],"frontMatter":{"slug":"29-azure-developer-cli","title":"29. Code to Cloud with `azd`","authors":["savannah"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"<FIXME>","tags":["serverless-september","30-days-of-serverless","microservices","azd","azure-developer-cli"]},"prevItem":{"title":"Serverless September - In a Nutshell","permalink":"/Cloud-Native/blog/serverless-status-post"},"nextItem":{"title":"28. Serverless + Power Platforms","permalink":"/Cloud-Native/blog/28-where-am-i"}},"content":"\x3c!-- FIXME --\x3e\\n<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/29-azure-developer-cli\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Code to Cloud with Azure Developer CLI\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Code to Cloud with Azure Developer CLI\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@savostrowski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/29-azure-developer-cli\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 29` of #30DaysOfServerless!\\n\\nWe are in the final days of the 30-day journey so it seemed appropriate to end the _End-to-End_ Developer Journey with a discussion on _tooling_ that can simplify and enhance the developer experience from development to deployment and beyond. Say hello to the **Azure Developer CLI**.\\n\\nReady? Let\'s go!\\n\\n:::tip Updated: October 6, 2022\\n\\nToday marked the [October 22 release](https://devblogs.microsoft.com/azure-sdk/azure-developer-cli-azd-october-2022-release/) of the Azure Developer CLI - bringing with it a few new features and community-targeted resources. Look out for a follow-up post to this one that dives into more details, just in time for **#Hacktoberfest!** \ud83c\udf1f\\n\\n:::\\n\\n---\\n\\n## What We\'ll Cover\\n * **A new tool has entered the chat:** Azure Developer CLI (`azd`)\\n * **(Template) Anatomy 101**: What makes an `azd` template?\\n * **End-to-end support:** Move code to cloud in a single step!\\n * **Best practices:** Monitor your application and run CI/CD on every commit\\n * **Exercise:** Try this yourself or create your own `azd` template\\n * **Resources:** For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## **A new tool has entered the chat:** What is the Azure Developer CLI (`azd`)?\\nThe Azure Developer CLI (`azd`) is a new, open source tool that makes it quick and simple for you to move your application from your local development environment to Azure while considering your end-to-end developer workflow. You might be familiar with other CLIs that focus on Infrastructure as Code or scaffolding your application but the Azure Developer CLI does all that and more!\\n\\nThe Azure Developer CLI commands are simple, high-level and map to core stages in your developer workflow. Think project initialization/creation, build, deploy, repeat!\\n\\n![](img/azd-workflow.png)\\n\\nBy using [idiomatic and flexible application templates](https://aka.ms/azure-dev/templates?source=serverless-september), the Azure Developer CLI uses recipes for common application architectures that you can customize for your use case. These templates include:\\n- best practices\\n- sample application code that goes beyond \\"Hello World!\\"\\n- infrastructure as code assets so you can move your code to the cloud and set up monitoring for your application, and\\n- all the bits to set up CI/CD to run on every commit to your repo against resources on Azure\\n\\n...all in the language(s) you\'re most comfortable in. You can use an [existing template](https://aka.ms/azure-dev/templates?source=serverless-september) or even create your own (more on that later!).\\n\\n## **(Template) Anatomy 101**: What makes an `azd` template?\\nSo now that you\'ve been introduced to the Azure Developer CLI, let\'s take a look at an `azd`-enabled codebase, which we call a template. You can think of a template as a recipe - it provides a solid foundation that you can customize depending on your preference/use case/requirements. \\n\\nTo make this concrete and because it\'s #ServerlessSeptember, we\'re going to walk through this [ToDo application template](https://github.com/Azure-Samples/todo-python-mongo-swa-func) that uses Azure Static Web Apps and Azure Functions.\\n\\n![](img/arch-diagram.png)\\n\\nLet\'s talk about the files in terms of their purpose:\\n\\n### Azure Developer CLI-specific files\\n  - `azure.yaml` - contains metadata that describes the application (Azure hosts, languages, template name) and serves as an entrypoint for functionality in Visual Studio Code (oh yeah, you can also use `azd` using [a VS Code extension](https://aka.ms/azure-dev/vscode-ext?source=serverless-september)!).\\n\\n### Application development support (code, run, debug, test)\\n  - `.devcontainer/` - support for if you\'re [writing code in a container](https://code.visualstudio.com/docs/remote/containers)\\n  - `.vscode/` - support for local development in Visual Studio Code via [launch.json](https://code.visualstudio.com/docs/editor/debugging) (for debugging) and [tasks.json](https://code.visualstudio.com/docs/editor/tasks) (for spinning up the web app for local development)\\n  - `src/` - contains all the sample application code which you can modify or swap out for your own application\\n  - `tests/` - test for the application, written using [Playwright](https://playwright.dev/)\\n\\n### Infrastructure as Code (provisioning and deploying infrastructure on Azure, programmatically)\\n  - `infra/` - contains all infrastructure as code (IaC) assets written in [Bicep](https://docs.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) or [Terraform](https://aka.ms/azure-dev/terraform); includes logic to set up all components we need to set up the application on Azure, wire everything up securely, and monitor application health, performance and usage!\\n\\n### CI/CD\\n  - `.github/` - contains a GitHub Actions workflow to set up a CI/CD pipeline that runs on every new commit to the repo\\n  - `.azdo/` - contains a Azure Pipelines workflow to set up a CI/CD pipeline that runs on every new commit to the repo\\n\\n\\n## **End-to-end support:** Move code to cloud in a single step!\\n### If you want to follow along in this section and don\'t already have the Azure Developer CLI installed, check out [these instructions](https://aka.ms/azure-dev/install-instructions?source=serverless-september) to install it on Windows, Linux or MacOS in your favorite terminal!\\n\\nSo now that we\'ve gone over what this template contains on GitHub, let\'s pull this template code down to our local machine, set it up for local development, provision the right infrastructure, and deploy the code on Azure in a **single step**.\\n\\nWhen designing the CLI, we wanted the experience to be both flexible and non-magical (no side effects, easy to understand). So, we\'re going to run this all with `azd up` but you could alternatively run a series of three commands and the outcome would be the same - `azd init --t Azure-Samples/todo-python-mongo-swa-func` (to pull the code down to your machine), `azd provision` (to provision infrastructure) and then `azd deploy` (to deploy application code on Azure). Choose your own adventure!\\n\\n![](img/single-step.png)\\n\\nSo let\'s walk through it. On running `azd up -t todo-python-mongo-swa-func`, I\'m prompted for a couple pieces of information as part of the `azd init` process being run under the hood:\\n    - **An environment name** - the prefix for the resource group that will be created to hold all Azure resources\\n    - **An Azure region** - the Azure location where your resources will be deployed\\n    - **An Azure subscription** - the Azure subscription where your resources will be deployed\\n![](img/start-up.png)\\n\\nOnce that information is provided, `azd` will pull down the code from GitHub and create a `.azure/` directory in the project root that contains all Azure Developer CLI environment information that you just entered. This directory will be important when it comes time to provision and deploy infrastructure in the next step in the `up` process.\\n\\nThe next step here is provisioning. `azd` is running `azd provision` on your behalf and leveraging the IaC assets in the `.infra/` directory in the project. As the tool works to provision, you\'ll see an output of each resource (name alongside a unique identifier which you can use to reference back to the Azure Portal, if you want)\\n![](img/provision-up.png)\\n\\nFinally, the final step here in running `azd up` is deployment. `azd` is running `azd deploy` and deploying the application code to the resources that we\'re provisioned in the previous phase of the process. Once this has completed, you\'ll be able to click on two different endpoint URLs - one for the backend and one for the frontend. \\n![](img/deploy-up.png)\\n\\nThe backend endpoint (`service api`) hosts the specification for the API via the `openapi.yaml` file that\'s also in the root of the project template. You can explore the endpoints that are available in the web app here. \\n![](img/backend.png)\\n\\nThe frontend endpoint (`service web`) hosts a fully-fledged and functional ToDo web app with a UI, Cosmos DB for the database and Key Vault for application secrets. This isn\'t just application hosting. It\'s really everything you need to be successful and productive, all set up on your behalf by the Azure Developer CLI.\\n![](img/frontend.png)\\n\\n...and that\'s it! We\'ve successfully deployed our application on Azure! \\n\\nBut there\'s more!\\n\\n## Best practices: Monitoring and CI/CD!\\nIn my opinion, it\'s not enough to _just_ set up the application on Azure! I want to know that my web app is performant and serving my users reliably! I also want to make sure that I\'m not inadvertently breaking my application as I continue to make changes to it. Thankfully, the Azure Developer CLI also handles all of this via two additional commands - `azd monitor` and `azd pipeline config`.\\n\\n### Application Monitoring\\nWhen we provisioned all of our infrastructure, we also set up application monitoring via a Bicep file in our `.infra/` directory that spec\'d out an Application Insights dashboard. By running `azd monitor` we can see the dashboard with live metrics that was configured for the application. \\n![](img/metrics.png)\\n\\nWe can also navigate to the Application Dashboard by clicking on the resource group name, where you can set a specific refresh rate for the dashboard, and see usage, reliability, and performance metrics over time.\\n![](img/dashboard.png)\\n\\nI don\'t know about everyone else but I have spent a ton of time building out similar dashboards. It can be super time-consuming to write all the queries and create the visualizations so this feels like a real time saver.\\n\\n### CI/CD\\nFinally let\'s talk about setting up CI/CD! This might be my favorite `azd` feature. As I mentioned before, the Azure Developer CLI has a command, `azd pipeline config`, which uses the files in the `.github/` directory to set up a GitHub Action. More than that, if there is no upstream repo, the Developer CLI will actually help you create one. But what does this mean exactly? Because our GitHub Action is using the same commands you\'d run in the CLI under the hood, we\'re actually going to have CI/CD set up to run on every commit into the repo, against real Azure resources. What a sweet collaboration feature!\\n\\n![](img/pipeline-config.png)\\n\\n\\nThat\'s it! We\'ve gone end-to-end with the Azure Developer CLI - initialized a project, provisioned the resources on Azure, deployed our code on Azure, set up monitoring logs and dashboards, and set up a CI/CD pipeline with GitHub Actions to run on every commit into the repo (on real Azure resources!).\\n\\n\\n## **Exercise:** Try it yourself or create your own template!\\nAs an exercise, try out the workflow above with [any template on GitHub](https://aka.ms/azure-dev/templates)!\\n\\nOr, try turning your own project into an Azure Developer CLI-enabled template by following [this guidance](https://aka.ms/azure-dev/enabletemplate). If you create your own template, don\'t forget to tag the repo with the [`azd-templates` topic](https://aka.ms/azure-dev/templates) on GitHub to help others find it (unfamiliar with GitHub topics? [Learn how to add topics to your repo](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/classifying-your-repository-with-topics#adding-topics-to-your-repository))! We\'d also love to chat with you about your experience creating an `azd` template - if you\'re open to providing feedback around this, please fill out [this form](https://aka.ms/azd-user-research-signup?source=serverless-september)!\\n\\n\\n## **Resources**\\n- [Read more about the Azure Developer CLI preview release](https://aka.ms/announcing-azure-dev-cli?source=serverless-september)\\n- [Install the Azure Developer CLI](https://aka.ms/azure-dev/install-instructions?source=serverless-september)\\n- [Familiarize yourself with our Developer Hub](https://aka.ms/azd?source=serverless-september)\\n- [Take a look at some foundational templates on GitHub](https://aka.ms/azure-dev/templates?source=serverless-september)\\n- [Download the Azure Developer CLI VS Code extension](https://aka.ms/azure-dev/vscode-ext?source=serverless-september)"},{"id":"28-where-am-i","metadata":{"permalink":"/Cloud-Native/blog/28-where-am-i","source":"@site/blog/2022-09-28/index.md","title":"28. Serverless + Power Platforms","description":"Build a Power Platform custom connector with Azure Functions and OpenAPI to read my current GPS location and display it on Google Maps and Naver Map.","date":"2022-09-28T00:00:00.000Z","formattedDate":"September 28, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"openapi","permalink":"/Cloud-Native/blog/tags/openapi"},{"label":"power-platform","permalink":"/Cloud-Native/blog/tags/power-platform"},{"label":"custom-connector","permalink":"/Cloud-Native/blog/tags/custom-connector"}],"readingTime":13.635,"hasTruncateMarker":false,"authors":[{"name":"Justin Yoo","title":"Senior Cloud Advocate @Microsoft","url":"https://github.com/justinyoo","imageURL":"https://github.com/justinyoo.png","key":"justin"}],"frontMatter":{"slug":"28-where-am-i","title":"28. Serverless + Power Platforms","authors":["justin"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","power platform","custom connector","openapi"],"image":"./img/banner.png","description":"Build a Power Platform custom connector with Azure Functions and OpenAPI to read my current GPS location and display it on Google Maps and Naver Map.","tags":["serverless-september","30-days-of-serverless","azure-functions","openapi","power-platform","custom-connector"]},"prevItem":{"title":"29. Code to Cloud with `azd`","permalink":"/Cloud-Native/blog/29-azure-developer-cli"},"nextItem":{"title":"\ud83d\ude80 | Monitor + Troubleshoot Apps","permalink":"/Cloud-Native/blog/zero2hero-func-07"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/28-where-am-i\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Serverless Power Platform Custom Connector for GPS Location\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: How to read my current GPS location and display it on Google Maps and Naver Map using Power Platform custom connector built with Azure Functions and OpenAPI\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/28-where-am-i\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 28` of #30DaysOfServerless! \\n\\nSince it\'s the serverless end-to-end week, I\'m going to discuss how to use a serverless application &ndash; [Azure Functions][az fncapp] with [OpenAPI extension][gh az fncapp openapi] &ndash; to be seamlessly integrated with [Power Platform custom connector][pp cuscon] through [Azure API Management][az apim] - in a post I call *\\"Where am I? My GPS Location with Serverless Power Platform Custom Connector\\"*\\n\\nOK. Are you ready? Let\'s get started!\\n\\n---\\n\\n## What We\'ll Cover\\n\\n * What is Power Platform custom connector?\\n * Proxy app to Google Maps and Naver Map API\\n * API Management integration\\n * Two ways of building custom connector\\n * Where am I? &ndash; Power Apps app\\n * Exercise: Try this yourself!\\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n:::info SAMPLE REPO\\nWant to follow along? Check out the [sample app on GitHub repository][gh sample] used in this post.\\n:::\\n\\n\\n\\n## What is Power Platform custom connector?\\n\\n[Power Platform][pp] is a low-code/no-code application development tool for [fusion teams][fusion dev] that consist of a group of people. Those people come from various disciplines, including field experts (domain experts), IT professionals and professional developers, to draw business values successfully. Within the fusion team, the domain experts become citizen developers or low-code developers by Power Platform. In addition, Making Power Platform more powerful is that it offers hundreds of connectors to other Microsoft 365 and third-party services like SAP, ServiceNow, Salesforce, Google, etc.\\n\\nHowever, what if you want to use your internal APIs or APIs not yet offering their official connectors? Here\'s an example. If your company has an inventory management system, and you want to use it within your [Power Apps][pp pa] or [Power Automate][pp pau]. That point is exactly where [Power Platform custom connectors][pp cuscon] is necessary.\\n\\n![Inventory Management System for Power Apps](./img/28-serverless-power-platform-custom-connector-01.png)\\n\\nTherefore, Power Platform custom connectors enrich those citizen developers\' capabilities because those connectors can connect any API applications for the citizen developers to use.\\n\\nIn this post, let\'s build a custom connector that provides a static map image generated by [Google Maps API][maps google] and [Naver Map API][maps naver] using your GPS location.\\n\\n\\n## Proxy app to Google Maps and Naver Map API\\n\\nFirst, let\'s build an Azure Functions app that connects to Google Maps and Naver Map. Suppose that you\'ve already got the API keys for both services. If you haven\'t yet, get the keys first by visiting [here for Google][maps google] and [here for Naver][maps naver]. Then, store them to `local.settings.json` within your Azure Functions app.\\n\\n```json\\n{\\n  \\"Values\\": {\\n    ...\\n    \\"Maps__Google__ApiKey\\": \\"<GOOGLE_MAPS_API_KEY>\\",\\n    \\"Maps__Naver__ClientId\\": \\"<NAVER_MAP_API_CLIENT_ID>\\",\\n    \\"Maps__Naver__ClientSecret\\": \\"<NAVER_MAP_API_CLIENT_SECRET>\\"\\n  }\\n}\\n```\\n\\nHere\'s the sample logic to get the static image from Google Maps API. It takes the latitude and longitude of your current location and image zoom level, then returns the static map image. There are a few hard-coded assumptions, though:\\n\\n* The image size should be 400x400.\\n* The image should be in `.png` format.\\n* The marker should show be red and show my location.\\n\\n```csharp\\npublic class GoogleMapService : IMapService\\n{\\n    public async Task<byte[]> GetMapAsync(HttpRequest req)\\n    {\\n        var latitude = req.Query[\\"lat\\"];\\n        var longitude = req.Query[\\"long\\"];\\n        var zoom = (string)req.Query[\\"zoom\\"] ?? \\"14\\";\\n\\n        var sb = new StringBuilder();\\n        sb.Append(\\"https://maps.googleapis.com/maps/api/staticmap\\")\\n          .Append($\\"?center={latitude},{longitude}\\")\\n          .Append(\\"&size=400x400\\")\\n          .Append($\\"&zoom={zoom}\\")\\n          .Append($\\"&markers=color:red|{latitude},{longitude}\\")\\n          .Append(\\"&format=png32\\")\\n          .Append($\\"&key={this._settings.Google.ApiKey}\\");\\n        var requestUri = new Uri(sb.ToString());\\n\\n        var bytes = await this._http.GetByteArrayAsync(requestUri).ConfigureAwait(false);\\n\\n        return bytes;\\n    }\\n}\\n```\\n\\nThe `NaverMapService` class has a similar logic with the same input and assumptions. Here\'s the code:\\n\\n```csharp\\npublic class NaverMapService : IMapService\\n{\\n    public async Task<byte[]> GetMapAsync(HttpRequest req)\\n    {\\n        var latitude = req.Query[\\"lat\\"];\\n        var longitude = req.Query[\\"long\\"];\\n        var zoom = (string)req.Query[\\"zoom\\"] ?? \\"13\\";\\n\\n        var sb = new StringBuilder();\\n        sb.Append(\\"https://naveropenapi.apigw.ntruss.com/map-static/v2/raster\\")\\n          .Append($\\"?center={longitude},{latitude}\\")\\n          .Append(\\"&w=400\\")\\n          .Append(\\"&h=400\\")\\n          .Append($\\"&level={zoom}\\")\\n          .Append($\\"&markers=color:blue|pos:{longitude}%20{latitude}\\")\\n          .Append(\\"&format=png\\")\\n          .Append(\\"&lang=en\\");\\n        var requestUri = new Uri(sb.ToString());\\n\\n        this._http.DefaultRequestHeaders.Clear();\\n        this._http.DefaultRequestHeaders.Add(\\"X-NCP-APIGW-API-KEY-ID\\", this._settings.Naver.ClientId);\\n        this._http.DefaultRequestHeaders.Add(\\"X-NCP-APIGW-API-KEY\\", this._settings.Naver.ClientSecret);\\n\\n        var bytes = await this._http.GetByteArrayAsync(requestUri).ConfigureAwait(false);\\n\\n        return bytes;\\n    }\\n}\\n```\\n\\nLet\'s take a look at the function endpoints. Here\'s for the Google Maps and Naver Map. As the `GetMapAsync(req)` method returns a byte array value, you need to transform it as `FileContentResult`, with the content type of `image/png`.\\n\\n```csharp\\n// Google Maps\\npublic class GoogleMapsTrigger\\n{\\n    [FunctionName(nameof(GoogleMapsTrigger.GetGoogleMapImage))]\\n    public async Task<IActionResult> GetGoogleMapImage(\\n        [HttpTrigger(AuthorizationLevel.Anonymous, \\"GET\\", Route = \\"google/image\\")] HttpRequest req)\\n    {\\n        this._logger.LogInformation(\\"C# HTTP trigger function processed a request.\\");\\n\\n        var bytes = await this._service.GetMapAsync(req).ConfigureAwait(false);\\n\\n        return new FileContentResult(bytes, \\"image/png\\");\\n    }\\n}\\n\\n// Naver Map\\npublic class NaverMapsTrigger\\n{\\n    [FunctionName(nameof(NaverMapsTrigger.GetNaverMapImage))]\\n    public async Task<IActionResult> GetNaverMapImage(\\n        [HttpTrigger(AuthorizationLevel.Anonymous, \\"GET\\", Route = \\"naver/image\\")] HttpRequest req)\\n    {\\n        this._logger.LogInformation(\\"C# HTTP trigger function processed a request.\\");\\n\\n        var bytes = await this._service.GetMapAsync(req).ConfigureAwait(false);\\n\\n        return new FileContentResult(bytes, \\"image/png\\");\\n    }\\n}\\n```\\n\\nThen, add the OpenAPI capability to each function endpoint. Here\'s the example:\\n\\n```csharp\\n// Google Maps\\npublic class GoogleMapsTrigger\\n{\\n    [FunctionName(nameof(GoogleMapsTrigger.GetGoogleMapImage))]\\n    // \u2b07\ufe0f\u2b07\ufe0f\u2b07\ufe0f Add decorators provided by the OpenAPI extension \u2b07\ufe0f\u2b07\ufe0f\u2b07\ufe0f\\n    [OpenApiOperation(operationId: nameof(GoogleMapsTrigger.GetGoogleMapImage), tags: new[] { \\"google\\" })]\\n    [OpenApiParameter(name: \\"lat\\", In = ParameterLocation.Query, Required = true, Type = typeof(string), Description = \\"The **latitude** parameter\\")]\\n    [OpenApiParameter(name: \\"long\\", In = ParameterLocation.Query, Required = true, Type = typeof(string), Description = \\"The **longitude** parameter\\")]\\n    [OpenApiParameter(name: \\"zoom\\", In = ParameterLocation.Query, Required = false, Type = typeof(string), Description = \\"The **zoom level** parameter &ndash; Default value is `14`\\")]\\n    [OpenApiResponseWithBody(statusCode: HttpStatusCode.OK, contentType: \\"image/png\\", bodyType: typeof(byte[]), Description = \\"The map image as an OK response\\")]\\n    // \u2b06\ufe0f\u2b06\ufe0f\u2b06\ufe0f Add decorators provided by the OpenAPI extension \u2b06\ufe0f\u2b06\ufe0f\u2b06\ufe0f\\n    public async Task<IActionResult> GetGoogleMapImage(\\n        [HttpTrigger(AuthorizationLevel.Anonymous, \\"GET\\", Route = \\"google/image\\")] HttpRequest req)\\n    {\\n        ...\\n    }\\n}\\n\\n// Naver Map\\npublic class NaverMapsTrigger\\n{\\n    [FunctionName(nameof(NaverMapsTrigger.GetNaverMapImage))]\\n    // \u2b07\ufe0f\u2b07\ufe0f\u2b07\ufe0f Add decorators provided by the OpenAPI extension \u2b07\ufe0f\u2b07\ufe0f\u2b07\ufe0f\\n    [OpenApiOperation(operationId: nameof(NaverMapsTrigger.GetNaverMapImage), tags: new[] { \\"naver\\" })]\\n    [OpenApiParameter(name: \\"lat\\", In = ParameterLocation.Query, Required = true, Type = typeof(string), Description = \\"The **latitude** parameter\\")]\\n    [OpenApiParameter(name: \\"long\\", In = ParameterLocation.Query, Required = true, Type = typeof(string), Description = \\"The **longitude** parameter\\")]\\n    [OpenApiParameter(name: \\"zoom\\", In = ParameterLocation.Query, Required = false, Type = typeof(string), Description = \\"The **zoom level** parameter &ndash; Default value is `13`\\")]\\n    [OpenApiResponseWithBody(statusCode: HttpStatusCode.OK, contentType: \\"image/png\\", bodyType: typeof(byte[]), Description = \\"The map image as an OK response\\")]\\n    // \u2b06\ufe0f\u2b06\ufe0f\u2b06\ufe0f Add decorators provided by the OpenAPI extension \u2b06\ufe0f\u2b06\ufe0f\u2b06\ufe0f\\n    public async Task<IActionResult> GetNaverMapImage(\\n        [HttpTrigger(AuthorizationLevel.Anonymous, \\"GET\\", Route = \\"naver/image\\")] HttpRequest req)\\n    {\\n        ...\\n    }\\n}\\n```\\n\\nRun the function app in the local. Here are the latitude and longitude values for Seoul, Korea.\\n\\n* latitude: 37.574703\\n* longitude: 126.978519\\n\\n![Google Map for Seoul](./img/28-serverless-power-platform-custom-connector-02.png)\\n\\nIt seems to be working! Let\'s deploy it to Azure.\\n\\n\\n## API Management integration\\n\\n[Visual Studio 2022][vs] provides a built-in deployment tool for [Azure Functions][az fncapp] app onto Azure. In addition, the deployment tool supports seamless integration with [Azure API Management][az apim] as long as your Azure Functions app enables the OpenAPI capability. In this post, I\'m going to use this feature. Right-mouse click on the Azure Functions project and select the \\"Publish\\" menu.\\n\\n![Visual Studio context menu for publish](./img/28-serverless-power-platform-custom-connector-03.png)\\n\\nThen, you will see the publish screen. Click the \\"\u2795 New\\" button to create a new publish profile.\\n\\n![Create a new publish profile](./img/28-serverless-power-platform-custom-connector-04.png)\\n\\nChoose \\"Azure\\" and click the \\"Next\\" button.\\n\\n![Choose the target platform for publish](./img/28-serverless-power-platform-custom-connector-05.png)\\n\\nSelect the app instance. This time simply pick up the \\"Azure Function App (Windows)\\" option, then click \\"Next\\".\\n\\n![Choose the target OS for publish](./img/28-serverless-power-platform-custom-connector-06.png)\\n\\nIf you already provision an Azure Function app instance, you will see it on the screen. Otherwise, create a new one. Then, click \\"Next\\".\\n\\n![Choose the target instance for publish](./img/28-serverless-power-platform-custom-connector-07.png)\\n\\nIn the next step, you are asked to choose the Azure API Management instance for integration. Choose one, or create a new one. Then, click \\"Next\\".\\n\\n![Choose the APIM instance for integration](./img/28-serverless-power-platform-custom-connector-08.png)\\n\\nFinally, select the publish method &ndash; either local publish or GitHub Actions workflow. Let\'s pick up the local publish method for now. Then, click \\"Finish\\".\\n\\n![Choose the deployment type](./img/28-serverless-power-platform-custom-connector-09.png)\\n\\nThe publish profile has been created. Click \\"Close\\" to move on.\\n\\n![Publish profile created](./img/28-serverless-power-platform-custom-connector-10.png)\\n\\nNow the function app is ready for deployment. Click the \\"Publish\\" button and see how it goes.\\n\\n![Publish function app](./img/28-serverless-power-platform-custom-connector-11.png)\\n\\nThe Azure function app has been deployed and integrated with the Azure API Management instance.\\n\\n![Function app published](./img/28-serverless-power-platform-custom-connector-12.png)\\n\\nGo to the published function app site, and everything looks OK.\\n\\n![Function app on Azure](./img/28-serverless-power-platform-custom-connector-13.png)\\n\\nAnd API Management shows the function app integrated perfectly.\\n\\n![Function app integrated with APIM](./img/28-serverless-power-platform-custom-connector-14.png)\\n\\nNow, you are ready to create a custom connector. Let\'s move on.\\n\\n\\n## Two ways of building custom connector\\n\\nThere are two ways to create a custom connector.\\n\\n\\n### Export custom connector from API Management\\n\\nFirst, you can directly use the built-in API Management feature. Then, click the ellipsis icon and select the \\"Create Power Connector\\" menu.\\n\\n![Create Power Connector menu](./img/28-serverless-power-platform-custom-connector-15.png)\\n\\nThen, you are redirected to this screen. While the \\"API\\" and \\"API display name\\" fields are pre-populated, you need to choose the Power Platform environment tied to your tenant. Choose an environment, click \\"Authenticate\\", and click \\"Create\\".\\n\\n![Create custom connector screen](./img/28-serverless-power-platform-custom-connector-16.png)\\n\\nCheck your custom connector on Power Apps or Power Automate side.\\n\\n![Custom connector created on Power Apps](./img/28-serverless-power-platform-custom-connector-17.png)\\n\\nHowever, there\'s a caveat to this approach. Because it\'s tied to your tenant, you should use the second approach if you want to use this custom connector on the other tenant.\\n\\n\\n### Import custom connector from OpenAPI document or URL\\n\\nClick the ellipsis icon again and select the \\"Export\\" menu.\\n\\n![Export menu](./img/28-serverless-power-platform-custom-connector-18.png)\\n\\nOn the Export API screen, choose the \\"OpenAPI v2 (JSON)\\" panel because Power Platform custom connector currently accepts version 2 of the OpenAPI document.\\n\\n![Select OpenAPI v2](./img/28-serverless-power-platform-custom-connector-19.png)\\n\\nDownload the OpenAPI document to your local computer and move to your Power Apps or Power Automate page under your desired environment. I\'m going to use the Power Automate page. First, go to the \\"Data\\" \u27a1\ufe0f \\"Custom connectors\\" page. Then, click the \\"\u2795 New custom connector\\" \u27a1\ufe0f \\"Import an OpenAPI file\\" at the top right corner.\\n\\n![New custom connector](./img/28-serverless-power-platform-custom-connector-20.png)\\n\\nWhen a modal pops up, give the custom connector name and import the OpenAPI document exported above. Then, click \\"Continue\\".\\n\\n![Import custom connector](./img/28-serverless-power-platform-custom-connector-21.png)\\n\\nActually, that\'s it! Next, click the \\"\u2714\ufe0f Create connector\\" button to create the connector.\\n\\n![Create custom connector](./img/28-serverless-power-platform-custom-connector-22.png)\\n\\nGo back to the custom connector page, and you will see the \\"Maps API\\" custom connector you just created.\\n\\n![Custom connector imported](./img/28-serverless-power-platform-custom-connector-23.png)\\n\\nSo, you are ready to create a Power Apps app to display your location on Google Maps or Naver Map! Let\'s move on.\\n\\n\\n## Where am I? &ndash; Power Apps app\\n\\nOpen the Power Apps Studio, and create an empty canvas app, named `Who am I` with a phone layout.\\n\\n\\n### Custom connector integration\\n\\nTo use the custom connector created above, you need to add it to the Power App. Click the cylinder icon on the left and click the \\"Add data\\" button.\\n\\n![Add custom connector to data pane](./img/28-serverless-power-platform-custom-connector-24.png)\\n\\nSearch the custom connector name, \\"Maps API\\", and click the custom connector to add.\\n\\n![Search custom connector](./img/28-serverless-power-platform-custom-connector-25.png)\\n\\nTo use the custom connector, you also need to create a connection to it. Click the \\"Connect\\" button and move on.\\n\\n![Create connection to custom connector](./img/28-serverless-power-platform-custom-connector-26.png)\\n\\nNow, you\'ve got the connection to the custom connector.\\n\\n![Connection to custom connector ready](./img/28-serverless-power-platform-custom-connector-27.png)\\n\\n\\n### Controls\\n\\nLet\'s build the Power Apps app. First of all, put three controls &ndash; [Image][pp pa controls image], [Slider][pp pa controls slider] and [Button][pp pa controls button] onto the canvas.\\n\\n![Power Apps control added](./img/28-serverless-power-platform-custom-connector-28.png)\\n\\nClick the \\"Screen1\\" control and change the value on the property \\"OnVisible\\" to the formula below. The formula stores the current slider value in the `zoomlevel` collection.\\n\\n```powerappsfl\\nClearCollect(\\n    zoomlevel,\\n    Slider1.Value\\n)\\n```\\n\\nClick the \\"Botton1\\" control and change the value on the property \\"OnSelected\\" to the formula below. It passes the current latitude, longitude and zoom level to the custom connector and receives the image data. The received image data is stored in the `result` collection.\\n\\n```powerappsfl\\nClearCollect(\\n    result,\\n    MAPS.GetGoogleMapImage(\\n        Location.Latitude,\\n        Location.Longitude,\\n        { zoom: First(zoomlevel).Value }\\n    )\\n)\\n```\\n\\nClick the \\"Image1\\" control and change the value on the property \\"Image\\" to the formula below. It gets the image data from the `result` collection.\\n\\n```powerappsfl\\nFirst(result).Url\\n```\\n\\nClick the \\"Slider1\\" control and change the value on the property \\"OnChange\\" to the formula below. It stores the current slider value to the `zoomlevel` collection, followed by calling the custom connector to get the image data against the current location.\\n\\n```powerappsfl\\nClearCollect(\\n    zoomlevel,\\n    Slider1.Value\\n);\\nClearCollect(\\n    result,\\n    MAPS.GetGoogleMapImage(\\n        Location.Latitude,\\n        Location.Longitude,\\n        { zoom: First(zoomlevel).Value }\\n    )\\n)\\n```\\n\\nThat seems to be OK. Let\'s click the \\"Where am I?\\" button. But it doesn\'t show the image. The `First(result).Url` value is actually similar to this:\\n\\n```powerappsfl\\nappres://blobmanager/1090a86393a843adbfcf428f0b90e91b/1\\n```\\n\\nIt\'s the image reference value somewhere you can\'t get there.\\n\\n\\n### Workaround &ndash; Power Automate workflow\\n\\nTherefore, you need a workaround using a Power Automate workflow to sort out this issue. Open the Power Automate Studio, create an instant cloud flow with the Power App trigger, and give it the \\"Where am I\\" name. Then add input parameters of `lat`, `long` and `zoom`.\\n\\n![Power Apps trigger on Power Automate workflow](./img/28-serverless-power-platform-custom-connector-29.png)\\n\\nAdd custom connector action to get the map image.\\n\\n![Select action to get the Google Maps image](./img/28-serverless-power-platform-custom-connector-30.png)\\n\\nIn the action, pass the appropriate parameters to the action.\\n\\n![Pass parameters to the custom connector action](./img/28-serverless-power-platform-custom-connector-31.png)\\n\\nAdd a \\"Response\\" action and put the following values into each field.\\n\\n* \\"Body\\" field:\\n\\n    ```bicep\\n    {\\n      \\"base64Image\\": <power_automate_expression>\\n    }\\n    ```\\n\\n    > The `<power_automate_expression>` should be `concat(\'data:\', body(\'GetGoogleMapImage\')?[\'$content-type\'], \';base64,\', body(\'GetGoogleMapImage\')?[\'$content\'])`.\\n\\n* \\"Response Body JSON Schema\\" field:\\n\\n    ```json\\n    {\\n      \\"type\\": \\"object\\",\\n      \\"properties\\": {\\n        \\"base64Image\\": {\\n          \\"type\\": \\"string\\"\\n        }\\n      }\\n    }\\n    ```\\n\\n![Format the Response action](./img/28-serverless-power-platform-custom-connector-32.png)\\n\\nLet\'s return to the Power Apps Studio and add the Power Automate workflow you created.\\n\\n![Add Power Automate workflow](./img/28-serverless-power-platform-custom-connector-33.png)\\n\\nSelect \\"Button1\\" and change the value on the property \\"OnSelect\\" below. It replaces the direct call to the custom connector with the Power Automate workflow.\\n\\n```powerappsfl\\nClearCollect(\\n    result,\\n    WhereamI.Run(\\n        Location.Latitude,\\n        Location.Longitude,\\n        First(zoomlevel).Value\\n    )\\n)\\n```\\n\\nAlso, change the value on the property \\"OnChange\\" of the \\"Slider1\\" control below, replacing the custom connector call with the Power Automate workflow call.\\n\\n```powerappsfl\\nClearCollect(\\n    zoomlevel,\\n    Slider1.Value\\n);\\nClearCollect(\\n    result,\\n    WhereamI.Run(\\n        Location.Latitude,\\n        Location.Longitude,\\n        First(zoomlevel).Value\\n    )\\n)\\n```\\n\\nAnd finally, change the \\"Image1\\" control\'s \\"Image\\" property value below.\\n\\n```powerappsfl\\nFirst(result).base64Image\\n```\\n\\nThe workaround has been applied. Click the \\"Where am I?\\" button to see your current location from Google Maps.\\n\\n![Run Power Apps app #1](./img/28-serverless-power-platform-custom-connector-34.png)\\n\\nIf you change the slider left or right, you will see either the zoomed-in image or the zoomed-out image.\\n\\n![Run Power Apps app #2](./img/28-serverless-power-platform-custom-connector-35.png)\\n\\nNow, you\'ve created a Power Apps app to show your current location using:\\n\\n* Google Maps API through the custom connector, and\\n* Custom connector written in Azure Functions with OpenAPI extension!\\n\\n\\n## Exercise: Try this yourself!\\n\\nYou can fork this [GitHub repository][gh sample] to your account and play around with it to see how the custom connector works. After forking the repository, make sure that you create all the necessary secrets to your repository documented in the README file.\\n\\nThen, click the \\"Deploy to Azure\\" button, and it will provision all necessary Azure resources and deploy an Azure Functions app for a custom connector.\\n\\n![Deploy To Azure](https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/deploytoazure.svg?sanitize=true)\\n\\nOnce everything is deployed successfully, try to create a [Power Apps app][pp pa] and [Power Automate workflow][pp pau] to see your current location in real-time!\\n\\n\\n## Resources: For self-study!\\n\\nWant to know more about Power Platform custom connector and Azure Functions OpenAPI extension? Here are several resources you can take a look at:\\n\\n* [**Microsoft Learn**: Transform your business applications with fusion development][pp learn fusion]\\n* [**GitHub repository**: Azure Functions OpenAPI Extension][gh az fncapp openapi]\\n\\n\\n[image-01]: ./img/28-serverless-power-platform-custom-connector-01.png\\n[image-02]: ./img/28-serverless-power-platform-custom-connector-02.png\\n[image-03]: ./img/28-serverless-power-platform-custom-connector-03.png\\n[image-04]: ./img/28-serverless-power-platform-custom-connector-04.png\\n[image-05]: ./img/28-serverless-power-platform-custom-connector-05.png\\n[image-06]: ./img/28-serverless-power-platform-custom-connector-06.png\\n[image-07]: ./img/28-serverless-power-platform-custom-connector-07.png\\n[image-08]: ./img/28-serverless-power-platform-custom-connector-08.png\\n[image-09]: ./img/28-serverless-power-platform-custom-connector-09.png\\n[image-10]: ./img/28-serverless-power-platform-custom-connector-10.png\\n[image-11]: ./img/28-serverless-power-platform-custom-connector-11.png\\n[image-12]: ./img/28-serverless-power-platform-custom-connector-12.png\\n[image-13]: ./img/28-serverless-power-platform-custom-connector-13.png\\n[image-14]: ./img/28-serverless-power-platform-custom-connector-14.png\\n[image-15]: ./img/28-serverless-power-platform-custom-connector-15.png\\n[image-16]: ./img/28-serverless-power-platform-custom-connector-16.png\\n[image-17]: ./img/28-serverless-power-platform-custom-connector-17.png\\n[image-18]: ./img/28-serverless-power-platform-custom-connector-18.png\\n[image-19]: ./img/28-serverless-power-platform-custom-connector-19.png\\n[image-20]: ./img/28-serverless-power-platform-custom-connector-20.png\\n[image-21]: ./img/28-serverless-power-platform-custom-connector-21.png\\n[image-22]: ./img/28-serverless-power-platform-custom-connector-22.png\\n[image-23]: ./img/28-serverless-power-platform-custom-connector-23.png\\n[image-24]: ./img/28-serverless-power-platform-custom-connector-24.png\\n[image-25]: ./img/28-serverless-power-platform-custom-connector-25.png\\n[image-26]: ./img/28-serverless-power-platform-custom-connector-26.png\\n[image-27]: ./img/28-serverless-power-platform-custom-connector-27.png\\n[image-28]: ./img/28-serverless-power-platform-custom-connector-28.png\\n[image-29]: ./img/28-serverless-power-platform-custom-connector-29.png\\n[image-30]: ./img/28-serverless-power-platform-custom-connector-30.png\\n[image-31]: ./img/28-serverless-power-platform-custom-connector-31.png\\n[image-32]: ./img/28-serverless-power-platform-custom-connector-32.png\\n[image-33]: ./img/28-serverless-power-platform-custom-connector-33.png\\n[image-34]: ./img/28-serverless-power-platform-custom-connector-34.png\\n[image-35]: ./img/28-serverless-power-platform-custom-connector-35.png\\n\\n\\n[gh sample]: https://github.com/justinyoo/google-naver-maps-custom-connector-sample\\n[gh az fncapp openapi]: https://aka.ms/azfunc-openapi\\n\\n[az fncapp]: https://docs.microsoft.com/azure/azure-functions/functions-overview?WT.mc_id=dotnet-75362-juyoo\\n\\n[az apim]: https://docs.microsoft.com/azure/api-management/api-management-key-concepts?WT.mc_id=dotnet-75362-juyoo\\n\\n[pp]: https://docs.microsoft.com/power-platform/?WT.mc_id=dotnet-75362-juyoo\\n[pp cuscon]: https://docs.microsoft.com/connectors/custom-connectors/?WT.mc_id=dotnet-75362-juyoo\\n[pp learn fusion]: https://docs.microsoft.com/training/paths/transform-business-applications-with-fusion-development/?WT.mc_id=dotnet-75362-juyoo\\n\\n[pp pa]: https://docs.microsoft.com/power-apps/powerapps-overview?WT.mc_id=dotnet-75362-juyoo\\n[pp pa controls image]: https://docs.microsoft.com/power-apps/maker/canvas-apps/controls/control-image?WT.mc_id=dotnet-75362-juyoo\\n[pp pa controls slider]: https://docs.microsoft.com/power-apps/maker/canvas-apps/controls/control-slider?WT.mc_id=dotnet-75362-juyoo\\n[pp pa controls button]: https://docs.microsoft.com/power-apps/maker/canvas-apps/controls/control-button?WT.mc_id=dotnet-75362-juyoo\\n\\n[pp pau]: https://docs.microsoft.com/power-automate/getting-started?WT.mc_id=dotnet-75362-juyoo\\n\\n[fusion dev]: https://www.gartner.com/en/articles/why-fusion-teams-matter\\n\\n[maps google]: https://developers.google.com/maps\\n[maps naver]: https://www.ncloud.com/product/applicationService/maps\\n\\n[vs]: https://visualstudio.microsoft.com/vs/?WT.mc_id=dotnet-75362-juyoo"},{"id":"zero2hero-func-07","metadata":{"permalink":"/Cloud-Native/blog/zero2hero-func-07","source":"@site/blog/zero-to-hero/2022-09-26-azurefunctions.md","title":"\ud83d\ude80 | Monitor + Troubleshoot Apps","description":"When you\u2019re running a function app, you want to be prepared for any issues that may arise, from 4xx errors to trigger failures. Azure Functions offers built-in integration with Azure Application Insights to monitor function executions. Let\'s learn more.","date":"2022-09-26T00:00:00.000Z","formattedDate":"September 26, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"}],"readingTime":4.76,"hasTruncateMarker":false,"authors":[{"name":"Madhura Bharadwaj","title":"Product Manager, Azure Functions @Microsoft","url":"https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/360851#profile","imageURL":"https://techcommunity.microsoft.com/t5/image/serverpage/image-id/252689i712A569920A3BE85/image-dimensions/150x150/image-coordinates/0%2C74%2C472%2C546?v=v2","key":"madhura"}],"frontMatter":{"slug":"zero2hero-func-07","title":"\ud83d\ude80 | Monitor + Troubleshoot Apps","authors":["madhura"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","monitoring"],"image":"./img/zero-to-hero-madhura.png","description":"When you\u2019re running a function app, you want to be prepared for any issues that may arise, from 4xx errors to trigger failures. Azure Functions offers built-in integration with Azure Application Insights to monitor function executions. Let\'s learn more.","tags":["serverless-september","zero-to-hero","azure-functions"]},"prevItem":{"title":"28. Serverless + Power Platforms","permalink":"/Cloud-Native/blog/28-where-am-i"},"nextItem":{"title":"25. Deploy Spring Boot App to ACA","permalink":"/Cloud-Native/blog/25-aca-java"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/zero2hero-func-07\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ZeroToHero: Monitoring and troubleshooting apps in Azure Functions \\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ZeroToHero: Monitoring and troubleshooting apps in Azure Functions\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/serverless-zero2hero.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://techcommunity.microsoft.com/t5/apps-on-azure-blog/error-handling-with-apache-kafka-extension-for-azure-functions/ba-p/3628936\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 26` of #30DaysOfServerless!\\n\\nToday, we have a special set of posts from our [Zero To Hero \ud83d\ude80](/serverless-september/ZeroToHero) initiative, featuring blog posts authored by our Product Engineering teams for #ServerlessSeptember. _Posts were originally published on the [Apps on Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/monitoring-and-troubleshooting-apps-in-azure-functions/ba-p/3638230?WT.mc_id=javascript-99907-cxa) blog on Microsoft Tech Community._\\n\\n---\\n\\n## What We\'ll Cover\\n * Monitoring your Azure Functions\\n * Built-in log streaming\\n * Live Metrics stream\\n * Troubleshooting Azure Functions\\n\\n![](./img/zero-to-hero-madhura.png)\\n\\n---\\n\\n## Monitoring your Azure Functions:\\n\\nAzure Functions uses **Application Insights** to collect and analyze log data from individual function executions in your function app.\\n\\n### Using Application Insights\\n\\nApplication Insights collects _log, performance, and error data_. By automatically detecting performance anomalies and featuring powerful analytics tools, you can more easily diagnose issues and better understand how your functions are used. These tools are designed to help you continuously improve performance and usability of your functions. You can even use Application Insights during local function app project development.\\n\\nTypically, you create an Application Insights instance when you create your function app. In this case, the instrumentation key required for the integration is already set as an application setting named `APPINSIGHTS_INSTRUMENTATIONKEY`. With Application Insights integration enabled, telemetry data is sent to your connected Application Insights instance. This data includes logs generated by the Functions host, traces written from your functions code, and performance data. In addition to data from your functions and the Functions host, you can also collect data from the [Functions scale controller](https://learn.microsoft.com/azure/azure-functions/functions-monitoring#scale-controller-logs?WT.mc_id=javascript-99907-cxa).\\n\\nBy default, the data collected from your function app is stored in Application Insights. In the [Azure portal](https://portal.azure.com/), Application Insights provides an extensive set of visualizations of your telemetry data. You can drill into error logs and query events and metrics. To learn more, including basic examples of how to view and query your collected data, see [Analyze Azure Functions telemetry in Application Insights](https://learn.microsoft.com/azure/azure-functions/analyze-telemetry-data?WT.mc_id=javascript-99907-cxa).\\n\\n### Using Log Streaming \\n\\nIn addition to this, you can have a smoother debugging experience through log streaming. There are two ways to view a stream of log files being generated by your function executions.\\n\\n * **Built-in log streaming**: the App Service platform lets you view a stream of your application log files. This is equivalent to the output seen when you debug your functions during [local development](https://learn.microsoft.com/azure/azure-functions/functions-develop-local?WT.mc_id=javascript-99907-cxa) and when you use the Test tab in the portal. All log-based information is displayed. For more information, see [Stream logs](https://learn.microsoft.com/azure/app-service/troubleshoot-diagnostic-logs#stream-logs?WT.mc_id=javascript-99907-cxa). This streaming method supports only a single instance and can\'t be used with an app running on Linux in a Consumption plan.\\n* **Live Metrics Stream**: when your function app is [connected to Application Insights](https://learn.microsoft.com/azure/azure-functions/configure-monitoring#enable-application-insights-integration?WT.mc_id=javascript-99907-cxa), you can view log data and other metrics in near real-time in the Azure portal using [Live Metrics Stream](https://learn.microsoft.com/azure/azure-monitor/app/live-stream?WT.mc_id=javascript-99907-cxa). Use this method when monitoring functions running on multiple-instances or on Linux in a Consumption plan. This method uses [sampled data](https://learn.microsoft.com/azure/azure-functions/configure-monitoring#configure-sampling?WT.mc_id=javascript-99907-cxa).\\nLog streams can be viewed both in the portal and in most local development environments.\\n\\n:::info Monitoring Azure Functions\\nLearn how to [configure monitoring for your Azure Functions](https://learn.microsoft.com/azure/azure-functions/configure-monitoring?source=recommendations&tabs=v2&WT.mc_id=javascript-99907-cxa). See [Monitoring Azure Functions data reference](https://learn.microsoft.com/azure/azure-functions/monitor-functions-reference?WT.mc_id=javascript-99907-cxa) for detailed information on the metrics and logs metrics created by Azure Functions.\\n:::\\n \\nIn addition to this, Azure Functions uses [Azure Monitor](https://learn.microsoft.com/azure/azure-monitor/overview) to [monitor the health of your function apps](https://learn.microsoft.com/azure/azure-functions/monitor-functions?tabs=portal). Azure Functions collects the same kinds of monitoring data as other Azure resources that are described in [Azure Monitor data collection](https://learn.microsoft.com/azure/azure-monitor/essentials/monitor-azure-resource#monitoring-data-from-azure-resources). See [Monitoring Azure Functions data reference](https://learn.microsoft.com/azure/azure-functions/monitor-functions-reference) for detailed information on the metrics and logs metrics created by Azure Functions.\\n\\n\\n## Troubleshooting your Azure Functions:\\n\\nWhen you do run into issues with your function app, Azure Functions diagnostics points out what\u2019s wrong. It guides you to the right information to troubleshoot and resolve the issue more easily and quickly.\\n\\nLet\u2019s explore how to use Azure Functions diagnostics to diagnose and solve common function app issues.\\n\\n 1. Navigate to your function app [in the Azure portal](https://portal.azure.com/?WT.mc_id=javascript-99907-cxa).\\n 2. Select Diagnose and solve problems to open Azure Functions diagnostics.\\n 3. Once you\u2019re here, there are multiple ways to retrieve the information you\u2019re looking for. Choose a category that best describes the issue of your function app by using the keywords in the homepage tile. You can also type a keyword that best describes your issue in the search bar. There\u2019s also a section at the bottom of the page that will directly take you to some of the more popular troubleshooting tools. For example, you could type execution to see a list of diagnostic reports related to your function app execution and open them directly from the homepage.\\n\\n![Monitoring and troubleshooting apps in Azure Functions](./img/madhura-functions-1.png)\\n\\n 4. For example, click on the Function App Down or Reporting Errors link under Popular troubleshooting tools section. You will find detailed analysis, insights and next steps for the issues that were detected. On the left you\u2019ll see a list of detectors. Click on them to explore more, or if there\u2019s a particular keyword you want to look for, type it Into the search bar on the top.\\n \\n![Monitoring and troubleshooting apps in Azure Functions](./img/madhura-functions-2.png)\\n\\n:::tip TROUBLESHOOTING TIP\\n\\nHere are some general troubleshooting tips that you can follow if you find your Function App throwing [Azure Functions Runtime unreachable](https://learn.microsoft.com/azure/azure-functions/functions-recover-storage-account?WT.mc_id=javascript-99907-cxa) error. \\n\\nAlso be sure to check out the recommended best practices to ensure your Azure Functions are highly reliable. [This article](https://learn.microsoft.com/azure/azure-functions/functions-best-practices?source=recommendations&tabs=csharp&WT.mc_id=javascript-99907-cxa) details some best practices for designing and deploying efficient function apps that remain healthy and perform well in a cloud-based environment.\\n:::\\nBonus tip:"},{"id":"25-aca-java","metadata":{"permalink":"/Cloud-Native/blog/25-aca-java","source":"@site/blog/2022-09-25/index.md","title":"25. Deploy Spring Boot App to ACA","description":"Learn how to deploy containerized Spring boot apps to Azure Container apps (ACA) using Azure Container Registry (ACR)","date":"2022-09-25T00:00:00.000Z","formattedDate":"September 25, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":6.255,"hasTruncateMarker":false,"authors":[{"name":"Brian Benz","title":"Senior Cloud Advocate @Microsoft","url":"https://github.com/bbenz","imageURL":"https://github.com/bbenz.png","key":"brian"}],"frontMatter":{"slug":"25-aca-java","title":"25. Deploy Spring Boot App to ACA","authors":["brian"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","containers","java","springboot"],"image":"./img/java/banner.png","description":"Learn how to deploy containerized Spring boot apps to Azure Container apps (ACA) using Azure Container Registry (ACR)","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"\ud83d\ude80 | Monitor + Troubleshoot Apps","permalink":"/Cloud-Native/blog/zero2hero-func-07"},"nextItem":{"title":"24. Deploy ASP.NET app to ACA","permalink":"/Cloud-Native/blog/24-aca-dotnet"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/23-aca-java\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Deploy Spring Boot App to ACA\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Deploy Spring Boot App to ACA\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/23-aca-java\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 25` of #30DaysOfServerless!\\n\\n\\n[Azure Container Apps](https://docs.microsoft.com/azure/container-apps/overview) enable application code packaged in containers to run and scale without the overhead of managing cloud infrastructure and container orchestration.  In this post I\'ll show you how to **deploy a Java application running on Spring Boot in a container to Azure Container Registry and Azure Container Apps.** \\n\\n---\\n\\n## What We\'ll Cover\\n * Introduction to Deploying Java containers in the cloud\\n * Step-by-step: Deploying to Azure Container Registry\\n * Step-by-step: Deploying and running on Azure Container Apps\\n * Resources: For self-study!\\n\\n![](./img/java/banner.png)\\n\\n---\\n\\n\\n## Deploy Java containers to cloud\\n\\nWe\'ll deploy a Java application running on Spring Boot in a container to Azure Container Registry and Azure Container Apps. Here are the main steps:\\n\\n- Create Azure Container Registry (ACR) on Azure portal\\n- Create Azure Container App (ACA) on Azure portal.\\n- Deploy code to Azure Container Registry from the Azure CLI. \\n- Deploy container from ACR to ACA using the Azure portal.\\n\\n:::info PRE-REQUISITES\\n-  **Active Azure subscription** with Contributor or Owner permissions. [Create an account for free](https://azure.microsoft.com/free/) if you don\'t have one.\\n- **GitHub account**. Sign up for [free](https://github.com/join) if you don\'t have one.\\n- Install **[Git](https://github.com/git-guides/install-git)**.\\n- Install the **[Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli)**.\\n:::\\n\\nSign in to Azure from the CLI using the ```az login``` command, and follow the prompts in your browser to complete the authentication process.  Also, ensure you\'re running the latest version of the CLI by using the ```az upgrade```  command.\\n\\n## 1. Get Sample Code\\nFork and clone the [sample GitHub repo](https://github.com/bbenz/spring-boot-docker-aca) to your local machine.  Navigate to the  and click **Fork** in the top-right corner of the page.\\n\\n> The [example code](https://github.com/bbenz/spring-boot-docker-aca) that we\'re using is a very basic containerized Spring Boot example.  There are a lot more details to learn about Spring boot apps in docker, for a deep dive check out this [Spring Boot Guide](https://spring.io/guides/gs/spring-boot-docker/) \\n\\n## 2. Run Sample Locally (Optional)\\n\\nIf you have docker installed locally, you can optionally test the code on your local machine.  Navigate to the root directory of the forked repository and run the following commands:\\n\\n```azurecli\\ndocker build -t spring-boot-docker-aca .\\ndocker run -p 8080:8080 spring-boot-docker-aca\\n```\\n\\nOpen a browser and go to https://localhost:8080.  You should see this message: \\n\\n```azurecli\\nHello Docker World\\n```\\n\\nThat indicates the the Spring Boot app is successfully running locally in a docker container. \\n\\nNext, let\'s set up an Azure Container Registry an an Azure Container App and deploy this container to the cloud!\\n\\n---\\n\\n## 3. Step-by-step: Deploy to ACR\\n\\nTo create a container registry from the [portal dashboard](https://portal.azure.com), Select **Create a resource > Containers > Container Registry**.\\n\\n![Navigate to container registry in portal](img/java/acr-portal-01.png)\\n\\nIn the Basics tab, enter values for Resource group and Registry name. The registry name must be unique within Azure, and contain 5-50 alphanumeric characters. Create a new resource group in the West US location named spring-boot-docker-aca.  Select the \'Basic\' SKU.\\n\\nKeep the default values for the remaining settings. Then select **Review + create**, then  **Create**.  When the Deployment succeeded message appears, select the container registry in the portal.\\n\\nNote the registry server name ending with azurecr.io. You will use this in the following steps when you push and pull images with Docker.\\n\\n### 3.1 Log into registry using the Azure CLI\\nBefore pushing and pulling container images, you must log in to the registry instance. Sign into the Azure CLI on your local machine, then run the ```az acr login``` command. For this step, use the registry name, not the server name ending with azurecr.io.\\n\\nFrom the command line, type: \\n\\n```azurecli\\naz acr login --name myregistryname\\n```\\nThe command returns **Login Succeeded** once completed.\\n\\n### 3.2 Build & deploy with `az acr build`\\nNext, we\'re going to deploy the docker container we created earlier using the AZ ACR Build command.  [AZ ACR Build](https://docs.microsoft.com/cli/azure/acr?view=azure-cli-latest#az-acr-build) creates a docker build from local code and pushes the container to Azure Container Registry if the build is successful. \\n\\nGo to your local clone of the **spring-boot-docker-aca** repo in the command line, type: \\n\\n```azurecli\\naz acr build --registry myregistryname --image spring-boot-docker-aca:v1 .\\n```\\n\\n### 3.3 List container images\\nOnce the AZ ACR Build command is complete, you should be able to view the container as a repository in the registry.  In the portal, open your registry and select **Repositories**, then select the **spring-boot-docker-aca** repository you created with docker push.  You should also see the **v1** image under Tags.\\n\\n\\n## 4. Deploy on ACA\\n\\nNow that we have an image in the Azure Container Registry, we can deploy it to Azure Container Apps. For the first deployment, we\'ll pull the container from our ACR as part of the ACA setup.\\n\\n### 4.1 Create a container app\\n\\nWe\'ll create the container app at the same place that we created the container registry in the Azure portal.  From the portal, select **Create a resource > Containers > Container App**.  In the *Basics* tab, set these values:\\n\\n### 4.2 Enter project details\\n\\n| Setting | Action |\\n|---|---|\\n| Subscription | Your Azure subscription. |\\n| Resource group | Use the **spring-boot-docker-aca** resource group |\\n| Container app name |  Enter **spring-boot-docker-aca**. |\\n\\n### 4.3 Create an environment\\n\\n1. In the *Create Container App environment* field, select **Create new**.\\n1. In the *Create Container App Environment* page on the *Basics* tab, enter the following values:\\n\\n    | Setting | Value |\\n    |---|---|\\n    | Environment name | Enter **my-environment**. |\\n    | Region | Select **westus3**. |\\n\\n1. Select **OK**.\\n1. Select the **Create** button at the bottom of the *Create Container App Environment* page.\\n1. Select the **Next: App settings** button at the bottom of the page.\\n\\n## 5. App settings tab\\n\\nThe *App settings* tab is where you connect to the ACR and pull the repository image:\\n\\n| Setting | Action |\\n|---|---|\\n| Use quickstart image | **Uncheck** the checkbox. |\\n| Name | Enter **spring-boot-docker-aca**. |\\n| Image source | Select **Azure Container Registry**|\\n| Registry | Select your ACR from the list. |\\n| Image | Select **spring-boot-docker-aca** from the list. |\\n| Image Tag | Select **v1** from the list. |\\n\\n### 5.1 Application ingress settings\\n\\n| Setting | Action |\\n|---|---|\\n| Ingress | Select **Enabled**. |\\n| Ingress visibility | Select **External** to publicly expose your container app. |\\n| Target port | Enter **8080**. |\\n\\n### 5.2 Deploy the container app\\n\\n1. Select the **Review and create** button at the bottom of the page.  \\n1. Select **Create**.\\n\\nOnce the deployment is successfully completed, you\'ll see the message: *Your deployment is complete*.\\n\\n### 5.3 Verify deployment\\n\\nIn the portal, go to the Overview of your **spring-boot-docker-aca** Azure Container App, and click on the Application Url.   You should see this message in the browser: \\n\\n```azurecli\\nHello Docker World\\n```\\n\\nThat indicates the the Spring Boot app is running in a docker container in your **spring-boot-docker-aca** Azure Container App.   \\n\\n\\n## Resources: For self-study!\\n\\nOnce you have an understanding of the basics in ths post, there is so much more to learn!  \\n- Check out the other [Serverless September posts](https://azure.github.io/Cloud-Native/blog).  \\n- For DevOps and Java on Azure, see the tutorials and workshops at https://aka.ms/devopsforjavashops\\n- Also see https://developer.microsoft.com/java for everything Java on Azure!\\n\\nThanks for stopping by!"},{"id":"24-aca-dotnet","metadata":{"permalink":"/Cloud-Native/blog/24-aca-dotnet","source":"@site/blog/2022-09-24/index.md","title":"24. Deploy ASP.NET app to ACA","description":"Deploy your containerized, multi-project .NET applications to Azure Container Apps","date":"2022-09-24T00:00:00.000Z","formattedDate":"September 24, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"dotnet","permalink":"/Cloud-Native/blog/tags/dotnet"},{"label":"asp.net","permalink":"/Cloud-Native/blog/tags/asp-net"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":18.71,"hasTruncateMarker":false,"authors":[{"name":"Alex Wolf","title":"Software Engineer @Microsoft","url":"https://github.com/alexwolfmsft","imageURL":"https://github.com/alexwolfmsft.png","key":"alexwolf"}],"frontMatter":{"slug":"24-aca-dotnet","title":"24. Deploy ASP.NET app to ACA","authors":["alexwolf"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/dotnet/banner.png","description":"Deploy your containerized, multi-project .NET applications to Azure Container Apps","tags":["serverless-september","30-days-of-serverless","dotnet","asp.net","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"25. Deploy Spring Boot App to ACA","permalink":"/Cloud-Native/blog/25-aca-java"},"nextItem":{"title":"21. CloudEvents with Event Grid","permalink":"/Cloud-Native/blog/21-cloudevents-via-event-grid"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/24-aca-dotnet\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Deploy an ASP.NET app to Azure Container Apps \\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Deploy an ASP.NET app to Azure Container Apps\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/24-aca-dotnet\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 24` of #30DaysOfServerless!\\n\\nWe continue exploring E2E scenarios with this tutorial where you\'ll deploy a containerized ASP.NET Core 6.0 application to Azure Container Apps. \\n\\nThe application consists of a front-end web app built using Blazor Server, as well as two Web API projects to manage data. These projects will exist as three separate containers inside of a shared container apps environment.\\n\\n---\\n\\n## What We\'ll Cover\\n * Deploy ASP.NET Core 6.0 app to Azure Container Apps\\n * Automate deployment workflows using GitHub Actions\\n * Provision and deploy resources using Azure Bicep\\n * Exercise: Try this yourself!\\n * Resources: For self-study!\\n\\n![](./img/dotnet/banner.png)\\n\\n---\\n\\n# Introduction\\n\\nAzure Container Apps enables you to run microservices and containerized applications on a serverless platform. With Container Apps, you enjoy the benefits of running containers while leaving behind the concerns of manually configuring cloud infrastructure and complex container orchestrators.\\n\\nIn this tutorial, you\'ll deploy a containerized ASP.NET Core 6.0 application to Azure Container Apps. The application consists of a front-end web app built using Blazor Server, as well as two Web API projects to manage data. These projects will exist as three separate containers inside of a shared container apps environment.\\n\\nYou will use GitHub Actions in combination with Bicep to deploy the application. These tools provide an approachable and sustainable solution for building CI/CD pipelines and working with Container Apps.\\n\\n:::info PRE-REQUISITES\\n- An Azure subscription. [Sign up for free](https://azure.microsoft.com).\\n- A [GitHub account](https://github.com/join), with access to GitHub Actions.\\n- The [Azure CLI](https://docs.microsoft.com/azure/install-azure-cli) installed locally.\\n- [Microsoft Visual Studio 2022](https://visualstudio.microsoft.com/vs/)\\n:::\\n\\n## Architecture\\n\\nIn this tutorial, we\'ll setup a container app environment with a separate container for each project in the sample store app. The major components of the sample project include:\\n\\n- A Blazor Server front-end web app to display product information\\n- A products API to list available products\\n- An inventory API to determine how many products are in stock\\n- GitHub Actions and Bicep templates to provision Azure resources and then build and deploy the sample app. \\n\\nYou will explore these templates later in the tutorial.\\n\\nPublic internet traffic should be proxied to the Blazor app. The back-end APIs should only be reachable via requests from the Blazor app inside the container apps environment. This setup can be achieved using container apps environment ingress configurations during deployment.\\n\\n![An architecture diagram of the shopping app](./img/dotnet/architecture.png)\\n\\n---\\n\\n## Project Sources\\n\\nWant to follow along? Fork the sample below. The tutorial can be completed with or without Dapr integration. Pick the path you feel comfortable in. Dapr provides various benefits that make working with Microservices easier - you can learn more in the docs. For this tutorial you will need GitHub and Azure CLI.\\n\\n:::info PICK YOUR PATH\\nTo follow along with this tutorial, fork the relevant sample project below.  \\n * [**Project Repo: Without Dapr**](https://github.com/Azure-Samples/dotNET-FrontEnd-to-BackEnd-on-Azure-Container-Apps)\\n * [**Project Repo: With Dapr**](https://github.com/Azure-Samples/dotNET-FrontEnd-to-BackEnd-with-DAPR-on-Azure-Container-Apps)\\n\\n:::\\n\\nYou can run the app locally from Visual Studio:\\n * Right click on the Blazor **Store** project and select **Set as Startup Project**. \\n * Press the start button at the top of Visual Studio to run the app. \\n * (Once running) start each API in the background by \\n  - right-clicking on the project node \\n  - selecting **Debug --\x3e Start without debugging**.\\n\\nOnce the Blazor app is running, you should see something like this:\\n\\n![An architecture diagram of the shopping app](./img/dotnet/store-ui.png)\\n\\n---\\n\\n## Configuring Azure credentials\\n\\nIn order to deploy the application to Azure through GitHub Actions, you first need to create a service principal. The service principal will allow the GitHub Actions process to authenticate to your Azure subscription to create resources and deploy code. You can [learn more about Service Principals](https://docs.microsoft.com/azure/create-an-azure-service-principal-azure-cli) in the Azure CLI documentation. For this step you\'ll need to be logged into the Azure CLI.\\n\\n1) If you have not done so already, make sure to [fork the sample project](https://github.com/Azure-Samples/dotNET-FrontEnd-to-BackEnd-on-Azure-Container-Apps) to your own GitHub account or organization. \\n\\n1) Once you have completed this step, create a service principal using the Azure CLI command below:\\n\\n    ```azurecli\\n    $subscriptionId=$(az account show --query id --output tsv)\\n    az ad sp create-for-rbac --sdk-auth --name WebAndApiSample --role Contributor --scopes /subscriptions/$subscriptionId\\n    ```\\n\\n1) Copy the JSON output of the CLI command to your clipboard\\n\\n1) Under the settings tab of your forked GitHub repo, create a new secret named **AzureSPN**. The name is important to match the Bicep templates included in the project, which we\'ll review later. Paste the copied service principal values on your clipboard into the secret and save your changes. This new secret will be used by the GitHub Actions workflow to authenticate to Azure.\\n\\n    :::image type=\\"content\\" source=\\"./img/dotnet/github-secrets.png\\" alt-text=\\"A screenshot of adding GitHub secrets.\\":::\\n\\n## Deploy using Github Actions\\n\\nYou are now ready to deploy the application to Azure Container Apps using GitHub Actions. The sample application includes a GitHub Actions template that is configured to build and deploy any changes to a branch named **deploy**.  The deploy branch does not exist in your forked repository by default, but you can easily create it through the GitHub user interface.\\n\\n1) Switch to the **Actions** tab along the top navigation of your GitHub repository. If you have not done so already, ensure that workflows are enabled by clicking the button in the center of the page.\\n\\n![A screenshot showing how to enable GitHub actions](./img/dotnet/enable-actions.png)\\n\\n1) Navigate to the main **Code** tab of your repository and select the **main** dropdown. Enter *deploy* into the branch input box, and then select **Create branch: deploy from \'main\'**.  \\n\\n![A screenshot showing how to create the deploy branch](./img/dotnet/create-branch.png)\\n\\n1) On the new **deploy** branch, navigate down into the **.github/workflows** folder. You should see a file called **deploy.yml**, which contains the main GitHub Actions workflow script. Click on the file to view its content. You\'ll learn more about this file later in the tutorial.\\n\\n1) Click the pencil icon in the upper right to edit the document.\\n\\n1) Change the **RESOURCE_GROUP_NAME:** value to *msdocswebappapis* or another valid resource group name of your choosing. \\n\\n1) In the upper right of the screen, select **Start commit** and then **Commit changes** to commit your edit. This will persist the change to the file and trigger the GitHub Actions workflow to build and deploy the app.\\n\\n![A screenshot showing how to commit changes](./img/dotnet/commit-changes.png)\\n\\n1) Switch to the **Actions** tab along the top navigation again. You should see the workflow running to create the necessary resources and deploy the app. The workflow may take several minutes to run. When it completes successfully, all of the jobs should have a green checkmark icon next to them.\\n\\n![The completed GitHub workflow.](./img/dotnet/github-actions-success.png)\\n\\n## Explore the Azure resources\\n\\nOnce the GitHub Actions workflow has completed successfully you can browse the created resources in the Azure portal.  \\n\\n1) On the left navigation, select **Resource Groups**. Next,choose the **msdocswebappapis** resource group that was created by the GitHub Actions workflow.\\n\\n2) You should see seven resources available that match the screenshot and table descriptions below.\\n\\n![The resources created in Azure.](./img/dotnet/azure-resources.png)\\n\\n\\n|Resource name  |Type  |Description  |\\n|---------|---------|---------|\\n|inventory     | Container app        | The containerized inventory API.          |\\n|msdocswebappapisacr     | Container registry         | A registry that stores the built Container images for your apps.         |\\n|msdocswebappapisai    | Application insights        | Application insights provides advanced monitoring, logging and metrics for your apps.         |\\n|msdocswebappapisenv     | Container apps environment         | A container environment that manages networking, security and resource concerns. All of your containers live in this environment.        |\\n|msdocswebappapislogs     | Log Analytics workspace         | A workspace environment for managing logging and analytics for the container apps environment         |\\n|products     | Container app         | The containerized products API.         |\\n|store     | Container app         | The Blazor front-end web app.         |\\n    \\n3) You can view your running app in the browser by clicking on the **store** container app. On the overview page, click the **Application Url** link on the upper right of the screen.\\n\\n    :::image type=\\"content\\" source=\\"./img/dotnet/application-url.png\\" alt-text=\\"The link to browse the app.\\":::\\n\\n## Understanding the GitHub Actions workflow\\n\\nThe GitHub Actions workflow created and deployed resources to Azure using the **deploy.yml** file in the **.github** folder at the root of the project. The primary purpose of this file is to respond to events - such as commits to a branch - and run jobs to accomplish tasks. The **deploy.yml** file in the sample project has three main jobs:\\n\\n- **Provision**: Create the necessary resources in Azure, such as the container apps environment. This step leverages Bicep templates to create the Azure resources, which you\'ll explore in a moment.\\n- **Build**: Create the container images for the three apps in the project and store them in the container registry.\\n- **Deploy**: Deploy the container images to the different container apps created during the provisioning job.\\n\\nThe **deploy.yml** file also accepts parameters to make the workflow more dynamic, such as setting the resource group name or the Azure region resources will be provisioned to. \\n\\nBelow is a commented version of the **deploy.yml** file that highlights the essential steps.\\n\\n```yml\\nname: Build and deploy .NET application to Container Apps\\n\\n# Trigger the workflow on pushes to the deploy branch\\non:\\n  push:\\n    branches:\\n    - deploy\\n\\nenv:\\n  # Set workflow variables\\n  RESOURCE_GROUP_NAME: msdocswebappapis\\n\\n  REGION: eastus\\n\\n  STORE_DOCKER: Store/Dockerfile\\n  STORE_IMAGE: store\\n\\n  INVENTORY_DOCKER: Store.InventoryApi/Dockerfile\\n  INVENTORY_IMAGE: inventory\\n\\n  PRODUCTS_DOCKER: Store.ProductApi/Dockerfile\\n  PRODUCTS_IMAGE: products\\n\\njobs:\\n  # Create the required Azure resources\\n  provision:\\n    runs-on: ubuntu-latest\\n\\n    steps:\\n\\n    - name: Checkout to the branch\\n      uses: actions/checkout@v2\\n\\n    - name: Azure Login\\n      uses: azure/login@v1\\n      with:\\n        creds: ${{ secrets.AzureSPN }}\\n\\n    - name: Create resource group\\n      uses: azure/CLI@v1\\n      with:\\n        inlineScript: >\\n          echo \\"Creating resource group in Azure\\"\\n          echo \\"Executing \'az group create -l ${{ env.REGION }} -n ${{ env.RESOURCE_GROUP_NAME }}\'\\"\\n          az group create -l ${{ env.REGION }} -n ${{ env.RESOURCE_GROUP_NAME }}\\n\\n    # Use Bicep templates to create the resources in Azure\\n    - name: Creating resources\\n      uses: azure/CLI@v1\\n      with:\\n        inlineScript: >\\n          echo \\"Creating resources\\"\\n          az deployment group create --resource-group ${{ env.RESOURCE_GROUP_NAME }} --template-file \'/github/workspace/Azure/main.bicep\' --debug\\n\\n  # Build the three app container images\\n  build:\\n    runs-on: ubuntu-latest\\n    needs: provision\\n    \\n    steps:\\n\\n    - name: Checkout to the branch\\n      uses: actions/checkout@v2\\n\\n    - name: Azure Login\\n      uses: azure/login@v1\\n      with:\\n        creds: ${{ secrets.AzureSPN }}\\n\\n    - name: Set up Docker Buildx\\n      uses: docker/setup-buildx-action@v1\\n\\n    - name: Login to ACR\\n      run: |\\n        set -euo pipefail\\n        access_token=$(az account get-access-token --query accessToken -o tsv)\\n        refresh_token=$(curl https://${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/oauth2/exchange -v -d \\"grant_type=access_token&service=${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io&access_token=$access_token\\" | jq -r .refresh_token)\\n        docker login -u 00000000-0000-0000-0000-000000000000 --password-stdin ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io <<< \\"$refresh_token\\"\\n\\n    - name: Build the products api image and push it to ACR\\n      uses: docker/build-push-action@v2\\n      with:\\n        push: true\\n        tags: ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/${{ env.PRODUCTS_IMAGE }}:${{ github.sha }}\\n        file: ${{ env.PRODUCTS_DOCKER }}\\n\\n    - name: Build the inventory api image and push it to ACR\\n      uses: docker/build-push-action@v2\\n      with:\\n        push: true\\n        tags: ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/${{ env.INVENTORY_IMAGE }}:${{ github.sha }}\\n        file: ${{ env.INVENTORY_DOCKER }}\\n\\n    - name: Build the frontend image and push it to ACR\\n      uses: docker/build-push-action@v2\\n      with:\\n        push: true\\n        tags: ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/${{ env.STORE_IMAGE }}:${{ github.sha }}\\n        file: ${{ env.STORE_DOCKER }}\\n\\n  # Deploy the three container images\\n  deploy:\\n    runs-on: ubuntu-latest\\n    needs: build\\n\\n    steps:\\n\\n    - name: Checkout to the branch\\n      uses: actions/checkout@v2\\n\\n    - name: Azure Login\\n      uses: azure/login@v1\\n      with:\\n        creds: ${{ secrets.AzureSPN }}\\n\\n    - name: Installing Container Apps extension\\n      uses: azure/CLI@v1\\n      with:\\n        inlineScript: >\\n          az config set extension.use_dynamic_install=yes_without_prompt\\n\\n          az extension add --name containerapp --yes\\n\\n    - name: Login to ACR\\n      run: |\\n        set -euo pipefail\\n        access_token=$(az account get-access-token --query accessToken -o tsv)\\n        refresh_token=$(curl https://${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/oauth2/exchange -v -d \\"grant_type=access_token&service=${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io&access_token=$access_token\\" | jq -r .refresh_token)\\n        docker login -u 00000000-0000-0000-0000-000000000000 --password-stdin ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io <<< \\"$refresh_token\\"\\n\\n    - name: Deploy Container Apps\\n      uses: azure/CLI@v1\\n      with:\\n        inlineScript: >\\n          az containerapp registry set -n products -g ${{ env.RESOURCE_GROUP_NAME }} --server ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io\\n\\n          az containerapp update -n products -g ${{ env.RESOURCE_GROUP_NAME }} -i ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/${{ env.PRODUCTS_IMAGE }}:${{ github.sha }}\\n\\n          az containerapp registry set -n inventory -g ${{ env.RESOURCE_GROUP_NAME }} --server ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io\\n\\n          az containerapp update -n inventory -g ${{ env.RESOURCE_GROUP_NAME }} -i ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/${{ env.INVENTORY_IMAGE }}:${{ github.sha }}\\n\\n          az containerapp registry set -n store -g ${{ env.RESOURCE_GROUP_NAME }} --server ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io\\n          \\n          az containerapp update -n store -g ${{ env.RESOURCE_GROUP_NAME }} -i ${{ env.RESOURCE_GROUP_NAME }}acr.azurecr.io/${{ env.STORE_IMAGE }}:${{ github.sha }}\\n\\n    - name: logout\\n      run: >\\n        az logout\\n\\n```\\n\\n## Understanding the Bicep templates\\n\\nDuring the provisioning stage of the GitHub Actions workflow, the **main.bicep** file is processed. Bicep files provide a declarative way of generating resources in Azure and are ideal for managing infrastructure as code. You can [learn more about Bicep](https://docs.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) in the related documentation.  The *main.bicep* file in the sample project creates the following resources:\\n\\n- The container registry to store images of the containerized apps.\\n- The container apps environment, which handles networking and resource management for the container apps.\\n- Three container apps - one for the Blazor front-end and two for the back-end product and inventory APIs.\\n- Configuration values to connect these services together\\n\\n### [*main.bicep* without Dapr](#tab/exclude-dapper)\\n\\n```yml\\nparam location string = resourceGroup().location\\n\\n# create the azure container registry\\nresource acr \'Microsoft.ContainerRegistry/registries@2021-09-01\' = {\\n  name: toLower(\'${resourceGroup().name}acr\')\\n  location: location\\n  sku: {\\n    name: \'Basic\'\\n  }\\n  properties: {\\n    adminUserEnabled: true\\n  }\\n}\\n\\n# create the aca environment\\nmodule env \'environment.bicep\' = {\\n  name: \'containerAppEnvironment\'\\n  params: {\\n    location: location\\n  }\\n}\\n\\n# create the various configuration pairs\\nvar shared_config = [\\n  {\\n    name: \'ASPNETCORE_ENVIRONMENT\'\\n    value: \'Development\'\\n  }\\n  {\\n    name: \'APPINSIGHTS_INSTRUMENTATIONKEY\'\\n    value: env.outputs.appInsightsInstrumentationKey\\n  }\\n  {\\n    name: \'APPLICATIONINSIGHTS_CONNECTION_STRING\'\\n    value: env.outputs.appInsightsConnectionString\\n  }\\n]\\n\\n# create the products api container app\\nmodule products \'container_app.bicep\' = {\\n  name: \'products\'\\n  params: {\\n    name: \'products\'\\n    location: location\\n    registryPassword: acr.listCredentials().passwords[0].value\\n    registryUsername: acr.listCredentials().username\\n    containerAppEnvironmentId: env.outputs.id\\n    registry: acr.name\\n    envVars: shared_config\\n    externalIngress: false\\n  }\\n}\\n\\n# create the inventory api container app\\nmodule inventory \'container_app.bicep\' = {\\n  name: \'inventory\'\\n  params: {\\n    name: \'inventory\'\\n    location: location\\n    registryPassword: acr.listCredentials().passwords[0].value\\n    registryUsername: acr.listCredentials().username\\n    containerAppEnvironmentId: env.outputs.id\\n    registry: acr.name\\n    envVars: shared_config\\n    externalIngress: false\\n  }\\n}\\n\\n# create the store api container app\\nvar frontend_config = [\\n  {\\n    name: \'ProductsApi\'\\n    value: \'http://${products.outputs.fqdn}\'\\n  }\\n  {\\n    name: \'InventoryApi\'\\n    value: \'http://${inventory.outputs.fqdn}\'\\n  }\\n]\\n\\nmodule store \'container_app.bicep\' = {\\n  name: \'store\'\\n  params: {\\n    name: \'store\'\\n    location: location\\n    registryPassword: acr.listCredentials().passwords[0].value\\n    registryUsername: acr.listCredentials().username\\n    containerAppEnvironmentId: env.outputs.id\\n    registry: acr.name\\n    envVars: union(shared_config, frontend_config)\\n    externalIngress: true\\n  }\\n}\\n\\n```\\n\\n### [*main.bicep* with Dapr](#tab/include-dapper)\\n\\n```yml\\n\\nparam location string = resourceGroup().location\\n\\n# create the azure container registry\\nresource acr \'Microsoft.ContainerRegistry/registries@2021-09-01\' = {\\n  name: toLower(\'${resourceGroup().name}acr\')\\n  location: location\\n  sku: {\\n    name: \'Basic\'\\n  }\\n  properties: {\\n    adminUserEnabled: true\\n  }\\n}\\n\\n# create the aca environment\\nmodule env \'environment.bicep\' = {\\n  name: \'containerAppEnvironment\'\\n  params: {\\n    location: location\\n  }\\n}\\n\\n# create the various config pairs\\nvar shared_config = [\\n  {\\n    name: \'ASPNETCORE_ENVIRONMENT\'\\n    value: \'Development\'\\n  }\\n  {\\n    name: \'APPINSIGHTS_INSTRUMENTATIONKEY\'\\n    value: env.outputs.appInsightsInstrumentationKey\\n  }\\n  {\\n    name: \'APPLICATIONINSIGHTS_CONNECTION_STRING\'\\n    value: env.outputs.appInsightsConnectionString\\n  }\\n]\\n\\n# create the products api container app\\nmodule products \'container_app.bicep\' = {\\n  name: \'products\'\\n  params: {\\n    name: \'products\'\\n    location: location\\n    registryPassword: acr.listCredentials().passwords[0].value\\n    registryUsername: acr.listCredentials().username\\n    containerAppEnvironmentId: env.outputs.id\\n    registry: acr.name\\n    envVars: shared_config\\n    externalIngress: false\\n  }\\n}\\n\\n# create the inventory api container app\\nmodule inventory \'container_app.bicep\' = {\\n  name: \'inventory\'\\n  params: {\\n    name: \'inventory\'\\n    location: location\\n    registryPassword: acr.listCredentials().passwords[0].value\\n    registryUsername: acr.listCredentials().username\\n    containerAppEnvironmentId: env.outputs.id\\n    registry: acr.name\\n    envVars: shared_config\\n    externalIngress: false\\n  }\\n}\\n\\n# create the store api container app\\nmodule store \'container_app.bicep\' = {\\n  name: \'store\'\\n  params: {\\n    name: \'store\'\\n    location: location\\n    registryPassword: acr.listCredentials().passwords[0].value\\n    registryUsername: acr.listCredentials().username\\n    containerAppEnvironmentId: env.outputs.id\\n    registry: acr.name\\n    envVars: shared_config\\n    externalIngress: true\\n  }\\n}\\n\\n```\\n\\n---\\n\\n### Bicep Modules \\n\\nThe *main.bicep* file references modules to create resources, such as `module products`. Modules are a feature of Bicep templates that enable you to abstract resource declarations into their own files or sub-templates. As the *main.bicep* file is processed, the defined modules are also evaluated. Modules allow you to create resources in a more organized and reusable way. They can also define input and output parameters that are passed to and from the parent template, such as the name of a resource.\\n\\nFor example, the *environment.bicep* module extracts the details of creating a container apps environment into a reusable template. The module defines necessary resource dependencies such as Log Analytics Workspaces and an Application Insights instance.\\n\\n### [*environment.bicep* without Dapr](#tab/exclude-dapper)\\n\\n```yml\\nparam baseName string = resourceGroup().name\\nparam location string = resourceGroup().location\\n\\nresource logs \'Microsoft.OperationalInsights/workspaces@2021-06-01\' = {\\n  name: \'${baseName}logs\'\\n  location: location\\n  properties: any({\\n    retentionInDays: 30\\n    features: {\\n      searchVersion: 1\\n    }\\n    sku: {\\n      name: \'PerGB2018\'\\n    }\\n  })\\n}\\n\\nresource appInsights \'Microsoft.Insights/components@2020-02-02\' = {\\n  name: \'${baseName}ai\'\\n  location: location\\n  kind: \'web\'\\n  properties: {\\n    Application_Type: \'web\'\\n    WorkspaceResourceId: logs.id\\n  }\\n}\\n\\nresource env \'Microsoft.App/managedEnvironments@2022-01-01-preview\' = {\\n  name: \'${baseName}env\'\\n  location: location\\n  properties: {\\n    appLogsConfiguration: {\\n      destination: \'log-analytics\'\\n      logAnalyticsConfiguration: {\\n        customerId: logs.properties.customerId\\n        sharedKey: logs.listKeys().primarySharedKey\\n      }\\n    }\\n  }\\n}\\n\\noutput id string = env.id\\noutput appInsightsInstrumentationKey string = appInsights.properties.InstrumentationKey\\noutput appInsightsConnectionString string = appInsights.properties.ConnectionString\\n\\n```\\n\\n### [*environment.bicep* with Dapr](#tab/include-dapper)\\n\\n```yml\\n\\nparam baseName string = resourceGroup().name\\nparam location string = resourceGroup().location\\n\\nresource logs \'Microsoft.OperationalInsights/workspaces@2021-06-01\' = {\\n  name: \'${baseName}logs\'\\n  location: location\\n  properties: any({\\n    retentionInDays: 30\\n    features: {\\n      searchVersion: 1\\n    }\\n    sku: {\\n      name: \'PerGB2018\'\\n    }\\n  })\\n}\\n\\nresource appInsights \'Microsoft.Insights/components@2020-02-02\' = {\\n  name: \'${baseName}ai\'\\n  location: location\\n  kind: \'web\'\\n  properties: {\\n    Application_Type: \'web\'\\n    WorkspaceResourceId: logs.id\\n  }\\n}\\n\\nresource env \'Microsoft.App/managedEnvironments@2022-01-01-preview\' = {\\n  name: \'${baseName}env\'\\n  location: location\\n  properties: {\\n    appLogsConfiguration: {\\n      destination: \'log-analytics\'\\n      logAnalyticsConfiguration: {\\n        customerId: logs.properties.customerId\\n        sharedKey: logs.listKeys().primarySharedKey\\n      }\\n    }\\n  }\\n}\\n\\noutput id string = env.id\\noutput appInsightsInstrumentationKey string = appInsights.properties.InstrumentationKey\\noutput appInsightsConnectionString string = appInsights.properties.ConnectionString\\n\\n```\\n---\\n\\nThe *container_apps.bicep* template defines numerous parameters to provide a reusable template for creating container apps. This allows the module to be used in other CI/CD pipelines as well. \\n\\n### [*container_app.bicep* without Dapr](#tab/exclude-dapper)\\n\\n```yml\\nparam name string\\nparam location string = resourceGroup().location\\nparam containerAppEnvironmentId string\\nparam repositoryImage string = \'mcr.microsoft.com/azuredocs/containerapps-helloworld:latest\'\\nparam envVars array = []\\nparam registry string\\nparam minReplicas int = 1\\nparam maxReplicas int = 1\\nparam port int = 80\\nparam externalIngress bool = false\\nparam allowInsecure bool = true\\nparam transport string = \'http\'\\nparam registryUsername string\\n@secure()\\nparam registryPassword string\\n\\nresource containerApp \'Microsoft.App/containerApps@2022-01-01-preview\' ={\\n  name: name\\n  location: location\\n  properties:{\\n    managedEnvironmentId: containerAppEnvironmentId\\n    configuration: {\\n      activeRevisionsMode: \'single\'\\n      secrets: [\\n        {\\n          name: \'container-registry-password\'\\n          value: registryPassword\\n        }\\n      ]      \\n      registries: [\\n        {\\n          server: registry\\n          username: registryUsername\\n          passwordSecretRef: \'container-registry-password\'\\n        }\\n      ]\\n      ingress: {\\n        external: externalIngress\\n        targetPort: port\\n        transport: transport\\n        allowInsecure: allowInsecure\\n      }\\n    }\\n    template: {\\n      containers: [\\n        {\\n          image: repositoryImage\\n          name: name\\n          env: envVars\\n        }\\n      ]\\n      scale: {\\n        minReplicas: minReplicas\\n        maxReplicas: maxReplicas\\n      }\\n    }\\n  }\\n}\\n\\noutput fqdn string = containerApp.properties.configuration.ingress.fqdn\\n\\n```\\n\\n### [*container_app.bicep* with Dapr](#tab/include-dapper)\\n\\n```yml\\n\\nparam name string\\nparam location string = resourceGroup().location\\nparam containerAppEnvironmentId string\\nparam repositoryImage string = \'mcr.microsoft.com/azuredocs/containerapps-helloworld:latest\'\\nparam envVars array = []\\nparam registry string\\nparam minReplicas int = 1\\nparam maxReplicas int = 1\\nparam port int = 80\\nparam externalIngress bool = false\\nparam allowInsecure bool = true\\nparam transport string = \'http\'\\nparam appProtocol string = \'http\'\\nparam registryUsername string\\n@secure()\\nparam registryPassword string\\n\\nresource containerApp \'Microsoft.App/containerApps@2022-01-01-preview\' ={\\n  name: name\\n  location: location\\n  properties:{\\n    managedEnvironmentId: containerAppEnvironmentId\\n    configuration: {\\n      dapr: {\\n        enabled: true\\n        appId: name\\n        appPort: port\\n        appProtocol: appProtocol\\n      }\\n      activeRevisionsMode: \'single\'\\n      secrets: [\\n        {\\n          name: \'container-registry-password\'\\n          value: registryPassword\\n        }\\n      ]      \\n      registries: [\\n        {\\n          server: registry\\n          username: registryUsername\\n          passwordSecretRef: \'container-registry-password\'\\n        }\\n      ]\\n      ingress: {\\n        external: externalIngress\\n        targetPort: port\\n        transport: transport\\n        allowInsecure: allowInsecure\\n      }\\n    }\\n    template: {\\n      containers: [\\n        {\\n          image: repositoryImage\\n          name: name\\n          env: envVars\\n        }\\n      ]\\n      scale: {\\n        minReplicas: minReplicas\\n        maxReplicas: maxReplicas\\n      }\\n    }\\n  }\\n}\\n\\noutput fqdn string = containerApp.properties.configuration.ingress.fqdn\\n\\n```\\n---\\n\\n## Understanding configuration differences with Dapr\\n\\nThe code for this specific sample application is largely the same whether or not Dapr is integrated. However, even with this simple app, there are a few benefits and configuration differences when using Dapr that are worth exploring. \\n\\nIn this scenario most of the changes are related to communication between the container apps. However, you can explore the full range of Dapr benefits by reading the [Dapr integration with Azure Container Apps](https://docs.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml) article in the conceptual documentation.\\n\\n### [Without Dapr](#tab/exclude-dapper)\\n\\nWithout Dapr the *main.bicep* template handles wiring up the front-end store app to communicate with the back-end apis by manually managing environment variables. The bicep template retrieves the fully qualified domains (fqdn) of the API apps as output parameters when they are created. Those configurations are then set as environment variables on the store container app.\\n\\n```yml\\n\\n# Retrieve environment variables from API container creation \\nvar frontend_config = [\\n  {\\n    name: \'ProductsApi\'\\n    value: \'http://${products.outputs.fqdn}\'\\n  }\\n  {\\n    name: \'InventoryApi\'\\n    value: \'http://${inventory.outputs.fqdn}\'\\n  }\\n]\\n\\n# create the store api container app, passing in config\\nmodule store \'container_app.bicep\' = {\\n  name: \'store\'\\n  params: {\\n    name: \'store\'\\n    location: location\\n    registryPassword: acr.listCredentials().passwords[0].value\\n    registryUsername: acr.listCredentials().username\\n    containerAppEnvironmentId: env.outputs.id\\n    registry: acr.name\\n    envVars: union(shared_config, frontend_config)\\n    externalIngress: true\\n  }\\n}\\n\\n```\\n\\nThe environment variables are then retrieved inside of the `program` class and used to configure the base URLs of the corresponding HTTP clients.\\n\\n```csharp\\n\\nbuilder.Services.AddHttpClient(\\"Products\\", (httpClient) => httpClient.BaseAddress = new Uri(builder.Configuration.GetValue<string>(\\"ProductsApi\\")));\\nbuilder.Services.AddHttpClient(\\"Inventory\\", (httpClient) => httpClient.BaseAddress = new Uri(builder.Configuration.GetValue<string>(\\"InventoryApi\\")));\\n\\n```\\n\\n### [With Dapr](#tab/include-dapper)\\n\\nDapr can be enabled on a container app when it is created, as seen below. This configuration adds a Dapr sidecar to the app to streamline discovery and communication features between the different container apps in your environment.\\n\\n```yml\\n\\n# Create the container app with Dapr enabled\\nresource containerApp \'Microsoft.App/containerApps@2022-01-01-preview\' ={\\n  name: name\\n  location: location\\n  properties:{\\n    managedEnvironmentId: containerAppEnvironmentId\\n    configuration: {\\n      dapr: {\\n        enabled: true\\n        appId: name\\n        appPort: port\\n        appProtocol: appProtocol\\n      }\\n      activeRevisionsMode: \'single\'\\n      secrets: [\\n        {\\n          name: \'container-registry-password\'\\n          value: registryPassword\\n        }\\n      ]      \\n      \\n    # Rest of template omitted for brevity...\\n  }\\n}\\n\\n```\\n\\nSome of these Dapr features can be surfaced through the `program` file. You can configure your HttpClient to leverage Dapr configurations when communicating with other apps in your environment.\\n\\n```csharp\\n\\n// reconfigure code to make requests to Dapr sidecar\\nvar baseURL = (Environment.GetEnvironmentVariable(\\"BASE_URL\\") ?? \\"http://localhost\\") + \\":\\" + (Environment.GetEnvironmentVariable(\\"DAPR_HTTP_PORT\\") ?? \\"3500\\");\\nbuilder.Services.AddHttpClient(\\"Products\\", (httpClient) =>\\n{\\n    httpClient.BaseAddress = new Uri(baseURL);\\n    httpClient.DefaultRequestHeaders.Add(\\"dapr-app-id\\", \\"Products\\");\\n});\\n\\nbuilder.Services.AddHttpClient(\\"Inventory\\", (httpClient) =>\\n{\\n    httpClient.BaseAddress = new Uri(baseURL);\\n    httpClient.DefaultRequestHeaders.Add(\\"dapr-app-id\\", \\"Inventory\\");\\n});\\n\\n```\\n\\n---\\n\\n## Clean up resources\\n\\nIf you\'re not going to continue to use this application, you can delete the Azure Container Apps and all the associated services by removing the resource group.\\n\\nFollow these steps in the Azure portal to remove the resources you created:\\n\\n1. In the Azure portal, navigate to the **msdocswebappsapi** resource group using the left navigation or search bar.\\n1. Select the **Delete resource group** button at the top of the resource group *Overview*.\\n1. Enter the resource group name **msdocswebappsapi** in the *Are you sure you want to delete \\"msdocswebappsapi\\"* confirmation dialog.\\n1. Select **Delete**.  \\n    The process to delete the resource group may take a few minutes to complete."},{"id":"21-cloudevents-via-event-grid","metadata":{"permalink":"/Cloud-Native/blog/21-cloudevents-via-event-grid","source":"@site/blog/2022-09-21/index.md","title":"21. CloudEvents with Event Grid","description":"Introducing CloudEvents, the CNCF\'s standard event spec, and how to consume it through Azure Event Grid, Logic Apps and Azure Functions","date":"2022-09-21T00:00:00.000Z","formattedDate":"September 21, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"cloudevents","permalink":"/Cloud-Native/blog/tags/cloudevents"},{"label":"azure-event-grid","permalink":"/Cloud-Native/blog/tags/azure-event-grid"},{"label":"azure-logic-apps","permalink":"/Cloud-Native/blog/tags/azure-logic-apps"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"}],"readingTime":8.155,"hasTruncateMarker":false,"authors":[{"name":"Justin Yoo","title":"Senior Cloud Advocate @Microsoft","url":"https://github.com/justinyoo","imageURL":"https://github.com/justinyoo.png","key":"justin"}],"frontMatter":{"slug":"21-cloudevents-via-event-grid","title":"21. CloudEvents with Event Grid","authors":["justin"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","serverless","event grid","logic apps","cloudevents"],"image":"./img/banner.png","description":"Introducing CloudEvents, the CNCF\'s standard event spec, and how to consume it through Azure Event Grid, Logic Apps and Azure Functions","tags":["serverless-september","cloudevents","azure-event-grid","azure-logic-apps","azure-functions"]},"prevItem":{"title":"24. Deploy ASP.NET app to ACA","permalink":"/Cloud-Native/blog/24-aca-dotnet"},"nextItem":{"title":"20. Integrate with Microsoft Graph","permalink":"/Cloud-Native/blog/20-events-graph"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/21-cloudevents-via-event-grid\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: CloudEvents and Azure Event Grid\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: How to Consume CloudEvents via Azure Event Grid\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/21-cloudevents-via-event-grid\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 21` of #30DaysOfServerless!\\n\\nWe\'ve so far walked through what [Azure Event Grid][az eg] is and how it generally works. Today, let\'s discuss how Azure Event Grid deals with [CloudEvents][ce].\\n\\n---\\n\\n## What We\'ll Cover\\n\\n- [What We\'ll Cover](#what-well-cover)\\n- [What is CloudEvents?](#what-is-cloudevents)\\n- [How Azure Event Grid brokers CloudEvents](#how-azure-event-grid-brokers-cloudevents)\\n  - [Azure Event Grid for Azure](#azure-event-grid-for-azure)\\n  - [Azure Event Grid for Systems outside Azure](#azure-event-grid-for-systems-outside-azure)\\n- [How Azure Logic Apps consumes CloudEvents](#how-azure-logic-apps-consumes-cloudevents)\\n- [Exercise: Try this yourself!](#exercise-try-this-yourself)\\n- [Resources: For self-study!](#resources-for-self-study)\\n\\n![](./img/banner.png)\\n\\n---\\n\\nOK. Let\'s get started!\\n\\n\\n## What is CloudEvents?\\n\\nNeedless to say, events are everywhere. Events come not only from event-driven systems but also from many different systems and devices, including IoT ones like Raspberry PI.\\n\\nBut the problem is that every event publisher (system/device that creates events) describes their events differently, meaning there is no standard way of describing events. It has caused many issues between systems, mainly from the interoperability perspective.\\n\\n1. Consistency: No standard way of describing events resulted in developers having to write their own event handling logic for each event source.\\n2. Accessibility: There were no common libraries, tooling and infrastructure to deliver events across systems.\\n3. Productivity: The overall productivity decreases because of the lack of the standard format of events.\\n\\n![Cloud Events Logo](img/cloudevents-icon-color.png)\\n\\nTherefore, [CNCF (Cloud-Native Computing Foundation)][cncf] has brought up the concept, called [CloudEvents][ce]. CloudEvents is a specification that commonly describes event data. Conforming any event data to this spec will simplify the event declaration and delivery across systems and platforms and more, resulting in a huge productivity increase.\\n\\n\\n## How Azure Event Grid brokers CloudEvents\\n\\nBefore CloudEvents, [Azure Event Grid][az eg] described events in their own way. Therefore, if you want to use Azure Event Grid, you should follow the event format/schema that Azure Event Grid declares. However, not every system/service/application follows the Azure Event Grid schema. Therefore, Azure Event Grid now supports [CloudEvents spec][az eg ce] as input and output formats.\\n\\n\\n### Azure Event Grid for Azure\\n\\nTake a look at the simple diagram below, which describes how Azure Event Grid captures events raised from various Azure services. In this diagram, Azure Key Vault takes the role of the event source or event publisher, and [Azure Logic Apps][az logapp] takes the role of the event handler (I\'ll discuss Azure Logic Apps as the event handler later in this post). We use [Azure Event Grid System Topic][az eg topic system] for Azure.\\n\\n![Azure Event Grid for Azure](./img/21-cloudevents-via-event-grid-01.png)\\n\\nTherefore, let\'s create an [Azure Event Grid System Topic][az eg topic system] that captures events raised from [Azure Key Vault][az kv] when a new version of a secret is added.\\n\\n![Azure Event Grid System Topic for Key Vault](./img/21-cloudevents-via-event-grid-02.png)\\n\\nAs Azure Event Grid makes use of the [pub/sub pattern][enterprisepattern pubsub], you need to create the [Azure Event Grid Subscription][ag eg sub] to consume the events. Here\'s the subscription that uses the Event Grid data format:\\n\\n![Azure Event Grid System Subscription for Key Vault in Event Grid Format][./img/21-cloudevents-via-event-grid-03.png]\\n\\nOnce you create the subscription, create a new version of the secret on Azure Key Vault. Then, Azure Key Vault raises an event, which is captured in the Event Grid format:\\n\\n```json\\n[\\n  {\\n    \\"id\\": \\"6f44b9c0-d37e-40e7-89be-f70a6da291cc\\",\\n    \\"topic\\": \\"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-aegce-krc/providers/Microsoft.KeyVault/vaults/kv-xxxxxxxx\\",\\n    \\"subject\\": \\"hello\\",\\n    \\"eventType\\": \\"Microsoft.KeyVault.SecretNewVersionCreated\\",\\n    \\"data\\": {\\n      \\"Id\\": \\"https://kv-xxxxxxxx.vault.azure.net/secrets/hello/064dfc082fec463f8d4610ed6118811d\\",\\n      \\"VaultName\\": \\"kv-xxxxxxxx\\",\\n      \\"ObjectType\\": \\"Secret\\",\\n      \\"ObjectName\\": \\"hello\\",\\n      \\"Version\\": \\"064dfc082fec463f8d4610ed6118811d\\",\\n      \\"NBF\\": null,\\n      \\"EXP\\": null\\n    },\\n    \\"dataVersion\\": \\"1\\",\\n    \\"metadataVersion\\": \\"1\\",\\n    \\"eventTime\\": \\"2022-09-21T07:08:09.1234567Z\\"\\n  }\\n]\\n```\\n\\nSo, how is it different from the CloudEvents format? Let\'s take a look. According to the [spec][ce spec json], the JSON data in CloudEvents might look like this:\\n\\n```json\\n{\\n  \\"id\\" : \\"C234-1234-1234\\",\\n  \\"source\\" : \\"/mycontext\\",\\n  \\"specversion\\" : \\"1.0\\",\\n  \\"type\\" : \\"com.example.someevent\\",\\n  \\"comexampleextension1\\" : \\"value\\",\\n  \\"time\\" : \\"2018-04-05T17:31:00Z\\",\\n  \\"datacontenttype\\" : \\"application/cloudevents+json\\",\\n  \\"data\\" : {\\n    \\"appinfoA\\" : \\"abc\\",\\n    \\"appinfoB\\" : 123,\\n    \\"appinfoC\\" : true\\n  }\\n}\\n```\\n\\nThis time, let\'s create another subscription using the CloudEvents schema. Here\'s how to create the subscription against the system topic:\\n\\n![Azure Event Grid System Subscription for Key Vault in CloudEvents Format](./img/21-cloudevents-via-event-grid-04.png)\\n\\nTherefore, Azure Key Vault emits the event data in the CloudEvents format:\\n\\n```json\\n{\\n  \\"id\\": \\"6f44b9c0-d37e-40e7-89be-f70a6da291cc\\",\\n  \\"source\\": \\"/subscriptions/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/resourceGroups/rg-aegce-krc/providers/Microsoft.KeyVault/vaults/kv-xxxxxxxx\\",\\n  \\"specversion\\": \\"1.0\\",\\n  \\"type\\": \\"Microsoft.KeyVault.SecretNewVersionCreated\\",\\n  \\"subject\\": \\"hello\\",\\n  \\"time\\": \\"2022-09-21T07:08:09.1234567Z\\",\\n  \\"data\\": {\\n    \\"Id\\": \\"https://kv-xxxxxxxx.vault.azure.net/secrets/hello/064dfc082fec463f8d4610ed6118811d\\",\\n    \\"VaultName\\": \\"kv-xxxxxxxx\\",\\n    \\"ObjectType\\": \\"Secret\\",\\n    \\"ObjectName\\": \\"hello\\",\\n    \\"Version\\": \\"064dfc082fec463f8d4610ed6118811d\\",\\n    \\"NBF\\": null,\\n    \\"EXP\\": null\\n  }\\n}\\n```\\n\\nCan you identify some differences between the Event Grid format and the CloudEvents format? Fortunately, both Event Grid schema and CloudEvents schema look similar to each other. But they might be significantly different if you use a different event source outside Azure.\\n\\n\\n### Azure Event Grid for Systems outside Azure\\n\\nAs mentioned above, the event data described outside Azure or your own applications within Azure might not be understandable by Azure Event Grid. In this case, we need to use [Azure Event Grid Custom Topic][az eg topic custom]. Here\'s the diagram for it:\\n\\n![Azure Event Grid for Applications outside Azure](./img/21-cloudevents-via-event-grid-05.png)\\n\\nLet\'s create the Azure Event Grid Custom Topic. When you create the topic, make sure that you use the CloudEvent schema during the provisioning process:\\n\\n![Azure Event Grid Custom Topic](./img/21-cloudevents-via-event-grid-06.png)\\n\\nIf your application needs to publish events to Azure Event Grid Custom Topic, your application should build the event data in the CloudEvents format. If you use a .NET application, add the [NuGet package][az eg nuget] first.\\n\\n```bash\\ndotnet add package Azure.Messaging.EventGrid\\n```\\n\\nThen, create the publisher instance. You\'ve already got the topic endpoint URL and the access key.\\n\\n```csharp\\nvar topicEndpoint = new Uri(\\"<Azure Event Grid Custom Topic Endpoint URL>\\");\\nvar credential = new AzureKeyCredential(\\"<Azure Event Grid Custom Topic Access Key>\\");\\nvar publisher = new EventGridPublisherClient(topicEndpoint, credential);\\n```\\n\\nNow, build the event data like below. Make sure that you follow the CloudEvents schema that requires additional metadata like event source, event type and content type.\\n\\n```csharp\\nvar source = \\"/your/event/source\\";\\nvar type = \\"com.source.event.your/OnEventOccurs\\";\\n\\nvar data = new MyEventData() { Hello = \\"World\\" };\\n\\nvar @event = new CloudEvent(source, type, data);\\n```\\n\\nAnd finally, send the event to Azure Event Grid Custom Topic.\\n\\n```csharp\\nawait publisher.SendEventAsync(@event);\\n```\\n\\nThe captured event data looks like the following:\\n\\n```json\\n{\\n  \\"id\\": \\"cc2b2775-52b8-43b8-a7cc-c1c33c2b2e59\\",\\n  \\"source\\": \\"/your/event/source\\",\\n  \\"type\\": \\"com.source.event.my/OnEventOccurs\\",\\n  \\"data\\": {\\n    \\"Hello\\": \\"World\\"\\n  },\\n  \\"time\\": \\"2022-09-21T07:08:09.1234567+00:00\\",\\n  \\"specversion\\": \\"1.0\\"\\n}\\n```\\n\\nHowever, due to limitations, someone might insist that their existing application doesn\'t or can\'t emit the event data in the CloudEvents format. In this case, what should we do? There\'s no standard way of sending the event data in the CloudEvents format to Azure Event Grid Custom Topic. One of the approaches we may be able to apply is to put a converter between the existing application and Azure Event Grid Custom Topic like below:\\n\\n![Azure Event Grid for Applications outside Azure with Converter](./img/21-cloudevents-via-event-grid-07.png)\\n\\nOnce the Function app (or any converter app) receives legacy event data, it internally converts the CloudEvents format and publishes it to Azure Event Grid.\\n\\n```csharp\\nvar data = default(MyRequestData);\\nusing (var reader = new StreamReader(req.Body))\\n{\\n    var serialised = await reader.ReadToEndAsync();\\n    data = JsonConvert.DeserializeObject<MyRequestData>(serialised);\\n}\\n\\nvar converted = new MyEventData() { Hello = data.Lorem };\\nvar @event = new CloudEvent(source, type, converted);\\n```\\n\\nThe converted event data is captured like this:\\n\\n```json\\n{\\n  \\"id\\": \\"df296da3-77cd-4da2-8122-91f631941610\\",\\n  \\"source\\": \\"/your/event/source\\",\\n  \\"type\\": \\"com.source.event.my/OnEventOccurs\\",\\n  \\"data\\": {\\n    \\"Hello\\": \\"ipsum\\"\\n  },\\n  \\"time\\": \\"2022-09-21T07:08:09.1234567+00:00\\",\\n  \\"specversion\\": \\"1.0\\"\\n}\\n```\\n\\nThis approach is beneficial in many integration scenarios to make all the event data canonicalised.\\n\\n\\n## How Azure Logic Apps consumes CloudEvents\\n\\nI put [Azure Logic Apps][az logapp] as the event handler in the previous diagrams. According to the [CloudEvents spec][ce spec webhook], each event handler must implement request validation to avoid abuse. One good thing about using Azure Logic Apps is that it has already implemented this request validation feature. It implies that we just subscribe to the topic and consume the event data.\\n\\nCreate a new Logic Apps instance and add the HTTP Request trigger. Once it saves, you will get the endpoint URL.\\n\\n![Azure Logic Apps with HTTP Request Trigger](./img/21-cloudevents-via-event-grid-08.png)\\n\\nThen, create the Azure Event Grid Subscription with:\\n\\n* Endpoint type: Webhook\\n* Endpoint URL: The Logic Apps URL from above.\\n\\n![Azure Logic Apps with HTTP Request Trigger](./img/21-cloudevents-via-event-grid-09.png)\\n\\nOnce the subscription is ready, this Logic Apps works well as the event handler. Here\'s how it receives the CloudEvents data from the subscription.\\n\\n![Azure Logic Apps that Received CloudEvents data](./img/21-cloudevents-via-event-grid-10.png)\\n\\nNow you\'ve got the CloudEvents data. It\'s entirely up to you to handle that event data however you want!\\n\\n\\n## Exercise: Try this yourself!\\n\\nYou can fork this [GitHub repository][gh sample] to your account and play around with it to see how Azure Event Grid with CloudEvents works. Alternatively, the \\"Deploy to Azure\\" button below will provision all necessary Azure resources and deploy an Azure Functions app to mimic the event publisher.\\n\\n[![Deploy To Azure](https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/deploytoazure.svg?sanitize=true)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fjustinyoo%2Fazure-event-grid-cloudevents-sample%2Fmain%2FResources%2Fazuredeploy.json)\\n\\n\\n## Resources: For self-study!\\n\\nWant to know more about CloudEvents in real-life examples? Here are several resources you can take a look at:\\n\\n* [Azure CLI for EventGrid Subscription to Custom Topic][post 1]\\n* [CloudEvents for Azure EventGrid via Azure Functions][post 2]\\n* [WebSub to EventGrid via CloudEvents, and Beyond][post 3]\\n* [Event-Driven KeyVault Secrets Rotation Management][post 4]\\n\\n\\n[image-logo]: img/cloudevents-icon-color.png\\n[image-01]: img/21-cloudevents-via-event-grid-01.png\\n[image-02]: img/21-cloudevents-via-event-grid-02.png\\n[image-03]: img/21-cloudevents-via-event-grid-03.png\\n[image-04]: img/21-cloudevents-via-event-grid-04.png\\n[image-05]: img/21-cloudevents-via-event-grid-05.png\\n[image-06]: img/21-cloudevents-via-event-grid-06.png\\n[image-07]: img/21-cloudevents-via-event-grid-07.png\\n[image-08]: img/21-cloudevents-via-event-grid-08.png\\n[image-09]: img/21-cloudevents-via-event-grid-09.png\\n[image-10]: img/21-cloudevents-via-event-grid-10.png\\n\\n\\n[cncf]: https://cncf.io/\\n[ce]: https://cloudevents.io/\\n[ce spec json]: https://github.com/cloudevents/spec/blob/v1.0/json-format.md#23-examples\\n[ce spec webhook]: https://github.com/cloudevents/spec/blob/v1.0/http-webhook.md#4-abuse-protection\\n\\n[az eg]: https://docs.microsoft.com/azure/event-grid/overview?WT.mc_id=dotnet-75362-juyoo\\n[az eg topic system]: https://docs.microsoft.com/azure/event-grid/system-topics?WT.mc_id=dotnet-75362-juyoo\\n[az eg topic custom]: https://docs.microsoft.com/azure/event-grid/custom-topics?WT.mc_id=dotnet-75362-juyoo\\n[ag eg sub]: https://docs.microsoft.com/azure/event-grid/concepts?WT.mc_id=dotnet-75362-juyoo#event-subscriptions\\n[az eg ce]: https://docs.microsoft.com/azure/event-grid/cloudevents-schema?WT.mc_id=dotnet-75362-juyoo\\n[az eg nuget]: https://www.nuget.org/packages/Azure.Messaging.EventGrid\\n\\n[az kv]: https://docs.microsoft.com/azure/key-vault/general/basic-concepts?WT.mc_id=dotnet-75362-juyoo\\n\\n[az logapp]: https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=dotnet-75362-juyoo\\n\\n[enterprisepattern pubsub]: https://www.enterpriseintegrationpatterns.com/PublishSubscribeChannel.html\\n\\n[gh sample]: https://github.com/justinyoo/azure-event-grid-cloudevents-sample\\n\\n[post 1]: https://techcommunity.microsoft.com/t5/apps-on-azure-blog/azure-cli-for-eventgrid-subscription-to-custom-topic/ba-p/2038834?WT.mc_id=dotnet-75362-juyoo\\n[post 2]: https://techcommunity.microsoft.com/t5/apps-on-azure-blog/cloudevents-for-azure-eventgrid-via-azure-functions/ba-p/2048140?WT.mc_id=dotnet-75362-juyoo\\n[post 3]: https://techcommunity.microsoft.com/t5/apps-on-azure-blog/websub-to-eventgrid-via-cloudevents-and-beyond/ba-p/2092709?WT.mc_id=dotnet-75362-juyoo\\n[post 4]: https://techcommunity.microsoft.com/t5/apps-on-azure-blog/event-driven-keyvault-secrets-rotation-management/ba-p/2187249?WT.mc_id=dotnet-75362-juyoo"},{"id":"20-events-graph","metadata":{"permalink":"/Cloud-Native/blog/20-events-graph","source":"@site/blog/2022-09-20/index.md","title":"20. Integrate with Microsoft Graph","description":"build a seamsless onboarding experience to new employees joining a company with the power of Microsoft Graph.","date":"2022-09-20T00:00:00.000Z","formattedDate":"September 20, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"},{"label":"microsoft-graph","permalink":"/Cloud-Native/blog/tags/microsoft-graph"},{"label":"logic-apps","permalink":"/Cloud-Native/blog/tags/logic-apps"},{"label":"microsoft-365","permalink":"/Cloud-Native/blog/tags/microsoft-365"},{"label":"event-hubs","permalink":"/Cloud-Native/blog/tags/event-hubs"}],"readingTime":9.87,"hasTruncateMarker":false,"authors":[{"name":"Ayca Bas","title":"Senior Cloud Advocate @Microsoft","url":"https://github.com/aycabas","imageURL":"https://github.com/aycabas.png","key":"ayca"}],"frontMatter":{"slug":"20-events-graph","title":"20. Integrate with Microsoft Graph","authors":["ayca"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"build a seamsless onboarding experience to new employees joining a company with the power of Microsoft Graph.","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices","microsoft-graph","logic-apps","microsoft-365","event-hubs"]},"prevItem":{"title":"21. CloudEvents with Event Grid","permalink":"/Cloud-Native/blog/21-cloudevents-via-event-grid"},"nextItem":{"title":"\ud83d\ude80 | Error Handling w/ Apache Kafka","permalink":"/Cloud-Native/blog/zero2hero-func-05"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/20-events-graph\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Integrate with Microsoft Graph\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Integrate with Microsoft Graph\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://aycabas.com/2022/09/28/build-seamless-automations-to-boost-productivity-with-microsoft-graph-event-hubs-and-logic-apps/\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 20` of #30DaysOfServerless!\\n\\nEvery day millions of people spend their precious time in productivity tools. What if you use data and intelligence behind the Microsoft applications (Microsoft Teams, Outlook, and many other Office apps) to build seamless automations and custom apps to boost productivity? \\n\\nIn this post, we\'ll learn how to build a seamless onboarding experience for new employees joining a company with the power of Microsoft Graph, integrated with Event Hubs and Logic Apps! \\n\\n---\\n\\n## What We\'ll Cover\\n- \u2728 The power of Microsoft Graph\\n- \ud83d\udd87\ufe0f How do Microsoft Graph and Event Hubs work together?\\n- \ud83d\udee0 Let\'s Build an Onboarding Workflow!\\n    - 1\ufe0f\u20e3 Setup Azure Event Hubs + Key Vault\\n    - 2\ufe0f\u20e3 Subscribe to `users`, receive change notifications from Logic Apps\\n    - 3\ufe0f\u20e3 Create Onboarding workflow in the Logic Apps\\n- \ud83d\ude80 Debug: Your onboarding experience\\n- \u270b Exercise: Try this tutorial out yourself!\\n- \ud83d\udcda Resources: For Self-Study\\n\\n![](./img/banner.png)\\n\\n---\\n\\n:::info PRE-REQUISITES (Recommended)\\n\\n- [Microsoft 365 Developer Program account](https://aka.ms/m365developers)\\n- [Microsoft Azure Subscription](https://azure.microsoft.com/free/)\\n:::\\n\\n## \u2728 The Power of Microsoft Graph\\nMicrosoft Graph is the gateway to data and intelligence in Microsoft 365 platform. Microsoft Graph exploses Rest APIs and client libraries to access data across Microsoft 365 core services such as Calendar, Teams, To Do, Outlook, People, Planner, OneDrive, OneNote and more.\\n\\n![Overview of Microsoft Graph](../2022-09-20/img/graph.png)\\n\\nYou can build custom experiences by using Microsoft Graph such as automating the onboarding process for new employees. When new employees are created in the Azure Active Directory, they will be automatically added in the Onboarding team on Microsoft Teams. \\n\\n![Solution architecture](../2022-09-20/img/architecture.png)\\n \\n---\\n\\n## \ud83d\udd87\ufe0f Microsoft Graph with Event Hubs\\n\\nMicrosoft Graph uses a webhook mechanism to track changes in resources and deliver change notifications to the clients. For example, with Microsoft Graph Change Notifications, you can receive change notifications when:\\n- a new task is added in the to-do list\\n- a user changes the presence status from busy to available\\n- an event is deleted/cancelled from the calendar\\n\\nIf you\'d like to track a large set of resources at a high frequency, use Azure Events Hubs instead of traditional webhooks to receive change notifications. Azure Event Hubs is a popular real-time events ingestion and distribution service built for scale.\\n\\n:::info EVENT GRID - PARTNER EVENTS\\n\\n> Microsoft Graph Change Notifications can be also received by using **Azure Event Grid** -- currently available for Microsoft Partners! Read the [Partner Events Overview](https://docs.microsoft.com/azure/event-grid/partner-events-overview) documentation for details.\\n:::\\n\\n## Setup Azure Event Hubs + Key Vault.\\n\\nTo get Microsoft Graph Change Notifications delivered to Azure Event Hubs, we\'ll have to setup Azure Event Hubs and Azure Key Vault. We\'ll use Azure Key Vault to access to Event Hubs connection string. \\n\\n### 1\ufe0f\u20e3 Create Azure Event Hubs\\n1. Go to [Azure Portal](https://portal.azure.com) and select **Create a resource**, type **Event Hubs** and select click **Create**.\\n1. Fill in the Event Hubs namespace creation details, and then click **Create**.\\n1. Go to the newly created Event Hubs namespace page, select **Event Hubs** tab from the left pane and **+ Event Hub**:\\n    - Name your Event Hub as *Event Hub*\\n    - Click **Create**.\\n1. Click the name of the Event Hub, and then select **Shared access policies** and **+ Add** to add a new policy:\\n    - Give a name to the policy\\n    - Check **Send** and **Listen**\\n    - Click **Create**.\\n1. After the policy has been created, click the name of the policy to open the details panel, and then copy the **Connection string-primary key** value. Write it down; you\'ll need it for the next step.\\n1. Go to **Consumer groups** tab in the left pane and select **+ Consumer group**, give a name for your consumer group as *onboarding* and select **Create**.\\n\\n### 2\ufe0f\u20e3 Create Azure Key Vault\\n1. Go to [Azure Portal](https://portal.azure.com) and select **Create a resource**, type **Key Vault** and select **Create**.\\n1. Fill in the Key Vault creation details, and then click **Review + Create**.\\n1. Go to newly created Key Vault and select **Secrets** tab from the left pane and click **+ Generate/Import**:\\n    - Give a name to the secret\\n    - For the value, paste in the connection string you generated at the Event Hubs step\\n    - Click **Create**\\n    - Copy the **name of the secret**.\\n1. Select **Access Policies** from the left pane and **+ Add Access Policy**:\\n    - For **Secret permissions**, select **Get** \\n    - For Principal, select **Microsoft Graph Change Tracking**\\n    - Click **Add**.\\n1. Select **Overview** tab from the left pane and copy the **Vault URI**.\\n\\n---\\n\\n## Subscribe for Logic Apps change notifications \\nTo start receiving Microsoft Graph Change Notifications, we\'ll need to create subscription to the resource that we\'d like to track - here, \'users\'. We\'ll use Azure Logic Apps to create subscription. \\n\\nTo create subscription for Microsoft Graph Change Notifications, we\'ll need to make a http post request to `https://graph.microsoft.com/v1.0/subscriptions`. Microsoft Graph requires Azure Active Directory authentication make API calls. First, we\'ll need to register an app to Azure Active Directory, and then we will make the Microsoft Graph Subscription API call with Azure Logic Apps.\\n\\n### 1\ufe0f\u20e3 Create an app in Azure Active Directory\\n1. In the [Azure Portal](https://portal.azure.com), go to **Azure Active Directory** and select **App registrations** from the left pane and select **+ New registration**. Fill in the details for the new App registration form as below:\\n    - Name: Graph Subscription Flow Auth\\n    - Supported account types: *Accounts in any organizational directory (Any Azure AD directory - Multitenant) and personal Microsoft accounts (e.g. Skype, Xbox)*\\n    - Select **Register**.\\n1. Go to newly registered app in Azure Active Directory, select **API permissions**:\\n    - Select **+ Add a permission** and **Microsoft Graph**\\n    - Select **Application permissions** and add `User.Read.All` and `Directory.Read.All`.\\n    - Select **Grant admin consent for *the organization***\\n1. Select **Certificates & secrets** tab from the left pane, select **+ New client secret**:\\n    - Choose desired expiry duration \\n    - Select **Add** \\n    - Copy the *value of the secret*.\\n1. Go to **Overview** from the left pane, copy *Application (client) ID* and *Directory (tenant) ID*.\\n\\n### 2\ufe0f\u20e3 Create subscription with Azure Logic Apps\\n1. Go to [Azure Portal](https://portal.azure.com) and select **Create a resource**, type **Logic apps** and select click **Create**.\\n1. Fill in the Logic Apps creation details, and then click **Create**.\\n1. Go to the newly created Logic Apps page, select **Workflows** tab from the left pane and select **+ Add**:\\n    - Give a name to the new workflow as *graph-subscription-flow*\\n    - Select **Stateful** as a state type\\n    - Click **Create**.\\n1. Go to *graph-subscription-flow*, and then select **Designer** tab.\\n1. In the Choose an operation section, search for **Schedule** and select **Recurrence** as a trigger. Fill in the parameters as below:\\n    - Interval: `61`\\n    - Frequency: `Minute`\\n    - Time zone: *Select your own time zone*\\n    - Start time: *Set a start time*\\n1. Select **+** button in the flow and select **add an action**. Search for **HTTP** and select **HTTP** as an action. Fill in the parameters as below: \\n    - Method: `POST`\\n    - URI: `https://graph.microsoft.com/v1.0/subscriptions`\\n    - Headers:\\n        - Key: `Content-type`\\n        - Value: `application/json`\\n    - Body:\\n    ```json\\n    {\\n    \\"changeType\\": \\"created, updated\\",\\n    \\"clientState\\": \\"secretClientValue\\",\\n    \\"expirationDateTime\\": \\"@{addHours(utcNow(), 1)}\\",\\n    \\"notificationUrl\\": \\"EventHub:https://<YOUR-VAULT-URI>/secrets/<YOUR-KEY-VAULT-SECRET-NAME>?tenantId=72f988bf-86f1-41af-91ab-2d7cd011db47\\",\\n    \\"resource\\": \\"users\\"\\n    }\\n    ```\\n    > In `notificationUrl`, make sure to replace `<YOUR-VAULT-URI>` with the vault uri and `<YOUR-KEY-VAULT-SECRET-NAME>` with the secret name that you copied from the Key Vault.\\n\\n    > In `resource`, define the resource type you\'d like to track changes. For our example, we will track changes for `users` resource.\\n    - Authentication:\\n        - Authentication type: `Active Directory OAuth`\\n        - Authority: `https://login.microsoft.com`\\n        - Tenant: *Directory (tenant) ID* copied from AAD app\\n        - Audience: `https://graph.microsoft.com`\\n        - Client ID: *Application (client) ID* copied from AAD app\\n        - Credential Type: `Secret`\\n        - Secret: *value of the secret* copied from AAD app\\n1. Select **Save** and run your workflow from the **Overview** tab.\\n> **Check your subscription in Graph Explorer:** If you\'d like to make sure that your subscription is created successfully by Logic Apps, you can go to [Graph Explorer](https://aka.ms/ge), login with your Microsoft 365 account and make `GET` request to `https://graph.microsoft.com/v1.0/subscriptions`. Your subscription should appear in the response after it\'s created successfully.\\n\\n![Subscription workflow success](../2022-09-20/img/subscription-succes.png)\\n\\nAfter subscription is created successfully by Logic Apps, Azure Event Hubs will receive notifications whenever there is a new user created in Azure Active Directory.\\n\\n---\\n\\n## Create Onboarding workflow in Logic Apps\\nWe\'ll create a second workflow in the Logic Apps to receive change notifications from Event Hubs when there is a new user created in the Azure Active Directory and add new user in Onboarding team on Microsoft Teams.\\n\\n1. Go to the Logic Apps you created in the previous steps, select **Workflows** tab and create a new workflow by selecting **+ Add**:\\n    - Give a name to the new workflow as *teams-onboarding-flow*\\n    - Select **Stateful** as a state type\\n    - Click **Create**.\\n1. Go to *teams-onboarding-flow*, and then select **Designer** tab.\\n1. In the Choose an operation section, search for **Event Hub**, select **When events are available in Event Hub** as a trigger. Setup Event Hub connection as below:\\n    - Create Connection:\\n        - Connection name: `Connection`\\n        - Authentication Type: `Connection String`\\n        - Connection String: Go to **Event Hubs > Shared Access Policies > RootManageSharedAccessKey** and copy *Connection string\u2013primary key*\\n        - Select **Create**.\\n    - Parameters:\\n        - Event Hub Name: `Event Hub`\\n        - Consumer Group Name: `onboarding`\\n1. Select **+** in the flow and **add an action**, search for **Control** and add **For each** as an action. Fill in For each action as below:\\n    - Select output from previous steps: `Events`\\n1. Inside For each, select **+** in the flow and **add an action**, search for **Data operations** and select **Parse JSON**. Fill in Parse JSON action as below:\\n    - Content: `Events Content`\\n    - Schema: Copy the json content from [schema-parse.json](../2022-09-20/img/schema-parse.json) and paste as a schema\\n  \\n1. Select **+** in the flow and **add an action**, search for **Control** and add **For each** as an action. Fill in For each action as below:\\n    - Select output from previous steps: `value`\\n1. 1. Inside For each, select **+** in the flow and **add an action**, search for **Microsoft Teams** and select **Add a member to a team**. Login with your Microsoft 365 account to create a connection and fill in Add a member to a team action as below:\\n    - Team: *Create an Onboarding team on Microsoft Teams and select*\\n    - A user AAD ID for the user to add to a team: `id`\\n1. Select **Save**.\\n\\n---\\n\\n## \ud83d\ude80 Debug your onboarding experience\\nTo debug our onboarding experience, we\'ll need to create a new user in Azure Active Directory and see if it\'s added in Microsoft Teams Onboarding team automatically.\\n1. Go to [Azure Portal](https://portal.azure.com) and select Azure Active Directory from the left pane and go to **Users**. Select **+ New user** and **Create new user**. Fill in the details as below:\\n    - User name: `JaneDoe`\\n    - Name: `Jane Doe`\\n\\n    ![new user in Azure Active Directory](../2022-09-20/img/new-user.png)\\n\\n1. When you added `Jane Doe` as a new user, it should trigger the *teams-onboarding-flow* to run.\\n![teams onboarding flow success](../2022-09-20/img/teams-onboarding-success.png)\\n\\n1. Once the *teams-onboarding-flow* runs successfully, you should be able to see `Jane Doe` as a member of the Onboarding team on Microsoft Teams! \ud83e\udd73\\n![new member in Onboarding team on Microsoft Teams](../2022-09-20/img/new-member-onboarding.png)\\n\\n:::success Congratulations! \ud83c\udf89\\nYou just built an onboarding experience using Azure Logic Apps, Azure Event Hubs and Azure Key Vault.\\n:::\\n\\n---\\n\\n## \ud83d\udcda Resources\\n- [Microsoft Graph Fundamentals](https://aka.ms/learn-graph)\\n- [Get change notifications delivered in different ways](https://docs.microsoft.com/graph/change-notifications-delivery)\\n- [Real-time presence with Microsoft 365, Azure, and Power Platform](https://docs.microsoft.com/azure/architecture/solution-ideas/articles/presence-microsoft-365-power-platform)\\n- [Partner Events overview for customers - Azure Event Grid](https://docs.microsoft.com/azure/event-grid/partner-events-overview)"},{"id":"zero2hero-func-05","metadata":{"permalink":"/Cloud-Native/blog/zero2hero-func-05","source":"@site/blog/zero-to-hero/2022-09-19-azurefunctions.md","title":"\ud83d\ude80 | Error Handling w/ Apache Kafka","description":"Recently we have launched the Apache Kafka extension for Azure functions in GA with some cool new features like deserialization of Avro Generic records and Kafka headers support. Let\'s learn more about it.","date":"2022-09-19T00:00:00.000Z","formattedDate":"September 19, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"}],"readingTime":5.33,"hasTruncateMarker":false,"authors":[{"name":"Ramya Oruganti","title":"Senior PM, Azure Functions @Microsoft","url":"https://twitter.com/ramyaoncloud","imageURL":"https://pbs.twimg.com/profile_images/588627587435397120/vuA4BT3a_400x400.jpg","key":"ramya"}],"frontMatter":{"slug":"zero2hero-func-05","title":"\ud83d\ude80 | Error Handling w/ Apache Kafka","authors":["ramya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/zero-to-hero-david.png","description":"Recently we have launched the Apache Kafka extension for Azure functions in GA with some cool new features like deserialization of Avro Generic records and Kafka headers support. Let\'s learn more about it.","tags":["serverless-september","zero-to-hero","azure-functions"]},"prevItem":{"title":"20. Integrate with Microsoft Graph","permalink":"/Cloud-Native/blog/20-events-graph"},"nextItem":{"title":"\ud83d\ude80 | Observability with ACA","permalink":"/Cloud-Native/blog/zero2hero-aca-06"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/zero2hero-func-05\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ZeroToHero: Error Handling with Apache Kafka extension for Azure Functions \\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ZeroToHero: Error Handling with Apache Kafka extension for Azure Functions \\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/serverless-zero2hero.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://techcommunity.microsoft.com/t5/apps-on-azure-blog/error-handling-with-apache-kafka-extension-for-azure-functions/ba-p/3628936\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 19` of #30DaysOfServerless!\\n\\nToday, we have a special set of posts from our [Zero To Hero \ud83d\ude80](/serverless-september/ZeroToHero) initiative, featuring blog posts authored by our Product Engineering teams for #ServerlessSeptember. _Posts were originally published on the [Apps on Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/error-handling-with-apache-kafka-extension-for-azure-functions/ba-p/3628936?WT.mc_id=javascript-99907-cxa) blog on Microsoft Tech Community._\\n\\n---\\n\\n## What We\'ll Cover\\n * Retry Policy Support - in Apache Kafka Extension\\n * AutoOffsetReset property - in Apache Kafka Extension\\n * Key support for Kafka messages - in Apache Kafka Extension\\n * References: Apache Kafka Extension for Azure Functions\\n\\n![](./img/ramya-functions-kafka.png)\\n\\n---\\n\\n_Recently we launched the [Apache Kafka extension for Azure functions](https://github.com/Azure/azure-functions-kafka-extension) in GA with some cool new features like deserialization of Avro Generic records and Kafka headers support. We received great responses - so we\'re back with more updates!_\\n\\n## Retry Policy support\\n\\nHandling errors in Azure Functions is important to avoid data loss or miss events or monitor the health of an application. Apache Kafka Extension for Azure Functions supports retry policy which tells the runtime to rerun a failed execution until either successful completion occurs or the maximum number of retries is reached.\\n\\nA retry policy is evaluated when a trigger function raises an uncaught exception. As a best practice, you should catch all exceptions in your code and rethrow any errors that you want to result in a retry.\\n\\nThere are two retry strategies supported by policy that you can configure :- fixed delay and exponential backoff\\n\\n1. **Fixed Delay** -  A specified amount of time is allowed to elapse between each retry.\\n2. **Exponential Backoff** - The first retry waits for the minimum delay. On subsequent retries, time is added exponentially to the initial duration for each retry, until the maximum delay is reached. Exponential back-off adds some small randomization to delays to stagger retries in high-throughput scenarios.\\n\\n:::info Please Note\\nRetry Policy for Kafka extension **is NOT supported** for C# (in proc and out proc) trigger and output binding. This is supported for languages like Java, Node (JS , TypeScript), PowerShell and Python trigger and output bindings.\\n:::\\n\\nHere is the sample code view of exponential backoff retry strategy\\n\\n![Error Handling with Apache Kafka extension for Azure Functions](./img/ramya-kafka-1.png)\\n\\n\\n## AutoOffsetReset property\\n\\nAutoOffsetReset property enables customers to configure the behaviour in the absence of an initial offset. Imagine a scenario when there is a need to change consumer group name. The consumer connected using a new consumer group had to reprocess all events starting from the oldest (earliest) one,  as this was the default one and this setting wasn\u2019t exposed as configurable option in the Apache Kafka extension for Azure Functions(previously). With the help of this kafka setting you can configure on how to start processing events for newly created consumer groups.\\n\\nDue to lack of the ability to configure this setting, offset commit errors were causing topics to restart from earliest offset\xb7 Users were looking to be able to set  offset setting  to either latest or earliest  based on their requirements.\\n\\nWe are happy to share that we have enabled the AutoOffsetReset setting as a configurable one to either - Earliest(Default) and Latest. Setting the value to Earliest configures the consumption of the messages from the the earliest/smallest offset or beginning of the topic partition. Setting the property to Latest configures the consumption of the messages from the latest/largest offset or from the end of the topic partition. This is supported for all the Azure Functions supported languages (C# (in & out), Java, Node (JS and TypeScript), PowerShell and python) and can be used for both triggers and output binding\\n\\n![Error Handling with Apache Kafka extension for Azure Functions](./img/ramya-kafka-2.png)\\n\\n## Key support for Kafka messages\\n\\nWith keys the producer/output binding can be mapped to broker and partition to write based on the message. So alongside the message value, we can choose to send a message key and that key can be whatever you want it could be a string, it could be a number . In case  you don\u2019t send the key, the key is set to null then the data will be sent in a [Round Robin](https://www.geeksforgeeks.org/round-robin-scheduling-with-different-arrival-times/) fashion to make it very simple. **But in case you send a key with your message**, all the messages that share the same key will always go to the same partition and thus you can enable grouping of similar messages into partitions\\n\\nPreviously while consuming a Kafka event message using the Azure Function kafka extension, the event key was always none although the key was present in the event message.\\n\\nKey support was implemented in the extension which enables customers to set/view key in the Kafka event messages coming in to the kafka trigger and set keys to the messages going in to kafka topics (with keys set) through output binding. Therefore key support was enabled in the extension to support both trigger and output binding for all Azure Functions supported languages ( (C# (in & out), Java, Node (JS and TypeScript), PowerShell and python)\\n\\nHere is the view of an output binding producer code where Kafka messages are being set with key\\n\\n![Error Handling with Apache Kafka extension for Azure Functions](./img/ramya-kafka-3.png)\\n\\n\\n## Conclusion:\\n\\nIn this article you have learnt about the latest additions to the Apache Kafka extension for Azure Functions. Incase you have been waiting for these features to get released or need them you are all set and please go head and try them out!! They are available in the latest extension bundles\\n\\n \\n:::info Want to learn more?\\nPlease refer to [Apache Kafka bindings for Azure Functions](https://docs.microsoft.com/azure/azure-functions/functions-bindings-kafka?tabs=in-process%2Cportal&pivots=programming-language-csharp) | Microsoft Docs for detail documentation, samples on the Azure function supported languages and more!\\n:::\\n\\n## References\\n\\n * [Apache Kafka bindings for Azure Functions | Microsoft Docs](https://docs.microsoft.com/azure/azure-functions/functions-bindings-kafka?tabs=in-process%2Cportal&pivots=programming-language-csharp)\\n\\n\\n:::tip FEEDBACK WELCOME\\n \\n * If you would like to provide feedback on Kafka trigger extension, please post them to our GitHub repository- Issues \xb7 [Azure/azure-functions-kafka-extension (github.com)](https://github.com/Azure/azure-functions-kafka-extension/issues)\\n * This extension is being developed in the open-source community. Please contribute, try out and post any issues on the [Azure Functions Kafka extension GitHub repo](https://github.com/Azure/azure-functions-kafka-extension)\\n:::\\n\\nKeep in touch with us on Twitter via [@AzureFunctions](https://twitter.com/AzureFunctions)."},{"id":"zero2hero-aca-06","metadata":{"permalink":"/Cloud-Native/blog/zero2hero-aca-06","source":"@site/blog/zero-to-hero/2022-09-19-containerapps.md","title":"\ud83d\ude80 | Observability with ACA","description":"Azure Container Apps provides several observability features to help you debug and diagnose your apps. There are both Azure portal and CLI options you can use to help understand the health of your apps and help identify when issues arise. Let\'s explore the options.","date":"2022-09-19T00:00:00.000Z","formattedDate":"September 19, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"}],"readingTime":4.83,"hasTruncateMarker":false,"authors":[{"name":"Mike Morton","title":"Principal PM, Container Apps @Microsoft","url":"https://github.com/BigMorty","imageURL":"https://github.com/BigMorty.png","key":"mikemorton"}],"frontMatter":{"slug":"zero2hero-aca-06","title":"\ud83d\ude80 | Observability with ACA","authors":["mikemorton"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","containerapps","serverless","concepts"],"image":"./img/banner.png","description":"Azure Container Apps provides several observability features to help you debug and diagnose your apps. There are both Azure portal and CLI options you can use to help understand the health of your apps and help identify when issues arise. Let\'s explore the options.","tags":["serverless-september","zero-to-hero","azure-container-apps","dapr"]},"prevItem":{"title":"\ud83d\ude80 | Error Handling w/ Apache Kafka","permalink":"/Cloud-Native/blog/zero2hero-func-05"},"nextItem":{"title":"18. Logic Apps + Computer Vision","permalink":"/Cloud-Native/blog/18-cloudmail"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/zero2hero-aca-06\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ZeroToHero: Observability with Azure Container Apps\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ZeroToHero: Observability with Azure Container Apps\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/serverless-zero2hero.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://techcommunity.microsoft.com/t5/apps-on-azure-blog/observability-with-azure-container-apps/ba-p/3627909\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 19` of #30DaysOfServerless!\\n\\nToday, we have a special set of posts from our [Zero To Hero \ud83d\ude80](/serverless-september/ZeroToHero) initiative, featuring blog posts authored by our Product Engineering teams for #ServerlessSeptember. _Posts were originally published on the [Apps on Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/observability-with-azure-container-apps/ba-p/3627909?WT.mc_id=javascript-99907-cxa) blog on Microsoft Tech Community._\\n\\n---\\n\\n## What We\'ll Cover\\n * Log Streaming - in Azure Portal\\n * Console Connect - in Azure Portal\\n * Metrics - using Azure Monitor\\n * Log Analytics - using Azure Monitor\\n * Metric Alerts and Log Alerts - using Azure Monitor\\n\\n![](./img/mike-aca-observability.png)\\n\\n---\\n\\nIn past weeks, [@kendallroden](https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/296868) wrote about [what it means to be Cloud-Native](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/go-cloud-native-with-azure-container-apps/ba-p/3616407) and [@Anthony Chu](https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/236816) the various ways to [get your apps running on Azure Container Apps](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/journey-to-the-cloud-with-azure-container-apps/ba-p/3622609). Today, we will talk about the **observability tools** you can use to observe, debug, and diagnose your Azure Container Apps.\\n\\n**Azure Container Apps** provides several observability features to help you debug and diagnose your apps. There are both Azure portal and CLI options you can use to help understand the health of your apps and help identify when issues arise.\\n\\nWhile these features are helpful throughout your container app\u2019s lifetime, there are two that are especially helpful.  Log streaming and console connect can be a huge help in the initial stages when issues often rear their ugly head. Let\'s dig into both of these a little.\\n\\n## Log Streaming\\nLog streaming allows you to use the Azure portal to view the streaming logs from your app. You\u2019ll see the logs written from the app to the container\u2019s console (stderr and stdout). If your app is running multiple revisions, you can choose from which revision to view logs. You can also select a specific replica if your app is configured to scale. Lastly, you can choose from which container to view the log output. This is useful when you are running a custom or Dapr sidecar container.\\n![view streaming logs](./img/mike-observability-1.png)\\n\\nHere\u2019s an example CLI command to view the logs of a container app.\\n\\n```bash\\naz containerapp logs show -n MyContainerapp -g MyResourceGroup\\n```\\nYou can find more information about the different options in our [CLI docs](https://aka.ms/container-apps/logs-cli).\\n\\n \\n## Console Connect\\nIn the Azure portal, you can connect to the console of a container in your app. Like log streaming, you can select the revision, replica, and container if applicable. After connecting to the console of the container, you can execute shell commands and utilities that you have installed in your container.  You can view files and their contents, monitor processes, and perform other debugging tasks.\\n\\nThis can be great for checking configuration files or even modifying a setting or library your container is using. Of course, updating a container in this fashion is not something you should do to a production app, but tweaking and re-testing an app in a non-production environment can speed up development.\\n\\n![](./img/mike-observability-2.png)\\n\\nHere\u2019s an example CLI command to connect to the console of a container app.\\n\\n```bash\\naz containerapp exec -n MyContainerapp -g MyResourceGroup\\n```\\n\\nYou can find more information about the different options in our [CLI docs](https://aka.ms/container-apps/exec-cli).\\n\\n\\n## Metrics\\nAzure Monitor collects metric data from your container app at regular intervals to help you gain insights into the performance and health of your container app. Container apps provide these metrics:\\n\\n- CPU usage\\n- Memory working set bytes\\n- Network in bytes\\n- Network out bytes\\n- Requests\\n- Replica count\\n- Replica restart count\\n\\nHere you can see the metrics explorer showing the replica count for an app as it scaled from one replica to fifteen, and then back down to one.\\n\\n![](./img/mike-observability-3.png)\\n\\nYou can also retrieve metric data through [the Azure CLI](https://aka.ms/container-apps/azure-monitor-metrics-cli).\\n\\n \\n\\n## Log Analytics\\nAzure Monitor Log Analytics is great for viewing your historical logs emitted from your container apps. There are two custom tables of interest, the ContainerAppConsoleLogs_CL which contains all the log messages written by your app (stdout and stderr), and the ContainerAppSystemLogs_CL which contain the system messages from the Azure Container Apps service.\\t\\n\\n![](./img/mike-observability-4.png)\\n\\nYou can also query Log Analytics through the [Azure CLI](https://aka.ms/container-apps/azure-monitor-logs-cli).\\n\\n\\n## Alerts\\nAzure Monitor alerts notify you so that you can respond quickly to critical issues. There are two types of alerts that you can define:\\n\\n * [Metric alerts](https://docs.microsoft.com/azure/azure-monitor/alerts/alerts-types#metric-alerts) based on Azure Monitor metric data\\n * [Log alerts](https://docs.microsoft.com/azure/azure-monitor/alerts/alerts-types#log-alerts) based on Azure Monitor Log Analytics data\\n\\nYou can create alert rules from metric charts in the metric explorer and from queries in Log Analytics. You can also define and manage alerts from the **Monitor|Alerts** page.\\n\\nHere is what creating an alert looks like in the Azure portal. In this case we are setting an alert rule from the metric explorer to trigger an alert if the replica restart count for a specific container app is greater than two within the last fifteen minutes.\\n\\n![](./img/mike-observability-5.png)\\n\\nTo learn more about alerts, refer to [Overview of alerts in Microsoft Azure](https://docs.microsoft.com/azure/azure-monitor/alerts/alerts-overview).\\n\\n\\n## Conclusion\\nIn this article, we looked at the several ways to observe, debug, and diagnose your Azure Container Apps. As you can see there are rich portal tools and a complete set of CLI commands to use. All the tools are helpful throughout the lifecycle of your app, be sure to take advantage of them when having an issue and/or to prevent issues.\\n\\nTo learn more, visit [Azure Container Apps | Microsoft Azure](https://aka.ms/containerapps) today!\\n\\n \\n:::info ASK THE EXPERT: LIVE Q&A\\nThe Azure Container Apps team will answer questions live on **September 29**. \\n * [Sign up to attend](https://reactor.microsoft.com/reactor/events/17004/?WT.mc_id=javascript-99907-ninarasi) for live Q&A with the team\\n * [submit your questions](https://github.com/Azure/Cloud-Native/issues/new?assignees=&labels=ask+the+expert&template=---ask-the-expert-.md&title=%5BAsk+The+Expert%5D++) ahead of time, for prioritization.\\n:::"},{"id":"18-cloudmail","metadata":{"permalink":"/Cloud-Native/blog/18-cloudmail","source":"@site/blog/2022-09-18/index.md","title":"18. Logic Apps + Computer Vision","description":"<FIXME>","date":"2022-09-18T00:00:00.000Z","formattedDate":"September 18, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":9.32,"hasTruncateMarker":false,"authors":[{"name":"Brian Benz","title":"Senior Cloud Advocate @Microsoft","url":"https://github.com/bbenz","imageURL":"https://github.com/bbenz.png","key":"brian"}],"frontMatter":{"slug":"18-cloudmail","title":"18. Logic Apps + Computer Vision","authors":["brian"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts","storage","cosmosdb","computervision"],"image":"./img/banner.png","description":"<FIXME>","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"\ud83d\ude80 | Observability with ACA","permalink":"/Cloud-Native/blog/zero2hero-aca-06"},"nextItem":{"title":"17. Logic Apps + Cosmos DB","permalink":"/Cloud-Native/blog/17-integrate-cosmosdb"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/18-cloudmail\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Logic Apps + Computer Vision\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Logic Apps + Computer Vision\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/18-cloudmail\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 18` of #30DaysOfServerless!\\n\\nYesterday my Serverless September post introduced you to making Azure Logic Apps and Azure Cosmos DB work together with a sample application that collects weather data.  Today I\'m sharing a more robust solution that actually reads my mail.  Let\'s learn about **Teaching the cloud to read your mail!**\\n\\nReady? Let\'s go!\\n\\n---\\n\\n## What We\'ll Cover\\n * Introduction to the ReadMail solution\\n * Setting up Azure storage, Cosmos DB and Computer Vision\\n * Connecting it all together with a Logic App \\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Introducing the ReadMail solution\\n\\nThe US Postal system offers [a subscription service](https://informeddelivery.usps.com/) that sends you images of mail it will be delivering to your home.  I decided it would be cool to try getting Azure to collect data based on these images, so that I could categorize my mail and track the types of mail that I received.  \\n\\nTo do this, I used Azure storage, Cosmos DB, Logic Apps, and computer vision.  When a new email comes in from the US Postal service (USPS), it triggers a logic app that:\\n\\n* Posts attachments to Azure storage\\n* Triggers Azure Computer vision to perform an OCR function on attachments\\n* Extracts any results into a JSON document\\n* Writes the JSON document to Cosmos DB \\n\\n![workflow for the readmail solution](img/readmailworkflow.png)\\n\\nIn this post I\'ll walk you through setting up the solution for yourself.  \\n\\n:::info Prerequisites\\n\\n- Contributor or Owner permissions on an active Azure subscription.\\n  - Don\'t have one? [Create an account for free](https://azure.microsoft.com/free/).\\n- A [USPS Informed Delivery account](https://informeddelivery.usps.com/).\\n  - Alternatively, any service that sends attached images via email\\n:::\\n\\n---\\n\\n## Setup Azure Services\\n\\nFirst, we\'ll create all of the target environments we need to be used by our Logic App, then we;ll create the Logic App.  \\n\\n### 1. Azure Storage \\n\\nWe\'ll be using Azure storage to collect attached images from emails as they arrive.  Adding images to Azure storage will also trigger a workflow that performs OCR on new attached images and stores the OCR data in Cosmos DB.  \\n \\nTo create a new Azure storage account from the [portal dashboard](https://portal.azure.com), Select **Create a resource > Storage account > Create**.  \\n\\nThe **Basics** tab covers all of the features and information that we will need for this solution: \\n\\n| Section | Field | Required or optional | Description |\\n|--|--|--|--|\\n| Project details | Subscription | Required | Select the subscription for the new storage account. |\\n| Project details | Resource group | Required | Create a new resource group that you will use for storage, Cosmos DB, Computer Vision and the Logic App. |\\n| Instance details | Storage account name | Required | Choose a unique name for your storage account. Storage account names must be between 3 and 24 characters in length and may contain numbers and lowercase letters only. |\\n| Instance details | Region | Required | Select the appropriate region for your storage account.  |\\n| Instance details | Performance | Required | Select **Standard** performance for general-purpose v2 storage accounts (default). |\\n| Instance details | Redundancy | Required | Select **locally-redundant Storage (LRS)** for this example.  |\\n\\nSelect **Review + create** to accept the remaining default options, then validate and create the account.\\n\\n### 2. Azure CosmosDB\\n\\nCosmosDB will be used to store the JSON documents returned by the COmputer Vision OCR process.  \\n\\n> See more details and screen shots for setting up CosmosDB in yesterday\'s Serverless September post - **Using Logic Apps with Cosmos DB**\\n\\nTo get started with Cosmos DB, you create an account, then a database, then a container to store JSON documents. To create a new Cosmos DB account from the [portal dashboard](https://portal.azure.com), Select **Create a resource > Azure Cosmos DB > Create**.  Choose **core SQL** for the API.\\n\\nSelect your subscription, then for simplicity use the same resource group you created when you set up storage.  Enter an account name and choose a location, select provisioned throughput capacity mode and apply the free tier discount. From here you can select **Review and Create**, then **Create** \\n\\nNext, create a new database and container. Go to the **Data Explorer** in your new Cosmos DB account, and choose **New Container**.  Name the database, and keep all the other defaults except:  \\n\\n| Setting | Action |\\n|---|---|\\n| Container ID | id |\\n| Container partition |  /id |\\n\\nPress **OK** to create a database and container\\n\\n### 3. Azure Computer Vision\\n\\nAzure Cognitive Services\' [Computer Vision](https://azure.microsoft.com/products/cognitive-services/computer-vision/) will perform an OCR process on each image attachment that is stored in Azure storage.  \\n\\nFrom the [portal dashboard](https://portal.azure.com), Select **Create a resource > AI + Machine Learning > Computer Vision > Create**. \\n\\nThe **Basics** and **Identity** tabs cover all of the features and information that we will need for this solution: \\n\\n**Basics Tab**\\n\\n| Section | Field | Required or optional | Description |\\n|--|--|--|--|\\n| Project details | Subscription | Required | Select the subscription for the new service. |\\n| Project details | Resource group | Required | Use the same resource group that you used for Azure storage and Cosmos DB. |\\n| Instance details | Region | Required | Select the appropriate region for your Computer Vision service. |\\n| Instance details | Name | Required | Choose a unique name for your Computer Vision service. |\\n| Instance details | Pricing | Required | Select the free tier for this example. |\\n\\n**Identity Tab**\\n\\n| Section | Field | Required or optional | Description |\\n|--|--|--|--|\\n| System assigned managed identity | Status | Required | Enable system assigned identity to grant the resource access to other existing resources. |\\n\\n\\nSelect **Review + create** to accept the remaining default options, then validate and create the account.\\n\\n---\\n\\n## Connect it all with a Logic App \\n\\nNow we\'re ready to put this all together in a Logic App workflow!  \\n\\n:::tip 1. Create Logic App\\n:::\\nFrom the [portal dashboard](https://portal.azure.com), Select **Create a resource > Integration > Logic App > Create**.  Name your Logic App and select a location, the rest of the settings can be left at their defaults.  \\n\\n\\n:::tip 2. Create Workflow: Add Trigger\\n:::\\nOnce the Logic App is created, select **Create a workflow from designer**.  \\n\\n>A workflow is a series of steps that defines a task or process. Each workflow starts with a single trigger, after which you must add one or more actions.\\n\\nWhen in designer, search for **outlook.com** on the right under **Add a trigger**.  Choose **outlook.com**.  Choose \\n**When a new email arrives** as the trigger.  \\n\\n>A trigger is always the first step in any workflow and specifies the condition for running any further steps in that workflow. \\n\\nSet the following values: \\n\\n| Parameter | Value | \\n|--|--|\\n| Folder | Inbox | \\n| Importance | Any | \\n| Only With Attachments | Yes | \\n| Include Attachments | Yes | \\n\\nThen add a new parameter:\\n\\n| Parameter | Value | \\n|--|--|\\n| From | Add the email address that sends you the email with attachments | \\n\\n\\n:::tip 3. Create Workflow: Add Action (for Trigger)\\n:::\\n\\nChoose **add an action** and choose **control > for-each**. \\n\\n![logic app for each](img/logicappforeach.png)\\n\\nInside the for-each action, in **Select an output from previous steps**, choose **attachments**.  Then, again inside the  for-each action, add the **create blob** action: \\n\\nSet the following values: \\n\\n| Parameter | Value | \\n|--|--|\\n| Folder Path | /mailreaderinbox | \\n| Blob Name | Attachments Name | \\n| Blob Content | Attachments Content | \\n\\nThis extracts attachments from the email and created a new blob for each attachment. \\n\\nNext, inside the same for-each action, add the **get blob content** action.\\n\\nSet the following values: \\n\\n| Parameter | Value | \\n|--|--|\\n| Blob | id | \\n| Infer content type | Yes | \\n\\n> We create and read from a blob for each attachment because Computer Vision needs a non-virtual source to read from when performing an OCR process. Because we enabled system assigned identity to grant Computer Vision to other existing resources, it can access the blob but not the outlook.com attachment.  Also, we pass the ID of the blob to use as a unique ID when writing to Cosmos DB.\\n\\n![create blob from attachments](img/createblobfromattachments.png)\\n\\nNext, inside the same for-each action, choose **add an action** and choose **control > condition**. Set the value to **Media Type > is equal to > image/JPEG**\\n\\n> The USPS sends attachments of multiple types, but we only want to scan attachments that have images of our mail, which are always JPEG images. If the condition is true, we will process the image with Computer Vision OCR and write the results to a JSON document in CosmosDB.\\n\\n\\nIn the **True** section of the condition, add an action and choose **Computer Vision API > Optical Character Recognition (OCR) to JSON**. \\n\\nSet the following values: \\n\\n| Parameter | Value | \\n|--|--|\\n| Image Source | Image Content | \\n| Image content | File Content | \\n\\nIn the same **True** section of the condition, choose **add an action** and choose Cosmos DB.  Choose **Create or Update Document** from the actions.  Select **Access Key**, and provide the primary read-write key (found under keys in Cosmos DB), and the Cosmos DB account ID (without \'documents.azure.com\'). \\n\\nNext, fill in your Cosmos DB Database ID and Collection ID.  Create a JSON document by selecting dynamic content elements and wrapping JSON formatting around them. \\n\\n>Be sure to use the ID passed from blob storage as your unique ID for CosmosDB.  That way you can troubleshoot and JSON or OCR issues by tracing back the JSON document in Cosmos Db to the blob in Azure storage.  Also, include the Computer Vision JSON response, as it contains the results of the Computer Vision OCR scan.  all other elements are optional.  \\n\\n\\n:::tip 4. TEST WORKFLOW\\n:::\\n\\nWhen complete, you should have an action the Logic App designer that looks something like this:  \\n\\n![Logic App workflow create or update document in cosmosdb](img/cosmoscreateorupdatedocument.png)\\n\\nSave the workflow and test the connections by clicking **Run Trigger > Run**.  If connections are working, you should see documents flowing into Cosmos DB each time that an email arrives with image attachments.   \\n\\nCheck the data in Cosmos Db by opening the Data explorer, then choosing the container you created and selecting **items**.  You should see documents similar to this: \\n\\n![Logic App workflow with trigger and action](img/readmailfinalresults.png)\\n\\n:::tip 1. Congratulations\\nYou just built your personal ReadMail solution with Logic Apps! \ud83c\udf89\\n:::\\n\\n---\\n\\n## Resources: For self-study!\\n\\nOnce you have an understanding of the basics in ths post, there is so much more to learn!  \\n\\n- Check out the other [Serverless September posts](https://azure.github.io/Cloud-Native/blog).  \\n- For more detail about Cosmos DB, see the docs at https://learn.microsoft.com/azure/cosmos-db/\\n- For more info on Logic Apps, see the docs at https://learn.microsoft.com/azure/logic-apps/\\n- For details on Azure Cognitive Services and Computer Vision, see https://azure.microsoft.com/products/cognitive-services/computer-vision/.\\n\\nThanks for stopping by!"},{"id":"17-integrate-cosmosdb","metadata":{"permalink":"/Cloud-Native/blog/17-integrate-cosmosdb","source":"@site/blog/2022-09-17/index.md","title":"17. Logic Apps + Cosmos DB","description":"<FIXME>","date":"2022-09-17T00:00:00.000Z","formattedDate":"September 17, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":5.3,"hasTruncateMarker":false,"authors":[{"name":"Brian Benz","title":"Senior Cloud Advocate @Microsoft","url":"https://github.com/bbenz","imageURL":"https://github.com/bbenz.png","key":"brian"}],"frontMatter":{"slug":"17-integrate-cosmosdb","title":"17. Logic Apps + Cosmos DB","authors":["brian"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts","logicapps"],"image":"./img/banner.png","description":"<FIXME>","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"18. Logic Apps + Computer Vision","permalink":"/Cloud-Native/blog/18-cloudmail"},"nextItem":{"title":"15. ACA + Serverless On Azure","permalink":"/Cloud-Native/blog/15-microservices-azure"}},"content":"\x3c!-- FIXME --\x3e\\n<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/17-integrate-cosmosdb\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/17-integrate-cosmosdb\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 17` of #30DaysOfServerless!\\n\\nIn past weeks, we\'ve covered serverless technologies that provide core capabilities (functions, containers, microservices) for building serverless solutions. This week we\'re looking at technologies that make **service integrations** more seamless, starting with **Logic Apps**. Let\'s look at one usage example today!\\n\\nReady? Let\'s Go!\\n\\n---\\n\\n## What We\'ll Cover\\n * Introduction to Logic Apps\\n * Settng up Cosmos DB for Logic Apps\\n * Setting up a Logic App connection and event\\n * Writing data to Cosmos DB from a Logic app\\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Introduction to Logic Apps\\n\\nPreviously in Serverless September, we\'ve covered Azure Functions, where the event triggers code. In Logic Apps, the event triggers a workflow that you design. Logic Apps enable serverless applications to connect to external sources for data then automate business processes via workflows.\\n\\nIn this post I\'ll walk you through setting up a Logic App that works with Cosmos DB.  For this example, we\'ll connect to the MSN weather service, an design a logic app workflow that collects data when weather changes, and writes the data to Cosmos DB.\\n\\n:::info PREREQUISITES\\n\\n* An active Azure subscription (with Contributor or Owner permissions).\\n* Don\'t have one? [Create an account for free](https://azure.microsoft.com/free/).\\n:::\\n\\n\\n## Setup Cosmos DB for Logic Apps\\nCosmos DB has [many APIs to choose from](https://learn.microsoft.com/azure/cosmos-db/choose-api), but to use the [default Logic App connection](https://docs.microsoft.com/connectors/documentdb/), we need to choose the a Cosmos DB SQL API.  We\'ll set this up via the Azure Portal. \\n\\nTo get started with Cosmos DB, you create an account, then a database, then a container to store JSON documents. To create a new Cosmos DB account from the [portal dashboard](https://portal.azure.com), Select **Create a resource > Azure Cosmos DB > Create**.  Choose **core SQL** for the API.\\n\\n![](img/cosmosdbapiselection.png)\\n\\nSelect your subscription, then create a new resource group called **CosmosWeather**.  Enter an account name and choose a location, select provisioned throughput capacity mode and apply the free tier discount. From here you can select **Review and Create**, then **Create** \\n\\n> Azure Cosmos DB is available in two different capacity modes: provisioned throughput and [serverless](https://docs.microsoft.com/azure/cosmos-db/throughput-serverless). You can perform the same database operations in both modes, but the way you get billed for these operations is different. We wil be using provisioned throughput and the free tier for this example.\\n\\n![Setup the CosmosDB account](img/cosmosdbaccount.png)\\n\\n\\nNext, create a new database and container. Go to the **Data Explorer** in your new Cosmos DB account, and choose **New Container**.  Name the database, and keep all the orher defaults except:  \\n\\n| Setting | Action |\\n|---|---|\\n| Container ID | id |\\n| Container partition |  /id |\\n\\nPress **OK** to create a database and container\\n\\n>A database is analogous to a traditional DBMS namespace. It\'s used to organize one or more containers.\\n\\n![Setup the CosmosDB Container](img/cosmosdbcontainer.png)\\n\\nNow we\'re ready to set up our logic app an write to Cosmos DB!  \\n\\n## Setup Logic App connection + event\\n\\nOnce the Cosmos DB SQL API account is created, we can set up our Logic App.  From the [portal dashboard](https://portal.azure.com), Select **Create a resource > Integration > Logic App > Create**.  Name your Logic App and select a location, the rest fo the settings can be left at their defaults.  Once you new Logic App is created, select **Create a workflow from designer** to get started.  \\n\\n>A workflow is a series of steps that defines a task or process. Each workflow starts with a single trigger, after which you must add one or more actions.\\n\\nWhen in designer, search for **weather** on the right under **Add a trigger**.  Choose **MSN Weather**.  Choose \\n**When the current conditions change** as the trigger.  \\n\\n>A trigger is always the first step in any workflow and specifies the condition for running any further steps in that workflow. \\n\\nAdd a location.  Valid locations are City, Region, State, Country, Landmark, Postal Code, latitude and longitude.  This triggers a new workflow when the conditions change for a location.\\n\\n## Write data from Logic App to Cosmos DB \\n\\nNow we are ready to set up the action to write data to Cosmos DB.  Choose **add an action** and choose Cosmos DB.  \\n\\n> An action is each step in a workflow after the trigger. Every action runs some operation in a workflow.\\n\\nIn this case, we will be writing a JSON document to the Cosmos DB container we created earlier.  Choose **Create or Update Document** from the actions.  At this point you should have a workflow in designer that looks something like this: \\n\\n![Logic App workflow with trigger](img/logicappworkflow1.png)\\n\\nStart wth the connection for set up the Cosmos DB action.  Select **Access Key**, and provide the primary read-write key (found under keys in Cosmos DB), and the Cosmos DB account ID (without \'documents.azure.com\'). \\n\\nNext, fill in your Cosmos DB Database ID and Collection ID.  Create a JSON document bt selecting dynamic content elements and wrapping JSON formatting around them.  \\n\\nYou will need a unique ID for each document that you write to Cosmos DB, for that you can use an expression.  Because we declared **id** to be our unique ID in Cosmos DB, we will use use that for the name.  Under expressions, type ```guid()``` and press enter to add a unique ID to the JSON document.  When complete, you should have a workflow in designer that looks something like this:  \\n\\n![Logic App workflow with trigger and action](img/logicappworkflow2.png)\\n\\nSave the workflow and test the connections by clicking **Run Trigger > Run**.  If connections are working, you should see documents flowing into Cosmos DB over the next few minutes.   \\n\\nCheck the data in Cosmos Db by opening the Data explorer, then choosing the container you created and selecting **items**.  You should see documents similar to this: \\n\\n![Logic App workflow with trigger and action](img/cosmosdresults.png)\\n\\n## Resources: For self-study!\\n\\nOnce you\'ve grasped the basics in ths post, there is so much more to learn!  \\n\\n- Check out the other [Serverless September posts](https://azure.github.io/Cloud-Native/blog).  \\n- For more detail about Cosmos DB, see the docs at https://learn.microsoft.com/azure/cosmos-db/\\n- For more info on Logic Apps, see the docs at https://learn.microsoft.com/azure/logic-apps/\\n\\nThanks for stopping by!"},{"id":"15-microservices-azure","metadata":{"permalink":"/Cloud-Native/blog/15-microservices-azure","source":"@site/blog/2022-09-15/index.md","title":"15. ACA + Serverless On Azure","description":"Recap of Week 2: Microservices, Azure Container Apps and Dapr","date":"2022-09-15T00:00:00.000Z","formattedDate":"September 15, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"}],"readingTime":3.565,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"},{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://github.com/devanshidiaries.png","key":"devanshi"}],"frontMatter":{"slug":"15-microservices-azure","title":"15. ACA + Serverless On Azure","authors":["nitya","devanshi"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Recap of Week 2: Microservices, Azure Container Apps and Dapr","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr"]},"prevItem":{"title":"17. Logic Apps + Cosmos DB","permalink":"/Cloud-Native/blog/17-integrate-cosmosdb"},"nextItem":{"title":"14. Build ACA with Dapr","permalink":"/Cloud-Native/blog/14-dapr-aca-quickstart"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/15-microservices-azure\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/15-microservices-azure\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 15` of #30DaysOfServerless!\\n\\nThis post marks the midpoint of our Serverless on Azure journey! Our [Week 2 Roadmap](https://azure.github.io/Cloud-Native/serverless-september/30DaysOfServerless/) showcased two key technologies - [Azure Container Apps (ACA)](https://learn.microsoft.com/azure/container-apps/) and [Dapr](https://dapr.io) - for building serverless microservices. We\'ll also look at what happened elsewhere in #ServerlessSeptember, then set the stage for our next week\'s focus: Serverless Integrations.\\n\\nReady? Let\'s Go!\\n\\n---\\n\\n## What We\'ll Cover\\n * **ICYMI**: This Week on #ServerlessSeptember\\n * **Recap**: Microservices, Azure Container Apps & Dapr\\n * **Coming Next:** Serverless Integrations\\n * **Exercise**: [Take the Cloud Skills Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi)\\n * **Resources**: For self-study!\\n\\n![](./img/banner.png)\\n\\n## This Week In Events\\n\\nWe had a number of activities happen this week - here\'s a quick summary:\\n * On **Zero To Hero:** <br/>Anthony Chu took us on a [Journey to the Cloud with Azure Container Apps](/blog/zero2hero-aca-04) exploring tools to simplify develop-deploy workflows for ACA. And Melony Qin talked about [Using Custom Handlers For Go](/blog/zero2hero-func-03), explaining how this allows extended languages support in Azure Functions.\\n * On **Serverless Hacks:**  <br/>Gwyn was joined by Liam Hampton as they talked about [How to DevOps and Serverless The Right Way](https://www.youtube.com/watch?v=EcsAcm22GqI). And it\'s not too late to complete the hack and [submit your solution to our hall of fame](https://azure.github.io/Cloud-Native/serverless-september/ServerlessHacks/).\\n * On **Ask The Expert:** <br/>We had our first Live Q&A Session featuring members of the Azure Functions team, hosted by Gwyn. Catch up on the [recording](https://www.youtube.com/watch?v=wB5Va1a-MeY) for useful tips and guidance.\\n\\n## This Week in #30Days\\n\\nIn our #30Days series we focused on Azure Container Apps and Dapr.\\n * In [Hello Container Apps](https://azure.github.io/Cloud-Native/blog/09-aca-fundamentals) we learned how Azure Container Apps helps you run microservices and containerized apps on serverless platforms. And we build and deployed our first ACA.\\n * In [Microservices Communication](https://azure.github.io/Cloud-Native/blog/microservices-10) we explored concepts like _environments_ and _virtual networking_, with a hands-on example to show how two microservices communicate in a deployed ACA.\\n * In [Scaling Your Container Apps](https://azure.github.io/Cloud-Native/blog/11-scaling-container-apps) we learned about KEDA (Kubernetes Event-Driven Autoscaler) and how to configure autoscaling for your ACA based on KEDA-supported triggers.\\n * In [Build with Dapr](https://azure.github.io/Cloud-Native/blog/12-build-with-dapr) we introduced the Distributed Application Runtime (Dapr) and learned how its Building Block APIs and sidecar architecture make it easier to develop microservices with ACA.\\n * In [Secure ACA Access](https://azure.github.io/Cloud-Native/blog/13-aca-managed-id) we learned how to secure ACA access to external services with - and without - Dapr, covering Secret Stores and Managed Identity.\\n * Finally, [Build ACA with Dapr](https://azure.github.io/Cloud-Native/blog/14-dapr-aca-quickstart) tied it all together with a enterprise app scenario where an orders processor (ACA) uses Dapr APIs (PubSub, State Management) to receive and store order messages from Azure Service Bus.\\n\\nHere\'s a visual recap:\\n\\n![](./../../static/img/banners/roadmap-Week2.png)\\n\\n\\n\\n## Self Study: Code Samples & Tutorials\\n\\nThere\'s no better way to get familiar with the concepts, than to dive in and play with code samples and hands-on tutorials. Here are 4 resources to bookmark and try out:\\n 1. [Dapr Quickstarts](https://docs.dapr.io/getting-started/quickstarts/) - these walk you through samples showcasing individual Building Block APIs - with multiple language options available.\\n 2. [Dapr Tutorials](https://docs.dapr.io/getting-started/tutorials/) provides more complex examples of microservices applications and tools usage, including a [Distributed Calculator](https://github.com/dapr/quickstarts/tree/master/tutorials/distributed-calculator) polyglot app.\\n 3. Next, try to [Deploy a Dapr application to Azure Container Apps](https://learn.microsoft.com/azure/container-apps/microservices-dapr?tabs=bash) to get familiar with the process of setting up the environment, then deploying the app.\\n 4. Or, explore the many [Azure Container Apps samples](https://learn.microsoft.com/azure/container-apps/samples?source=recommendations) showcasing various features and more complex architectures tied to real world scenarios.\\n\\n## What\'s Next: Serverless Integrations!\\n\\nSo far we\'ve talked about core technologies (Azure Functions, Azure Container Apps, Dapr) that provide foundational support for your serverless solution. Next, we\'ll look at **Serverless Integrations** - specifically at technologies like Azure Logic Apps and Azure Event Grid that _automate workflows_ and create seamless end-to-end solutions that integrate _other_ Azure services in serverless-friendly ways.\\n\\n## Take the Challenge! \\n\\nThe [**Cloud Skills Challenge**](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi) is still going on, and we\'ve already had hundreds of participants join and complete the learning modules to skill up on Serverless.\\n\\nThere\'s still time to join and get yourself on the leaderboard. Get familiar with Azure Functions, SignalR, Logic Apps, Azure SQL and more - in serverless contexts!! \\n\\n\\n---"},{"id":"14-dapr-aca-quickstart","metadata":{"permalink":"/Cloud-Native/blog/14-dapr-aca-quickstart","source":"@site/blog/2022-09-14/index.md","title":"14. Build ACA with Dapr","description":"Let\'s build our first Azure Container Apps solution with Dapr!","date":"2022-09-14T00:00:00.000Z","formattedDate":"September 14, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":20.61,"hasTruncateMarker":false,"authors":[{"name":"Taisser Joudeh","title":"Modern Apps Consultant @Microsoft","url":"https://github.com/tjoudeh","imageURL":"https://github.com/tjoudeh.png","key":"taiseer"}],"frontMatter":{"slug":"14-dapr-aca-quickstart","title":"14. Build ACA with Dapr","authors":["taiseer"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","serverless","dapr","containerapps","dotnet"],"image":"./img/banner.png","description":"Let\'s build our first Azure Container Apps solution with Dapr!","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"15. ACA + Serverless On Azure","permalink":"/Cloud-Native/blog/15-microservices-azure"},"nextItem":{"title":"13. Secrets + Managed Identity","permalink":"/Cloud-Native/blog/13-aca-managed-id"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/14-dapr-aca-quickstart\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Container Apps + Dapr\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Container Apps + Dapr\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/14-dapr-aca-quickstart\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 14` of #30DaysOfServerless!\\n\\nIn the past few days we focused our attention on Azure Container Apps, building microservices-based solutions and learning related concepts like environments, networking and auto-scaling - before introducing the sidecar capability of Dapr. Today, we look at how Dapr and ACA work seamlessly together to simplify microservices development in the cloud.\\n\\n---\\n\\n## What We\'ll Cover\\n * Dapr refresher\\n * Application scenario we are covering today\\n * Quickstart: Build your first ACA with Dapr\\n * Exercise: Try this yourself!\\n * What\'s Next: Advanced scenario in 12-part series \\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Introduction To Dapr\\nAs developers, we are often tasked with create scalable resilient and distributed microservices, but face challenges such as recovering state after failures, establishing reliable communication between services, integrating with external resources and instrumenting distributed tracing for end-to-end solution observability. Dapr (Distributed Application Runtime) offers an approach for solving these common problems more easily. \\n\\nDapr provides its core capabilities as a set of [Building Blocks](https://docs.dapr.io/concepts/building-blocks-concept/) as detailed in the introduction to dapr article released as a part of this series. Building Blocks provide consistent APIs that abstract away the implementation details to keep microservices code simple and portable.\\n\\n## Today\'s App Scenario\\nIn this blog post we will create an Azure Container App which will act as an internal-only, background processor service. This service will not be accessible from the internet or from other services directly. We will also configure two Dapr building blocks (APIs): Pub/Sub and State Management. Let\'s take a look at the architecture diagram below to have better understanding of what we are building:\\n\\n![Diagram showing architecture of sample project](img/ACA-Tutorial-AsyncComm-0922.jpg)\\n\\nOur service, `orders-processor`, will be processing messages published to an Azure Service Bus Topic named `orderreceivedtopic`. The Dapr Pub/Sub building block will be configured by providing a configuration file named `pubsub-svcbus.yaml` which contains all the needed information to establish the connection between the container app and the service bus topic. Once a message is consumed by the `orders-processor` service, it will store a copy of it in Azure Cosmos DB. To wire up Cosmos DB, we will use the Dapr State Store building block and a `statestore-cosmosdb.yaml` component.\\n\\nBecause we are leveraging Dapr, we will not introduce any SDK for Azure Service Bus nor Azure Cosmos DB; everything will be configured using the component files, so let\'s jump into the code! :)\\n\\n:::info Looking for Advanced scenarios?\\nThis scenario is a simplified version of a detailed tutorial which covers more advanced scenarios, if you are interested you can check more [Advanced scenarios on my blog.](https://bitoftech.net/2022/08/25/tutorial-building-microservice-applications-azure-container-apps-dapr/)\\n:::\\n\\n## Build ACA with Dapr\\nIn today\'s post, we\'ll be using VS Code to build the app using ASP.NET Core 6.0. In the process, we\'ll setup our development environment with the relevant command-line tools and VS Code extensions. In addition, we will use the Azure CLI to create the Azure resources which will be used in this solution.\\n\\n_Note: Completing this exercise may incur a a cost of a few USD based on your Azure subscription._\\n\\nFirst, make sure you have your development environment setup and configured.\\n:::info PRE-REQUISITES\\n\\n 1. **An Azure account with an active subscription** - [Create an account for free](https://azure.microsoft.com/free/?ref=microsoft.com&utm_source=microsoft.com&utm_medium=docs&utm_campaign=visualstudio)\\n 2. **dotnet 6.0** - [Install](https://dotnet.microsoft.com/download/dotnet/6.0)\\n 3. **Docker Desktop** - [Install](https://docs.docker.com/desktop/install/windows-install/) \\n 4. **Visual Studio Code** - [Install](https://code.visualstudio.com/)\\n 5. **VS Code Docker extension** - [Install](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker)\\n 6. **Dapr CLI. Details on installation on this post too** - [Install](https://docs.dapr.io/getting-started/install-dapr-cli/)\\n 7. **VS Code Dapr extension. Depends on Dapr CLI** - [Install](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-dapr)\\n 8. **Azure CLI** - [Install](https://docs.microsoft.com/cli/azure/install-azure-cli)\\n:::\\n\\n### Create the service project (Web API)\\n\\n1. Open a command-line terminal and create a folder for your project. Use the `code` command to launch Visual Studio Code from that directory as shown:\\n\\n   ```powershell\\n   mkdir orders-service\\n   cd orders-service\\n   code .\\n    ```\\n    \\n2. From VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder `orders-service` and initialize the project by typing: `dotnet new webapi -o Orders.Processor  --no-https` This will create and ASP.NET Web API project scaffolded with 1 single controller. \\n\\n3. We need to containerize this application so we can push it to Azure Container Registry as a docker image and deploy it to Azure Container Apps. To do so, Open the VS Code Command Palette (<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>p</kbd>) and select `Docker: Add Docker Files to Workspace...`\\n    - Use `.NET: ASP.NET Core` when prompted for application platform.\\n    - Choose `Linux` when prompted to choose the operating system.\\n    - You will be asked if you want to add Docker Compose files. Select `No`.\\n    - Take a not of the provided **application port** as we will be using later on.\\n    - `Dockerfile` and `.dockerignore` files are added to the workspace.\\n  \\n4. Now we will add the DTO which will be used to deserialize the consumed message from Azure Service Bus Topic, so add a new file named `OrderModel.cs` under a new folder named `Models` and use the code below\\n    ```csharp\\n    public class OrderModel\\n    {\\n        public Guid OrderId { get; set; } = Guid.NewGuid();\\n        public string Reference { get; set; } = string.Empty;\\n        public int Quantity { get; set; }\\n        public DateTime CreatedOn { get; set; }\\n    }\\n    ```\\n    \\n5. Install Dapr Client NuGet package, we will use this package to subscribe to the Azure Service Bus Topic in a programmatic way. From the developer command prompt or PowerShell terminal type `dotnet add package Dapr.AspNetCore`\\n\\n6. Create an API endpoint for the consumer/service to subscribe to the topic, this endpoint will start receiving the messages published to the topic `orderreceivedtopic`. Add a new controller named `ExternalOrdersController.cs` under the `Controllers` folder and use the code below:\\n\\n    ```csharp\\n    [ApiController]\\n    [Route(\\"api/externalorders\\")]\\n    public class ExternalOrdersController : ControllerBase\\n    {\\n        private readonly ILogger<ExternalOrdersController> _logger;\\n        private readonly DaprClient _daprClient;\\n        public ExternalOrdersController(ILogger<ExternalOrdersController> logger, DaprClient daprClient)\\n        {\\n            _logger = logger;\\n            _daprClient = daprClient;\\n        }\\n\\n        [Topic(\\"pubsub-servicebus\\", \\"orderreceivedtopic\\")]\\n        [HttpPost(\\"orderreceived\\")]\\n        public async Task<IActionResult> OrderReceived([FromBody] OrderModel orderModel)\\n        {\\n            _logger.LogInformation(\\"Received new order at: \'{0}\' Order Id: \'{1}\' Order reference: \'{2}\', Order quantity: \'{3}\'\\",\\n                                    DateTime.UtcNow, orderModel.OrderId, orderModel.Reference, orderModel.Quantity);\\n\\n            //Do your business logic with order received\\n            orderModel.CreatedOn = DateTime.UtcNow;\\n\\n            ////ToDo: Your exercise :) Save the received message into CosmoDb using the SveStateAsync\\n            //await _daprClient.SaveStateAsync<OrderModel>(\\"statestore-cosmosdb\\", orderModel.OrderId.ToString(), orderModel);\\n\\n            //Return 200 ok to acknowledge order is processed successfully          \\n            return Ok($\\"Order Processing completed successfully\\");\\n\\n            //Retunr 400 bad request to retry re-processing based on service broker configuration\\n            //return BadRequest($\\"Failed to process order due to: failure reason\\");\\n        }\\n    }\\n    ```\\n  \\n  In summary, the above steps result in: \\n    - An action method called `orderreceived` which can be reached on the route `api/externalorders/orderreceived` and receives an `OrderModel` object.\\n    - An attribute `Topic` on the action method including the name of the pub/sub component and the topic to subscribe to. \\n    - Business logic for processing the message which will result in an appropriate response which dictates if the message was process successfully, should be retried or should be dead-lettered.\\n\\n      \\n7. Register the Dapr client and Subscribe handler at service startup. Open the file `Program.cs` and replace with the content below:\\n    ```csharp\\n        var builder = WebApplication.CreateBuilder(args);\\n\\n        // Add services to the container.\\n\\n        builder.Services.AddControllers().AddDapr();\\n        // Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\\n        builder.Services.AddEndpointsApiExplorer();\\n        builder.Services.AddSwaggerGen();\\n\\n        var app = builder.Build();\\n\\n        // Configure the HTTP request pipeline.\\n        if (app.Environment.IsDevelopment())\\n        {\\n        app.UseSwagger();\\n        app.UseSwaggerUI();\\n        }\\n\\n        app.UseAuthorization();\\n\\n        app.UseCloudEvents();\\n\\n        app.MapControllers();\\n\\n        app.MapSubscribeHandler();\\n\\n        app.Run();\\n    ```\\n    :::note Want to know more?\\n       Check this [blog post](https://bitoftech.net/2022/09/02/azure-container-apps-async-communication-with-dapr-pub-sub-api-part-6/) which describes in detail how the consumer was able to discover available topic names, Pub/Sub names, and which routes/endpoints to push messages to.\\n    :::\\n\\n### Provision Azure Service Bus, Topic and Subscription\\n\\nWe need to create the Azure Service Bus so we can configure the Dapr Pub/Sub component and test locally\\n\\n1. Open your Powershell console and login to Azure by using the command `az login`. If you have multiple subscriptions, set the subscription you want to use in this tutorial before proceeding, you can do this by using `az account set --subscription <name or id>`. Calling `az upgrade` is a good practice to ensure you are running the latest Aure CLI version.\\n\\n2. Create an Azure Resource Group by using the code below, feel free to change the name and location of the resource group\\n    ```powershell\\n    $RESOURCE_GROUP=\\"orders-services-rg\\"\\n    $LOCATION=\\"eastus\\"\\n    az group create `\\n      --name $RESOURCE_GROUP `\\n      --location \\"$LOCATION\\"\\n    ```\\n    \\n3. Create the necessary Azure Service Bus resource and retrieve the primary connection string (for local dev testing).\\n    \\n    ```powershell\\n    $NamespaceName=\\"ordersservices\\"\\n    $TopicName=\\"orderreceivedtopic\\"\\n    $TopicSubscription=\\"orders-processor-subscription\\"\\n\\n    ##Create servicebus namespace\\n    az servicebus namespace create --resource-group $RESOURCE_GROUP --name $NamespaceName --location $LOCATION\\n\\n    ##Create a topic under namespace\\n    az servicebus topic create --resource-group $RESOURCE_GROUP --namespace-name $NamespaceName --name $TopicName\\n\\n    ##Create a topic subscription\\n    az servicebus topic subscription create `\\n      --resource-group $RESOURCE_GROUP `\\n      --namespace-name $NamespaceName `\\n      --topic-name $TopicName `\\n      --name $TopicSubscription\\n\\n    ##List connection string\\n    az servicebus namespace authorization-rule keys list --resource-group $RESOURCE_GROUP --namespace-name $NamespaceName --name RootManageSharedAccessKey --query primaryConnectionString --output tsv\\n    ```\\n    \\nYou can navigate to the Azure Portal and check that the resource group is created and the service bus namespace is created too.\\n\\n\\n### Setup Dapr for local dev\\n\\nIn order to run Dapr locally on our development machine, we need to install Dapr CLI, you can follow the [official documentation](https://docs.dapr.io/getting-started/install-dapr-cli/) or use the steps below.\\n\\n1. Install the Dapr CLI, run PowerShell console as an administrator and run the below command: \\n    ```powershell\\n     powershell -Command \\"iwr -useb https://raw.githubusercontent.com/dapr/cli/master/install/install.ps1 | iex\\"\\n    ```  \\n    Note: You might need to execute the following  PowerShell command `Set-ExecutionPolicy RemoteSigned -scope CurrentUser` before installing the Dapr CLI, this command is to allow local PowerShell scripts to run regardless of signature, and requires trusted digital signatures only for remote scripts.\\n\\n2. Initialize Dapr in your local development environment. By initializing Dapr, we will fetch and install the Dapr sidecar binaries locally, and we will create a development environment that streamlines application development with Dapr. To do so open the PowerShell console as an administrator and run the below command:\\n\\n    ```powershell\\n    dapr init\\n    ```\\n \\n    To verify the deployment; check Dapr version by running the following command: `dapr --version` \\n    \\n    :::note Want to know more?\\n        Check this [blog post](https://bitoftech.net/2022/08/29/dapr-integration-with-azure-container-apps/) which describes in detail what components added to your machine when we called `dapr init`\\n    ::: \\n\\n\\n### Create a local Dapr Component file for Pub/Sub \\n\\nDapr uses a modular design where functionality is delivered as a component. Each component has an interface definition. All of the components are pluggable so that you can swap out one component with the same interface for another.\\n\\nComponents are configured at design-time with a YAML file which is stored in either a components/local folder within your solution, or globally in the .dapr folder created when invoking dapr init [(read here for more details)](https://bitoftech.net/2022/08/29/dapr-integration-with-azure-container-apps/). These YAML files adhere to the generic [Dapr component schema](https://docs.dapr.io/operations/components/component-schema/), but each is specific to the component specification.\\n\\n1. Create 2 new folders under the project root directory `orders-service`, one called `dapr-component` and the second one `component` (will be used in next steps). Add a new yaml file called `pubsub-svcbus.yaml` under folder `dapr-component` using the content below:\\n\\n    ```yaml\\n    apiVersion: dapr.io/v1alpha1\\n    kind: Component\\n    metadata:\\n      name: pubsub-servicebus\\n    spec:\\n      type: pubsub.azure.servicebus\\n      version: v1\\n      metadata:\\n      - name: connectionString # Used for local dev testing.\\n        value: \\"<connection string from step 2.3>\\"\\n      - name: consumerID\\n        value: \\"orders-processor-subscription\\"\\n    scopes:\\n    - orders-processor\\n    ```\\n    \\n    Note that we used the name `pubsub-servicebus` which should match the name of Pub/Sub component we\'ve used earlier in the `ExternalOrdersController.cs` controller on the action method with the attribute `Topic`. As well we have set the metadata (key/value) to allow us to connect to Azure Service Bus topic. The metdata `consumerID` value should match the topic subscription name `orders-processor-subscription`. We have set the scopes section to include the `orders-processor` app id, as this will be the specific application that needs access to Azure Service Bus.\\n    \\n    You need to replace the `connectionString` value with your Service Bus connection string. This is only needed for your local testing on your development machine, we\'ll be using a different approach (**Managed Identities**) when deploying Dapr component to Azure Container Apps Environment. For full metadata specs, you can [check this page](https://docs.dapr.io/reference/components-reference/supported-pubsub/setup-azure-servicebus/).\\n\\n    :::warning\\n        The above sample uses secrets as plain strings for local dev testing. It is recommended to use Managed Identities approach when we deploy the app to Azure Container Apps. Your Dapr components directory should be added to your .gitignore to avoid checking in secrets.\\n    ::: \\n\\n### Preview Dapr app locally for e2e testing\\n\\n1. Within VS Code, open PowerShell terminal, change the directory in the terminal to folder `orders-service` and run the below command in PS terminal:\\n\\n    ```powershell\\n    dapr run --app-id orders-processor --app-port 5039 --dapr-http-port 3500 --components-path \\"../dapr-components\\" dotnet run\\n    ```\\n    \\n    When using the `dapr run` command we are running a dapr process as a sidecar next to the Web API application. The following properties were configured:\\n\\n    - app-id: The unique identifier of the application. Used for service discovery, state encapsulation, and the pub/sub consumer identifier.\\n    - app-port: This parameter tells Dapr which port your application is listening on, you can get the app port from `dockerfile` in the Web API Project.\\n    - dapr-http-port: the HTTP port for Dapr to listen on.\\n    - components-path: path to the Dapr component(s) folder.\\n\\n    If all is working as expected, you can open the VS Code Dapr extension to see the application `orders-processor` up and running as shown below:\\n    \\n    ![Image showing Dapr Application up and Running](img/DaprRunning.jpg)\\n\\n2. To publish a message to the topic `orderreceivedtopic` we can use Dapr extension: \\n    - Right click on the Dapr application `orders-processor` and select `Publish Message to Application`.\\n    - Wizard will ask what is the Pub/sub component name you want to publish to, provide `pubsub-servicebus` and hit enter.\\n    - Wizard will ask what topic name to publish to, provide `orderreceivedtopic` and hit enter.\\n    - Wizard will ask to provide a JSON payload for the method, provide the JSON below and hit enter.\\n      ```json\\n      {\\n          \\"reference\\": \\"Order 1\\",\\n          \\"quantity\\": 5,\\n          \\"createdOn\\": \\"2022-08-19T12:45:22.0983978Z\\"\\n      }\\n      ```\\n\\nTo check the results, go to the VS Code terminal and check the logs. In the action method, we are logging information when a message is consumed. You should see something similar to the below\\n    ![Image showing logs in terminal](img/TerminalLogs.jpg)\\n    \\n    :::info Want to debug Dapr application locally?\\n      If you want to set breakpoints and debug your daper application locally, you can do this in VS code by following simple steps. This is very important when you are running multiple services together and want to test your microservice where multi-services are invoking each other. To learn more, you can continue reading on [my blog.](https://bitoftech.net/2022/08/29/dapr-integration-with-azure-container-apps/)\\n    :::\\n\\n\\n### Deploy the app to Azure Container Apps\\n\\nWe will follow few steps in order to deploy the service `Orders.Processor` to Azure Container Apps, but we need to do one addition before deploying, we have to create a component file for Azure Service Bus which meets the [specs defined by Azure Container Apps](https://docs.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml#configure-dapr-components).\\n      \\n  1. Create a new yaml file named `pubsub-svcbus.yaml` and add it under folder `components` (folder created earlier), use the file content below:\\n      ```yaml\\n      # pubsub.yaml for Azure Service Bus component\\n      componentType: pubsub.azure.servicebus\\n      version: v1\\n      metadata:\\n      - name: namespaceName\\n        value: \\"ordersservices.servicebus.windows.net\\"\\n      - name: consumerID\\n        value: \\"orders-processor-subscription\\"  \\n      # Application scopes  \\n      scopes:\\n      - orders-processor\\n      ```\\n      \\nThings to notice here:\\n      - We didn\'t specify the component name `pubsub-servicebus` when we created this component file, we are going to specify it once we add this dapr component to Azure Container Apps Environment via CLI.\\n      - We are not referencing any service bus connection strings as the authentication between Dapr and Azure Service Bus will be configured using Managed Identities. \\n      - The metadata `namespaceName` value is set to the address of the Service Bus namespace as a fully qualified domain name. The key is mandatory when using Managed Identities for authentication.\\n      - We are setting the metadata `consumerID` value to match the topic subscription name `orders-processor-subscription`. If you didn\'t set this metadata, dapr runtime will try to create a subscription using the dapr application ID.\\n      \\n  2. Createan  Azure Container Registry (ACR) instance in the resource group to build/push and store docker images of our service. Feel free to change the name of the ACR, to do so run the following command:\\n      ```powershell\\n        ## Create Azure Container Registry\\n        $ACR_NAME=\\"ordersservicesacr\\"\\n        az acr create `\\n          --resource-group $RESOURCE_GROUP `\\n          --name $ACR_NAME `\\n          --sku Basic `\\n          --admin-enabled true\\n      ```\\n      \\n  3. Build the Web API project on ACR and push the docker image to ACR. Use the below command to initiate the image build and push process using ACR:\\n      ```powershell\\n      ## Build and push image to ACR\\n      $BACKEND_SVC_NAME=\\"orders-processor\\"\\n      cd {YourLocalPath}\\\\orders-service\\n      az acr build --registry $ACR_NAME --image $BACKEND_SVC_NAME --file \'Orders.Processor/Dockerfile\' .      \\n      ```\\n      \\n  4. Provision an Azure Container Apps Env and Container App: the Azure Container Apps Environment acts as a secure boundary around a group of all container apps:\\n      ```powershell\\n\\n        ## Upgrade az container app cli or install it\\n        az extension add --name containerapp --upgrade\\n\\n        ## Create ACA Env\\n        $ENVIRONMENT=\\"orders-services-aca-env\\"\\n\\n        az containerapp env create `\\n          --name $ENVIRONMENT `\\n          --resource-group $RESOURCE_GROUP `\\n          --location $LOCATION\\n      ```\\n      \\n   5. Deploy the Dapr Pub/Sub Component to the Azure Container Apps Environment using the following command: \\n   \\n      ```powershell\\n          az containerapp env dapr-component set `\\n          --name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\\n          --dapr-component-name pubsub-servicebus `\\n          --yaml \'.\\\\components\\\\pubsub-svcbus.yaml\'\\n      ```\\n      \\n   6. Create a new Azure Container App with the below capabilities:\\n      - Ingress should be disabled\\n      - Dapr needs to be enabled \\n\\n      To achieve the above run the below PowerShell script:\\n      \\n      ```powershell\\n      ## Create Azure COntain App\\n      $BACKEND_SVC_NAME=\\"orders-processor\\"\\n\\n      az containerapp create `\\n        --name $BACKEND_SVC_NAME  `\\n        --resource-group $RESOURCE_GROUP `\\n        --environment $ENVIRONMENT `\\n        --registry-server \\"$ACR_NAME.azurecr.io\\" `\\n        --image \\"$ACR_NAME.azurecr.io/$BACKEND_SVC_NAME\\" `\\n        --min-replicas 1 `\\n        --max-replicas 1 `\\n        --cpu 0.50 --memory 1.0Gi `\\n        --enable-dapr `\\n        --dapr-app-id  $BACKEND_SVC_NAME `\\n        --dapr-app-port 5039\\n      ```\\n      \\n### Configure Managed Identities in Azure Container App   \\nAs you noticed so far, we are not using any connection strings to establish the relation between our Container App and Azure Service Bus, we will rely on [Managed Identities](https://learn.microsoft.com/azure/container-apps/managed-identity?tabs=portal%2Cdotnet) to allow our container app to access Azure Service Bus. \\n\\nWe will be using a `system-assigned` identity with a role assignments to grant our container app the `Azure Service Bus Data Receiver` role which will allow it to receive messages from Service Bus queues and subscriptions.\\n\\n  1. Run the command below to create `system-assigned` identity for our container app:\\n      ```PowerShell\\n      ##assigning the system assigned identity\\n      az containerapp identity assign `\\n        --resource-group $RESOURCE_GROUP `\\n        --name $BACKEND_SVC_NAME `\\n        --system-assigned\\n      ```\\n      \\n     This command will create an Enterprise Application (so a Service Principal) within Azure AD, which is linked to our container app, the output of this command will be as the below, keep a note of the property `principalId` as we are going to use it in the next step.\\n     ```Json\\n      {\\n        \\"principalId\\": \\"456782b0-d5be-4dbd-afa0-5e2cff05d04d\\",\\n        \\"tenantId\\": \\"0a02a8b1-XXXX-XXXX-XXXX-67ceb9132d81\\",\\n        \\"type\\": \\"SystemAssigned\\"\\n      }\\n     ```\\n     \\n     Note: This can be done from Azure Portal as described [here.](https://learn.microsoft.com/azure/container-apps/managed-identity?tabs=portal%2Cdotnet#add-a-system-assigned-identity)\\n  \\n  2. Next, we need to associate the container app system-identity with the target Azure Service Bus resouce. You can read more about [Azure built-in roles for Azure Service Bus.](https://learn.microsoft.com/azure/service-bus-messaging/service-bus-managed-service-identity#azure-built-in-roles-for-azure-service-bus). Run the command below to associate the `system-assigned` with access-control role `Azure Service Bus Data Receiver`\\n      ```PowerShell\\n        $subscription_id = \\"<Your Azure Subscription ID>\\"\\t## Your Azure Subscription\\n        $principalId = \\"456782b0-d5be-4dbd-afa0-5e2cff05d04d\\" ## Principal Id after creating system identity for container app \\n        $roleNameOrId =  \\"Azure Service Bus Data Receiver\\" ## Built in role name\\n        $resourceName = \\"ordersservices\\" ##Name of your Service Bus Namespace\\n\\n        az role assignment create `\\n        --assignee $principalId `\\n        --role $roleNameOrId `\\n        --scope /subscriptions/$subscription_id/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.ServiceBus/namespaces/$resourceName\\n      ```\\n      \\n     You can verify from Azure Portal that the association relation is created by going to your container app, select `identity` tab, then click on `Azure role assignments` button, you should see the role assignment below:\\n    ![Image showing container apps role assignment](img/RoleAssignment-S.jpg)\\n    \\n  3. Lastly, we need to restart the container app revision, to do so run the command below:\\n     ```PowerShell\\n      ##Get revision name and assign it to a variable\\n      $REVISION_NAME = (az containerapp revision list `\\n              --name $BACKEND_SVC_NAME  `\\n              --resource-group $RESOURCE_GROUP `\\n              --query [0].name)\\n      \\n      ##Restart revision by name\\t\\t\\t\\t\\t\\t\\t   \\n      az containerapp revision restart `\\n        --resource-group $RESOURCE_GROUP `\\n        --name $BACKEND_SVC_NAME  `\\n        --revision $REVISION_NAME\\n     ```\\n\\n### Run end-to-end Test on Azure\\n\\nFrom the Azure Portal, select the Azure Container App `orders-processor` and navigate to `Log stream` under `Monitoring` tab, leave the stream connected and opened. From the Azure Portal, select the Azure Service Bus Namespace `ordersservices`, select the topic `orderreceivedtopic`, select the subscription named `orders-processor-subscription`, then click on `Service Bus Explorer (preview)`. From there we need to publish/send a message. Use the JSON payload below\\n\\n    ```json\\n      {\\n        \\"data\\": {\\n            \\"reference\\": \\"Order 150\\",\\n            \\"quantity\\": 150,\\n            \\"createdOn\\": \\"2022-05-10T12:45:22.0983978Z\\"\\n          }\\n      }\\n    ```\\n    \\n If all is configured correctly, you should start seeing the information logs in Container Apps Log stream, similar to the images below\\n  ![Image showing publishing messages from Azure Service](img/SvsBusPublishMessage-S.jpg)\\n \\n Information logs on the `Log stream` of the deployed Azure Container App\\n  ![Image showing ACA Log Stream](img/ACA-Logstream-s.jpg)\\n\\n:::success \ud83c\udf89 CONGRATULATIONS\\nYou have successfully deployed to the cloud an Azure Container App and configured Dapr Pub/Sub API with Azure Service Bus.\\n:::\\n\\n### 9. Clean up\\n\\nIf you are done with the tutorial, use the following command to delete the resource group and all its contained resources to avoid incurring further costs.\\n\\n```powershell\\naz group delete --name $RESOURCE_GROUP\\n```\\n\\n## Exercise\\nI left for you the configuration of the Dapr State Store API with Azure Cosmos DB :) \\n\\nWhen you look at the action method `OrderReceived` in controller `ExternalOrdersController`, you will see that I left a line with `ToDo:` note, this line is responsible to save the received message (OrderModel) into Azure Cosmos DB. \\n\\nThere is no need to change anything on the code base (other than removing this commented line), that\'s the beauty of Dapr Building Blocks and how easy it allows us to plug components to our microservice application without any plumping and brining external SDKs.\\n\\nFor sure you need to work on the configuration part of Dapr State Store by creating a new component file like what we have done with the Pub/Sub API, things that you need to work on are:\\n- Provision Azure Cosmos DB Account and obtain its masterKey.\\n- Create a Dapr Component file adhering to Dapr Specs.\\n- Create an Azure Container Apps component file adhering to ACA component specs.\\n- Test locally on your dev machine using Dapr Component file.\\n- Register the new Dapr State Store component with Azure Container Apps Environment and set the Cosmos Db masterKey from the Azure Portal. _If you want to challenge yourself more, use the Managed Identity approach as done in this post! The right way to protect your keys and you will not worry about managing CosmosDb keys anymore!_\\n- Build a new image of the application and push it to Azure Container Registry.\\n- Update Azure Container Apps and create a new revision which contains the updated code.\\n- Verify the results by checking Azure Cosmos DB, you should see the Order Model stored in Cosmos DB.\\n\\nIf you need help, you can always refer to my blog post [Azure Container Apps State Store With Dapr State Management API](https://bitoftech.net/2022/08/29/azure-container-apps-state-store-with-dapr-state-management-api/) which contains exactly what you need to implement here, so I\'m very confident you will be able to complete this exercise with no issues, happy coding :)\\n\\n## What\'s Next?\\nIf you enjoyed working with Dapr and Azure Container Apps, and you want to have a deep dive with more complex scenarios (Dapr bindings, service discovery, auto scaling with KEDA, sync services communication, distributed tracing, health probes, etc...) where multiple services deployed to a single Container App Environment; I have created a detailed tutorial which should walk you through step by step with through details to build the application.\\n\\nSo far, the published posts below, and I\'m publishing more posts on weekly basis, so stay tuned :)\\n\\n- [Tutorial for building Microservice Applications with Azure Container Apps and Dapr \u2013 Part 1](https://bitoftech.net/2022/08/25/tutorial-building-microservice-applications-azure-container-apps-dapr/)\\n- [Deploy backend API Microservice to Azure Container Apps \u2013 Part 2](https://bitoftech.net/2022/08/25/deploy-microservice-application-azure-container-apps/)\\n- [Communication between Microservices in Azure Container Apps \u2013 Part 3](https://bitoftech.net/2022/08/25/communication-microservices-azure-container-apps/)\\n- [Dapr Integration with Azure Container Apps \u2013 Part 4](https://bitoftech.net/2022/08/29/dapr-integration-with-azure-container-apps/)\\n- [Azure Container Apps State Store With Dapr State Management API \u2013 Part 5](https://bitoftech.net/2022/08/29/azure-container-apps-state-store-with-dapr-state-management-api/)\\n- [Azure Container Apps Async Communication with Dapr Pub/Sub API \u2013 Part 6](https://bitoftech.net/2022/09/02/azure-container-apps-async-communication-with-dapr-pub-sub-api-part-6/)\\n- [Azure Container Apps with Dapr Bindings Building Block \u2013 Part 7](https://bitoftech.net/2022/09/05/azure-container-apps-with-dapr-bindings-building-block/)\\n- [Azure Container Apps Monitoring and Observability with Application Insights \u2013 Part 8](https://bitoftech.net/2022/09/09/azure-container-apps-monitoring-and-observability-with-application-insights-part-8/)\\n- [Continuous Deployment for Azure Container Apps using GitHub Actions \u2013 Part 9](https://bitoftech.net/2022/09/13/continuous-deployment-for-azure-container-apps-using-github-actions-part-9/)\\n- [Use Bicep to Deploy Dapr Microservices Apps to Azure Container Apps \u2013 Part 10](https://bitoftech.net/2022/09/16/use-bicep-to-deploy-dapr-microservices-apps-to-azure-container-apps-part-10/)\\n- [Azure Container Apps Auto Scaling with KEDA \u2013 Part 11](https://bitoftech.net/2022/09/22/azure-container-apps-auto-scaling-with-keda-part-11/)\\n- _Integrate Health probes in Azure Container Apps \u2013 Part 12_\\n\\n## Resources\\n- [Azure Container Apps documentation](https://docs.microsoft.com/azure/container-apps/)\\n- [Getting started with Dapr](https://docs.dapr.io/getting-started/)\\n- [Dapr for .NET Developers](https://docs.microsoft.com/dotnet/architecture/dapr-for-net-developers/)\\n- [az containerapp cli](https://docs.microsoft.com/cli/azure/containerapp?view=azure-cli-latest)"},{"id":"13-aca-managed-id","metadata":{"permalink":"/Cloud-Native/blog/13-aca-managed-id","source":"@site/blog/2022-09-13/index.md","title":"13. Secrets + Managed Identity","description":"Learn to make use of Container Apps (ACA) secrets and managed identities to securely access cloud-hosted resources that your ACA depends on! ","date":"2022-09-13T00:00:00.000Z","formattedDate":"September 13, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":10.78,"hasTruncateMarker":false,"authors":[{"name":"Kendall Roden","title":"Azure Container Apps PM @Microsoft","url":"https://github.com/kendallroden","imageURL":"https://github.com/kendallroden.png","key":"kendall"}],"frontMatter":{"slug":"13-aca-managed-id","title":"13. Secrets + Managed Identity","authors":["kendall"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Learn to make use of Container Apps (ACA) secrets and managed identities to securely access cloud-hosted resources that your ACA depends on! ","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"14. Build ACA with Dapr","permalink":"/Cloud-Native/blog/14-dapr-aca-quickstart"},"nextItem":{"title":"12. Build With Dapr!","permalink":"/Cloud-Native/blog/12-build-with-dapr"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/13-aca-managed-id\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Secrets in Azure Container Apps\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Secrets in Azure Container Apps\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@kendallroden\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/13-aca-managed-id\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 13` of #30DaysOfServerless! \\n\\nIn the previous post, we learned about all things Distributed Application Runtime (Dapr) and highlighted the capabilities you can unlock through managed Dapr in Azure Container Apps! Today, we\'ll dive into how we can make use of Container Apps secrets and managed identities to securely access cloud-hosted resources that your Container Apps depend on! \\n\\nReady? Let\'s go.\\n  \\n---\\n\\n ## What We\'ll Cover\\n  * Secure access to external services overview\\n  * Using Container Apps Secrets\\n  * Using Managed Identity for connecting to Azure resources\\n  * Using Dapr secret store component references (Dapr-only)\\n  * Conclusion   \\n  * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Securing access to external services\\n\\nIn most, if not all, microservice-based applications, one or more services in the system will rely on other cloud-hosted resources; Think external services like databases, secret stores, message brokers, event sources, etc. To interact with these services, an application must have the ability to establish a secure connection. Traditionally, an application will authenticate to these backing resources using some type of connection string or password. \\n  \\nI\'m not sure if it was just me, but one of the first things I learned as a developer was to ensure credentials and other sensitive information were never checked into the codebase. The ability to inject these values at runtime is a non-negotiable.\\n  \\nIn Azure Container Apps, applications can securely leverage connection information via **Container Apps Secrets**. If the resource is Azure-based, a more ideal solution that removes the dependence on secrets altogether is using Managed Identity. \\n\\nSpecifically for Dapr-enabled container apps, users can now tap into the power of the **Dapr secrets API!** With this new capability unlocked in Container Apps, users can call the Dapr secrets API from application code to securely access secrets from Key Vault or other backing secret stores. In addition, customers can also make use of a secret store component reference when wiring up Dapr state store components and more! \\n\\nALSO, I\'m excited to share that **support for  Dapr + Managed Identity is now available**!!. What does this mean? It means that you can enable Managed Identity for your container app - and when establishing connections via Dapr, the Dapr sidecar can use this identity! This means simplified components without the need for secrets when connecting to Azure services! \\n  \\nLet\'s dive a bit deeper into the following three topics:\\n  1. Using Container Apps secrets in your container apps\\n  2. Using Managed Identity to connect to Azure services\\n  3. Connecting to services securely for Dapr-enabled apps \\n                                                                      \\n## Secure access to external services without Dapr  \\n\\n### Leveraging Container Apps secrets at runtime \\n\\nUsers can leverage this approach for any values which need to be securely stored, however, it is recommended to use Managed Identity where possible when connecting to Azure-specific resources. \\n  \\nFirst, let\'s establish a few important points regarding secrets in container apps:  \\n- Secrets are scoped at the container app level, meaning secrets cannot be shared across container apps today \\n- When running in multiple-revision mode, \\n  - changes to secrets **do not** generate a new revision\\n  - running revisions will not be automatically restarted to reflect changes. If you want to force-update existing container app revisions to reflect the changed secrets values, you will need to perform revision restarts. \\n  \\n:::info STEP 1\\nProvide the secure value as a secret parameter when creating your container app using the syntax **\\"SECRET_NAME=SECRET_VALUE\\"**\\n:::\\n\\n  ```bash\\n  az containerapp create \\\\\\n    --resource-group \\"my-resource-group\\" \\\\\\n    --name queuereader \\\\\\n    --environment \\"my-environment-name\\" \\\\\\n    --image demos/queuereader:v1 \\\\\\n    --secrets \\"queue-connection-string=$CONNECTION_STRING\\"\\n  ```\\n\\n:::info STEP 2 \\nCreate an environment variable which references the value of the secret created in step 1 using the syntax **\\"ENV_VARIABLE_NAME=secretref:SECRET_NAME\\"**\\n:::\\n  \\n  ```bash\\n  az containerapp create \\\\\\n    --resource-group \\"my-resource-group\\" \\\\\\n    --name myQueueApp \\\\\\n    --environment \\"my-environment-name\\" \\\\\\n    --image demos/myQueueApp:v1 \\\\\\n    --secrets \\"queue-connection-string=$CONNECTIONSTRING\\" \\\\\\n    --env-vars \\"QueueName=myqueue\\" \\"ConnectionString=secretref:queue-connection-string\\"\\n  ```\\n\\nThis **ConnectionString** environment variable can be used within your application code to securely access the connection string value at runtime.\\n                                                                                       \\n### Using Managed Identity to connect to Azure services\\n  \\nA managed identity from Azure Active Directory (Azure AD) allows your container app to access other Azure AD-protected resources. This approach is recommended where possible as it eliminates the need for managing secret credentials in your container apps and allows you to properly scope the permissions needed for a given container app using role-based access control. Both system-assigned and user-assigned identities are available in container apps. For more background on managed identities in Azure AD, see [Managed identities for Azure resources](https://learn.microsoft.com/azure/active-directory/managed-identities-azure-resources/overview).\\n  \\nTo configure your app with a system-assigned managed identity you will follow similar steps to the following: \\n\\n:::info STEP 1\\nRun the following command to create a system-assigned identity for your container app \\n:::\\n  \\n  ```bash\\n  az containerapp identity assign \\\\\\n    --name \\"myQueueApp\\" \\\\\\n    --resource-group \\"my-resource-group\\" \\\\\\n    --system-assigned\\n  ```\\n  \\n:::info STEP 2\\nRetrieve the identity details for your container app and store the Principal ID for the identity in a variable **\\"PRINCIPAL_ID\\"**\\n:::\\n\\n  ```bash\\n  az containerapp identity show \\\\\\n    --name \\"myQueueApp\\" \\\\\\n    --resource-group \\"my-resource-group\\"\\n  ```\\n  \\n:::info STEP 3 \\nAssign the appropriate roles and permissions to your container app\'s managed identity using the Principal ID in step 2 based on the resources you need to access (example below)\\n:::\\n  \\n  ```bash\\n  az role assignment create \\\\\\n    --role \\"Storage Queue Data Contributor\\" \\\\\\n    --assignee $PRINCIPAL_ID \\\\\\n    --scope \\"/subscriptions/<subscription>/resourceGroups/<resource-group>/providers/Microsoft.Storage/storageAccounts/<storage-account>/queueServices/default/queues/<queue>\\"\\n ```\\n  \\nAfter running the above commands, your container app will be able to access your Azure Store Queue because it\'s managed identity has been assigned the \\"Store Queue Data Contributor\\" role. The role assignments you create will be contingent solely on the resources your container app needs to access. To instrument your code to use this managed identity, see more details [here](https://learn.microsoft.com/azure/container-apps/managed-identity?tabs=portal%2Cdotnet#connect-to-azure-services-in-app-code). \\n\\nIn addition to using managed identity to access services from your container app, you can also use managed identity to [pull your container images from Azure Container Registry](https://learn.microsoft.com/azure/container-apps/containers#container-registries).\\n\\n## Secure access to external services with Dapr  \\n\\nFor Dapr-enabled apps, there are a few ways to connect to the resources your solutions depend on. In this section, we will discuss when to use each approach. \\n  1. Using Container Apps secrets in your Dapr components\\n  1. Using Managed Identity with Dapr Components \\n  1. Using Dapr Secret Stores for runtime secrets and component references \\n\\n### Using Container Apps secrets in Dapr components\\n\\nPrior to providing support for the Dapr Secret\'s Management building block, this was the only approach available for securely storing sensitive values for use in Dapr components. \\n\\nIn Dapr OSS, when no secret store reference is provided in a Dapr component file, the default secret store is set to \\"Kubernetes secrets\\". In Container Apps, we do not expose the ability to use this default store. Rather, Container Apps secrets can be used in it\'s place. \\n  \\nWith the introduction of the Secrets API and the ability to use Dapr + Managed Identity, this approach is useful for a limited number of scenarios: \\n  - Quick demos and dev/test scenarios using the Container Apps CLI \\n  - Securing values when a secret store is not configured or available for use\\n  - Using service principal credentials to configure an Azure Key Vault secret store component (Using Managed Identity is recommend) \\n  - Securing access credentials which may be required when creating a non-Azure secret store component \\n\\n:::info STEP 1 \\nCreate a Dapr component which can be used by one or more services in the container apps environment. In the below example, you will create a secret to store the storage account key and reference this secret from the appropriate Dapr metadata property. \\n:::\\n  \\n   ```yaml\\n      componentType: state.azure.blobstorage\\n      version: v1\\n      metadata:\\n      - name: accountName\\n        value: testStorage\\n      - name: accountKey\\n        secretRef: account-key\\n      - name: containerName\\n        value: myContainer\\n      secrets:\\n      - name: account-key\\n        value: \\"<STORAGE_ACCOUNT_KEY>\\"\\n      scopes:\\n      - myApp\\n   ```\\n  \\n:::info STEP 2\\nDeploy the Dapr component using the below command with the appropriate arguments.\\n:::\\n  \\n ```bash \\n  az containerapp env dapr-component set \\\\\\n    --name \\"my-environment\\" \\\\\\n    --resource-group \\"my-resource-group\\" \\\\\\n    --dapr-component-name statestore \\\\\\n    --yaml \\"./statestore.yaml\\"\\n  ```\\n  \\n### Using Managed Identity with Dapr Components \\n\\nDapr-enabled container apps can now make use of managed identities within Dapr components. This is the most ideal path for connecting to Azure services securely, and allows for the removal of sensitive values in the component itself. \\n\\nThe Dapr sidecar makes use of the existing identities available within a given container app; Dapr itself does not have it\'s own identity. Therefore, the steps to enable Dapr + MI are similar to those in the section regarding managed identity for non-Dapr apps. See example steps below specifically for using a system-assigned identity: \\n\\n 1. Create a system-assigned identity for your container app \\n 2. Retrieve the identity details for your container app and store the Principal ID for the identity in a variable **\\"PRINCIPAL_ID\\"**\\n 3. Assign the appropriate roles and permissions (for accessing resources backing your Dapr components) to your ACA\'s managed identity using the Principal ID\\n 4. Create a simplified Dapr component without any secrets required \\n \\n  ```yaml\\n      componentType: state.azure.blobstorage\\n      version: v1\\n      metadata:\\n      - name: accountName\\n        value: testStorage\\n      - name: containerName\\n        value: myContainer\\n      scopes:\\n      - myApp\\n   ```\\n 5. Deploy the component to test the connection from your container app via Dapr! \\n  \\nKeep in mind, all Dapr components will be loaded by each Dapr-enabled container app in an environment by default. In order to avoid apps without the appropriate permissions from loading a component unsuccessfully, use scopes. This will ensure that only applications with the appropriate identities to access the backing resource load the component. \\n  \\n### Using Dapr Secret Stores for runtime secrets and component references  \\n\\nDapr integrates with secret stores to provide apps and other components with secure storage and access to secrets such as access keys and passwords. The Dapr Secrets API is now available for use in Container Apps. \\n\\nUsing Dapr\u2019s secret store building block typically involves the following:\\n  - Setting up a component for a specific secret store solution.\\n  - Retrieving secrets using the Dapr secrets API in the application code.\\n  - Optionally, referencing secrets in Dapr component files.\\n  \\n![](./img/secrets-overview-cloud-stores.png)\\n  \\nLet\'s walk through a couple sample workflows involving the use of Dapr\'s Secrets Management capabilities! \\n \\n####  Setting up a component for a specific secret store solution\\n\\n1. Create an Azure Key Vault instance for hosting the secrets required by your application.\\n  \\n  ```bash\\n  az keyvault create --name \\"<your-unique-keyvault-name>\\" --resource-group \\"my-resource-group\\" --location \\"<your-location>\\"\\n  ```\\n  \\n2. Create an Azure Key Vault component in your environment without the secrets values, as the connection will be established to Azure Key Vault via Managed Identity.\\n  \\n  ```yaml \\n      componentType: secretstores.azure.keyvault\\n      version: v1\\n      metadata:\\n      - name: vaultName\\n        value: \\"[your_keyvault_name]\\"\\n      scopes:\\n      - myApp \\n  ```\\n  \\n  ```bash \\n  az containerapp env dapr-component set \\\\\\n    --name \\"my-environment\\" \\\\\\n    --resource-group \\"my-resource-group\\" \\\\\\n    --dapr-component-name secretstore \\\\\\n    --yaml \\"./secretstore.yaml\\"\\n  ```\\n  \\n3. Run the following command to create a system-assigned identity for your container app \\n  \\n  ```bash\\n  az containerapp identity assign \\\\\\n    --name \\"myApp\\" \\\\\\n    --resource-group \\"my-resource-group\\" \\\\\\n    --system-assigned\\n  ```\\n  \\n4. Retrieve the identity details for your container app and store the Principal ID for the identity in a variable **\\"PRINCIPAL_ID\\"**\\n\\n  ```bash\\n  az containerapp identity show \\\\\\n    --name \\"myApp\\" \\\\\\n    --resource-group \\"my-resource-group\\"\\n  ```\\n  \\n5. Assign the appropriate roles and permissions to your container app\'s managed identity to access Azure Key Vault\\n  \\n  ```bash\\n  az role assignment create \\\\\\n  --role \\"Key Vault Secrets Officer\\" \\\\\\n  --assignee $PRINCIPAL_ID \\\\\\n  --scope /subscriptions/{subscriptionid}/resourcegroups/{resource-group-name}/providers/Microsoft.KeyVault/vaults/{key-vault-name}\\n ```\\n \\n6. Begin using the Dapr Secrets API in your application code to retrieve secrets! See additional details [here](https://docs.dapr.io/reference/api/secrets_api/).\\n  \\n#### Referencing secrets in Dapr component files\\n  \\nOnce a Dapr secret store component is available in the environment, it can be used to retrieve secrets for use in other components. For example, when creating a state store component, you can add a reference to the Dapr secret store from which you would like to source connection information. You will no longer use secrets directly in the component spec, but rather will instruct the Dapr sidecar to retrieve the secrets from the specified store. \\n  \\n  ```yaml\\n        componentType: state.azure.blobstorage\\n        version: v1\\n        metadata:\\n        - name: accountName\\n          value: testStorage\\n        - name: accountKey\\n          secretRef: account-key\\n        - name: containerName\\n          value: myContainer\\n        secretStoreComponent: \\"<SECRET_STORE_COMPONENT_NAME>\\"\\n        scopes:\\n          - myApp\\n  ```\\n  \\n## Summary \\n  \\nIn this post, we have covered the high-level details on how to work with secret values in Azure Container Apps for both Dapr and Non-Dapr apps. In the next article, we will walk through a complex Dapr example from end-to-end which makes use of the new support for Dapr + Managed Identity. Stayed tuned for additional documentation around Dapr secrets as it will be release in the next two weeks! \\n\\n## Resources\\n\\nHere are the main resources to explore for self-study:\\n * [Azure Container Apps Secrets](https://learn.microsoft.com/azure/container-apps/manage-secrets?tabs=azure-cli)\\n * [Managed Identities in Azure Container Apps](https://learn.microsoft.com/azure/container-apps/managed-identity?tabs=portal%2Cdotnet)\\n * [Dapr Documentation: Core Concepts](https://v1-9.docs.dapr.io/concepts/)\\n * [Dapr Quickstarts](https://docs.dapr.io/getting-started/quickstarts/)\\n * [Dapr Tutorials](https://docs.dapr.io/getting-started/tutorials/)\\n * [Azure Container Apps: Dapr Integration](https://learn.microsoft.com/azure/container-apps/dapr-overview)\\n * [Dapr-enabled Azure Container Apps: Using Azure CLI](https://learn.microsoft.com/azure/container-apps/microservices-dapr)\\n * [Dapr-enabled Azure Container Apps: Using Bicep or ARM](https://learn.microsoft.com/azure/container-apps/microservices-dapr-azure-resource-manager)"},{"id":"12-build-with-dapr","metadata":{"permalink":"/Cloud-Native/blog/12-build-with-dapr","source":"@site/blog/2022-09-12/index.md","title":"12. Build With Dapr!","description":"Today we\'ll shift gears and talk about Dapr - the Distributed Application Runtime - and how it makes microservices development with ACA _easier_","date":"2022-09-12T00:00:00.000Z","formattedDate":"September 12, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":7.395,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"}],"frontMatter":{"slug":"12-build-with-dapr","title":"12. Build With Dapr!","authors":["nitya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Today we\'ll shift gears and talk about Dapr - the Distributed Application Runtime - and how it makes microservices development with ACA _easier_","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"13. Secrets + Managed Identity","permalink":"/Cloud-Native/blog/13-aca-managed-id"},"nextItem":{"title":"\ud83d\ude80 | Use Custom Handlers For Go","permalink":"/Cloud-Native/blog/zero2hero-func-03"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/12-build-with-dapr\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Dapr Integration with ACA\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Dapr Integration with ACA\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"http://azure.github.io/Cloud-Native/assets/images/banner-cc3cfe656444b6f21e4bc8d2c541bc3e.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/12-build-with-dapr\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 12` of #30DaysOfServerless!\\n\\nSo far we\'ve looked at Azure Container Apps - what it is, how it enables microservices communication, and how it enables auto-scaling with KEDA compliant scalers. Today we\'ll shift gears and talk about Dapr - the Distributed Application Runtime - and how it makes microservices development with ACA _easier_ with core building blocks and a sidecar architecture!\\n\\nReady? Let\'s go!\\n\\n---\\n\\n## What We\'ll Cover\\n * What is Dapr and why use it?\\n * Building Block APIs\\n * Dapr Quickstart and Tutorials\\n * Dapr-enabled ACA: A Sidecar Approach\\n * Exercise: Build & Deploy a Dapr-enabled ACA.\\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n\\n## Hello, Dapr! \\n\\nBuilding distributed applications is hard. Building **reliable and portable microservces** means having middleware that deals with challenges like service discovery, sync and async communications, state management, secure information sharing and more. Integrating these support services into your application can be challenging from both development and maintenance perspectives, adding complexity that is independent of the core application logic you want to focus on.\\n\\nThis is where [**Dapr (Distributed Application Runtime)**](https://dapr.io) shines - [it\'s defined as:](https://docs.dapr.io/):\\n>  a portable, event-driven runtime that makes it easy for any developer to build resilient, stateless and stateful applications that run on the cloud and edge and embraces the diversity of languages and developer frameworks. \\n\\nBut what does this actually mean to me as an app developer? \\n\\n---\\n\\n## Dapr + Apps: A Sidecar Approach\\n\\nThe strength of Dapr lies in its ability to:\\n\\n * abstract complexities of distributed systems middleware - with  **Building Block APIs** that implement components using best practices to tackle key challenges.\\n * implement a **Sidecar Pattern** with interactions via APIs - allowing applications to keep their codebase clean and focus on app logic.\\n * be **Incrementally Adoptable** - allowing developers to start by integrating one API, then evolving to use more as and when needed.\\n * be **Platform Agnostic** - allowing applications to be developed in a preferred language or framework without impacting integration capabilities.\\n\\nThe application-dapr sidecar interaction is illustrated below. The API abstraction allows applications to get the desired functionality without having to know _how_ it was implemented, or without having to integrate Dapr-specific code into their codebase. Note how the sidecar process listens on port `3500` and the API provides clear routes for the specific building blocks supported by Dapr (e.g, `/secrets`, `/state` etc.)\\n\\n![](https://docs.dapr.io/images/overview-sidecar-model.png)\\n\\n---\\n\\n## Dapr Building Blocks: API Interactions\\n\\nDapr Building Blocks refers to **HTTP and gRPC endpoints exposed by Dapr** API endpoints exposed by the Dapr sidecar, providing key capabilities like state management, observability, service-to-service invocation, pub/sub messaging and more to the associated application. \\n\\n| | **Building Blocks: Under the Hood**|\\n|:--|:--|\\n|![](https://docs.dapr.io/images/concepts-building-blocks.png) | The Dapr API is implemented by [modular components](https://docs.dapr.io/concepts/building-blocks-concept/) that codify best practices for tackling the specific challenge that they represent. The API abstraction allows component implementations to evolve, or alternatives to be used , without requiring changes to the application codebase. |\\n\\n![](https://docs.dapr.io/images/building_blocks.png)\\n\\nThe [latest Dapr release](https://docs.dapr.io/concepts/building-blocks-concept/) has the building blocks shown in the above figure. Not all capabilities are available to Azure Container Apps by default -  check the [documentation](https://learn.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml#unsupported-dapr-capabilities) for the latest updates on this. For now, Azure Container Apps + Dapr integration provides the following capabilities to the application:\\n \\n * [Service-to-Service Invocation](https://docs.dapr.io/developing-applications/building-blocks/service-invocation/service-invocation-overview/) for synchronous communications\\n * [State management](https://docs.dapr.io/developing-applications/building-blocks/state-management/state-management-overview/) for transactions and CRUD operations\\n * [Pub/Sub messaging](https://docs.dapr.io/developing-applications/building-blocks/pubsub/pubsub-overview) for asynchronous (message-driven) communications\\n * [Bindings](https://docs.dapr.io/developing-applications/building-blocks/bindings/bindings-overview/) for seamless workflow integrations using event triggers\\n * [Actors](https://docs.dapr.io/developing-applications/building-blocks/actors/actors-overview/) for encapsulated & reusable objects that enable reliable, scalable behaviors\\n * [Observability](https://learn.microsoft.com/azure/container-apps/observability) to monitor application events for health and performance\\n * [Secrets](https://docs.dapr.io/developing-applications/building-blocks/secrets/) for securely accessing sensitive values.\\n\\nIn the next section, we\'ll dive into Dapr-enabled Azure Container Apps. Before we do that, here are a couple of resources to help you explore the Dapr platform by itself, and get more hands-on experience with the concepts and capabilities:\\n * [Dapr Quickstarts](https://docs.dapr.io/getting-started/quickstarts/) - build your first Dapr app, then explore quickstarts for a core APIs including service-to-service invocation, pub/sub, state mangement, bindings and secrets management.\\n * [Dapr Tutorials](https://docs.dapr.io/getting-started/tutorials/) - go beyond the basic quickstart and explore more realistic service integrations and usage scenarios. Try the [distributed calculator](https://github.com/dapr/quickstarts/tree/master/tutorials/distributed-calculator) example!\\n\\n\\n## Integrate Dapr & Azure Container Apps\\n\\nDapr currently has a [v1.9 (preview)](https://v1-9.docs.dapr.io/) version, but Azure Container Apps supports [Dapr v1.8](https://learn.microsoft.com/azure/container-apps/dapr-overview#current-supported-dapr-version). In this section, we\'ll look at what it takes to enable, configure, and use, Dapr integration with Azure Container Apps. It involves 3 steps: _enabling_ Dapr using settings, _configuring_ Dapr components (API) for use, then invoking the APIs.\\n\\nHere\'s a simple [a publisher-subscriber scenario](https://learn.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml#dapr-settings) from the documentation. We have two Container apps identified as `publisher-app` and `subscriber-app` deployed in a single environment. Each ACA has an activated `daprd` sidecar, allowing them to use the _Pub/Sub_ API to communicate asynchronously with each other - without having to write the underlying pub/sub implementation themselves. Rather, we can see that the Dapr API uses a `pubsub,azure.servicebus` **component** to implement that capability.\\n\\n![Pub/sub example](https://learn.microsoft.com/azure/container-apps/media/dapr-overview/dapr-in-aca.png)\\n\\nLet\'s look at how this is setup.\\n\\n### 1. [Enable Dapr in ACA: Settings](https://learn.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml#enable-dapr) \\n\\nWe can enable Dapr integration in the Azure Container App during creation by _specifying settings_ in one of two ways, based on your development preference:\\n * **Using Azure CLI**: use custom commandline options for each setting\\n * **Using Infrastructure-as-Code (IaC)**: using properties for Bicep, ARM templates\\n\\nOnce enabled, Dapr will run in the same _environment_ as the Azure Container App, and listen on **port 3500** for API requests. The Dapr sidecar can be shared my multiple Container Apps _deployed in the same environment_. \\n\\nThere are four main settings we will focus on for this demo - the example below shows the ARM template properties, but you can [find the equivalent CLI parameters here](https://learn.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml#enable-dapr) for comparison.\\n * `dapr.enabled` - enable Dapr for Azure Container App\\n * `dapr.appPort` - specify port on which app is listening\\n * `dapr.appProtocol` - specify if using `http` (default) or `gRPC` for API\\n * `dapr.appId` - specify unique application ID for service discovery, usage\\n\\nThese are defined under the `properties.configuration` section for your resource. Changing Dapr settings does not update the revision but it _will_ restart ACA revisions and replicas. Here is what the relevant section of the ARM template looks like for the `publisher-app` ACA in the scenario shown above.\\n\\n ```json\\n \\"dapr\\": {\\n    \\"enabled\\": true,\\n    \\"appId\\": \\"publisher-app\\",\\n    \\"appProcotol\\": \\"http\\",\\n    \\"appPort\\": 80\\n  }\\n ```\\n\\n### 2. [Configure Dapr in ACA:  Components](https://learn.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml#configure-dapr-components)\\n\\nThe next step after activating the Dapr sidecar, is to define the _APIs_ that you want to use and potentially specify the **Dapr components** (specific implementations of that API) that you prefer. These components are created at environment-level and by default, Dapr-enabled containers apps in an environment will load the complete set of deployed components -- **use the `scopes` property** to ensure only components needed by a given app are loaded at runtime. Here\'s what the ARM template `resources` section looks like for the example above. This tells us that the environment has a `dapr-pubsub` component of type `pubsub.azure.servicebus` deployed - where that component is loaded by container apps with dapr ids (`publisher-app`, `subscriber-app`).\\n\\n:::info  USING MANAGED IDENTITY + DAPR\\n\\nThe secrets approach used here is idea for demo purposes. However, we recommend using _Managed Identity with Dapr_ in production. For more details on secrets, check out tomorrow\'s post on _Secrets and Managed Identity in Azure Container Apps_\\n:::\\n  \\n```json\\n{\\n  \\"resources\\": [\\n    {\\n      \\"type\\": \\"daprComponents\\",\\n      \\"name\\": \\"dapr-pubsub\\",\\n      \\"properties\\": {\\n        \\"componentType\\": \\"pubsub.azure.servicebus\\",\\n        \\"version\\": \\"v1\\",\\n        \\"secrets\\": [\\n          {\\n            \\"name\\": \\"sb-root-connectionstring\\",\\n            \\"value\\": \\"value\\"\\n          }\\n        ],\\n        \\"metadata\\": [\\n          {\\n            \\"name\\": \\"connectionString\\",\\n            \\"secretRef\\": \\"sb-root-connectionstring\\"\\n          }\\n        ],\\n        // Application scopes\\n        \\"scopes\\": [\\"publisher-app\\", \\"subscriber-app\\"]\\n\\n      }\\n    }\\n  ]\\n}\\n```\\n\\nWith this configuration, the ACA is now set to use pub/sub capabilities from the Dapr sidecar, using standard HTTP requests to the exposed API endpoint for this service.\\n\\n## Exercise: Deploy Dapr-enabled ACA\\n\\nIn the next couple posts in this series, we\'ll be discussing how you can use the Dapr secrets API and doing a walkthrough of a more complex example, to show how Dapr-enabled Azure Container Apps are created and deployed. \\n\\nHowever, you can get hands-on experience with these concepts by walking through one of these two tutorials, each providing an alternative approach to configure and setup the application describe in the scenario below:\\n * **Tutorial 1**: [Deploy a Dapr-enabled ACA using **Azure CLI**](https://learn.microsoft.com/azure/container-apps/microservices-dapr)\\n * **Tutorial 2**: [Deploy a Dapr-enabled ACA using **Bicep or ARM templates**](https://learn.microsoft.com/azure/container-apps/microservices-dapr)\\n\\n![](https://learn.microsoft.com/azure/container-apps/media/microservices-dapr/azure-container-apps-microservices-dapr.png)\\n\\n\\n## Resources\\n\\nHere are the main resources to explore for self-study:\\n * [Dapr Documentation: Core Concepts](https://v1-9.docs.dapr.io/concepts/)\\n * [Dapr Quickstarts](https://docs.dapr.io/getting-started/quickstarts/)\\n * [Dapr Tutorials](https://docs.dapr.io/getting-started/tutorials/)\\n * [Azure Container Apps: Dapr Integration](https://learn.microsoft.com/azure/container-apps/dapr-overview)\\n * [Dapr-enable Azure Container Apps: Using Azure CLI](https://learn.microsoft.com/azure/container-apps/microservices-dapr)\\n * [Dapr-enabled Azure Container Apps: Using Bicep or ARM](https://learn.microsoft.com/azure/container-apps/microservices-dapr-azure-resource-manager)"},{"id":"zero2hero-func-03","metadata":{"permalink":"/Cloud-Native/blog/zero2hero-func-03","source":"@site/blog/zero-to-hero/2022-09-12-azurefunctions.md","title":"\ud83d\ude80 | Use Custom Handlers For Go","description":"Azure functions support multiple programming languages including C#, F#, Java, JavaScript, Python, typescript, and PowerShell. If you want to get extended language support with Azure functions for other languages such as Go, and Rust, that\u2019s where custom handler comes in.","date":"2022-09-12T00:00:00.000Z","formattedDate":"September 12, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"}],"readingTime":5.075,"hasTruncateMarker":false,"authors":[{"name":"Melony Qin","title":"Product Manager, Azure Functions @Microsoft","url":"https://github.com/cloudmelon","imageURL":"https://github.com/cloudmelon.png","key":"melony"}],"frontMatter":{"slug":"zero2hero-func-03","title":"\ud83d\ude80 | Use Custom Handlers For Go","authors":["melony"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/zero-to-hero-david.png","description":"Azure functions support multiple programming languages including C#, F#, Java, JavaScript, Python, typescript, and PowerShell. If you want to get extended language support with Azure functions for other languages such as Go, and Rust, that\u2019s where custom handler comes in.","tags":["serverless-september","zero-to-hero","azure-functions","azure-container-apps","dapr"]},"prevItem":{"title":"12. Build With Dapr!","permalink":"/Cloud-Native/blog/12-build-with-dapr"},"nextItem":{"title":"\ud83d\ude80 | Journey to the Cloud With ACA","permalink":"/Cloud-Native/blog/zero2hero-aca-04"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/zero2hero-func-03\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ZeroToHero: Serverless Go Apps Using Custom Handlers\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ZeroToHero: Serverless Go Apps Using Custom Handlers\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/serverless-zero2hero.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://techcommunity.microsoft.com/t5/apps-on-azure-blog/building-serverless-go-applications-with-azure-functions-custom/ba-p/3623617\\" />\\n</head>\\n\\n---\\n\\n\\nWelcome to `Day 12` of #30DaysOfServerless!\\n\\n\\nToday, we have a special set of posts from our [Zero To Hero \ud83d\ude80](/serverless-september/ZeroToHero) initiative, featuring blog posts authored by our Product Engineering teams for #ServerlessSeptember. _Posts were originally published on the [Apps on Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/building-serverless-go-applications-with-azure-functions-custom/ba-p/3623617?WT.mc_id=javascript-99907-cxa) blog on Microsoft Tech Community._\\n\\n---\\n\\n## What We\'ll Cover\\n * What are Custom Handlers, and why use them?\\n * How Custom Handler Works\\n * Message Processing With Azure Custom Handler\\n * Azure Portal Monitoring\\n\\n![](./img/zero-to-hero-melony.png)\\n\\n---\\n \\nIf you have been working with [Azure Functions](https://docs.microsoft.com/azure/azure-functions/?WT.mc_id=javascript-99907-cxa) for a while, you may know Azure Functions is a serverless FaaS (Function as a Service) offered provided by Microsoft Azure, which is built for your key scenarios, including building web APIs, processing file uploads, responding to database changes, processing IoT data streams, managing message queues, and more.\\n\\n\\n## Custom Handlers: What and Why\\n\\nAzure functions support multiple programming languages including C#, F#, Java, JavaScript, Python, typescript, and PowerShell. If you want to get **extended language support with Azure functions for other languages** such as Go, and Rust, that\u2019s where custom handler comes in.\\n\\nAn Azure function custom handler allows the use of any language that supports HTTP primitives and author Azure functions. With custom handlers, you can use triggers and input and output bindings via extension bundles,  hence it supports all the triggers and bindings you\'re used to with Azure functions.\\n\\n\\n## How a Custom Handler Works\\n\\nLet\u2019s take a look at custom handlers and how it works.  \\n * A request is sent to the function host when an event is triggered.  It\u2019s up to the function host to issue a request payload to the custom handler, which holds the trigger and inputs binding data as well as other metadata for the function. \\n  * The custom handler is a local HTTP web server. It executes the function code and returns a response payload to the Functions host. \\n  * The Functions host passes data from the response to the function\'s output bindings which will be passed to the downstream stream services for data processing. \\n  \\nCheck out [this article to know more about Azure functions custom handlers](https://docs.microsoft.com/azure/azure-functions/functions-custom-handlers?WT.mc_id=javascript-99907-cxa).\\n\\n---\\n\\n## Message processing with Custom Handlers\\n\\n[Message processing](https://docs.microsoft.com/azure/architecture/guide/technology-choices/messaging?WT.mc_id=javascript-99907-cxa) is one of the key scenarios that Azure functions are trying to address. In the message-processing scenario, events are often collected in queues. These events can trigger Azure functions to execute a piece of business logic. \\n\\nYou can use the Service Bus trigger to respond to messages from an [Azure Service Bus queue](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-messaging-overview?WT.mc_id=javascript-99907-cxa) - it\'s then up to the Azure functions custom handlers to take further actions to process the messages. The process is described in the following diagram:\\n\\n![Building Serverless Go Applications with Azure functions custom handlers](./img/melony-processing.png)\\n\\nIn Azure function, the `function.json` defines the function\'s trigger, input and output bindings, and other configuration settings. Note that every function can have multiple bindings, but it can only have one trigger. The following is an example of setting up the Service Bus queue trigger in the function.json file :\\n\\n```json\\n{\\n \\"bindings\\": [\\n   {\\n     \\"name\\": \\"queueItem\\",\\n     \\"type\\": \\"serviceBusTrigger\\",\\n     \\"direction\\": \\"in\\",\\n     \\"queueName\\": \\"functionqueue\\",\\n     \\"connection\\": \\"ServiceBusConnection\\"\\n    }\\n   ]\\n}\\n```\\n\\nYou can add a binding definition in the function.json to write the output to a database or other locations of your desire. [Supported bindings can be found here](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=csharp#add-bindings-to-a-function&WT.mc_id=javascript-99907-cxa).\\n\\nAs we\u2019re programming in Go, so we need to set the value of `defaultExecutablePath` to handler in the `customHandler.description` section in the `host.json` file.\\n\\nAssume we\u2019re programming in Windows OS, and we have named our go application as `server.go`,  after we executed `go build server.go` command,  it produces an executable called `server.exe`. So here we set `server.exe` in the `host.json` as the following example :\\n\\n```json\\n  \\"customHandler\\": {\\n    \\"description\\": {\\n      \\"defaultExecutablePath\\": \\"./server.exe\\",\\n      \\"workingDirectory\\": \\"\\",\\n      \\"arguments\\": []\\n    }\\n  }\\n```\\n\\nWe\u2019re showcasing a simple Go application here with Azure functions custom handlers where we print out the messages received from the function host. The following is the full code of `server.go` application :\\n\\n```go\\npackage main\\n\\nimport (\\n\\t\\"encoding/json\\"\\n\\t\\"fmt\\"\\n\\t\\"log\\"\\n\\t\\"net/http\\"\\n\\t\\"os\\"\\n)\\n\\ntype InvokeRequest struct {\\n\\tData     map[string]json.RawMessage\\n\\tMetadata map[string]interface{}\\n}\\n\\nfunc queueHandler(w http.ResponseWriter, r *http.Request) {\\n\\tvar invokeRequest InvokeRequest\\n\\n\\td := json.NewDecoder(r.Body)\\n\\td.Decode(&invokeRequest)\\n\\n\\tvar parsedMessage string\\n\\tjson.Unmarshal(invokeRequest.Data[\\"queueItem\\"], &parsedMessage)\\n\\n\\tfmt.Println(parsedMessage)\\n}\\n\\nfunc main() {\\n\\tcustomHandlerPort, exists := os.LookupEnv(\\"FUNCTIONS_CUSTOMHANDLER_PORT\\")\\n\\tif !exists {\\n\\t\\tcustomHandlerPort = \\"8080\\"\\n\\t}\\n\\tmux := http.NewServeMux()\\n\\tmux.HandleFunc(\\"/MessageProcessorFunction\\", queueHandler)\\n\\tfmt.Println(\\"Go server Listening on: \\", customHandlerPort)\\n\\tlog.Fatal(http.ListenAndServe(\\":\\"+customHandlerPort, mux))\\n\\n}\\n```\\n\\nEnsure you have [Azure functions core tools](https://github.com/Azure/azure-functions-core-tools) installed, then we can use func start command to start our function. Then we\u2019ll have have a [C#-based Message Sender application](https://github.com/cloudmelon/cloud-native-serverless/tree/main/message-sender-servicebus/MessageSendToServiceBus) on Github to send out 3000 messages to the Azure service bus queue. You\u2019ll see Azure functions instantly start to process the messages and print out the message as the following:\\n\\n![Monitoring Serverless Go Applications with Azure functions custom handlers](./img/melony-logging.png)\\n\\n---\\n\\n## Azure portal monitoring\\n\\nLet\u2019s go back to Azure portal portal the events see how those messages in Azure Service Bus queue were being processed. There was 3000 messages were queued in the Service Bus queue ( the Blue line stands for incoming Messages ). The outgoing messages (the red line in smaller wave shape ) showing there are progressively being read by Azure functions as the following :\\n\\n![Monitoring Serverless Go Applications with Azure functions custom handlers](./img/melony-monitoring.png)\\n\\nCheck out [this article about monitoring Azure Service bus](https://docs.microsoft.com/azure/service-bus-messaging/monitor-service-bus?WT.mc_id=javascript-99907-cxa) for further information.\\n\\n## Next steps\\n\\nThanks for following along, we\u2019re looking forward to hearing your feedback.  Also, if you discover potential issues, please record them on [Azure Functions host](https://github.com/Azure/azure-functions-host/issues)  GitHub repository or tag us [@AzureFunctions on Twitter](https://twitter.com/AzureFunctions). \\n\\n\\n:::info RESOURCES \\nStart to build your serverless applications with custom handlers, check out the official documentation:\\n\\n * [Getting started with Azure functions custom handlers](https://docs.microsoft.com/azure/azure-functions/functions-custom-handlers?WT.mc_id=javascript-99907-cxa) \\n * [Create a Go or Rust function in Azure using Visual Studio Code](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-other?tabs=go%2Cwindows&WT.mc_id=javascript-99907-cxa)\\n:::\\n\\nLife is a journey of learning.  Let\u2019s stay tuned!"},{"id":"zero2hero-aca-04","metadata":{"permalink":"/Cloud-Native/blog/zero2hero-aca-04","source":"@site/blog/zero-to-hero/2022-09-12-containerapps.md","title":"\ud83d\ude80 | Journey to the Cloud With ACA","description":"In this article, we discuss how Azure Container Apps is purpose-built to support Cloud-Native applications.","date":"2022-09-12T00:00:00.000Z","formattedDate":"September 12, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"}],"readingTime":4.89,"hasTruncateMarker":false,"authors":[{"name":"Anthony Chu","title":"Principal Product Manager @Microsoft","url":"https://github.com/anthonychu","imageURL":"https://github.com/anthonychu.png","key":"anthony"}],"frontMatter":{"slug":"zero2hero-aca-04","title":"\ud83d\ude80 | Journey to the Cloud With ACA","authors":["anthony"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","containerapps","serverless","concepts"],"image":"./img/banner.png","description":"In this article, we discuss how Azure Container Apps is purpose-built to support Cloud-Native applications.","tags":["serverless-september","zero-to-hero","azure-functions","azure-container-apps","dapr"]},"prevItem":{"title":"\ud83d\ude80 | Use Custom Handlers For Go","permalink":"/Cloud-Native/blog/zero2hero-func-03"},"nextItem":{"title":"11. Scaling Container Apps","permalink":"/Cloud-Native/blog/11-scaling-container-apps"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/zero2hero-aca-01\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ZeroToHero: Go Cloud-Native With Azure Container Apps\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ZeroToHero: Go Cloud-Native With Azure Container Apps\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/serverless-zero2hero.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://techcommunity.microsoft.com/t5/apps-on-azure-blog/go-cloud-native-with-azure-container-apps/ba-p/3616407\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 12` of #30DaysOfServerless!\\n\\nToday, we have a special set of posts from our [Zero To Hero \ud83d\ude80](/serverless-september/ZeroToHero) initiative, featuring blog posts authored by our Product Engineering teams for #ServerlessSeptember. _Posts were originally published on the [Apps on Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/journey-to-the-cloud-with-azure-container-apps/ba-p/3622609?WT.mc_id=javascript-99907-cxa) blog on Microsoft Tech Community._\\n\\n---\\n\\n## What We\'ll Cover\\n * Using Visual Studio\\n * Using Visual Studio Code: Docker, ACA extensions\\n * Using Azure CLI\\n * Using CI/CD Pipelines\\n\\n![](./img/zero-to-hero-anthony.png)\\n\\n---\\n\\nLast week, [@kendallroden](https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/296868?WT.mc_id=javascript-99907-cxa) wrote about [what it means to be Cloud-Native](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/go-cloud-native-with-azure-container-apps/ba-p/3616407) and how Azure Container Apps provides a serverless containers platform for hosting all of your Cloud-Native applications. Today, we\u2019ll walk through a few ways to get your apps up and running on Azure Container Apps.\\n\\nDepending on where you are in your Cloud-Native app development journey, you might choose to use different tools to deploy your apps.\\n\\n * **\u201cRight-click, publish\u201d** \u2013 Deploying an app directly from an IDE or code editor is often seen as a bad practice, but it\u2019s one of the quickest ways to test out an app in a cloud environment.\\n * **Command line interface** \u2013 CLIs are useful for deploying apps from a terminal. Commands can be run manually or in a script.\\n * **Continuous integration/deployment** \u2013 To deploy production apps, the recommended approach is to automate the process in a robust CI/CD pipeline.\\n \\nLet\'s explore some of these options in more depth.\\n\\n## Visual Studio\\n \\nVisual Studio 2022 has built-in support for deploying .NET applications to Azure Container Apps. You can use the familiar publish dialog to provision Container Apps resources and deploy to them directly. This helps you prototype an app and see it run in Azure Container Apps with the least amount of effort.\\n\\n![Journey to the cloud with Azure Container Apps](./img/anthony-create-new.png)\\n\\nOnce you\u2019re happy with the app and it\u2019s ready for production, Visual Studio allows you to push your code to GitHub and set up a GitHub Actions workflow to build and deploy your app every time you push changes. You can do this by checking a box.\\n\\n![Journey to the cloud with Azure Container Apps](./img/anthony-deployment-type.png)\\n \\n\\n## Visual Studio Code\\n \\nThere are a couple of valuable extensions that you\u2019ll want to install if you\u2019re working in VS Code.\\n\\n\\n### Docker extension\\n \\nThe Docker extension provides commands for building a container image for your app and pushing it to a container registry. It can even do this without requiring Docker Desktop on your local machine --- the \u201cBuild image in Azure\u201d command remotely builds and pushes a container image to Azure Container Registry.\\n\\n![Journey to the cloud with Azure Container Apps](./img/anthony-vscode-docker.png)\\n\\nAnd if your app doesn\u2019t have a dockerfile, the extension will generate one for you.\\n\\n![Journey to the cloud with Azure Container Apps](./img/anthony-vscode-dockerfile.png)\\n\\n### Azure Container Apps extension\\n\\nOnce you\u2019ve built your container image and pushed it to a registry, the Azure Container Apps VS Code extension provides commands for creating a container app and deploying revisions using the image you\u2019ve built.\\n\\n![Journey to the cloud with Azure Container Apps](./img/anthony-aca-extension.png)\\n\\n\\n## Azure CLI\\n \\n\\nThe Azure CLI can be used to manage pretty much anything in Azure. For Azure Container Apps, you\u2019ll find commands for creating, updating, and managing your Container Apps resources.\\n\\nJust like in VS Code, with a few commands in the Azure CLI, you can create your Azure resources, build and push your container image, and then deploy it to a container app.\\n\\nTo make things as simple as possible, the Azure CLI also has an \u201caz containerapp up\u201d command. This single command takes care of everything that\u2019s needed to turn your source code from your local machine to a cloud-hosted application in Azure Container Apps.\\n\\n```bash\\naz containerapp up --name myapp --source ./src\\n```\\n \\nWe saw earlier that Visual Studio can generate a GitHub Actions workflow to automatically build and deploy your app on every commit. \u201caz containerapp up\u201d can do this too. The following adds a workflow to a repo.\\n\\n```bash\\naz containerapp up --name myapp --repo https://github.com/myorg/myproject\\n```\\n\\n## CI/CD pipelines\\n\\nWhen it\u2019s time to take your app to production, it\u2019s strongly recommended to set up a CI/CD pipeline to automatically and repeatably build, test, and deploy it. We\u2019ve already seen that tools such as Visual Studio and Azure CLI can automatically generate a workflow for GitHub Actions. You can set up a pipeline in Azure DevOps too. This is an example Azure DevOps pipeline.\\n\\n \\n```yml\\ntrigger:\\n  branches:\\n    include:\\n    - main\\n\\npool:\\n  vmImage: ubuntu-latest\\n\\nstages:\\n\\n- stage: Build\\n\\n  jobs:\\n  - job: build\\n    displayName: Build app\\n\\n    steps:\\n    - task: Docker@2\\n      inputs:\\n        containerRegistry: \'myregistry\'\\n        repository: \'hello-aca\'\\n        command: \'buildAndPush\'\\n        Dockerfile: \'hello-container-apps/Dockerfile\'\\n        tags: \'$(Build.BuildId)\'\\n\\n- stage: Deploy\\n\\n  jobs:\\n  - job: deploy\\n    displayName: Deploy app\\n\\n    steps:\\n    - task: AzureCLI@2\\n      inputs:\\n        azureSubscription: \'my-subscription(5361b9d6-46ea-43c3-a898-15f14afb0db6)\'\\n        scriptType: \'bash\'\\n        scriptLocation: \'inlineScript\'\\n        inlineScript: |\\n          # automatically install Container Apps CLI extension\\n          az config set extension.use_dynamic_install=yes_without_prompt\\n\\n          # ensure registry is configured in container app\\n          az containerapp registry set \\\\\\n            --name hello-aca \\\\\\n            --resource-group mygroup \\\\\\n            --server myregistry.azurecr.io \\\\\\n            --identity system\\n\\n          # update container app\\n          az containerapp update \\\\\\n            --name hello-aca \\\\\\n            --resource-group mygroup \\\\\\n            --image myregistry.azurecr.io/hello-aca:$(Build.BuildId)\\n```\\n\\nConclusion\\n \\n\\nIn this article, we looked at a few ways to deploy your Cloud-Native applications to Azure Container Apps and how to decide which one to use based on where you are in your app\u2019s journey to the cloud.\\n\\nTo learn more, visit [Azure Container Apps | Microsoft Azure](https://azure.microsoft.com/services/container-apps/?WT.mc_id=javascript-99907-cxa) today!\\n\\n:::info ASK THE EXPERT: LIVE Q&A\\nThe Azure Container Apps team will answer questions live on **September 29**. \\n * [Sign up to attend](https://reactor.microsoft.com/reactor/events/17004/?WT.mc_id=javascript-99907-ninarasi) for live Q&A with the team\\n * [submit your questions](https://github.com/Azure/Cloud-Native/issues/new?assignees=&labels=ask+the+expert&template=---ask-the-expert-.md&title=%5BAsk+The+Expert%5D++) ahead of time, for prioritization.\\n:::"},{"id":"11-scaling-container-apps","metadata":{"permalink":"/Cloud-Native/blog/11-scaling-container-apps","source":"@site/blog/2022-09-11/index.md","title":"11. Scaling Container Apps","description":"<FIXME>","date":"2022-09-11T00:00:00.000Z","formattedDate":"September 11, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"keda","permalink":"/Cloud-Native/blog/tags/keda"},{"label":"autoscaling","permalink":"/Cloud-Native/blog/tags/autoscaling"}],"readingTime":6.27,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"11-scaling-container-apps","title":"11. Scaling Container Apps","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","container-apps","keda","serverless","concepts","scaling"],"image":"./img/banner.png","description":"<FIXME>","tags":["serverless-september","30-days-of-serverless","azure-container-apps","keda","autoscaling"]},"prevItem":{"title":"\ud83d\ude80 | Journey to the Cloud With ACA","permalink":"/Cloud-Native/blog/zero2hero-aca-04"},"nextItem":{"title":"10. Microservices Communication","permalink":"/Cloud-Native/blog/microservices-10"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/11-scaling-container-apps\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Scaling Your Container Apps\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Scaling Your Container Apps\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"http://azure.github.io/Cloud-Native/assets/images/banner-3e6ce6ac4f59bb1c536972dced457df3.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/11-scaling-container-apps\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 11` of #30DaysOfServerless!\\n\\nYesterday we explored Azure Container Concepts related to environments, networking and microservices communication - and illustrated these with a deployment example. Today, we turn our attention to _scaling_ your container apps with demand.\\n\\n---\\n\\n## What We\'ll Cover\\n * What makes ACA Serverless?\\n * What is Keda?\\n * Scaling Your ACA\\n * ACA Scaling In Action\\n * Exercise: Explore [azure-opensource-labs](https://aka.ms/oss-labs) examples\\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n\\n## So, what makes Azure Container Apps \\"serverless\\"?\\n\\nToday we are going to focus on what makes Azure Container Apps (ACA) a \\"serverless\\" offering. But what does the term \\"*serverless*\\" really mean? As much as we\'d like to think there aren\'t any servers involved, that is certainly not the case. In general, \\"serverless\\" means that most (if not all) server maintenance has been abstracted away from you.\\n\\nWith serverless, you don\'t spend any time managing and patching servers. This concern is offloaded to Azure and you simply focus on adding business value through application delivery. In addition to operational efficiency, cost efficiency can be achieved with serverless on-demand pricing models. Your workload horizontally scales out based on need and you only pay for what you use. To me, this is **serverless**, and my teammate [@StevenMurawski](https://github.com/smurawski) said it best... \\"*being able to **scale to zero **is what gives ACA it\'s serverless magic*.\\"\\n\\n## Scaling your Container Apps\\n\\nIf you don\'t know by now, ACA is built on a solid open-source foundation. Behind the scenes, it runs on a managed Kubernetes cluster and includes several open-source components out-of-the box including [Dapr](https://dapr.io/) to help you build and run microservices, [Envoy Proxy](https://www.envoyproxy.io/) for ingress capabilities, and [KEDA](https://keda.sh/) for event-driven autoscaling. Again, you do not need to install these components yourself. All you need to be concerned with is enabling and/or configuring your container app to leverage these components.\\n\\nLet\'s take a closer look at autoscaling in ACA to help you optimize your container app.\\n\\n### What is KEDA?\\n\\nKEDA stands for **K**ubernetes **E**vent-**D**riven **A**utoscaler. It is an open-source project initially started by Microsoft and Red Hat and has been donated to the [Cloud-Native Computing Foundation (CNCF)](https://www.cncf.io/). It is being maintained by a [community of 200+ contributors and adopted by many large organizations](https://keda.sh/community/). In terms of its status as a CNCF project it is currently in the [**Incubating Stage**](https://github.com/cncf/toc/blob/main/process/graduation_criteria.md#incubating-stage) which means the project has gone through significant due diligence and on its way towards the [**Graduation Stage**](https://github.com/cncf/toc/blob/main/process/graduation_criteria.md#graduation-stage).\\n\\nPrior to KEDA, horizontally scaling your Kubernetes deployment was achieved through the [Horizontal Pod Autoscaler (HPA)](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) which relies on resource metrics such as CPU and memory to determine when additional replicas should be deployed. Being limited to CPU and memory falls a bit short for certain workloads. This is especially true for apps that need to processes messages from a queue or HTTP-based apps that can handle a specific amount of incoming HTTP requests at a time. KEDA aims to fill that gap and provides a much more robust framework for scaling by working in conjunction with HPA. It offers many [scalers](https://keda.sh/docs/scalers/) for you to implement and even allows your deployments to **scale to zero**! \ud83e\udd73\\n\\n![KEDA architecture](./img/keda-arch.png)\\n\\n### Configuring ACA scale rules\\n\\nAs I mentioned above, ACA\'s autoscaling feature leverages KEDA and gives you the ability to configure the number of replicas to deploy based on rules (event triggers). The number of replicas can be configured as a static number or a range (minimum and maximum). So if you need your containers to run 24/7, set the min and max to be the same value. By default, when you deploy a container app, it is set to scale from 0 to 10 replicas. The default scaling rule uses **HTTP scaling** and defaults to a [minimum of 10 concurrent requests](https://docs.microsoft.com/azure/container-apps/scale-app#http) per second. Once the threshold of 10 concurrent request per second is met, another replica will be deployed until it reaches the maximum number of replicas.\\n\\n> At the time of this writing, a container app can have up to 30 replicas.\\n\\n![Default autoscaler](./img/default-autoscaler.png)\\n\\nAs a best practice, if you have a **Min / max replicas** range configured, you should configure a scaling rule even if it is just explicitly setting the default values.\\n\\n![Adding HTTP scaling rule](./img/http-rule.png)\\n\\nIn addition to **HTTP scaling**, you can also configure an **Azure queue** rule, which allows you to use [Azure Storage Queues](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction) as an event data source.\\n\\n![Adding Azure Queue scaling rule](./img/queue-rule.png)\\n\\nThe most flexibility comes with the **Custom** rule type. This opens up a LOT more options for scaling. All of [KEDA\'s event-based scalers](https://keda.sh/docs/scalers/) are supported with this option \ud83d\ude80\\n\\n![Adding Custom scaling rule](./img/custom-rule.png)\\n\\n### Translating KEDA templates to Azure templates\\n\\nWhen you implement **Custom** rules, you need to become familiar with translating KEDA templates to [Azure Resource Manager templates](https://docs.microsoft.com/azure/container-apps/azure-resource-manager-api-spec?tabs=arm-template) or [ACA YAML manifests](https://docs.microsoft.com/azure/container-apps/azure-resource-manager-api-spec?tabs=yaml). The [KEDA scaler](https://keda.sh/docs/scalers/) documentation is great and it should be simple to translate KEDA template `metadata` to an ACA rule `metadata`.\\n\\nThe images below shows how to translated a scaling rule which uses Azure Service Bus as an event data source. The custom rule type is set to `azure-servicebus` and details of the service bus is added to the Metadata section. One important thing to note here is that the connection string to the service bus was added as a secret on the container app and the trigger parameter must be set to `connection`.\\n\\n![Azure Container App custom rule metadata](./img/keda-metadata.png)\\n\\n![Azure Container App custom rule metadata](./img/aca-metadata.png)\\n\\nAdditional examples of KEDA scaler conversion can be found in the resources section and example video below.\\n\\n## See Container App scaling in action\\n\\nNow that we\'ve built up some foundational knowledge on how ACA autoscaling is implemented and configured, let\'s look at a few examples.\\n\\n### Autoscaling based on HTTP traffic load\\n\\n<div style={{ padding:\'56.25% 0 0 0\', position:\'relative\' }}><iframe src=\\"https://player.vimeo.com/video/746678347?h=8f5ada4431&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479\\" frameborder=\\"0\\" allow=\\"autoplay; fullscreen; picture-in-picture\\" allowfullscreen style={{ position:\'absolute\', top:0, left:0, width:\'100%\', height:\'100%\' }} title=\\"http-scaling\\"></iframe></div><script src=\\"https://player.vimeo.com/api/player.js\\"><\/script>\\n\\n### Autoscaling based on Azure Service Bus message queues\\n\\n<div style={{ padding:\'56.25% 0 0 0\', position:\'relative\' }}><iframe src=\\"https://player.vimeo.com/video/746678266?h=89701121ed&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479\\" frameborder=\\"0\\" allow=\\"autoplay; fullscreen; picture-in-picture\\" allowfullscreen style={{ position:\'absolute\' ,top:0, left:0, width:\'100%\', height:\'100%\' }} title=\\"event-driven-scaling.mp4\\"></iframe></div><script src=\\"https://player.vimeo.com/api/player.js\\"><\/script>\\n\\n## Summary\\n\\nACA brings you a true serverless experience and gives you the ability to configure autoscaling rules based on KEDA scaler templates. This gives you flexibility to scale based on a wide variety of data sources in an event-driven manner. With the amount built-in scalers currently available, there is probably a scaler out there for all your use cases. If not, I encourage you to get involved with the [KEDA community](https://keda.sh/community/) and help make it better!\\n\\n## Exercise\\n\\nBy now, you\'ve probably read and seen enough and now ready to give this autoscaling thing a try. The example I walked through in the videos above can be found at the [azure-opensource-labs](https://aka.ms/oss-labs) repo. I highly encourage you to head over to the [containerapps-terraform](https://github.com/Azure-Samples/azure-opensource-labs/tree/main/cloud-native/containerapps-terraform) folder and try the lab out. There you\'ll find instructions which will cover all the steps and tools you\'ll need implement autoscaling container apps within your own Azure subscription.\\n\\nIf you have any questions or feedback, please let us know in the comments below or reach out on Twitter [@pauldotyu](https://twitter.com/pauldotyu)\\n\\nHave fun scaling your containers!\\n\\n## Resources\\n\\n* [Set scaling rules in Azure Container Apps](https://docs.microsoft.com/azure/container-apps/scale-app)\\n* [Kubernetes Event-driven Autoscaling (KEDA)](https://keda.sh/)\\n* [KEDA Scalers](https://keda.sh/docs/scalers/)\\n* [KEDA scalers conversion](https://docs.microsoft.com/azure/container-apps/scale-app#keda-scalers-conversion)"},{"id":"microservices-10","metadata":{"permalink":"/Cloud-Native/blog/microservices-10","source":"@site/blog/2022-09-10/index.md","title":"10. Microservices Communication","description":"Continuing our journey into Azure Container Apps with a look at microservices hosting, and how they communicate with each other in the context of Azure Container Apps!","date":"2022-09-10T00:00:00.000Z","formattedDate":"September 10, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"},{"label":"docker-compose","permalink":"/Cloud-Native/blog/tags/docker-compose"}],"readingTime":7.655,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"microservices-10","title":"10. Microservices Communication","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","serverless","containers","microservices"],"image":"./img/banner.png","description":"Continuing our journey into Azure Container Apps with a look at microservices hosting, and how they communicate with each other in the context of Azure Container Apps!","tags":["serverless-september","30-days-of-serverless","azure-container-apps","microservices","docker-compose"]},"prevItem":{"title":"11. Scaling Container Apps","permalink":"/Cloud-Native/blog/11-scaling-container-apps"},"nextItem":{"title":"09. Hello, Azure Container Apps","permalink":"/Cloud-Native/blog/09-aca-fundamentals"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/microservices-10\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Microservices Communications with Azure Container Apps\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Microservices Communications with Azure Container Apps\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/microservices-10\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 10` of #30DaysOfServerless!\\n\\nWe continue our exploraton into Azure Container Apps, with today\'s focus being _communication_ between microservices, and how to configure your Azure Container Apps environment in the context of a deployment example.\\n\\n---\\n\\n## What We\'ll Cover\\n\\n- ACA Environments & Virtual Networking\\n- Basic Microservices Communications\\n- Walkthrough: ACA Deployment Example\\n- Summary and Next Steps\\n- Exercise: Try this yourself!\\n- Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Introduction\\n\\nIn yesterday\'s post, we learned what the Azure Container Apps (ACA) service is and the problems it aims to solve. It is considered to be a Container-as-a-Service platform since much of the complex implementation details of running a Kubernetes cluster is managed for you.\\n\\nSome of the use cases for ACA include event-driven processing jobs and background tasks, but this article will focus on hosting microservices, and how they can communicate with each other within the ACA service. At the end of this article, you will have a solid understanding of how networking and communication is handled and will leave you with a few tutorials to try.\\n\\n## Environments and virtual networking in ACA\\n\\nBefore we jump into microservices communication, we should review how networking works within ACA. With ACA being a managed service, Azure will take care of most of your underlying infrastructure concerns. As you provision an ACA resource, Azure provisions an Environment to deploy Container Apps into. This environment is your isolation boundary.\\n\\n![Azure Container Apps Environment](https://docs.microsoft.com/azure/container-apps/media/environments/azure-container-apps-environments.png)\\n\\nBy default, Azure creates and manages a new Virtual Network (VNET) for you and the VNET is associated with the environment. As you deploy container apps, they are deployed into the same VNET and the environment is assigned a static public IP address which allows your apps to be accessible over the internet. This VNET is not visible or manageable.\\n\\nIf you need control of the networking flows within the VNET, you can pre-provision one and tell Azure to deploy an environment within it. This \\"bring-your-own\\" VNET model allows you to deploy an environment in either **External** or **Internal** modes. Deploying an environment in **External** mode gives you the flexibility of managing your own VNET, while still allowing your containers to be accessible from outside the environment; a static public IP address is assigned to the environment. When deploying in **Internal** mode, your containers are accessible within the environment and/or VNET but not accessible from the internet.\\n\\nBringing your own VNET will require some planning and you will need dedicate an empty subnet which will be used exclusively by the ACA environment. The size of your subnet will be dependant on how many containers you plan on deploying and your scaling requirements and one requirement to know is that the subnet address range must have have a `/23` CIDR prefix at minimum. You will also need to think about your deployment strategy since ACA has the concept of **Revisions** which will also consume IPs from your subnet.\\n\\nSome additional restrictions to consider when planning your subnet address space is listed in the Resources section below and can be addressed in future posts, so be sure to follow us on [dev.to](https://dev.to/azure) and bookmark the [ServerlessSeptember](https://aka.ms/serverless-september) site.\\n\\n## Basic microservices communication in ACA\\n\\nWhen it comes to communications between containers, ACA addresses this concern with its **Ingress** capabilities. With **HTTP Ingress** enabled on your container app, you can expose your app on a HTTPS endpoint.\\n\\nIf your environment is deployed using default networking and your containers needs to be accessible from outside the environment, you will need to set the **Ingress traffic** option to **Accepting traffic from anywhere**. This will generate a Full-Qualified Domain Name (FQDN) which you can use to access your app right away. The ingress feature also generates and assigns a Secure Socket Layer (SSL) certificate for the FQDN.\\n\\n![External ingress on Container App](./img/external-ingress.png)\\n\\nIf your environment is deployed using default networking and your containers only need to communicate with other containers in the environment, you\'ll need to set the **Ingress traffic** option to **Limited to Container Apps Environment**. You get a FQDN here as well, but in the section below we\'ll see how that changes.\\n\\n![Internal ingress on Container App](./img/internal-ingress.png)\\n\\nAs mentioned in the networking section above, if you deploy your ACA environment into a VNET in **internal** mode, your options will be **Limited to Container Apps Environment** or **Limited to VNet**.\\n\\n![Ingress on internal virtual network](./img/internal-vnet-ingress.png)\\n\\n> Note how the **Accepting traffic from anywhere** option is greyed out. If your VNET is deployed in **external** mode, then the option will be available.\\n\\n## Let\'s walk though an example ACA deployment\\n\\nThe diagram below illustrates a simple microservices application that I deployed to ACA. The three container apps all have ingress enabled. The `greeting-service` app calls two backend services; a `hello-service` that returns the text **Hello** (in random casing) and a `world-service` that returns the text **World** (in a few random languages). The greeting-service concatenates the two strings together and returns **Hello World** to the browser. The greeting-service is the only service accessible via external ingress while two backend services are only accessible via internal ingress.\\n\\n![Greeting Service overview](./img/greeting-service-overview.png)\\n\\nWith ingress enabled, let\'s take a quick look at the FQDN structures. Here is the FQDN of the **external** greeting-service.\\n\\n`https://greeting-service.victoriouswave-3749d046.eastus.azurecontainerapps.io`\\n\\nWe can break it down into these components:\\n\\n`https://`**[YOUR-CONTAINER-APP-NAME]**`.`**[RANDOM-NAME]**`-`**[RANDOM-CHARACTERS]**`.`**[AZURE-REGION]**`.containerapps.io`\\n\\nAnd here is the FQDN of the **internal** hello-service.\\n\\n`https://hello-service.internal.victoriouswave-3749d046.eastus.azurecontainerapps.io`\\n\\nCan you spot the difference between FQDNs?\\n\\nThat was too easy \ud83d\ude09... the word `internal` is added as a subdomain in the FQDN between your container app name and the random name for all internal ingress endpoints.\\n\\n`https://`**[YOUR-CONTAINER-APP-NAME]**`.internal.`**[RANDOM-NAME]**`-`**[RANDOM-CHARACTERS]**`.`**[AZURE-REGION]**`.containerapps.io`\\n\\nNow that we know the internal service FQDNs, we use them in the greeting-service app to achieve basic service-to-service communications.\\n\\nSo we can inject FQDNs of downstream APIs to upstream apps using environment variables, but the downside to this approach is that need to deploy downstream containers ahead of time and this dependency will need to be planned for during your deployment process. There are ways around this and one option is to leverage the auto-injected environment variables within your app code.\\n\\nIf I use the Console blade for the hello-service container app and run the `env` command, you will see environment variables named `CONTAINER_APP_NAME` and `CONTAINER_APP_ENV_DNS_SUFFIX`. You can use these values to determine FQDNs within your upstream app.\\n\\n![hello-service environment variables](./img/hello-service.png)\\n\\nBack in the `greeting-service` container I can invoke the hello-service container\'s `sayhello` method. I know the container app name is hello-service and this service is exposed over an internal ingress, therefore, if I add the `internal` subdomain to the `CONTAINER_APP_ENV_DNS_SUFFIX` I can invoke a HTTP request to the hello-service from my greeting-service container.\\n\\n![Invoke the sayHello method from the greeting-service container](./img/say-hello.png)\\n\\nAs you can see, the ingress feature enables communications to other container apps over HTTP/S and ACA will inject environment variables into our container to help determine what the ingress FQDNs would be. All we need now is a little bit of code modification in the greeting-service app and build the FQDNs of our backend APIs by retrieving these environment variables.\\n\\n![Greeting service code](./img/greeting-service-code.png)\\n\\n... and now we have a working microservices app on ACA! \ud83c\udf89\\n\\n![Hello World](./img/aca-microservice.png)\\n\\n## Summary and next steps\\n\\nWe\'ve covered Container Apps networking and the basics of how containers communicate with one another. However, there is a better way to address service-to-service invocation using Dapr, which is an open-source framework for building microservices. It is natively integrated into the ACA service and in a future post, you\'ll learn how to enable it in your Container App to address microservices concerns and more. So stay tuned!\\n\\n## Exercises\\n\\nAs a takeaway for today\'s post, I encourage you to complete this [tutorial](https://docs.microsoft.com/azure/container-apps/communicate-between-microservices?tabs=bash&pivots=acr-remote) and if you\'d like to deploy the sample app that was presented in this article, my teammate [@StevenMurawski](https://github.com/smurawski) is hosting a [docker-compose-examples](https://github.com/smurawski/docker-compose-examples) repo which includes samples for deploying to ACA using Docker Compose files. To learn more about the `az containerapp compose` command, a link to his blog articles are listed in the Resources section below.\\n\\nIf you have any questions or feedback, please let us know in the comments below or reach out on Twitter [@pauldotyu](https://twitter.com/pauldotyu)\\n\\nHave fun packing and shipping containers! See you in the next post!\\n\\n## Resources\\n\\n- [Tutorial: Communication between microservices in Azure Container Apps](https://docs.microsoft.com/azure/container-apps/communicate-between-microservices?tabs=bash&pivots=acr-remote)\\n- [Tutorial: greeting-service (docker-compose-example)](https://github.com/smurawski/docker-compose-examples/tree/main/nodejs_greet)\\n- [Concept: Azure Container App Environments](https://docs.microsoft.com/azure/container-apps/environment)\\n- [Concept: Azure Container App Ingress](https://docs.microsoft.com/azure/container-apps/networking#http-edge-proxy-behavior)\\n- [Concept: Azure Container App VNET Restrictions](https://docs.microsoft.com/azure/container-apps/networking#restrictions)\\n- [Blog: Accelerating Azure Container Apps with the Azure CLI and Compose Files](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/accelerating-azure-container-apps-with-the-azure-cli-and-compose/ba-p/3516636)\\n- [Blog: More Fun with Azure Container Apps and Compose Files](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/more-fun-with-azure-container-apps-and-compose-files/ba-p/3570234)\\n\\n> The sample app presented here was inspired by services demonstrated in the book [Introducing Distributed Application Runtime (Dapr): Simplifying Microservices Applications Development Through Proven and Reusable Patterns and Practices](https://www.amazon.com/Introducing-Distributed-Application-Runtime-Dapr/dp/1484269977). Go check it out to leran more about Dapr!\\n\\n\x3c!-- hidden links --\x3e\\n\\n[vnets]: https://docs.microsoft.com/azure/virtual-network/virtual-networks-overview\\n[nsg]: https://docs.microsoft.com/azure/virtual-network/network-security-groups-overview\\n[vnet-peering]: https://docs.microsoft.com/azure/virtual-network/virtual-network-peering-overview\\n[aca-external-vnet]: https://docs.microsoft.com/azure/container-apps/vnet-custom?tabs=bash&pivots=azure-cli\\n[aca-internal-vnet]: https://docs.microsoft.com/azure/container-apps/vnet-custom-internal?tabs=bash&pivots=azure-cli\\n[aca-console]: https://docs.microsoft.com/azure/container-apps/observability?tabs=bash#container-console"},{"id":"09-aca-fundamentals","metadata":{"permalink":"/Cloud-Native/blog/09-aca-fundamentals","source":"@site/blog/2022-09-09/index.md","title":"09. Hello, Azure Container Apps","description":"Kickstarting Week 2 of #30DaysOfServerless with an introduction to Azure Container Apps and core concepts relevant to building microservices-driven solutions","date":"2022-09-09T00:00:00.000Z","formattedDate":"September 9, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"},{"label":"microservices","permalink":"/Cloud-Native/blog/tags/microservices"}],"readingTime":11.67,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"}],"frontMatter":{"slug":"09-aca-fundamentals","title":"09. Hello, Azure Container Apps","authors":["nitya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Kickstarting Week 2 of #30DaysOfServerless with an introduction to Azure Container Apps and core concepts relevant to building microservices-driven solutions","tags":["serverless-september","30-days-of-serverless","azure-container-apps","dapr","microservices"]},"prevItem":{"title":"10. Microservices Communication","permalink":"/Cloud-Native/blog/microservices-10"},"nextItem":{"title":"08. Functions + Serverless On Azure","permalink":"/Cloud-Native/blog/08-functions-azure"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/09-aca-fundamentals\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Introduction to Container Apps Core Concepts\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Introduction to Container Apps Core Concepts\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/assets/images/banner-2b8cf81d448cbb7f947a85dd71631b84.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/09-aca-fundamentals\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 9` of #30DaysOfServerless!\\n\\n---\\n\\n## What We\'ll Cover\\n * The Week Ahead\\n * Hello, Container Apps!\\n * Quickstart: Build Your First ACA!\\n * Under The Hood: Core ACA Concepts\\n * Exercise: Try this yourself!\\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## The Week Ahead\\n\\nWelcome to Week 2 of #ServerlessSeptember, where we put the focus on **Microservices** and building Cloud-Native applications that are optimized for **serverless** solutions on Azure. One week is not enough to do this complex topic justice so consider this a 7-part jumpstart to the longer journey.\\n\\n 1. **Hello, Container Apps (ACA)** - Learn about Azure Container Apps, a key service that helps you _run microservices and containerized apps on a serverless platform_. Know the core concepts. (_Tutorial 1: First ACA_)\\n 2. **Communication with Microservices** - Dive deeper into two key concepts: _environments_ and _virtual networking_. Learn how microservices communicate in ACA, and walkthrough an example. _(Tutorial 2: ACA with 3 Microservices)_\\n 3. **Scaling Your Container Apps** - Learn about KEDA. Understand how to configure your ACA for auto-scaling with KEDA-supported triggers. Put this into action by walking through a tutorial. _(Tutorial 3: Configure Autoscaling_)\\n 4. **Hello, Distributed Application Runtime (Dapr)** - Learn about Dapr and how its _Building Block APIs_ simplify microservices development with ACA. Know how the _sidecar pattern_ enables incremental adoption of Dapr APIs without requiring any Dapr code integration in app. (_Tutorial 4: Setup & Explore Dapr_)\\n 5. **Building ACA with Dapr** - See how Dapr works with ACA by building a Dapr-enabled Azure Container App. Walk through a .NET tutorial using Pub/Sub and State Management APIs in an enterprise scenario. (_Tutorial 5: Build ACA with Dapr_)\\n 6. **Managing Secrets With Dapr** - We\'ll look at the Secrets API (a key Building Block of Dapr) and learn how it simplifies management of sensitive information in ACA.\\n 7. **Microservices + Serverless On Azure** - We recap Week 2 (_Microservices_) and set the stage for Week 3 ( _Integrations_) of Serverless September. Plus, self-study resources including ACA development tutorials in different languages.\\n\\nReady? Let\'s go!\\n\\n---\\n\\n## Azure Container Apps!\\n\\nWhen building your application, your first decision is about _where you host your application_. The [Azure Architecture Center has a handy chart](https://docs.microsoft.com/azure/architecture/guide/technology-choices/compute-decision-tree?WT.mc_id=javascript-99907-ninarasi) to help you decide between choices like Azure Functions, Azure App Service, Azure Container Instances, Azure Container Apps and more. But if you are new to this space, you\'ll need a good understanding of the terms and concepts behind the services Today, we\'ll focus on _Azure Container Apps_ (ACA) - so let\'s start with the fundamentals.\\n\\n\\n### Containerized App Defined\\n\\nA containerized app is one where the application components, dependencies, and configuration, are packaged into a single file (**container image**), which can be instantiated in an isolated runtime environment (**container**) that is portable across hosts (OS). This makes containers lightweight and scalable - and ensures that applications behave consistently on different host platforms.\\n\\nContainer images can be shared via  **container registries** (public or private) helping developers discover and deploy related apps with less effort. **Scaling** a containerized app can be as simple as activating more instances of its container image. However, this requires **container orchestrators** to automate the management of container apps for efficiency. Orchestrators use technologies like Kubernetes to support capabilities like _workload scheduling, self-healing and auto-scaling on demand_.\\n\\n### Cloud-Native & Microservices\\n\\nContainers are seen as one of the [5 pillars of Cloud-Native app development](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/go-cloud-native-with-azure-container-apps/ba-p/3616407?WT.mc_id=javascript-99907-cxa), an approach where applications are designed explicitly to take advantage of the unique benefits of modern dynamic environments (involving public, private and hybrid clouds). Containers are particularly suited to **serverless solutions based on microservices**.\\n\\n * _With serverless_ - developers use **managed services** instead of managing their own infrastructure. Services are typically event-driven and can be configured for autoscaling with rules tied to event triggers. Serverless is cost-effective, with developers paying only for the compute cycles and resources they use.\\n * _With microservices_ - developers **compose their applications from independent components**. Each component can be deployed in its own container, and scaled at that granularity. This simplifies component reuse (across apps) and maintainability (over time) - with developers evolving functionality at microservice (vs. app) levels.\\n\\n### Hello, Azure Container Apps!\\n\\nAzure Container Apps is the managed service that helps you run containerized apps and microservices as a serverless compute solution, on Azure. You can:\\n\\n * **deploy serverless API endpoints** - autoscaled by HTTP request traffic\\n * **host background processing apps** - autoscaled by CPU or memory load\\n * **handle event-driven processing** - autoscaled by #messages in queue\\n * **run microservices** - autoscaled by any KEDA-supported scaler.\\n\\nWant a quick intro to the topic? Start by watching the short video below - then read these two posts from our _ZeroToHero_ series:\\n * [Go Cloud-Native with Azure Container Apps](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/go-cloud-native-with-azure-container-apps/ba-p/3616407?WT.mc_id=javascript-99907-cxa) - also see [the illustrated guide](/assets/images/Go-Cloud-Native-f6ac3225c3d9741a1fbff81030f7f830.png)\\n * [Journey to the cloud with Azure Container Apps](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/journey-to-the-cloud-with-azure-container-apps/ba-p/3622609?WT.mc_id=javascript-99907-cxa) - for developer tooling options.\\n\\n<iframe width=\\"600\\" height=\\"400\\" src=\\"https://www.youtube.com/embed/b3dopSTnSRg\\" title=\\"How to Build and Deliver Apps Fast and Scalable with Azure Container Apps\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\" allowfullscreen></iframe>\\n\\n---\\n\\n## Deploy Your First ACA\\n\\n### Dev Options\\n\\nWe typically have **three options** for development:\\n * Use the [Azure Portal](https://docs.microsoft.com/azure/container-apps/get-started-existing-container-image-portal?pivots=container-apps-private-registry) - provision and deploy from a browser.\\n * Use [Visual Studio Code](https://docs.microsoft.com/azure/container-apps/deploy-visual-studio-code) (with relevant extensions) - if you prefer an IDE\\n * Using [Azure CLI](https://docs.microsoft.com/azure/container-apps/get-started-existing-container-image?tabs=bash&pivots=container-apps-private-registry) - if you prefer to build and deploy from command line.\\n\\nThe documentation site has quickstarts for three contexts:\\n * [using a sample container image](https://docs.microsoft.com/azure/container-apps/quickstart-portal) - pre-existing example on Azure for convenience\\n * [using a custom container image](https://docs.microsoft.com/azure/container-apps/get-started-existing-container-image-portal?pivots=container-apps-private-registry) - to understand container registry usage\\n * [using code on your local machine](https://docs.microsoft.com/azure/container-apps/quickstart-code-to-cloud?tabs=bash%2Ccsharp&pivots=acr-remote) - to start from source repo\\n\\nFor this quickstart, we\'ll go with the first option (sample image) so we can move quickly to core concepts. We\'ll leave the others as an exercise for you to explore.\\n\\n### 1. Setup Resources\\n\\n:::info PRE-REQUISITES\\nYou need:\\n * An Azure account with an active subscription\\n * An installed [Azure CLI](https://docs.microsoft.com/cli/azure/install-azure-cli)\\n:::\\n\\nStart by logging into Azure from the CLI. The command should launch a browser to complete the auth flow (or give you an option to take an alternative path).\\n\\n```bash\\n$ az login\\n```\\n\\nSuccessful authentication will result in extensive command-line output detailing the status of your subscription. \\n\\nNext, install the Azure Container Apps extension for the CLI\\n\\n```bash\\n$ az extension add --name containerapp --upgrade\\n...\\nThe installed extension \'containerapp\' is in preview.\\n```\\n\\nOnce successfully installed, register the `Microsoft.App` namespace.\\n\\n```bash\\n$ az provider register --namespace Microsoft.App\\n```\\n\\nThen set local _environment variables_ in that terminal - and verify they are set correctly:\\n\\n```bash\\n$ RESOURCE_GROUP=\\"my-container-apps\\"\\n$ LOCATION=\\"canadacentral\\"\\n$ CONTAINERAPPS_ENVIRONMENT=\\"my-environment\\"\\n\\n$ echo $LOCATION $RESOURCE_GROUP $CONTAINERAPPS_ENVIRONMENT\\ncanadacentral my-container-apps my-environment\\n```\\n\\nNow you can use Azure CLI to provision a _resource group_ for this tutorial. Creating a resource group also makes it easier for us to delete/reclaim all resources used at the end of this tutorial.\\n\\n```bash\\naz group create \\\\\\n  --name $RESOURCE_GROUP \\\\\\n  --location $LOCATION\\n```\\n\\n:::success Congratulations\\n\\nYou completed the Setup step!\\n\\nOn completion, the console should print out the details of the newly created resource group. You should also be able to visit the Azure Portal and find the newly-active `my-container-apps` resource group under your active subscription.\\n\\n:::\\n\\n### 2. Create Environment\\n\\nAn environment is like the picket fence around your property. It creates a _secure boundary_ that contains a group of container apps - such that all apps deployed to it share the same virtual network and logging resources.\\n\\n```bash\\n$ az containerapp env create \\\\\\n  --name $CONTAINERAPPS_ENVIRONMENT \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --location $LOCATION\\n\\nNo Log Analytics workspace provided.\\nGenerating a Log Analytics workspace with name ...\\n```\\nThis can take a few minutes. When done, you will see the terminal display more details. You can also check the resource group in the portal and see that a _Container Apps Environment_ and a _Log Analytics Workspace_ are created for you as part of this step.\\n\\nYou\'ve got the fence set up. Now it\'s time to build your home - er, container app!\\n\\n### 3. Create Container App\\n\\nHere\'s the command we\'ll use to create our first Azure Container App. Note that the `--image` argument provides the link to a pre-existing `containerapps-helloworld` image. \\n\\n```bash\\naz containerapp create \\\\\\n  --name my-container-app \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --environment $CONTAINERAPPS_ENVIRONMENT \\\\\\n  --image mcr.microsoft.com/azuredocs/containerapps-helloworld:latest \\\\\\n  --target-port 80 \\\\\\n  --ingress \'external\' \\\\\\n  --query properties.configuration.ingress.fqdn\\n...\\n...\\n\\nContainer app created. Access your app at <URL>\\n```\\n\\nThe `--ingress` property shows that the app is open to _external_ requests; in other words, it is publicly visible at the `<URL>` that is printed out on the terminal on successsful completion of this step.\\n\\n### 4. Verify Deployment\\n\\nLet\'s see if this works. You can verify that your container app by visitng the URL returned above in your browser. You should see something like this!\\n\\n![Container App Hello World](img/container-app.png)\\n\\nYou can also visit the Azure Portal and look under the created Resource Group. You should see a new `Container App` type of resource was created after this step.\\n\\n:::success Congratulations\\nYou just created and deployed your first \\"Hello World\\" Azure Container App! This validates your local development environment setup and existence of a valid Azure subscription.\\n:::\\n\\n### 5. Clean Up Your Resources\\n\\nIt\'s good practice to clean up resources once you are done with a tutorial. \\n\\n:::warning THIS ACTION IS IRREVERSIBLE\\n This command deletes the resource group we created above - and all resources in it. So make sure you specified the right name, then confirm deletion.\\n:::\\n\\n\\n```bash\\n$ az group delete --name $RESOURCE_GROUP\\nAre you sure you want to perform this operation? (y/n): \\n```\\n\\nNote that you can also delete the resource group from the Azure Portal interface if that feels more comfortable. For now, we\'ll just use the Portal to verify that deletion occurred. If you had previously opened the Resource Group page for the created resource, just refresh it. You should see something like this:\\n\\n![Resource Not Found](./img/resource-not-found.png)\\n\\n---\\n\\n## Core Concepts\\n\\n:::info COMING SOON\\nAn illustrated guide summarizing these concepts in a single sketchnote.\\n:::\\n\\nWe covered a lot today - we\'ll stop with a quick overview of core concepts behind Azure Container Apps, each linked to documentation for self-study. We\'ll dive into more details on _some_ of these concepts in upcoming articles:\\n\\n * [Environments](https://docs.microsoft.com/azure/container-apps/environment) - are the _secure boundary_ around a group of container apps that are deployed in the same virtual network. They write logs to a shared Log Analytics workspace and can communicate seamlessly using Dapr, if used.\\n * [Containers](https://docs.microsoft.com/azure/container-apps/containers) refer to the _container image_ deployed in the Azure Container App. They can use any runtime, programming language, or development stack - and be discovered using any public or private container registry. A container app can support multiple containers.\\n * [Revisions](https://docs.microsoft.com/azure/container-apps/revisions) are _immutable_ snapshots of an Azure Container App. The first revision is created when the ACA is first deployed, with new revisions created when redeployment occurs with [revision-scope changes](https://docs.microsoft.com/azure/container-apps/revisions#revision-scope-changes). Multiple revisions can run concurrently in an environment.\\n * [Application Lifecycle Management](https://docs.microsoft.com/azure/container-apps/application-lifecycle-management) revolves around these revisions, with a container app having three phases: _deployment_, _update_ and _deactivation_.\\n * [Microservices](https://docs.microsoft.com/azure/container-apps/microservices) are independent units of functionality in Cloud-Native architectures. _A single container app typically represents a single microservice_, and can be composed from one or more containers. Microservices can now be scaled and upgraded indepedently, giving your application more flexbility and control.\\n * [Networking](https://docs.microsoft.com/azure/container-apps/networking) architecture consist of a virtual network (VNET) associated with the environment. Unless you provide a custom VNET at environment creation time, a default VNET is automatically created. The VNET configuration determines access (ingress, internal vs. external) and can influence auto-scaling choices (e.g., use HTTP Edge Proxy and scale based on number of HTTP requests).\\n * [Observability](https://docs.microsoft.com/azure/container-apps/observability) is about monitoring the health of your application and diagnosing it to improve reliability or performance. Azure Container Apps has a number of features - from Log streaming and Container console to integration with Azure Monitor - to provide a holistic view of application status over time.\\n * [Easy Auth](https://docs.microsoft.com/azure/container-apps/authentication) is possible with built-in support for authentication and authorization including support for popular identity providers like Facebook, Google, Twitter and GitHub - alongside the Microsoft Identity Platform.\\n\\nKeep these terms in mind as we walk through more tutorials this week, to see how they find application in real examples. Finally, a note on Dapr, the [Distributed Application Runtime](http://dapr.io) that abstracts away many of the challenges posed by distributed systems - and lets you focus on your application logic.\\n\\n:::info DAPR INTEGRATION MADE EASY\\n \\n[Dapr](https://docs.microsoft.com/azure/container-apps/dapr-overview?tabs=bicep1%2Cyaml) uses a sidecar architecture, allowing Azure Container Apps to communicate with Dapr Building Block APIs over either gRPC or HTTP. Your ACA can be built to run with or without Dapr - giving you the flexibility to _incrementally adopt_ specific APIs and unlock related capabilities as the need arises.\\n:::\\n\\n![](https://docs.dapr.io/images/overview-sidecar-model.png)\\n\\nIn later articles this week, we\'ll do a deeper dive into Dapr and build our first Dapr-enable Azure Container App to get a better understanding of this integration.\\n\\n## Exercise\\n\\nCongratulations! You made it! By now you should have a good idea of what Cloud-Native development means, why Microservices and Containers are important to that vision - and how Azure Container Apps helps simplify the building and deployment of _microservices based applications_ using _serverless architectures_ on Azure.\\n\\nNow it\'s your turn to reinforce learning by doing.\\n * Try walking through this quickstart yourself, but [using the Azure Portal](https://docs.microsoft.com/azure/container-apps/quickstart-portal) option.\\n * Then try a [custom container image](https://docs.microsoft.com/azure/container-apps/deploy-visual-studio-code) option using Visual Studio Code, and validate your IDE-based setup for future tutorials.\\n\\n## Resources\\n\\nThree key resources to bookmark and explore:\\n * [Azure Container Apps](https://docs.microsoft.com/azure/container-apps/) - documentation\\n * [Distributed Application Runtime (Dapr)](https://docs.dapr.io/) - documentation\\n * [Azure Container Apps](https://docs.microsoft.com/azure/container-apps/samples) - samples for exploration"},{"id":"08-functions-azure","metadata":{"permalink":"/Cloud-Native/blog/08-functions-azure","source":"@site/blog/2022-09-08/index.md","title":"08. Functions + Serverless On Azure","description":"Introduction to Azure Functions, from core concepts to hello world!","date":"2022-09-08T00:00:00.000Z","formattedDate":"September 8, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"serverless-hacks","permalink":"/Cloud-Native/blog/tags/serverless-hacks"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/blog/tags/ask-the-expert"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"azure-event-grid","permalink":"/Cloud-Native/blog/tags/azure-event-grid"},{"label":"azure-logic-apps","permalink":"/Cloud-Native/blog/tags/azure-logic-apps"},{"label":"serverless-e2e","permalink":"/Cloud-Native/blog/tags/serverless-e-2-e"}],"readingTime":4.935,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"},{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://github.com/devanshidiaries.png","key":"devanshi"}],"frontMatter":{"slug":"08-functions-azure","title":"08. Functions + Serverless On Azure","authors":["nitya","devanshi"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Introduction to Azure Functions, from core concepts to hello world!","tags":["serverless-september","30-days-of-serverless","serverless-hacks","zero-to-hero","ask-the-expert","azure-functions","azure-container-apps","azure-event-grid","azure-logic-apps","serverless-e2e"]},"prevItem":{"title":"09. Hello, Azure Container Apps","permalink":"/Cloud-Native/blog/09-aca-fundamentals"},"nextItem":{"title":"07. Functions for Python Devs","permalink":"/Cloud-Native/blog/07-functions-python"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/functions-1\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/08-functions-azure\\" />\\n</head>\\n\\n---\\n:::warning SEP 08: CHANGE IN PUBLISHING SCHEDULE\\n\\nStarting from Week 2 (Sep 8), we\'ll be publishing blog posts in _batches_ rather than on a daily basis, so you can read a series of related posts together. _Don\'t want to miss updates?_ Just [subscribe to the feed](https://azure.github.io/Cloud-Native/blog/rss.xml)\\n:::\\n\\n---\\n\\nWelcome to `Day 8` of #30DaysOfServerless!\\n\\nThis marks the end of our [Week 1 Roadmap](https://azure.github.io/Cloud-Native/serverless-september/30DaysOfServerless/#azure-functions) focused on Azure Functions!! Today, we\'ll do a quick recap of all #ServerlessSeptember activities in Week 1, set the stage for Week 2 - and leave you with some excellent tutorials you should explore to build more advanced scenarios with Azure Functions.\\n\\nReady? Let\'s go.\\n\\n---\\n\\n\\n## What We\'ll Cover\\n * Azure Functions: Week 1 Recap\\n * Advanced Functions: Explore Samples\\n * End-to-End: Serverless Hacks & Cloud Skills\\n * What\'s Next: Hello, Containers & Microservices\\n * Challenge: [Complete the Learning Path](https://docs.microsoft.com/training/paths/create-serverless-applications/?WT.mc_id=javascript-99907-cxa)\\n\\n![](./img/banner.png)\\n\\n---\\n\\n\\n## Week 1 Recap: #30Days & Functions\\n\\nCongratulations!! We made it to the end of Week 1 of #ServerlessSeptember. Let\'s recap what we learned so far:\\n\\n * In [Core Concepts](/blog/02-functions-intro) we looked at where Azure Functions fits into the serverless options available on Azure. And we learned about key concepts like Triggers, Bindings, Custom Handlers and Durable Functions.\\n * In [Build Your First Function](/blog/03-functions-quickstart) we looked at the tooling options for creating Functions apps, testing them locally, and deploying them to Azure - as we built and deployed our first Functions app.\\n * In the next 4 posts, we explored new Triggers, Integrations, and Scenarios - as we looked at building Functions Apps in Java, JavaScript, .NET and Python.\\n * And in the Zero-To-Hero series, we learned about [Durable Entities](/blog/zero2hero-func-02) - and how we can use them to create _stateful_ serverless solutions using a [Chirper Sample](https://github.com/Azure/azure-functions-durable-extension/tree/dev/samples/entitites-csharp/Chirper) as an example scenario.\\n\\nThe illustrated roadmap below summarizes what we covered each day this week, as we bring our **Functions-as-a-Service** exploration to a close.\\n\\n![](./../../static/img/banners/roadmap-Week1.png)\\n\\n---\\n\\n## Advanced Functions: Code Samples\\n\\nSo, now that we\'ve got our first Functions app under our belt, and validated our local development setup for tooling, where can we go next? A good next step is to explore different triggers and bindings, that drive richer end-to-end scenarios. For example:\\n\\n * [**Integrate Functions with Azure Logic Apps**](https://docs.microsoft.com/azure/azure-functions/functions-twitter-email?WT.mc_id=javascript-99907-cxa) - we\'ll discuss Azure Logic Apps in Week 3. For now, think of it as a [workflow automation](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=javascript-99907-cxa) tool that lets you integrate seamlessly with other supported Azure services to drive an end-to-end scenario. In this tutorial, we set up a workflow connecting Twitter (get tweet) to Azure Cognitive Services (analyze sentiment) - and use that to trigger an Azure Functions app to send email about the result.\\n * [**Integrate Functions with Event Grid**](https://docs.microsoft.com/azure/event-grid/resize-images-on-storage-blob-upload-event?tabs=nodejsv10&WT.mc_id=javascript-99907-cxa) - we\'ll discuss Azure Event Grid in Week 3. For now, think of it as an eventing service connecting event sources (publishers) to event handlers (subscribers) at cloud scale. In this tutorial, we handle a common use case - a workflow where loading an image to Blob Storage triggers an Azure Functions app that implements a [resize function](https://github.com/Azure-Samples/storage-blob-resize-function-node), helping automatically generate thumbnails for the uploaded image.\\n * [**Integrate Functions with CosmosDB and SignalR**](https://docs.microsoft.com/training/modules/automatic-update-of-a-webapp-using-azure-functions-and-signalr/?WT.mc_id=javascript-99907-cxa) to bring real-time push-based notifications to your web app. It achieves this by using a Functions app that is triggered by changes in a CosmosDB backend, causing it to broadcast that update (_push notification_ to connected web clients over SignalR, in real time.\\n\\nWant more ideas? Check out the [Azure Samples for Functions](https://docs.microsoft.com/samples/browse/?products=azure-functions&WT.mc_id=javascript-99907-cxa) for implementations, and browse the [Azure Architecture Center](https://docs.microsoft.com/azure/architecture/browse/?expanded=azure&products=azure-functions&WT.mc_id=javascript-99907-cxa) for reference architectures from real-world scenarios that involve Azure Functions usage.\\n\\n---\\n\\n## E2E Scenarios: Hacks & Cloud Skills\\n\\n_Want to systematically work your way through a single End-to-End scenario involving Azure Functions alongside other serverless support technologies?_ Check out the [Serverless Hacks](/serverless-september/ServerlessHacks) activity happening during #ServerlessSeptember, and learn to build this **\\"Serverless Tollbooth Application\\"** in a series of 10 challenges. Check out the [video series for a reference solution in .NET](https://aka.ms/serverless-september/videos) and sign up for weekly office hours to join peers and discuss your solutions or challenges.\\n\\n![](./../../static/img/banners/wth-serverless.png)\\n\\n_Or perhaps you prefer to learn core concepts with code in a structured learning path?_ We have that covered. Check out the [12-module](https://docs.microsoft.com/training/paths/create-serverless-applications/?WT.mc_id=javascript-99907-cxa) **\\"Create Serverless Applications\\"** course from Microsoft Learn which walks your through concepts, one at a time, with code. Even better - [sign up for the free Cloud Skills Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi) and _complete the same path_ (in under 30 days) but this time, with the added fun of competing against your peers for a spot on a leaderboard, and swag.\\n\\n---\\n\\n## What\'s Next? Hello, Cloud-Native!\\n\\nSo where to next? In Week 2 we turn our attention from _Functions-as-a-Service_ to building more complex backends using _Containers and Microservices_. We\'ll focus on two core technologies - [Azure Container Apps](https://docs.microsoft.com/azure/container-apps/?WT.mc_id=javascript-99907-ninarasi) and [Dapr](https://docs.dapr.io/?WT.mc_id=javascript-99907-ninarasi) (Distributed Application Runtime) - both key components of a broader vision around **[Building Cloud-Native Applications in Azure](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-99907-ninarasi)**.\\n\\nWhat is Cloud-Native you ask? \\n\\nFortunately for you, we have an excellent introduction in our Zero-to-Hero article on [Go Cloud-Native with Azure Container Apps](/blog/zero2hero-aca-01) - that explains the **5 pillars of Cloud-Native** and highlights the value of Azure Container Apps (scenarios) and Dapr (sidecar architecture) for simplified microservices-based solution with auto-scale capability. Prefer a visual summary? Here\'s an illustrate guide to that article for convenience.\\n\\n![Go Cloud-Native](../../static/img/artwork/Go-Cloud-Native.png) [**Download a higher resolution version of the image**](../../static/img/artwork/Go-Cloud-Native-orig.png)\\n\\n---\\n\\n## [Take The Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi)\\n\\nWe typically end each post with an exercise or activity to reinforce what you learned. For Week 1, we encourage you to take the Cloud Skills Challenge and work your way through at least a subset of the modules, for hands-on experience with the different Azure Functions concepts, integrations, and usage.\\n\\n> See you in Week 2!"},{"id":"07-functions-python","metadata":{"permalink":"/Cloud-Native/blog/07-functions-python","source":"@site/blog/2022-09-07/index.md","title":"07. Functions for Python Devs","description":"Let\'s build a wildfire detection site and application using Azure Functions for Python, with Timer Trigger and CosmosDB bindings!","date":"2022-09-07T00:00:00.000Z","formattedDate":"September 7, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"python","permalink":"/Cloud-Native/blog/tags/python"}],"readingTime":6.865,"hasTruncateMarker":false,"authors":[{"name":"Jay Miller","title":"Senior Cloud Advocate @Microsoft","url":"https://github.com/kjaymiller","imageURL":"https://github.com/kjaymiller.png","key":"jay"}],"frontMatter":{"slug":"07-functions-python","title":"07. Functions for Python Devs","authors":["jay"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Let\'s build a wildfire detection site and application using Azure Functions for Python, with Timer Trigger and CosmosDB bindings!","tags":["serverless-september","30-days-of-serverless","azure-functions","python"]},"prevItem":{"title":"08. Functions + Serverless On Azure","permalink":"/Cloud-Native/blog/08-functions-azure"},"nextItem":{"title":"06. Functions for .NET Devs","permalink":"/Cloud-Native/blog/06-functions-dotnet"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog07-functions-python\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Functions For Python developers\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions For Python developers\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/07-functions-python\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 7` of #30DaysOfServerless!\\n\\nOver the past couple of days, we\'ve explored Azure Functions from the perspective of specific programming languages. Today we\'ll continue that trend by looking at Python - exploring the Timer Trigger and CosmosDB binding, and showcasing integration with a FastAPI-implemented web app.\\n\\nReady? Let\'s go.\\n\\n---\\n\\n## What We\'ll Cover\\n * **Developer Guidance**: Azure Functions On Python\\n * **Build & Deploy**: Wildfire Detection Apps with Timer Trigger + CosmosDB\\n * **Demo: My Fire Map App**: Using FastAPI and Azure Maps to visualize data\\n * **Next Steps**: Explore Azure Samples\\n * **Exercise**: Try this yourself!\\n * **Resources**: For self-study!\\n\\n![](./img/banner.png)\\n\\n\\n---\\n\\n## Developer Guidance\\nIf you\'re a Python developer new to serverless on Azure, start with the [Azure Functions Python Developer Guide](https://docs.microsoft.com/azure/azure-functions/functions-reference-python?tabs=asgi%2Capplication-level&WT.mc_id=javascript-99907-cxa). It covers:\\n\\n* Quickstarts with Visual Studio Code and Azure CLI\\n* Adopting best practices for hosting, reliability and efficiency.\\n* Tutorials showcasing Azure automation, image classification and more\\n* Samples showcasing Azure Functions features for Python developers\\n\\nNow let\'s dive in and build our first Python-based Azure Functions app.\\n\\n---\\n\\n## Detecting Wildfires Around the World?\\n\\nI live in California which is known for lots of wildfires. I wanted to create a proof of concept for developing an application that could let me know if there was a wildfire detected near my home. \\n\\nNASA has a few satelites orbiting the Earth that can detect wildfires. These satelites take scans of the radiative heat in and use that to determine the likelihood of a wildfire. NASA updates their information about every 30 minutes and it can take about four hours for to scan and process information. \\n\\n![Fire Point Near Austin, TX](img/Fire%20Point%20in%20Austin,%20TX.png)\\n\\nI want to get the information but I don\'t want to ping NASA or another service every time I check.\\n\\nWhat if I occaisionally download all the data I need? Then I can ping that as much as I like.\\n\\nI can create a script that does just that. Any time I say _I can create a script_ that is a verbal queue for me to consider using an Azure function. With the function being ran in the cloud, I can ensure the script runs even when I\'m not at my computer. \\n\\n### How the Timer Trigger Works\\n\\nThis function will utilize the Timer Trigger. This means Azure will call this function to run at a scheduled interval. This isn\'t the only way to keep the data in sync, but we know that arcgis, the service that we\'re using says that data is only updated every 30 minutes or so.\\n\\nTo learn more about the TimerTrigger as a concept, check out the [Azure Functions documentation around Timers](https://docs.microsoft.com/azure/azure-functions/functions-bindings-timer?tabs=in-process&pivots=programming-language-python&WT.mc_id=javascript-99907-cxa).\\n\\nWhen we create the function we tell it a few things like where the script will live (in our case in `__init__.py`) the type and direction and notably _often it should run_. We specify the timer using `schedule\\": <The CRON INTERVAL>`. For us we\'re using `0 0,30 * * *` which means every 30 minutes at the hour and half-hour.\\n\\n```json\\n{\\n  \\"scriptFile\\": \\"__init__.py\\",\\n  \\"bindings\\": [\\n    {\\n      \\"name\\": \\"reqTimer\\",\\n      \\"type\\": \\"timerTrigger\\",\\n      \\"direction\\": \\"in\\",\\n      \\"schedule\\": \\"0 0,30 * * * *\\"\\n    }\\n  ]\\n}\\n```\\n\\nNext, we create the code that runs when the function is called.\\n\\n### Connecting to the Database and our Source\\n\\n> Disclaimer: The data that we\'re pulling is for educational purposes only. This is not meant to be a production level application. You\'re welcome play with this project but ensure that you\'re using the data [in compliance with Esri](https://www.esri.com/legal/overview).\\n\\n\\nOur function does two important things. \\n\\n1. It pulls data from ArcGIS that meets the parameters\\n2. It stores that pulled data into our database\\n\\nIf you want to check out the code in its entirety, check out the [GitHub repository](https://github.com/kjaymiller/fire-map).\\n\\nPulling the data from ArcGIS is easy. We can use the [ArcGIS Python API](https://developers.arcgis.com/python/). Then, we need to load the service layer. Finally we query that layer for the specific data.\\n\\n```python\\ndef write_new_file_data(gis_id:str, layer:int=0) -> FeatureSet:\\n    \\"\\"\\"Returns a JSON String of the Dataframe\\"\\"\\"\\n    fire_data = g.content.get(gis_id) \\n    feature = fire_data.layers[layer] # Loading Featured Layer from ArcGIS\\n    q = feature.query(\\n        where=\\"confidence >= 65 AND hours_old  <= 4\\", #The filter for the query\\n        return_distince_values=True,\\n        out_fields=\\"confidence, hours_old\\", # The data we want to store with our points\\n        out_sr=4326, # The spatial reference of the data\\n    )\\n    return q   \\n```\\n\\nThen we need to store the data in our database.\\n\\nWe\'re using [Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/introduction?WT.mc_id=javascript-99907-cxa) for this. COSMOSDB is a NoSQL database, which means that the data looks a lot like a python dictionary as it\'s JSON. This means that we don\'t need to worry about converting the data into a format that can be stored in a relational database.\\n\\nThe second reason is that Cosmos DB is tied into the Azure ecosystem so that if we want to create functions Azure events around it, we can.\\n\\nOur script grabs the information that we pulled from ArcGIS and stores it in our database. \\n\\n```python\\nasync with CosmosClient.from_connection_string(COSMOS_CONNECTION_STRING) as client:\\n    container = database.get_container_client(container=CONTAINER)\\n    for record in data:\\n        await container.create_item(\\n            record,\\n            enable_automatic_id_generation=True,\\n        )\\n```\\n\\nIn our code each of these functions live in their own space. So in the main function we focus solely on what azure functions will be doing. The script that gets called is `__init__.py`. There we\'ll have the function call the other functions running.\\n\\nWe created another function called `load_and_write` that does all the work outlined above. `__init__.py` will call that.\\n\\n```python\\nasync def main(reqTimer: func.TimerRequest) -> None:\\n    database=database\\n    container=container\\n    await update_db.load_and_write(gis_id=GIS_LAYER_ID, database=database, container=container)\\n```\\n\\nThen we deploy the function to Azure. I like to use VS Code\'s Azure Extension but you can also deploy it [a few other ways](https://docs.microsoft.com/azure/azure-functions/functions-deployment-technologies?WT.mc_id=javascript-99907-cxa).\\n\\n![Deploying the function via VS Code](img/Deploy%20to%20Function%20App%20using%20VS%20Code.png)\\n\\nOnce the function is deployed we can load the Azure portal and see a ping whenever the function is called.\\n![The pings correspond to the Function being ran](img/Function%20Execution%20Count.png)\\n\\nWe can also see the data now living in the datastore.\\n![Document in Cosmos DB](img/Data%20Explorer.png)\\n\\n### It\'s in the Database, Now What?\\nNow the real fun begins. We just loaded the last bit of fire data into a database. We can now query that data and serve it to others. \\n\\nAs I mentioned before, our Cosmos DB data is also stored in Azure, which means that we can deploy Azure Functions [to trigger when new data is added](https://docs.microsoft.com/azure/azure-functions/functions-bindings-cosmosdb-v2?tabs=in-process%2Cfunctionsv2&pivots=programming-language-python&WT.mc_id=javascript-99907-cxa). Perhaps you can use this to check for fires near you and use a [Logic App](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=javascript-99907-cxa) to send an alert to your phone or email.\\n\\nAnother option is to create a web application that talks to the database and displays the data. I\'ve created an example of this using FastAPI \u2013 <https://jm-func-us-fire-notify.azurewebsites.net>.\\n\\n![Website that Checks for Fires](img/Check%20for%20Fires.gif)\\n\\n---\\n\\n## Next Steps\\n\\nThis article showcased the Timer Trigger and the HTTP Trigger for Azure Functions in Python. Now try exploring other triggers and bindings by browsing [Bindings code samples for Python](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=python#bindings-code-examples&WT.mc_id=javascript-99907-cxa) and [Azure Functions samples for Python](https://docs.microsoft.com/samples/browse/?products=azure-functions&WT.mc_id=javascript-99907-cxa&languages=python&WT.mc_id=javascript-99907-cxa)\\n\\nOnce you\'ve tried out the samples, you may want to explore more advanced integrations or extensions for serverless Python scenarios. Here are some suggestions:\\n * [Develop Python worker extensions for Azure Functions](https://docs.microsoft.com/azure/azure-functions/develop-python-worker-extensions?tabs=windows%2Cpypi&WT.mc_id=javascript-99907-cxa) and publish to PyPI or GitHub.\\n * [Connect Azure Functions to Azure Storage](https://docs.microsoft.com/azure/azure-functions/functions-add-output-binding-storage-queue-cli?pivots=programming-language-python&tabs=in-process%2Cbash%2Cbrowser&WT.mc_id=javascript-99907-cxa) using the CLI\\n * [Create Real-Time alerts with Azure Functions and SignalR Service](https://docs.microsoft.com/azure/azure-signalr/signalr-quickstart-azure-functions-python?toc=%2Fazure%2Fazure-functions%2Ftoc.json&WT.mc_id=javascript-99907-cxa)\\n\\nAnd check out the resources for more tutorials to build up your Azure Functions skills.\\n\\n\\n## Exercise\\n\\nI encourage you to fork [the repository](https://github.com/kjaymiller/fire-map) and try building and deploying it yourself! You can see the TimerTrigger and a HTTPTrigger building the website. \\n\\nThen try extending it. Perhaps if wildfires are a big thing in your area, you can use some of the data available in [Planetary Computer](https://planetarycomputer.microsoft.com?WT.mc_id=javascript-99907-cxa) to check out some other datasets.\\n\\n\\n## Resources\\n\\n * [Azure For Functions Python Developer Guide](https://docs.microsoft.com/azure/azure-functions/functions-reference-python?tabs=asgi%2Capplication-level&WT.mc_id=javascript-99907-cxa)\\n * [Python Quickstart: Create Your First Function App](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-python?WT.mc_id=javascript-99907-cxa)\\n * [Use FastAPI Framework With Azure Functions](https://docs.microsoft.com/samples/azure-samples/fastapi-on-azure-functions/azure-functions-python-create-fastapi-app/?WT.mc_id=javascript-99907-cxa)\\n * [Use Flask Framework with Azure Functions](https://docs.microsoft.com/samples/azure-samples/flask-app-on-azure-functions/azure-functions-python-create-flask-app/?WT.mc_id=javascript-99907-cxa)\\n * [Tutorial: Apply ML models in Azure Functions with Python and TensorFlow](https://docs.microsoft.com/azure/azure-functions/functions-machine-learning-tensorflow?tabs=bash&WT.mc_id=javascript-99907-cxa)"},{"id":"06-functions-dotnet","metadata":{"permalink":"/Cloud-Native/blog/06-functions-dotnet","source":"@site/blog/2022-09-06/index.md","title":"06. Functions for .NET Devs","description":"#30DaysOfServerless: Azure Functions for the .NET Developer","date":"2022-09-06T00:00:00.000Z","formattedDate":"September 6, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"dotnet","permalink":"/Cloud-Native/blog/tags/dotnet"}],"readingTime":9.5,"hasTruncateMarker":false,"authors":[{"name":"Mike James","title":"Cloud Advocate @Microsoft","url":"https://github.com/MikeCodesDotNet","imageURL":"https://github.com/MikeCodesDotNet.png","key":"mike"},{"name":"Matt Soucoup","title":"Principal Cloud Advocate @Microsoft","url":"https://github.com/codemillmatt","imageURL":"https://github.com/codemillmatt.png","key":"matt"}],"frontMatter":{"slug":"06-functions-dotnet","title":"06. Functions for .NET Devs","authors":["mike","matt"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"#30DaysOfServerless: Azure Functions for the .NET Developer","tags":["serverless-september","30-days-of-serverless","azure-functions","dotnet"]},"prevItem":{"title":"07. Functions for Python Devs","permalink":"/Cloud-Native/blog/07-functions-python"},"nextItem":{"title":"\ud83d\ude80 | Durable Entities Walkthrough","permalink":"/Cloud-Native/blog/zero2hero-func-02"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/functions-1\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/06-functions-dotnet\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 6` of #30DaysOfServerless!\\n\\nThe theme for this week is Azure Functions. Today we\'re going to talk about why Azure Functions are a great fit for .NET developers.\\n\\n---\\n\\n## What We\'ll Cover\\n\\n* What is serverless computing? \\n* How does Azure Functions fit in?\\n* Let\'s build a simple Azure Function in .NET\\n* Developer Guide, Samples & Scenarios\\n* Exercise: Explore the [Create Serverless Applications](https://docs.microsoft.com/training/paths/create-serverless-applications/?WT.mc_id=javascript-99907-cxa) path.\\n* Resources: For self-study!\\n\\n![A banner image that has the title of this article with the author\'s photo and a drawing that summarizes the demo application.](./img/banner.png)\\n\\n---\\n\\nThe leaves are changing colors and there\'s a chill in the air, or for those lucky folks in the Southern Hemisphere, the leaves are budding and a warmth is in the air. Either way, that can only mean one thing - it\'s **Serverless September!\ud83c\udf42** So today, we\'re going to take a look at Azure Functions - what they are, and _why they\'re a great fit for .NET developers_.\\n\\n\\n## What is serverless computing?\\n\\nFor developers, serverless computing means you write highly compact individual functions that do one thing - and run in the cloud. These functions [are triggered by some external event](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=csharp&WT.mc_id=javascript-99907-cxa). That event could be a record being inserted into a database, a file uploaded into BLOB storage, a timer interval elapsed, or even a simple HTTP request.\\n\\nBut... servers are still definitely involved! What has changed from other types of cloud computing is that the idea and **ownership of the server** has been abstracted away.\\n\\nA lot of the time you\'ll hear folks refer to this as [Functions as a Service or FaaS](/blog/02-functions-intro). The defining characteristic is all you need to do is put together your application logic. Your code is going to be invoked in response to events - and the cloud provider takes care of everything else. You literally get to focus on only the business logic you need to run in response to something of interest - **no worries about hosting**.\\n\\nYou do not need to worry about wiring up the plumbing between the service that originates the event and the serverless runtime environment. The cloud provider will handle the mechanism to call your function in response to whatever event you chose to have the function react to. And it passes along any data that is relevant to the event to your code.\\n\\nAnd here\'s a really neat thing. **You only pay for the time the serverless function is running.** So, if you have a function that is triggered by an HTTP request, and you rarely get requests to your function, you would rarely pay.\\n\\n### How does Azure Functions fit in?\\n\\nMicrosoft\'s [Azure Functions](https://docs.microsoft.com/azure/azure-functions/?WT.mc_id=javascript-99907-cxa) is a modern serverless architecture, offering event-driven cloud computing that is easy for developers to use. It provides a way to run small pieces of code or Functions in the cloud without developers having to worry themselves about the infrastructure or platform the Function is running on.\\n\\nThat means we\'re only concerned about writing the logic of the Function. And we can write that logic in our choice of languages... like C#. We are also able to add packages from NuGet to Azure Functions\u2014this way, we don\'t have to reinvent the wheel and can use well-tested libraries.\\n\\nAnd the Azure Functions runtime takes care of a ton of neat stuff for us, like passing in information about the event that caused it to kick off - in a strongly typed variable. It also [\\"binds\\"](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?WT.mc_id=javascript-99907-cxa) to other services, like Azure Storage, we can easily access those services from our code without having to worry about new\'ing them up.\\n\\n## Let\'s build an Azure Function!\\n\\n### Scaffold the Function\\n\\nDon\'t worry about having an Azure subscription or even being connected to the internet\u2014we can develop and debug Azure Functions locally using either [Visual Studio](https://docs.microsoft.com/azure/azure-functions/functions-develop-vs?tabs=in-process&WT.mc_id=javascript-99907-cxa) or [Visual Studio Code](https://docs.microsoft.com/azure/azure-functions/functions-develop-vs-code?tabs=csharp&WT.mc_id=javascript-99907-cxa)!\\n\\nFor this example, I\'m going to use Visual Studio Code to build up a Function that responds to an [HTTP trigger](https://docs.microsoft.com/azure/azure-functions/functions-bindings-http-webhook-trigger?WT.mc_id=javascript-99907-cxa) and then writes a message to an [Azure Storage Queue](https://docs.microsoft.com/azure/azure-functions/functions-bindings-storage-queue-output?WT.mc_id=javascript-99907-cxa).\\n\\n![Diagram of the how the Azure Function will use the HTTP trigger and the Azure Storage Queue Binding](img/flow.png)\\n\\nThe incoming HTTP call is the **trigger** and the message queue the Function writes to is an **output binding**. Let\'s have at it!\\n\\n:::info\\nYou do need to have some tools downloaded and installed to get started. First and foremost, you\'ll need [Visual Studio Code](https://code.visualstudio.com/). Then you\'ll need the [Azure Functions extension](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions&WT.mc_id=javascript-99907-cxa) for VS Code to do the development with. Finally, you\'ll need the [Azurite Emulator](https://docs.microsoft.com/azure/storage/common/storage-use-azurite?tabs=visual-studio-code&WT.mc_id=javascript-99907-cxa) installed as well\u2014this will allow us to write to a message queue locally.\\n\\nOh! And of course, [.NET 6](https://docs.microsoft.com/dotnet/core/tools/?WT.mc_id=javascript-99907-cxa)!\\n:::\\n\\nNow with all of the tooling out of the way, let\'s write a Function!\\n\\n\\n1. Fire up Visual Studio Code. Then, from the command palette, type: `Azure Functions: Create New Project`\\n\\n  ![Screenshot of create a new function dialog in VS Code](img/1-create-new.png)\\n\\n2. Follow the steps as to which directory you want to create the project in and which .NET runtime and language you want to use.\\n\\n  ![Screenshot of VS Code prompting which directory and language to use](img/2-language.png)\\n\\n3. Pick **.NET 6** and **C#**.\\n\\n  It will then prompt you to pick the folder in which your Function app resides and then select a template.\\n\\n  ![Screenshot of VS Code prompting you to pick the Function trigger template](img/3-selecttemplate.png)\\n\\n  Pick the **HTTP trigger** template. When prompted for a name, call it: **PostToAQueue**.\\n\\n\\n### Execute the Function Locally\\n\\n1. After giving it a namespace, it prompts for an authorization level\u2014pick Anonymous. **Now we have a Function!** Let\'s go ahead and hit F5 and see it run!\\n\\n\\n:::info\\nAfter the templates have finished installing, you may get a prompt to download additional components\u2014these are NuGet packages. Go ahead and do that.\\n:::\\n\\nWhen it runs, you\'ll see the Azure Functions logo appear in the Terminal window with the URL the Function is located at. Copy that link.\\n\\n![Screenshot of the Azure Functions local runtime starting up](img/5-start.png)\\n\\n 2. Type the link into a browser, adding a `name` parameter as shown in this example: `http://localhost:7071/api/PostToAQueue?name=Matt`. The Function will respond with a message. You can even set breakpoints in Visual Studio Code and step through the code!\\n\\n### Write To Azure Storage Queue\\n\\nNext, we\'ll get this HTTP trigger Function to write to a local Azure Storage Queue. First we need to add the Storage NuGet package to our project. In the terminal, type:\\n\\n```bash\\ndotnet add package Microsoft.Azure.WebJobs.Extensions.Storage\\n```\\n\\nThen set a configuration setting to tell the Function runtime where to find the Storage. Open up local.settings.json and set \\"AzureWebJobsStorage\\" to \\"UseDevelopmentStorage=true\\". The full file will look like:\\n\\n```json\\n{\\n  \\"IsEncrypted\\": false,\\n  \\"Values\\": {\\n    \\"AzureWebJobsStorage\\": \\"UseDevelopmentStorage=true\\",\\n    \\"AzureWebJobsDashboard\\": \\"\\"\\n  }\\n}\\n```\\n\\nThen create a new class within your project. This class will hold nothing but properties. Call it whatever you want and add whatever properties you want to it. I called mine TheMessage and added an Id and Name properties to it.\\n\\n```csharp\\npublic class TheMessage\\n{\\n    public string Id { get; set; }\\n    public string Name { get; set; }\\n}\\n```\\n\\nFinally, change your PostToAQueue Function, so it looks like the following:\\n\\n```csharp\\n\\npublic static class PostToAQueue\\n{\\n    [FunctionName(\\"PostToAQueue\\")]        \\n    public static async Task<IActionResult> Run(\\n        [HttpTrigger(AuthorizationLevel.Anonymous, \\"get\\", \\"post\\", Route = null)] HttpRequest req,\\n        [Queue(\\"demoqueue\\", Connection = \\"AzureWebJobsStorage\\")] IAsyncCollector<TheMessage> messages,\\n        ILogger log)\\n    {        \\n        string name = req.Query[\\"name\\"];\\n\\n        await messages.AddAsync(new TheMessage { Id = System.Guid.NewGuid().ToString(), Name = name });\\n\\n        return new OkResult();\\n    }\\n}\\n\\n```\\n\\nNote the addition of the `messages` variable. This is telling the Function to use the storage connection we specified before via the `Connection` property. And it is also specifying which queue to use in that storage account, in this case `demoqueue`.\\n\\nAll the code is doing is pulling out the `name` from the query string, new\'ing up a new `TheMessage` class and adding that to the `IAsyncCollector` variable.\\n\\n**That will add the new message to the queue!**\\n\\nMake sure Azurite is started within VS Code (both the queue and blob emulators). Run the app and send the same GET request as before: `http://localhost:7071/api/PostToAQueue?name=Matt`.\\n\\nIf you have the Azure Storage Explorer installed, you can browse your local Queue and see the new message in there!\\n\\n![Screenshot of Azure Storage Explorer with the new message in the queue](img/7-new-queue.png)\\n\\n## Summing Up\\n\\nWe had a quick look at what Microsoft\'s serverless offering, Azure Functions, is comprised of. It\'s a full-featured FaaS offering that enables you to write functions in your language of choice, including reusing packages such as those from NuGet.\\n\\nA highlight of Azure Functions is the way they are triggered and bound. The triggers define how a Function starts, and bindings are akin to input and output parameters on it that correspond to external services. The best part is that the Azure Function runtime takes care of maintaining the connection to the external services so you don\'t have to worry about new\'ing up or disposing of the connections yourself. \\n\\nWe then wrote a quick Function that gets triggered off an HTTP request and then writes a query string parameters from that request into a local Azure Storage Queue.\\n\\n## What\'s Next\\n\\nSo, where can you go from here? \\n\\nThink about how you can **build real-world scenarios by integrating other Azure services**. For example, you could use serverless integrations to build a workflow where the input payload received using an HTTP Trigger, is now stored in Blob Storage (output binding), which in turn triggers another service (e.g., Cognitive Services) that processes the blob and returns an enhanced result. \\n\\n_Keep an eye out for an update to this post where we walk through a scenario like this with code_. Check out the  resources below to help you get started on your own.\\n\\n\\n## Exercise\\n\\nThis brings us close to the end of Week 1 with Azure Functions. We\'ve learned core concepts, built and deployed our first Functions app, and explored quickstarts and scenarios for different programming languages. So, what can you do to explore this topic on your own?\\n\\n* Explore the [Create Serverless Applications](https://docs.microsoft.com/training/paths/create-serverless-applications/?WT.mc_id=javascript-99907-cxa) learning path which has several modules that explore Azure Functions integrations with various services.\\n* Take up the [Cloud Skills Challenge](https://docs.microsoft.com/training/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi) and complete those modules in a fun setting where you compete with peers for a spot on the leaderboard!\\n\\nThen come back tomorrow as we wrap up the week with a discussion on end-to-end scenarios, a recap of what we covered this week, and a look at what\'s ahead next week.\\n\\n\\n\\n## Resources\\n\\nStart here for developer guidance in getting started with Azure Functions as a .NET/C# developer:\\n\\n* [Develop C# class library functions using Azure Functions](https://docs.microsoft.com/azure/azure-functions/functions-dotnet-class-library?tabs=v2%2Ccmd&WT.mc_id=javascript-99907-cxa). \\n* [Using C# to develop .NET isolated process functions](https://docs.microsoft.com/azure/azure-functions/dotnet-isolated-process-guide?WT.mc_id=javascript-99907-cxa).\\n* [Quickstart: Create your first C# function in Azure using Visual Studio](https://docs.microsoft.com/azure/azure-functions/functions-create-your-first-function-visual-studio?tabs=in-process&WT.mc_id=javascript-99907-cxa).\\n\\nThen learn about [supported Triggers and Bindings](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=csharp#bindings-code-examples?WT.mc_id=javascript-99907-cxa) for C#, with code snippets to show how they are used. \\n\\nFinally, explore [Azure Functions samples for C#](https://docs.microsoft.com/samples/browse/?products=azure-functions&languages=csharp&WT.mc_id=javascript-99907-cxa) and learn to implement serverless solutions. Examples include:\\n * Using Azure Functions to [check storage of Azure Cognitive Services on a schedule](https://docs.microsoft.com/samples/azure-samples/azure-search-dotnet-samples/check-storage-usage/?WT.mc_id=javascript-99907-cxa) using Timer Triggers.\\n* Using Azure Functions to [implement a ToDo Backend API](https://docs.microsoft.com/samples/azure-samples/azure-sql-binding-func-dotnet-todo/todo-backend-dotnet-azure-sql-bindings-azure-functions/?WT.mc_id=javascript-99907-cxa) illustrating Azure SQL integration."},{"id":"zero2hero-func-02","metadata":{"permalink":"/Cloud-Native/blog/zero2hero-func-02","source":"@site/blog/zero-to-hero/2022-09-06-azurefunctions.md","title":"\ud83d\ude80 | Durable Entities Walkthrough","description":"Durable Entities are a special type of Azure Functions that allow you to implement stateful objects in a serverless environment.","date":"2022-09-06T00:00:00.000Z","formattedDate":"September 6, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"}],"readingTime":7.465,"hasTruncateMarker":false,"authors":[{"name":"David Justo","title":"Software Engineer @Microsoft","url":"https://github.com/davidmrdavid","imageURL":"https://github.com/davidmrdavid.png","key":"davidjusto"}],"frontMatter":{"slug":"zero2hero-func-02","title":"\ud83d\ude80 | Durable Entities Walkthrough","authors":["davidjusto"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","containerapps","serverless","concepts"],"image":"./img/zero-to-hero-david.png","description":"Durable Entities are a special type of Azure Functions that allow you to implement stateful objects in a serverless environment.","tags":["serverless-september","zero-to-hero","azure-functions","azure-container-apps","dapr"]},"prevItem":{"title":"06. Functions for .NET Devs","permalink":"/Cloud-Native/blog/06-functions-dotnet"},"nextItem":{"title":"\ud83d\ude80 | Go Cloud-Native with ACA","permalink":"/Cloud-Native/blog/zero2hero-aca-01"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/zero2hero-func-02\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ZeroToHero: A Walkthrough of Durable Entities\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ZeroToHero: A Walkthrough of Durable Entities\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/serverless-zero2hero.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://techcommunity.microsoft.com/t5/apps-on-azure-blog/a-walkthrough-of-durable-entities/ba-p/3616832\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 6` of #30DaysOfServerless!\\n\\n\\nToday, we have a special set of posts from our [Zero To Hero \ud83d\ude80](/serverless-september/ZeroToHero) initiative, featuring blog posts authored by our Product Engineering teams for #ServerlessSeptember. _Posts were originally published on the [Apps on Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/a-walkthrough-of-durable-entities/ba-p/3616832?WT.mc_id=javascript-99907-cxa) blog on Microsoft Tech Community._\\n\\n---\\n\\n## What We\'ll Cover\\n * What are Durable Entities\\n * Some Background\\n * A Programming Model\\n * Entities for a Micro-Blogging Platform\\n\\n![](./img/zero-to-hero-david.png)\\n\\n---\\n \\n\\n[Durable Entities](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-entities?tabs=csharp&WT.mc_id=javascript-99907-cxa) are a special type of Azure Function that allow you to implement stateful objects in a serverless environment. They make it easy to introduce stateful components to your app without needing to manually persist data to external storage, so you can focus on your business logic. We\u2019ll demonstrate their power with a real-life example in the last section.\\n\\n## Entities 101: Some Background\\n \\nProgramming Durable Entities feels a lot like object-oriented programming, except that these \u201cobjects\u201d exist in a distributed system. Like objects, each Entity instance has a unique identifier, i.e. an entity ID that can be used to read and manipulate their internal state. Entities define a list of operations that constrain how their internal state is managed, like an object interface.\\n\\nSome experienced readers may realize that Entities sound a lot like an implementation of the Actor Pattern. For a discussion of the relationship between Entities and Actors, please refer to [this documentation](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-entities?tabs=csharp#comparison-with-virtual-actors).\\n\\nEntities are a part of the Durable Functions Extension, an extension of Azure Functions that empowers programmers with stateful abstractions for serverless, such as Orchestrations (i.e. workflows).\\n\\n[Durable Functions](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=csharp) is available in most Azure Functions runtime environments: .NET, Node.js, Python, PowerShell, and Java (preview). For this article, we\u2019ll focus on the C# experience, but note that Entities are also available in Node.js and Python; their availability in other languages is underway.\\n\\n\\n## Entities 102: The programming model\\n \\nImagine you want to implement a simple Entity that just counts things. Its interface allows you to get the current count, add to the current count, and to reset the count to zero.\\n\\nIf you implement this in an object-oriented way, you\u2019d probably define a class (say \u201cCounter\u201d) with a method to get the current count (say \u201cCounter.Get\u201d), another to add to the count (say \u201cCounter.Add\u201d), and another to reset the count (say \u201cCounter.Reset\u201d). Well, the implementation of an Entity in C# is not that different from this sketch:\\n\\n\\n```\\n[JsonObject(MemberSerialization.OptIn)] \\npublic class Counter \\n{ \\n    [JsonProperty(\\"value\\")] \\n    public int Value { get; set; } \\n \\n    public void Add(int amount)  \\n    { \\n        this.Value += amount; \\n    } \\n\\n    public Task Reset()  \\n    { \\n        this.Value = 0; \\n        return Task.CompletedTask; \\n    } \\n \\n    public Task<int> Get()  \\n    { \\n        return Task.FromResult(this.Value); \\n    } \\n    [FunctionName(nameof(Counter))] \\n    public static Task Run([EntityTrigger] IDurableEntityContext ctx) \\n        => ctx.DispatchAsync<Counter>(); \\n\\n} \\n```\\n\\nWe\u2019ve defined a class named Counter, with an internal count stored in the variable \u201cValue\u201d which is manipulated through the \u201cAdd\u201d and \u201cReset\u201d methods, and which can be read via \u201cGet\u201d.\\n\\nThe \u201cRun\u201d method is simply boilerplate required for the Azure Functions framework to interact with the object we\u2019ve defined \u2013 it\u2019s the method that the framework calls internally when it needs to load the Entity object. When `DispatchAsync` is called, the Entity and its corresponded state (the last count in \u201cValue\u201d) is loaded from storage. Again, this is mostly just boilerplate: your Entity\u2019s business logic lies in the rest of the class.\\n\\nFinally, the Json annotation on top of the class and the Value field tells the Durable Functions framework that the \u201cValue\u201d field is to be durably persisted as part of the durable state on each Entity invocation. If you were to annotate other class variables with JsonProperty, they would also become part of the managed state.\\n\\n \\n\\n## Entities for a micro-blogging platform\\n \\nWe\u2019ll try to implement a simple micro-blogging platform, a la Twitter. Let\u2019s call it \u201cChirper\u201d. In Chirper, users write chirps (i.e tweets), they can follow, and unfollow other users, and they can read the chirps of users they follow.\\n\\n### Defining Entity\\nJust like in OOP, it\u2019s useful to begin by identifying what are the stateful agents of this scenario. In this case, users have state (who they follow and their chirps), and chirps have state in the form of their content. So, we could model these stateful agents as Entities!\\n\\nBelow is a potential way to implement a User for Chirper as an Entity:\\n\\n```\\n  [JsonObject(MemberSerialization = MemberSerialization.OptIn)] \\n  public class User: IUser  \\n  { \\n      [JsonProperty] \\n      public List<string> FollowedUsers { get; set; }  = new List<string>(); \\n\\n      public void Add(string user) \\n      { \\n          FollowedUsers.Add(user); \\n      } \\n\\n      public void Remove(string user) \\n      { \\n          FollowedUsers.Remove(user); \\n      } \\n\\n      public Task<List<string>> Get() \\n      { \\n          return Task.FromResult(FollowedUsers); \\n      } \\n      // note: removed boilerplate \u201cRun\u201d method, for conciseness. \\n  } \\n```\\n\\nIn this case, our Entity\u2019s internal state is stored in \u201cFollowedUsers\u201d which is an array of accounts followed by this user. The operations exposed by this entity allow clients to read and modify this data: it can be read by \u201cGet\u201d, a new follower can be added via \u201cAdd\u201d, and a user can be unfollowed via \u201cRemove\u201d.\\n\\nWith that, we\u2019ve modeled a Chirper\u2019s user as an Entity! Recall that Entity instances each has a unique ID, so we can consider that unique ID to correspond to a specific user account.\\n\\nWhat about chirps? Should we represent them as Entities as well? That would certainly be valid. However, we would then need to create a mapping between an entity ID and every chirp entity ID that this user wrote.\\n\\nFor demonstration purposes, a simpler approach would be to create an Entity that stores the list of all chirps authored by a given user; call it UserChirps. Then, we could fix each User Entity to share the same entity ID as its corresponding UserChirps Entity, making client operations easier.\\n\\nBelow is a simple implementation of UserChirps:\\n\\n```\\n  [JsonObject(MemberSerialization = MemberSerialization.OptIn)] \\n  public class UserChirps : IUserChirps \\n  { \\n      [JsonProperty] \\n      public List<Chirp> Chirps { get; set; } = new List<Chirp>(); \\n\\n      public void Add(Chirp chirp) \\n      { \\n          Chirps.Add(chirp); \\n      } \\n\\n      public void Remove(DateTime timestamp) \\n      { \\n          Chirps.RemoveAll(chirp => chirp.Timestamp == timestamp); \\n      } \\n\\n      public Task<List<Chirp>> Get() \\n      { \\n          return Task.FromResult(Chirps); \\n      } \\n\\n      // Omitted boilerplate \u201cRun\u201d function \\n  } \\n```\\n\\nHere, our state is stored in Chirps, a list of user posts. Our operations are the same as before: Get, Read, and Add. It\u2019s the same pattern as before, but we\u2019re representing different data.\\n\\nTo put it all together, let\u2019s set up Entity clients to generate and manipulate these Entities according to some REST API.\\n\\n### Interacting with Entity\\n\\nBefore going there, let\u2019s talk briefly about how you can interact with an Entity. Entity interactions take one of two forms -- [calls and signals](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-entities?tabs=csharp#access-entities):\\n\\nCalling an entity is a two-way communication. You send an operation message to the entity and then wait for the response message before you continue. The response can be a result value or an error.\\nSignaling an entity is a one-way (fire-and-forget) communication. You send an operation message but don\u2019t wait for a response. You have the reassurance that the message will be delivered eventually, but you don\u2019t know when and don\u2019t know what the response is.\\nFor example, when you read the state of an Entity, you are performing a \u201ccall\u201d interaction. When you record that a user has followed another, you may choose to simply signal it.\\n\\nNow say user with a given userId (say \u201cdurableFan99\u201d ) wants to post a chirp. For this, you can write an HTTP endpoint to signal the UserChips entity to record that chirp. We can leverage the HTTP Trigger functionality from Azure Functions and pair it with an entity client binding that signals the Add operation of our Chirp Entity:\\n\\n```\\n[FunctionName(\\"UserChirpsPost\\")] \\npublic static async Task<HttpResponseMessage> UserChirpsPost( \\n    [HttpTrigger(AuthorizationLevel.Function, \\"post\\", Route = \\"user/{userId}/chirps\\")] \\n    HttpRequestMessage req, \\n    DurableClient] IDurableClient client, \\n    ILogger log,  \\n    string userId) \\n    { \\n        Authenticate(req, userId); \\n        var chirp = new Chirp() \\n        { \\n            UserId = userId, \\n            Timestamp = DateTime.UtcNow, \\n            Content = await req.Content.ReadAsStringAsync(), \\n        }; \\n        await client.SignalEntityAsync<IUserChirps>(userId, x => x.Add(chirp)); \\n        return req.CreateResponse(HttpStatusCode.Accepted, chirp); \\n    } \\n``` \\n\\nFollowing the same pattern as above, to get all the chirps from a user, you could read the status of your Entity via `ReadEntityStateAsync`, which follows the call-interaction pattern as your client expects a response:\\n\\n```\\n[FunctionName(\\"UserChirpsGet\\")] \\npublic static async Task<HttpResponseMessage> UserChirpsGet( \\n  [HttpTrigger(AuthorizationLevel.Function, \\"get\\", Route = \\"user/{userId}/chirps\\")] HttpRequestMessage req, \\n  [DurableClient] IDurableClient client, \\n  ILogger log, \\n  string userId) \\n  { \\n\\n      Authenticate(req, userId); \\n      var target = new EntityId(nameof(UserChirps), userId); \\n      var chirps = await client.ReadEntityStateAsync<UserChirps>(target); \\n      return chirps.EntityExists \\n            ? req.CreateResponse(HttpStatusCode.OK, chirps.EntityState.Chirps) \\n            : req.CreateResponse(HttpStatusCode.NotFound); \\n  } \\n```\\n\\nAnd there you have it! To play with a complete implementation of Chirper, you can try out our sample in the [Durable Functions extension repo](https://github.com/Azure/azure-functions-durable-extension/tree/dev/samples/entitites-csharp/Chirper).  \\n\\nThank you!\\n \\n:::info\\nThanks for following along, and we hope you find Entities as useful as we do! If you have questions or feedback, please file issues in the repo above or tag us [@AzureFunctions](https://twitter.com/AzureFunctions) on Twitter\\n:::"},{"id":"zero2hero-aca-01","metadata":{"permalink":"/Cloud-Native/blog/zero2hero-aca-01","source":"@site/blog/zero-to-hero/2022-09-06-containerapps.md","title":"\ud83d\ude80 | Go Cloud-Native with ACA","description":"In this article, we discuss how Azure Container Apps is purpose-built to support Cloud-Native applications.","date":"2022-09-06T00:00:00.000Z","formattedDate":"September 6, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"zero-to-hero","permalink":"/Cloud-Native/blog/tags/zero-to-hero"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"dapr","permalink":"/Cloud-Native/blog/tags/dapr"}],"readingTime":7.435,"hasTruncateMarker":false,"authors":[{"name":"Kendall Roden","title":"Azure Container Apps PM @Microsoft","url":"https://github.com/kendallroden","imageURL":"https://github.com/kendallroden.png","key":"kendall"}],"frontMatter":{"slug":"zero2hero-aca-01","title":"\ud83d\ude80 | Go Cloud-Native with ACA","authors":["kendall"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","containerapps","serverless","concepts"],"image":"./img/banner.png","description":"In this article, we discuss how Azure Container Apps is purpose-built to support Cloud-Native applications.","tags":["serverless-september","zero-to-hero","azure-functions","azure-container-apps","dapr"]},"prevItem":{"title":"\ud83d\ude80 | Durable Entities Walkthrough","permalink":"/Cloud-Native/blog/zero2hero-func-02"},"nextItem":{"title":"05. Functions for JS Devs","permalink":"/Cloud-Native/blog/05-functions-js"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/zero2hero-aca-01\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#ZeroToHero: Go Cloud-Native With Azure Container Apps\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#ZeroToHero: Go Cloud-Native With Azure Container Apps\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/serverless-zero2hero.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://techcommunity.microsoft.com/t5/apps-on-azure-blog/go-cloud-native-with-azure-container-apps/ba-p/3616407\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 6` of #30DaysOfServerless!\\n\\nToday, we have a special set of posts from our [Zero To Hero \ud83d\ude80](/serverless-september/ZeroToHero) initiative, featuring blog posts authored by our Product Engineering teams for #ServerlessSeptember. _Posts were originally published on the [Apps on Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/go-cloud-native-with-azure-container-apps/ba-p/3616407?WT.mc_id=javascript-99907-cxa) blog on Microsoft Tech Community._\\n\\n---\\n\\n## What We\'ll Cover\\n * Defining Cloud-Native\\n * Introduction to Azure Container Apps\\n * Dapr In Azure Container Apps\\n * Conclusion\\n\\n![](./img/zero-to-hero-kendall.png)\\n\\n---\\n\\n\\n## Defining Cloud-Native \\n \\nWhile I\u2019m positive I\u2019m not the first person to ask this, I think it\u2019s an appropriate way for us to kick off this article: **\u201cHow many developers does it take to define Cloud-Native?\u201d** I hope you aren\u2019t waiting for a punch line because I seriously want to know your thoughts (drop your perspectives in the comments..) but if you ask me, the limit does not exist!\\n\\nA quick online search of the topic returns a laundry list of articles, e-books, twitter threads, etc. all trying to nail down the one true definition. While diving into the rabbit hole of Cloud-Native, you will inevitably find yourself on the Cloud-Native Computing Foundation (CNCF) site. The CNCF is part of the Linux Foundation and aims to make \\"Cloud-Native computing ubiquitous\\" through deep open source project and community involvement. The CNCF has also published arguably the most popularized definition of Cloud-Native which begins with the following statement:\\n\\n> \u201cCloud-Native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds.\\"\\n\\nOver the past four years, my day-to-day work has been driven primarily by the surging demand for application containerization and the drastic adoption of Kubernetes as the de-facto container orchestrator. Customers are eager to learn and leverage patterns, practices and technologies that enable building \\"loosely coupled systems that are resilient, manageable, and observable\\". Enterprise developers at these organizations are being tasked with rapidly deploying event-driven, horizontally-scalable, polyglot services via repeatable, code-to-cloud pipelines.\\n\\nWhile building Cloud-Native solutions can enable rapid innovation, the transition to adopting a Cloud-Native architectural approach comes with a steep learning curve and a new set of considerations. In a document published by Microsoft called What is Cloud-Native?, there are a few key areas highlighted to aid customers in the adoption of best practices for building modern, portable applications which I will summarize below:\\n \\n**Cloud infrastructure**\\n\\n * Cloud-Native applications leverage cloud infrastructure and make use of Platform-as-a-service offerings\\n * Cloud-Native applications depend on highly-elastic infrastructure with automatic scaling, self-healing, and monitoring capabilities\\n \\n**Modern application design**\\n * Cloud-Native applications should be constructed using principles outlined in the 12 factor methodology\\n \\n**Microservices**\\n * Cloud-Native applications are typically composed of microservices where each core function, or service, is built and deployed independently\\n \\n**Containers**\\n\\n * Cloud-Native applications are typically deployed using containers as a packaging mechanism where an application\'s code and dependencies are bundled together for consistency of deployment\\n * Cloud-Native applications leverage container orchestration technologies- primarily Kubernetes- for achieving capabilities such as workload scheduling, self-healing, auto-scale, etc.\\n \\n**Backing services**\\n * Cloud-Native applications are ideally stateless workloads which retrieve and store data in data stores external to the application hosting infrastructure. Cloud providers like Azure provide an array of backing data services which can be securely accessed from application code and provide capabilities for ensuring application data is highly-available\\n \\n**Automation**\\n* Cloud-Native solutions should use deployment automation for backing cloud infrastructure via versioned, parameterized Infrastructure as Code (IaC) templates which provide a consistent, repeatable process for provisioning cloud resources.\\n* Cloud-Native solutions should make use of modern CI/CD practices and pipelines to ensure successful, reliable infrastructure and application deployment.\\n \\n\\n## Azure Container Apps\\n \\nIn many of the conversations I\'ve had with customers that involve talk of Kubernetes and containers, the topics of cost-optimization, security, networking, and reducing infrastructure and operations inevitably arise. I personally have yet to meet with any customers eager to have their developers get more involved with infrastructure concerns.\\n\\nOne of my former colleagues, Jeff Hollan, made a statement while appearing on a 2019 episode of The Cloud-Native Show where he shared his perspective on Cloud-Native:\\n\\n> \\"When I think about Cloud-Native... it\'s writing applications in a way where you are specifically thinking about the benefits the cloud can provide... to me, serverless is the perfect realization of that because the only reason you can write serverless applications is because the cloud exists.\\"\\n\\nI must say that I agree with Jeff\'s perspective. In addition to optimizing development practices for the Cloud-Native world, reducing infrastructure exposure and operations is equally as important to many organizations and can be achieved as a result of cloud platform innovation.\\n\\nIn May of 2022, Microsoft announced the general availability of Azure Container Apps. Azure Container Apps provides customers with the ability to run microservices and containerized applications on a serverless, consumption-based platform. \\n\\nFor those interested in taking advantage of the open source ecosystem while reaping the benefits of a managed platform experience, Container Apps run on Kubernetes and provides a set of managed open source projects embedded directly into the platform including the Kubernetes Event Driven Autoscaler (KEDA), the Distributed Application Runtime (Dapr) and Envoy.\\n\\n![Azure Kubernetes Service vs. Azure Container Apps](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/401287i073CFBD50CB3A0B9/image-size/large?v=v2&px=999&WT.mc_id=javascript-99907-cxa)\\n\\nContainer apps provides other Cloud-Native features and capabilities in addition to those above including, but not limited to: \\n\\n * [Revisions](https://docs.microsoft.com/azure/container-apps/application-lifecycle-management?WT.mc_id=javascript-99907-cxa): immutable snapshot representative of a specific version of a container app which can take advantage of the [managed traffic splitting capability](https://docs.microsoft.com/azure/container-apps/revisions-manage?tabs=bash&WT.mc_id=javascript-99907-cxa) \\n * [Health probes](https://docs.microsoft.com/azure/container-apps/health-probes?tabs=arm-template?WT.mc_id=javascript-99907-cxa): Based on [Kubernetes health probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/?WT.mc_id=javascript-99907-cxa) with support for Readiness, Liveness and Startup \\n * [Built-in authentication](https://docs.microsoft.com/azure/container-apps/authentication-openid?WT.mc_id=javascript-99907-cxa)\\n * [Managed Identity](https://docs.microsoft.com/azure/container-apps/managed-identity?tabs=portal%2Cdotnet&WT.mc_id=javascript-99907-cxa)\\n * [Custom domain names and certificates](https://docs.microsoft.com/azure/container-apps/custom-domains-certificates?WT.mc_id=javascript-99907-cxa)\\n * [Virtual Network injection](https://docs.microsoft.com/azure/container-apps/networking?WT.mc_id=javascript-99907-cxa)\\n * [Platform observability](https://docs.microsoft.com/azure/container-apps/observability?tabs=bash&WT.mc_id=javascript-99907-cxa) : log streaming, console connect, Azure monitor \\n \\nThe ability to dynamically scale and support growing numbers of users, events, and requests is one of the core requirements for most Cloud-Native, distributed applications. Azure Container Apps is purpose-built with this and other Cloud-Native tenants in mind. \\n\\n![What can you build with Azure Container Apps?](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/401522iACA9C8FFC49FE161/image-size/large?v=v2&px=999)\\n\\n## Dapr in Azure Container Apps\\n \\nAs a quick personal note before we dive into this section I will say I am a bit bias about Dapr. When Dapr was first released, I had an opportunity to immediately get involved and became an early advocate for the project. It is created by developers for developers, and solves tangible problems customers architecting distributed systems face:\\n\\n:::info HOW DO I\\n * integrate with external systems that my app has to react and respond to?\\n * create event driven apps which reliably send events from one service to another?\\n * observe the calls and events between my services to diagnose issues in production?\\n * access secrets securely from within my application?\\n * discover other services and call methods on them?\\n * prevent committing to a technology early and have the flexibility to swap out an alternative based on project or environment changes?\\n:::\\n \\nWhile existing solutions were in the market which could be used to address some of the concerns above, there was not a lightweight, CNCF-backed project which could provide a unified approach to solve the more fundamental ask from customers: \\"How do I make it easy for developers to build microservices based on Cloud-Native best practices?\\"\\n\\n\\n:::success Enter Dapr!\\n\\nThe [Distributed Application Runtime (Dapr)](https://dapr.io/) provides APIs that simplify microservice connectivity. Whether your communication pattern is service to service invocation or pub/sub messaging, Dapr helps you write resilient and secured microservices. By letting Dapr\u2019s sidecar take care of the complex challenges such as service discovery, message broker integration, encryption, observability, and secret management, you can focus on business logic and keep your code simple.\\"\\n:::\\n\\nThe Container Apps platform provides a managed and supported Dapr integration which eliminates the need for deploying and managing the Dapr OSS project. In addition to providing managed upgrades, the platform also exposes a simplified Dapr interaction model to increase developer productivity and reduce the friction required to leverage Dapr capabilities. While the Dapr integration makes it easier for customers to adopt Cloud-Native best practices in container apps it is not required to make use of the container apps platform. \\n\\n![Image on Dapr](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/401284iA1296A6F33D804B2/image-size/large?v=v2&px=999)\\n\\nFor additional insight into the dapr integration visit aka.ms/aca-dapr. \\n\\n \\n\\n## Conclusion\\n \\nBacked by and integrated with powerful Cloud-Native technologies, Azure Container Apps strives to make developers productive, while reducing the operational overhead and learning curve that typically accompanies adopting a cloud-native strategy. \\n\\nIf you are interested in building resilient, portable and highly-scalable apps visit [Azure Container Apps | Microsoft Azure](https://azure.microsoft.com/services/container-apps/) today!\\n\\n\\n:::info ASK THE EXPERT: LIVE Q&A\\nThe Azure Container Apps team will answer questions live on **September 29**. \\n * [Sign up to attend](https://reactor.microsoft.com/reactor/events/17004/?WT.mc_id=javascript-99907-ninarasi) for live Q&A with the team\\n * [submit your questions](https://github.com/Azure/Cloud-Native/issues/new?assignees=&labels=ask+the+expert&template=---ask-the-expert-.md&title=%5BAsk+The+Expert%5D++) ahead of time, for prioritization.\\n:::"},{"id":"05-functions-js","metadata":{"permalink":"/Cloud-Native/blog/05-functions-js","source":"@site/blog/2022-09-05/index.md","title":"05. Functions for JS Devs","description":"Introduction to Azure Functions, from core concepts to hello world!","date":"2022-09-05T00:00:00.000Z","formattedDate":"September 5, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"azure-container-apps","permalink":"/Cloud-Native/blog/tags/azure-container-apps"},{"label":"javascript","permalink":"/Cloud-Native/blog/tags/javascript"}],"readingTime":6.74,"hasTruncateMarker":false,"authors":[{"name":"Aaron Powell","title":"Principal Cloud Advocate @Microsoft","url":"https://github.com/aaronpowell","imageURL":"https://github.com/aaronpowell.png","key":"aaron"}],"frontMatter":{"slug":"05-functions-js","title":"05. Functions for JS Devs","authors":["aaron"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Introduction to Azure Functions, from core concepts to hello world!","tags":["serverless-september","30-days-of-serverless","azure-functions","azure-container-apps","javascript"]},"prevItem":{"title":"\ud83d\ude80 | Go Cloud-Native with ACA","permalink":"/Cloud-Native/blog/zero2hero-aca-01"},"nextItem":{"title":"04. Functions For Java Devs","permalink":"/Cloud-Native/blog/04-functions-java"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/05-functions-js\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Functions for JavaScript Developers\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions for JavaScript Developers\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/05-functions-js\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 5` of #30DaysOfServerless!\\n\\n_Yesterday_ we looked at Azure Functions from the perspective of a Java developer. _Today_, we\'ll do a similar walkthrough from the perspective of a JavaScript developer. \\n\\nAnd, we\'ll use this to explore another popular usage scenario for Azure Functions: **building a serverless HTTP API using JavaScript**. \\n\\nReady? Let\'s go.\\n\\n---\\n\\n## What We\'ll Cover\\n * Developer Guidance\\n * Create Azure Function with CLI\\n * Calling an external API\\n * Azure Samples & Scenarios for JS\\n * Exercise: Support searching\\n * Resources: For self-study!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Developer Guidance\\n\\nIf you\'re a JavaScript developer new to serverless on Azure, start by exploring the [Azure Functions JavaScript Developers Guide](https://docs.microsoft.com/azure/azure-functions/functions-reference-node?tabs=v2-v3-v4-export%2Cv2-v3-v4-done%2Cv2%2Cv2-log-custom-telemetry%2Cv2-accessing-request-and-response%2Cwindows-setting-the-node-version&WT.mc_id=javascript-99907-cxa). It covers:\\n * Quickstarts for Node.js - using Visual Code, CLI or Azure Portal\\n * Guidance on hosting options and performance considerations\\n * Azure Functions [bindings](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=javascript#bindings-code-examples?WT.mc_id=javascript-99907-cxa) and ([code samples](https://docs.microsoft.com/samples/browse/?products=azure-functions&languages=javascript&WT.mc_id=javascript-99907-cxa)) for JavaScript\\n * Scenario examples - integrations with other Azure Services\\n\\n\\n### Node.js 18 Support \\n\\n:::info Node.js 18 Support (Public Preview)\\nAzure Functions support for Node.js 18 [entered Public Preview on Aug 31, 2022](https://azure.microsoft.com/updates/public-preview-nodejs-18-in-azure-functions/?WT.mc_id=javascript-99907-cxa) and is supported by the [Azure Functions v.4.x runtime!](https://docs.microsoft.com/azure/azure-functions/functions-versions?tabs=azure-cli%2Cin-process%2Cv4&pivots=programming-language-javascript&WT.mc_id=javascript-99907-cxa)\\n:::\\n\\nAs we continue to explore how we can use Azure Functions, today we\'re going to look at using JavaScript to create one, and we\'re going to be using the newly released **Node.js 18 support for Azure Functions** to make the most out of the platform. \\n\\nEnsure you have Node.js 18 and Azure Functions v4.x versions installed, along with a text editor (I\'ll use VS Code in this post), and a terminal, then we\'re ready to go.\\n\\n\\n\\n## Scenario: Calling The GitHub API\\n\\nThe application we\'re going to be building today will use the GitHub API to return a random commit message, so that we don\'t need to come up with one ourselves! After all, naming things can be really hard! \ud83e\udd23 \\n\\n\\n### Creating the Azure Function\\nTo create our Azure Function, we\'re going to use the [Azure Functions CLI](https://docs.microsoft.com/azure/azure-functions/functions-run-local?tabs=v4%2Cwindows%2Ccsharp%2Cportal%2Cbash&WT.mc_id=javascript-99907-cxa), which we can install using npm:\\n\\n```bash\\nnpm install --global azure-function-core-tools\\n```\\n\\nOnce that\'s installed, we can use the new `func` command to initalise our project:\\n\\n```bash\\nfunc init --worker-runtime node --language javascript\\n```\\n\\nWhen running `func init` we can either provide the `worker-runtime` and `language` as arguments, or use the menu system that the tool will provide us. For brevity\'s stake, I\'ve used the arguments here, specifying that we want `node` as the runtime and `javascript` as the language, but you could change that to `typescript` if you\'d prefer to use TypeScript.\\n\\nOnce the `init` command is completed, you should have a `.vscode` folder, and the files `.gitignore`, `host.json`, `local.settings.json`, and `package.json`.\\n\\n![Files generated by func init](./img/light/01.png#gh-light-mode-only)![Files generated by func init](./img/01.png#gh-dark-mode-only)\\n\\n### Adding a HTTP Trigger\\n\\nWe have an empty Functions app so far, what we need to do next is create a Function that it will run, and we\'re going to make a HTTP Trigger Function, which is a Function that responds to HTTP requests. We\'ll use the `func new` command to create that:\\n\\n```bash\\nfunc new --template \\"HTTP Trigger\\" --name \\"get-commit-message\\"\\n```\\n\\nWhen this completes, we\'ll have a folder for the Function, using the name we provided, that contains the files`function.json` and `index.js`. Let\'s open the `function.json` to understand it a little bit:\\n\\n```json\\n{\\n  \\"bindings\\": [\\n    {\\n      \\"authLevel\\": \\"function\\",\\n      \\"type\\": \\"httpTrigger\\",\\n      \\"direction\\": \\"in\\",\\n      \\"name\\": \\"req\\",\\n      \\"methods\\": [\\n        \\"get\\",\\n        \\"post\\"\\n      ]\\n    },\\n    {\\n      \\"type\\": \\"http\\",\\n      \\"direction\\": \\"out\\",\\n      \\"name\\": \\"res\\"\\n    }\\n  ]\\n}\\n```\\n\\nThis file is used to tell Functions about the Function that we\'ve created and what it does, so it knows to handle the appropriate events. We have a `bindings` node which contains the event bindings for our Azure Function. The first binding is using the `type` `httpTrigger`, which indicates that it\'ll be executed, or _triggered_, by a HTTP event, and the `methods` indicates that it\'s listening to both **GET** and **POST** (you can change this for the right HTTP methods that you want to support). The HTTP request information will be bound to a property in the Functions context called `req`, so we can access query strings, the request body, etc.\\n\\nThe other binding we have has the direction of `out`, meaning that it\'s something that the Function will _return_ to the called, and since this is a HTTP API, the `type` is `http`, indicating that we\'ll return a HTTP response, and that response will be on a property called `res` that we add to the Functions context.\\n\\nLet\'s go ahead and start the Function and call it:\\n\\n```bash\\nfunc start\\n```\\n\\n![Starting the Function](./img/light/02.png#gh-light-mode-only)![Starting the Function](./img/02.png#gh-dark-mode-only)\\n\\n\\nWith the Function started, access the endpoint `http://localhost:7071/api/get-commit-message` via a browser or using `cURL`:\\n\\n```bash\\ncurl http://localhost:7071/api/get-commit-message\\\\?name\\\\=ServerlessSeptember\\n```\\n\\n![Hello from Azure Functions](./img/light/03.png#gh-light-mode-only)![Hello from Azure Functions](./img/03.png#gh-dark-mode-only)\\n\\n:::success \ud83c\udf89 CONGRATULATIONS\\nYou created and ran a JavaScript function app locally!\\n:::\\n\\n### Calling an external API\\n\\nIt\'s time to update the Function to do what we want to do - call the GitHub Search API and get some commit messages. The endpoint that we\'ll be calling is [https://api.github.com/search/commits?q=language:javascript](https://api.github.com/search/commits?q=language:javascript).\\n\\n_Note: The GitHub API is [rate limited](https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting) and this sample will call it unauthenticated, so be aware of that in your own testing._\\n\\nTo call this API, we\'ll leverage the newly released [`fetch` support in Node 18](https://nodejs.org/en/blog/announcements/v18-release-announce/#fetch-experimental) and `async`/`await`, to make for a very clean Function.\\n\\nOpen up the `index.js` file, and delete the contents of the existing `Function`, so we have a empty one:\\n\\n```javascript\\nmodule.exports = async function (context, req) {\\n\\n}\\n```\\n\\n_The default template uses CommonJS, but you can use ES Modules with Azure Functions if you prefer._\\n\\nNow we\'ll use `fetch` to call the API, and unpack the JSON response:\\n\\n```javascript\\nmodule.exports = async function (context, req) {\\n    const res = await fetch(\\"https://api.github.com/search/commits?q=language:javascript\\");\\n    const json = await res.json();\\n    const messages = json.items.map(item => item.commit.message);\\n    context.res = {\\n        body: {\\n            messages\\n        }\\n    };\\n}\\n```\\n\\nTo send a response to the client, we\'re setting the `context.res` property, where `res` is the name of the output binding in our `function.json`, and giving it a body that contains the commit messages.\\n\\nRun `func start` again, and call the endpoint:\\n\\n```bash\\ncurl http://localhost:7071/api/get-commit-message\\n```\\n\\nThe you\'ll get some commit messages:\\n\\n![A series of commit messages from the GitHub Search API](./img/light/04.png#gh-light-mode-only)![A series of commit messages from the GitHub Search API](./img/04.png#gh-dark-mode-only)\\n\\n\\n:::success \ud83c\udf89 CONGRATULATIONS\\nThere we go, we\'ve created an Azure Function which is used as a proxy to another API, that we call (using native `fetch` in Node.js 18) and from which we return a subset of the JSON payload.\\n:::\\n\\n\\n## Next Steps\\n\\n### Other Triggers, Bindings\\n\\nThis article focused on using the HTTPTrigger and relevant bindings, to build a serverless API using Azure Functions. How can you explore other supported bindings, with code samples to illustrate usage?\\n * Start with the [Bindings](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=javascript#bindings-code-examples?WT.mc_id=javascript-99907-cxa) documentation to get a list of supported triggers/bindings for JavaScript\\n * Explore the [Azure serverless community library](https://www.serverlesslibrary.net/?language=JavaScript) and [Azure Samples](https://docs.microsoft.com/samples/browse/?products=azure-functions&languages=javascript&WT.mc_id=javascript-99907-cxa) resources by technology.\\n\\n### Scenarios with Integrations\\n\\nOnce you\'ve tried out the samples, try building an end-to-end scenario by using these triggers to integrate seamlessly with other services. Here are some suggestions:\\n * [Azure Queue storage trigger and bindings](https://docs.microsoft.com/azure/azure-functions/functions-bindings-storage-queue?tabs=in-process%2Cextensionv5%2Cextensionv3&pivots=programming-language-javascript&WT.mc_id=javascript-99907-cxa)\\n * [Show GitHub start count with Azure SignalR service](https://docs.microsoft.com/azure/azure-signalr/signalr-quickstart-azure-functions-javascript?toc=%2Fazure%2Fazure-functions%2Ftoc.json&WT.mc_id=javascript-99907-cxa)\\n * [Deploy a GraphQL API as an Azure Function](https://docs.microsoft.com/azure/developer/javascript/how-to/with-web-app/graphql/azure-function-hello-world?tabs=visualstudiocode&WT.mc_id=javascript-99907-cxa)\\n\\n\\n## Exercise: Support searching\\n\\nThe GitHub Search API allows you to provide search parameters via the `q` query string. In this sample, we hard-coded it to be `language:javascript`, but as a follow-on exercise, expand the Function to allow the caller to provide the search terms as a query string to the Azure Function, which is passed to the GitHub Search API. Hint - have a look at the `req` argument.\\n\\n## Resources\\n\\n- [Public preview of Node.js 18 for Azure Functions](https://azure.microsoft.com/updates/public-preview-nodejs-18-in-azure-functions/?WT.mc_id=javascript-99907-cxa)\\n- [`fetch` support in Node.js 18](https://nodejs.org/en/blog/announcements/v18-release-announce/#fetch-experimental)\\n- [Refactor Node.js and Express APIs to Serverless APIs with Azure Functions](https://docs.microsoft.com/learn/modules/shift-nodejs-express-apis-serverless/?WT.mc_id=javascript-99907-cxa)"},{"id":"04-functions-java","metadata":{"permalink":"/Cloud-Native/blog/04-functions-java","source":"@site/blog/2022-09-04/index.md","title":"04. Functions For Java Devs","description":"Introducing Azure Functions to the Java Developer. Learn how to create and deploy your first Java Functions app, and where you can go from here.","date":"2022-09-04T00:00:00.000Z","formattedDate":"September 4, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"java","permalink":"/Cloud-Native/blog/tags/java"},{"label":"serverless","permalink":"/Cloud-Native/blog/tags/serverless"}],"readingTime":7.465,"hasTruncateMarker":false,"authors":[{"name":"Rory Preddy","title":"Principal Cloud Advocate @Microsoft","url":"https://github.com/roryp","imageURL":"https://github.com/roryp.png","key":"rory"}],"frontMatter":{"slug":"04-functions-java","title":"04. Functions For Java Devs","authors":["rory"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Introducing Azure Functions to the Java Developer. Learn how to create and deploy your first Java Functions app, and where you can go from here.","tags":["serverless-september","azure-functions","java","serverless"]},"prevItem":{"title":"05. Functions for JS Devs","permalink":"/Cloud-Native/blog/05-functions-js"},"nextItem":{"title":"03. Build Your First Function","permalink":"/Cloud-Native/blog/03-functions-quickstart"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/04-functions-java\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Azure Functions: For The Java Developer\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions For The Java Developer\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/assets/images/post-kickoff-4a04995b44f0cc4a784fb4ab5e29cf7c.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/04-functions-java\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 4` of #30DaysOfServerless!\\n\\n_Yesterday_ we walked through an Azure Functions Quickstart with JavaScript, and used it to understand the general Functions App structure, tooling and developer experience. \\n\\n_Today_ we\'ll look at developing Functions app with a _different_ programming language - namely, **Java** - and explore developer guidance, tools and resources to build serverless Java solutions on Azure.\\n\\n---\\n\\n## What We\'ll Cover\\n * **Developer Guidance**: For Azure Functions on Java\\n * **Build & Deploy**: Our First Java Functions App\\n * **Usage Tutorials**: Integrate App with other Azure Services\\n * **Azure Samples**: Explore samples for other triggers, bindings\\n * **Exercise:** [Develop Java serverless Functions on Azure using Maven](https://docs.microsoft.com/learn/modules/develop-azure-functions-app-with-maven-plugin/) \\n * **Resources**: Check out [Java at Microsoft](https://developer.microsoft.com/java/) and use [Java Your Way](https://aka.ms/JavaYourWay)!\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Developer Guidance\\n\\nIf you\'re a Java developer new to serverless on Azure, start by exploring the [Azure Functions Java Developer Guide](https://docs.microsoft.com/azure/azure-functions/functions-reference-java?tabs=bash%2Cconsumption). It covers: \\n * Quickstarts with [Visual Studio Code](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-java) and [Azure CLI](https://docs.microsoft.com/azure/azure-functions/create-first-function-cli-java?tabs=bash%2Cazure-cli%2Cbrowser)\\n * Building with Maven-based tooling for [Gradle](https://docs.microsoft.com/azure/azure-functions/functions-create-first-java-gradle), [Eclipse](https://docs.microsoft.com/azure/azure-functions/functions-create-maven-eclipse) & [IntelliJ IDEA](https://docs.microsoft.com/azure/azure-functions/functions-create-maven-intellij)\\n * Exploring [project scaffolding](https://docs.microsoft.com/azure/azure-functions/functions-reference-java?tabs=bash%2Cconsumption#project-scaffolding) & [JDK runtimes](https://docs.microsoft.com/azure/azure-functions/functions-reference-java?tabs=bash%2Cconsumption#jdk-runtime-availability-and-support) (Java 8 and Java 11)\\n * Using [Java annotations for Triggers, Bindings](https://docs.microsoft.com/azure/azure-functions/functions-reference-java?tabs=bash%2Cconsumption#triggers-and-annotations) - with [reference](https://docs.microsoft.com/java/api/com.microsoft.azure.functions.annotation?view=azure-java-stable) docs.\\n * Adopting [best practices](https://docs.microsoft.com/azure/azure-functions/functions-best-practices?tabs=java) for hosting, reliability and efficiency.\\n * Java [code samples](https://docs.microsoft.com/samples/azure-samples/azure-functions-samples-java/azure-functions-java/) and [integration tutorials](https://docs.microsoft.com/azure/azure-functions/functions-event-hub-cosmos-db?tabs=bash)\\n\\nIn this blog post, we\'ll dive into one quickstart, and discuss other resources briefly, for awareness! Do check out the recommended exercises and resources for self-study! \\n\\n---\\n\\n## My First Java Functions App\\n\\nIn today\'s post, we\'ll walk through the [Quickstart: Azure Functions](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-java) tutorial using Visual Studio Code. In the process, we\'ll setup our development environment with the relevant command-line tools and VS Code extensions to make building Functions app simpler.\\n\\n_Note: Completing this exercise may incur a a cost of a few USD cents based on your Azure subscription. Explore [pricing details](https://azure.microsoft.com/pricing/details/functions/#pricing) to learn more_.\\n\\nFirst, make sure you have your development environment setup and configured.\\n\\n:::info PRE-REQUISITES\\n\\n 1. **An Azure account with an active subscription** - [Create an account for free](https://azure.microsoft.com/free/?ref=microsoft.com&utm_source=microsoft.com&utm_medium=docs&utm_campaign=visualstudio)\\n 2. **The Java Development Kit, version 11 or 8.** - [Install](https://docs.microsoft.com/azure/developer/java/fundamentals/java-support-on-azure)\\n 3. **Apache Maven, version 3.0 or above.** - [Install](https://maven.apache.org/)\\n 4. **Visual Studio Code.** - [Install](https://code.visualstudio.com/)\\n 5. **The Java extension pack** - [Install](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-pack)\\n 6. **The Azure Functions extension for Visual Studio Code** - [Install](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions)\\n:::\\n\\n\\n### VS Code Setup\\n\\n:::note NEW TO VISUAL STUDIO CODE?\\nStart with the [Java in Visual Studio Code](https://code.visualstudio.com/docs/languages/java) tutorial to jumpstart your learning!\\n:::\\n\\nInstall the [Extension Pack for Java](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-pack) (shown below) to install 6 popular extensions to help development workflow from creation to testing, debugging, and deployment.\\n\\n![Extension Pack for Java](./img/java-extensions.png)\\n\\nNow, it\'s time to get started on our first Java-based Functions app.\\n\\n\\n\\n### 1. Create App\\n\\n1. Open a command-line terminal and create a folder for your project. Use the `code` command to launch Visual Studio Code from that directory as shown:\\n\\n    ```bash\\n    $ mkdir java-function-resource-group-api\\n    $ cd java-function-resource-group-api\\n    $ code .\\n    ```\\n\\n2. Open the Visual Studio Command Palette (<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>p</kbd>) and select `Azure Functions: create new project` to kickstart the create workflow. Alternatively, you can click the Azure icon (on activity sidebar), to get the `Workspace` window,  click \\"+\\" and pick the \\"Create Function\\" option as shown below.\\n\\n    ![Screenshot of creating function in Azure from Visual Studio Code.](./img/32-create-new-project.png)\\n\\n3. This triggers a multi-step workflow. Fill in the information for each step as shown in the following prompts. **Important:** Start this process from an empty folder - the workflow will populate it with the scaffold for your Java-based Functions app.\\n\\n    |Prompt|Value|\\n    |--|--|\\n    |**Choose the directory location.**|You should either create a new folder or choose an empty folder for the project workspace. Don\'t choose a project folder that is already part of a workspace.|\\n    |**Select a language**| Choose `Java`.|\\n    |**Select a version of Java**| Choose `Java 11` or `Java 8`, the Java version on which your functions run in Azure. Choose a Java version that you\'ve verified locally. |\\n    | **Provide a group ID** | Choose `com.function`. |\\n    | **Provide an artifact ID** | Enter `myFunction`. |\\n    | **Provide a version** | Choose `1.0-SNAPSHOT`. |\\n    | **Provide a package name** | Choose `com.function`. |\\n    | **Provide an app name** | Enter `HttpExample`. |\\n    | **Select the build tool for Java project** | Choose `Maven`. |\\n\\n\\nVisual Studio Code uses the provided information and generates an Azure Functions project. You can view the local project files in the Explorer - it should look like this:\\n\\n![Azure Functions Scaffold For Java](./img/java-scaffold.png)\\n\\n### 2. Preview App\\n\\n\\nVisual Studio Code integrates with the Azure Functions Core tools to let you run this project on your local development computer before you publish to Azure.\\n\\n1. To build and run the application, use the following Maven command. You should see output similar to that shown below.\\n\\n  ```bash\\n  $ mvn clean package azure-functions:run\\n  ..\\n  ..\\n  Now listening on: http://0.0.0.0:7071\\n  Application started. Press Ctrl+C to shut down.\\n\\n  Http Functions:\\n\\n    HttpExample: [GET,POST] http://localhost:7071/api/HttpExample\\n  ...\\n  ```\\n\\n2. Copy the URL of your HttpExample function from this output to a browser and append the query string **?name=<YOUR_NAME>**, making the full URL something like `http://localhost:7071/api/HttpExample?name=Functions`. The browser should display a message that echoes back your query string value. The terminal in which you started your project also shows log output as you make requests.\\n\\n:::success \ud83c\udf89 CONGRATULATIONS\\nYou created and ran a function app locally!\\n:::\\n\\nWith the **Terminal** panel focused, press <kbd>Ctrl + C</kbd> to stop Core Tools and disconnect the debugger. After you\'ve verified that the function runs correctly on your local computer, it\'s time to use Visual Studio Code and Maven to publish and test the project on Azure.\\n\\n### 3. Sign into Azure\\n\\nBefore you can deploy, sign in to your Azure subscription.\\n\\n```bash\\naz login\\n```\\n\\nThe az login command signs you into your Azure account.\\n\\nUse the following command to deploy your project to a new function app.\\n\\n```bash\\nmvn clean package azure-functions:deploy\\n```\\n\\nWhen the creation is complete, the following Azure resources are created in your subscription:\\n\\n* Resource group. Named as java-functions-group.\\n* Storage account. Required by Functions. The name is generated randomly based on Storage account name requirements.\\n* Hosting plan. Serverless hosting for your function app.The name is *java-functions-app-service-plan*.\\n* Function app. A function app is the deployment and execution unit for your functions. The name is randomly generated based on your artifactId, appended with a randomly generated number.\\n\\n\\n### 4. Deploy App\\n\\n1. Back in the **Resources** area in the side bar, expand your subscription, your new function app, and **Functions**. Right-click (Windows) or <kbd>Ctrl -</kbd> click (macOS) the `HttpExample` function and choose **Execute Function Now...**.\\n\\n    ![Screenshot of executing function in Azure from Visual Studio Code.](./img/32-execute-function-now.png)\\n\\n2. In **Enter request body** you see the request message body value of `{ \\"name\\": \\"Azure\\" }`. Press Enter to send this request message to your function.\\n\\n3. When the function executes in Azure and returns a response, a notification is raised in Visual Studio Code.\\n\\nYou can also copy the complete Invoke URL shown in the output of the publish command into a browser address bar, appending the query parameter ?name=Functions. The browser should display similar output as when you ran the function locally.\\n\\n:::success \ud83c\udf89 CONGRATULATIONS\\nYou deployed your function app to Azure, and invoked it!\\n:::\\n\\n\\n### 5. Clean up\\n\\nUse the following command to delete the resource group and all its contained resources to avoid incurring further costs.\\n\\n```bash\\naz group delete --name java-functions-group\\n```\\n\\n## Next Steps\\n\\nSo, where can you go from here? The example above used a familiar `HTTP Trigger` scenario with a single Azure service (Azure Functions). Now, think about how you can build richer workflows by using other triggers and integrating with other Azure or third-party services.\\n\\n### Other Triggers, Bindings\\n\\nCheck out [Azure Functions Samples In Java](https://docs.microsoft.com/samples/azure-samples/azure-functions-samples-java/azure-functions-java/) for samples (and short use cases) that highlight other triggers - with code! This includes triggers to integrate with CosmosDB, Blob Storage, Event Grid, Event Hub, Kafka and more.\\n\\n### Scenario with Integrations\\n\\nOnce you\'ve tried out the samples, try building an end-to-end scenario by using these triggers to integrate seamlessly with other Services. Here are a couple of useful tutorials:\\n * Azure Functions with [Event Hub trigger and CosmosDB output binding](https://docs.microsoft.com/azure/azure-functions/functions-event-hub-cosmos-db?tabs=bash)\\n * GitHub Star Count app with [SignalR trigger](https://docs.microsoft.com/azure/azure-signalr/signalr-quickstart-azure-functions-java?toc=%2Fazure%2Fazure-functions%2Ftoc.json)\\n\\n\\n## Exercise\\n\\nTime to put this into action and validate your development workflow:\\n * Walk through this tutorial yourself, and deploy your first function!\\n * Complete the [Develop Java serverless Functions on Azure using Maven](https://docs.microsoft.com/learn/modules/develop-azure-functions-app-with-maven-plugin/) module\\n\\n## Resources\\n * [Azure Functions: Java Quickstarts](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-java)\\n * [Best Practices for Java Apps On Azure](https://docs.microsoft.com/learn/paths/best-practices-java-azure/)\\n * [Java at Microsoft](https://developer.microsoft.com/java/) \\n * [Java with EventHub Trigger and CosmosDB Binding](https://docs.microsoft.com/azure/azure-functions/functions-event-hub-cosmos-db?tabs=bash)\\n * [Java Integrations: Azure Functions and SignalR](https://docs.microsoft.com/azure/azure-signalr/signalr-quickstart-azure-functions-java?toc=%2Fazure%2Fazure-functions%2Ftoc.json)\\n * [Java Samples: Azure Functions](https://docs.microsoft.com/samples/browse/?products=azure-functions&languages=java)"},{"id":"03-functions-quickstart","metadata":{"permalink":"/Cloud-Native/blog/03-functions-quickstart","source":"@site/blog/2022-09-03/index.md","title":"03. Build Your First Function","description":"Let\'s build our first Azure Functions app - and get familiar with the relevant developer tools and resources!","date":"2022-09-03T00:00:00.000Z","formattedDate":"September 3, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"},{"label":"vscode","permalink":"/Cloud-Native/blog/tags/vscode"},{"label":"devtools","permalink":"/Cloud-Native/blog/tags/devtools"}],"readingTime":8.155,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"}],"frontMatter":{"slug":"03-functions-quickstart","title":"03. Build Your First Function","authors":["nitya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Let\'s build our first Azure Functions app - and get familiar with the relevant developer tools and resources!","tags":["serverless-september","30-days-of-serverless","azure-functions","vscode","devtools"]},"prevItem":{"title":"04. Functions For Java Devs","permalink":"/Cloud-Native/blog/04-functions-java"},"nextItem":{"title":"02. Learn Core Concepts","permalink":"/Cloud-Native/blog/02-functions-intro"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/03-functions-quickstart\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Build Your First Function\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Build Your First Function\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/03-functions-quickstart\\" />\\n</head>\\n\\n---\\n\\nWelcome to `Day 3` of #30DaysOfServerless!\\n\\n_Yesterday_ we learned core concepts and terminology for Azure Functions, the signature _Functions-as-a-Service_ option on Azure. _Today_ we take our first steps into building and deploying an Azure Functions app, and validate local development setup.\\n\\nReady? Let\'s go.\\n\\n---\\n\\n## What We\'ll Cover\\n\\n * Review the [Azure Functions Developer Guide](https://docs.microsoft.com/azure/azure-functions/functions-reference?tabs=blob&WT.mc_id=javascript-99907-ninarasi)\\n * Build your first Function App [with VS Code](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-node?WT.mc_id=javascript-99907-ninarasi)\\n * Develop locally [using Azure Functions Core Tools](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2)\\n * Review [Local Testing & Development](https://docs.microsoft.com/azure/azure-functions/functions-develop-local?WT.mc_id=javascript-99907-ninarasi) guidelines\\n * Check out the [Durable Functions Quickstart](https://docs.microsoft.com/azure/azure-functions/durable/quickstart-js-vscode?WT.mc_id=javascript-99907-ninarasi)\\n * **Exercise**: Take the [Cloud Skills Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi)!\\n * **Resources**: [#30DaysOfServerless Collection](https://aka.ms/30DaysOfServerless/collection).\\n\\n![](./img/banner.png)\\n\\n---\\n\\n## Developer Guidance\\n\\nBefore we jump into development, let\'s familiarize ourselves with language-specific guidance from the Azure Functions Developer Guide. We\'ll review the [JavaScript version](https://docs.microsoft.com/azure/azure-functions/functions-reference?tabs=blob&WT.mc_id=javascript-99907-ninarasi) but guides for F#, Java, Python, C# and PowerShell are also available.\\n\\n 1. A **function** is defined by two things: _code_ (written in a supported programming language) and _configuration_ (specified in a `functions.json` file, declaring the triggers, bindings and other context for execution).\\n\\n 2. A **function app** is the _unit of deployment_ for your functions, and is associated with a single execution context or runtime. It can contain multiple functions, but they _must_ be in the same language. \\n\\n 3. A **host configuration** is _runtime-specific configuration_ that affects all functions running in a given function app instance. It is defined in a `host.json` file.\\n\\n 4. A recommended **folder structure** is defined for the function app, but may vary based on the programming language used. Check [the documentation on folder structures](https://docs.microsoft.com/azure/azure-functions/functions-reference?tabs=blob#folder-structure&WT.mc_id=javascript-99907-ninarasi) to learn the default for _your_ preferred language.\\n\\nHere\'s an [example of the JavaScript folder structure](https://docs.microsoft.com/azure/azure-functions/functions-reference-node?WT.mc_id=javascript-99907-ninarasi) for a function app containing two functions with some shared dependencies. Note that `host.json` (runtime configuration) is defined once, in the root directory. And `function.json` is defined separately for each function.\\n\\n```\\nFunctionsProject\\n | - MyFirstFunction\\n | | - index.js\\n | | - function.json\\n | - MySecondFunction\\n | | - index.js\\n | | - function.json\\n | - SharedCode\\n | | - myFirstHelperFunction.js\\n | | - mySecondHelperFunction.js\\n | - node_modules\\n | - host.json\\n | - package.json\\n | - local.settings.json\\n```\\n\\nWe\'ll dive into what the contents of these files look like, when we build and deploy the first function. We\'ll cover `local.settings.json` in the _About Local Testing_ section at the end.\\n\\n---\\n\\n## My First Function App\\n\\nThe documentation provides **quickstart** options for all supported languages. We\'ll walk through the _JavaScript_ versions in this article. You have two options for development: \\n  * using [Visual Studio Code](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-node) for an IDE-driven experience\\n  * using [Azure CLI](https://docs.microsoft.com/azure/azure-functions/create-first-function-cli-node?tabs=azure-cli%2Cbrowser) for a commandline-driven experience.\\n\\nI\'m a huge fan of VS Code - so I\'ll be working through that tutorial today. \\n\\n:::info PRE-REQUISITES\\n\\n * Have an Azure account (with active subscription) | **[Create one for free](https://azure.microsoft.com/free/?ref=microsoft.com&utm_source=microsoft.com&utm_medium=docs&utm_campaign=visualstudio)**\\n * Install Azure Functions Core Tools | **[Verify it\'s version 4.x](https://docs.microsoft.com/azure/azure-functions/functions-run-local#v2)**\\n * Install Azure Functions VS Code Extension | **[Currently v 1.7.4](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions)**\\n * Install Node.js v16 or v18 (preview) | **[Manage versions with NVM](https://github.com/nvm-sh/nvm)**\\n\\nDon\'t forget to validate your setup by checking the versions of installed software.\\n:::\\n\\n### Install VSCode Extension\\nInstalling the Visual Studio Code extension should automatically open this page in your IDE with similar quickstart instructions, but potentially more recent screenshots.\\n\\n![Visual Studio Code Extension for VS Code](./img/vscode.png)\\n\\n Note that it may make sense to install the [Azure tools for Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=ms-vscode.vscode-node-azure-pack) extensions pack if you plan on working through the many projects in Serverless September. This includes the Azure Functions extension by default.\\n\\n### Create First Function App\\n\\nWalk through the [Create local [project]](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-node#create-an-azure-functions-project) steps of the quickstart. The process is quick and painless and scaffolds out this folder structure and files. Note the existence (and locations) of `functions.json` and `host.json` files.\\n\\n ![Final screenshot for VS Code workflow](./img/vscode-6.png)\\n\\n### Explore the Code\\n\\n**Check out the `functions.json` configuration file.** It shows that the function is activated by an `httpTrigger` with an input binding (tied to `req` payload) and an output binding (tied to `res` payload). And it supports both GET and POST requests on the exposed URL.\\n\\n```json\\n{\\n  \\"bindings\\": [\\n    {\\n      \\"authLevel\\": \\"anonymous\\",\\n      \\"type\\": \\"httpTrigger\\",\\n      \\"direction\\": \\"in\\",\\n      \\"name\\": \\"req\\",\\n      \\"methods\\": [\\n        \\"get\\",\\n        \\"post\\"\\n      ]\\n    },\\n    {\\n      \\"type\\": \\"http\\",\\n      \\"direction\\": \\"out\\",\\n      \\"name\\": \\"res\\"\\n    }\\n  ]\\n}\\n```\\n\\n**Check out `index.js` - the function implementation**. We see it logs a message to the console when invoked. It then extracts a `name` value from the input payload (req) and crafts a different `responseMessage` based on the presence/absence of a valid name. It returns this response in the output payload (res).\\n\\n```js\\nmodule.exports = async function (context, req) {\\n    context.log(\'JavaScript HTTP trigger function processed a request.\');\\n\\n    const name = (req.query.name || (req.body && req.body.name));\\n    const responseMessage = name\\n        ? \\"Hello, \\" + name + \\". This HTTP triggered function executed successfully.\\"\\n        : \\"This HTTP triggered function executed successfully. Pass a name in the query string or in the request body for a personalized response.\\";\\n\\n    context.res = {\\n        // status: 200, /* Defaults to 200 */\\n        body: responseMessage\\n    };\\n}\\n```\\n\\n### Preview Function App Locally\\n\\nYou can now run this function app locally using [Azure Functions Core Tools](https://docs.microsoft.com/azure/azure-functions/functions-run-local). VS Code integrates seamlessly with this CLI-based tool, making it possible for you to exploit all its capabilities without leaving the IDE. In fact, the workflow will even prompt you to _install_ those tools if they didn\'t already exist in your local dev environment.\\n\\nNow run the function app locally by clicking on the \\"Run and Debug\\" icon in the activity bar (highlighted, left) and pressing the \\"\u25b6\ufe0f\\" (`Attach to Node Functions`) to start execution. On success, your console output should show something like this. \\n\\n ![Final screenshot for VS Code workflow](./img/vscode-7.png)\\n\\nYou can test the function locally by visiting the Function Url shown (`http://localhost:7071/api/HttpTrigger1`) or by opening the _Workspace_ region of the Azure extension, and selecting the `Execute Function now` menu item as shown.\\n\\n ![Final screenshot for VS Code workflow](./img/vscode-8.png)\\n\\nIn the latter case, the `Enter request body` popup will show a pre-populated request of `{\\"name\\":\\"Azure\\"}` that you can submit. \\n\\n ![Final screenshot for VS Code workflow](./img/vscode-9.png)\\n \\n On successful execution, your VS Code window will show a notification as follows. Take note of the console output - it shows the message encoded in `index.js`.\\n\\n ![Final screenshot for VS Code workflow](./img/vscode-10.png)\\n\\nYou can also visit the deployed function URL directly in a local browser - testing the case for a request made with no `name` payload attached. Note how the response in the browser now shows the non-personalized version of the message!\\n\\n ![Final screenshot for VS Code workflow](./img/vscode-11.png)\\n\\n\\n:::success \ud83c\udf89 **Congratulations**\\nYou created and ran a function app locally!\\n:::\\n\\n### (Re)Deploy to Azure\\n\\nNow, just follow the [creating a function app in Azure](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-node#publish-the-project-to-azure) steps to deploy it to Azure, using an active subscription! The deployed app resource should now show up under the `Function App` Resources where you can click `Execute Function Now` to test the Azure-deployed version instead. You can also look up the function URL in the portal and visit that link in your local browser to trigger the function without the name context.\\n\\n\\n:::success \ud83c\udf89 **Congratulations**\\nYou have an Azure-hosted serverless function app!\\n:::\\n\\n\\nChallenge yourself and try to [change the code and redeploy](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-node#run-the-function-in-azure) to Azure to return something different. _You have effectively created a serverless API endpoint!_ \\n\\n---\\n\\n## About Core Tools\\n\\nThat was a lot to cover! In the next few days we\'ll have more examples for Azure Functions app development - focused on different programming languages. So let\'s wrap today\'s post by reviewing two helpful resources.\\n\\nFirst, let\'s talk about [Azure Functions Core Tools](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2) - the command-line tool that lets you develop, manage, and deploy, Azure Functions projects from your **local development environment**. It is used transparently by the VS Code extension - but you can use it directly from a terminal for a powerful command-line end-to-end developer experience! The Core Tools commands are organized into the following contexts:\\n \\n  * [`func`](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2#func-init) - commands to create and run functions locally\\n  * [`func azure`](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2#func-azure-functionapp-fetch-app-settings) - work with resource slike Azure Functions and Azure Storage\\n  * [`func durable`](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2#func-durable-delete-task-hub) - work with Durable Functions\\n  * [`func extensions`](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2#func-extensions-install) - manage extensions (default nuget.org)\\n  * [`func kubernetes`](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2#func-kubernetes-deploy) - work with Kubernetes and Azure Functions\\n  * [`func settings`](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2#func-settings-decrypt) - manage environment settings for local Functions host\\n  * [`func templates`](https://docs.microsoft.com/azure/azure-functions/functions-core-tools-reference?tabs=v2#func-templates-list) - list available templates\\n\\nLearn how to [work with Azure Functions Core Tools](https://docs.microsoft.com/azure/azure-functions/functions-run-local?tabs=v4%2Cmacos%2Ccsharp%2Cportal%2Cbash). Not only can it help with quick command execution, it can also be invaluable for debugging issues that may not always be visible or understandable in an IDE.\\n\\n## About Local Testing\\n\\nYou might have noticed that the scaffold also produced a `local.settings.json` file. What is that and why is it useful? By definition, the local.settings.json file _\\"stores app settings and settings used by local development tools. Settings in the local.settings.json file are used only when you\'re running your project locally.\\"_\\n\\nRead the guidance on [Code and test Azure Functions Locally](https://docs.microsoft.com/azure/azure-functions/functions-develop-local?WT.mc_id=javascript-99907-ninarasi#local-settings-file) to learn more about how to configure development environments locally, for your preferred programming language, to support testing and debugging on the local Functions runtime.\\n\\n## Exercise\\nWe made it! Now it\'s your turn!! Here are a few things you can try to apply what you learned and reinforce your understanding:\\n * Walk through this quickstart on your own!\\n * Then try the [Durable Functions Quickstart](https://docs.microsoft.com/azure/azure-functions/durable/quickstart-js-vscode?WT.mc_id=javascript-99907-ninarasi) as a stretch goal!\\n * And take the [Cloud Skills Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi) to skill up in fun ways\\n\\n## Resources\\n\\nBookmark and visit the [#30DaysOfServerless Collection](https://aka.ms/30DaysOfServerless/collection). It\'s the one-stop collection of resources we will keep updated with links to relevant documentation and learning resources."},{"id":"02-functions-intro","metadata":{"permalink":"/Cloud-Native/blog/02-functions-intro","source":"@site/blog/2022-09-02/index.md","title":"02. Learn Core Concepts","description":"Introduction to Azure Functions, from core concepts to hello world!","date":"2022-09-02T00:00:00.000Z","formattedDate":"September 2, 2022","tags":[{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"},{"label":"30-days-of-serverless","permalink":"/Cloud-Native/blog/tags/30-days-of-serverless"},{"label":"azure-functions","permalink":"/Cloud-Native/blog/tags/azure-functions"}],"readingTime":8.16,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"}],"frontMatter":{"slug":"02-functions-intro","title":"02. Learn Core Concepts","authors":["nitya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"],"image":"./img/banner.png","description":"Introduction to Azure Functions, from core concepts to hello world!","tags":["serverless-september","30-days-of-serverless","azure-functions"]},"prevItem":{"title":"03. Build Your First Function","permalink":"/Cloud-Native/blog/03-functions-quickstart"},"nextItem":{"title":"01. It\'s 30DaysOfServerless!","permalink":"/Cloud-Native/blog/01-kickoff"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/blog/functions-1\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"#30DaysOfServerless: Azure Functions Fundamentals\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/banners/post-kickoff.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/blog/02-functions-intro\\" />\\n</head>\\n\\n---\\n\\nWelcome to Day 2\ufe0f\u20e3 of #30DaysOfServerless!\\n\\nToday, we kickstart our journey into serveless on Azure with a look at _Functions As a Service_. We\'ll explore Azure Functions - from core concepts to usage patterns. \\n\\nReady? Let\'s Go!\\n\\n---\\n\\n## What We\'ll Cover\\n * What is Functions-as-a-Service? (FaaS)\\n * What is Azure Functions?\\n * Triggers, Bindings and Custom Handlers\\n * What is Durable Functions?\\n * Orchestrators, Entity Functions and Application Patterns\\n * **Exercise**: Take the [Cloud Skills Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi)!\\n * **Resources**: [#30DaysOfServerless Collection](https://aka.ms/30DaysOfServerless/collection).\\n\\n![](./img/banner.png)\\n\\n---\\n\\n\\n## 1. What is FaaS?\\n\\nFaas stands for [Functions As a Service (FaaS)](https://docs.microsoft.com/azure/architecture/guide/technology-choices/compute-decision-tree?WT.mc_id=javascript-99907-ninarasi ). But what does that mean for us as application developers? We know that \\nbuilding and deploying modern applications **at scale** can get _complicated_ and it starts with us needing to take decisions on _Compute_. In other words, we need to answer this question: \\"**where should I host my application given my resource dependencies and scaling requirements?**\\" \\n\\n![this useful flowchart](./img/compute-choices.png )\\n\\nAzure has [this useful flowchart](https://docs.microsoft.com/azure/architecture/guide/technology-choices/compute-decision-tree?WT.mc_id=javascript-99907-ninarasi ) (shown below) to guide your decision-making. You\'ll see that hosting options generally fall into three categories:\\n * **Infrastructure as a Service (IaaS)** - where you provision and manage Virtual Machines yourself (cloud provider manages infra).\\n * **Platform as a Service (PaaS)** - where you use a provider-_managed_ hosting environment like Azure Container Apps.\\n * **Functions as a Service (FaaS)** - where you forget about hosting environments and simply _deploy your code_ for the provider to run.\\n\\nHere, \\"serverless\\" compute refers to hosting options where we (as developers) can focus on building apps _without having to manage the infrastructure_. See [serverless compute options on Azure](https://azure.microsoft.com/solutions/serverless/?WT.mc_id=javascript-99907-ninarasi ) for more information.\\n\\n---\\n\\n## 2. Azure Functions\\n\\n[Azure Functions](https://docs.microsoft.com/azure/azure-functions/?WT.mc_id=javascript-99907-ninarasi ) is the Functions-as-a-Service (FaaS) option on Azure. It is the ideal serverless solution if your application is event-driven with short-lived workloads. With Azure Functions, we develop applications as modular blocks of code (`functions`) that are executed on demand, in response to configured events (`triggers`). This approach brings us two advantages:\\n * _It saves us money._ We only pay for the time the function runs.\\n * _It scales with demand._ We have 3 hosting plans for flexible scaling behaviors.\\n\\nAzure Functions can be programmed in many popular languages (C#, F#, Java, JavaScript, TypeScript, PowerShell or Python), with Azure providing [language-specific](https://docs.microsoft.com/azure/azure-functions/supported-languages?WT.mc_id=javascript-99907-ninarasi ) handlers and default [runtimes](https://docs.microsoft.com/azure/azure-functions/supported-languages#languages-by-runtime-version?WT.mc_id=javascript-99907-ninarasi ) to execute them.\\n\\n:::tip Concept: Custom Handlers\\n\\n* What if we wanted to program in a non-supported language? \\n* Or we wanted to use a different runtime for a supported language? \\n:::\\n\\n**[Custom Handlers](https://docs.microsoft.com/azure/azure-functions/functions-custom-handlers?WT.mc_id=javascript-99907-ninarasi )** have you covered! These are lightweight webservers that can receive and process input events from the Functions host - and return responses that can be delivered to any output targets. By this definition, custom handlers can be implemented by _any language that supports receiving HTTP events_. Check out [the quickstart for writing a custom handler](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-other?tabs=go%2Cmacos&WT.mc_id=javascript-99907-ninarasi ) in Rust or Go.\\n\\n![Custom Handlers](./img/azure-functions-custom-handlers-overview.png)\\n\\n\\n:::tip Concept: Trigger and Bindings\\n\\nWe talked about what functions are (code blocks). But when are they invoked or executed? And how do we provide inputs (arguments) and retrieve outputs (results) from this execution?\\n:::\\n\\nThis is where **triggers** and **bindings** come in.\\n\\n * `Triggers` define how a function is invoked and what associated data it will provide. _A function must have exactly one trigger_.\\n * `Bindings` _declaratively_ define how a resource is connected to the function. The resource or binding can be of type input, output, or both. _Bindings are optional. A Function can have multiple input, output bindings_.\\n\\nAzure Functions comes with a number of [supported bindings](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=csharp#supported-bindings&WT.mc_id=javascript-99907-ninarasi) that can be used to integrate relevant services to power a specific scenario. For instance:\\n * [HTTP Triggers](https://docs.microsoft.com/azure/azure-functions/functions-bindings-http-webhook?tabs=in-process%2Cfunctionsv2&pivots=programming-language-javascript&WT.mc_id=javascript-99907-ninarasi) - invokes the function in response to an `HTTP request`. Use this to implement serverless APIs for your application.\\n * [Event Grid Triggers](https://docs.microsoft.com/azure/azure-functions/functions-bindings-event-grid?tabs=in-process%2Cextensionv3&pivots=programming-language-javascript&WT.mc_id=javascript-99907-ninarasi) invokes the function on receiving events from an Event Grid. Use this to process events reactively, and potentially publish responses back to custom Event Grid topics.\\n * [SignalR Service Trigger](https://docs.microsoft.com/azure/azure-functions/functions-bindings-signalr-service-trigger?tabs=in-process&pivots=programming-language-javascript&WT.mc_id=javascript-99907-ninarasi) invokes the function in response to messages from Azure SignalR, allowing your application to take actions with _real-time contexts_.\\n\\nTriggers and bindings help you abstract your function\'s interfaces to other components it interacts with, eliminating hardcoded integrations. They are [configured differently based on the programming language](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=csharp#trigger-and-binding-definitions&WT.mc_id=javascript-99907-ninarasi ) you use. For example - JavaScript functions are configured in the [functions.json](https://docs.microsoft.com/azure/azure-functions/functions-reference?tabs=blob#function-code?WT.mc_id=javascript-99907-ninarasi ) file. Here\'s an example of what that looks like.\\n\\n\\n```js\\n{\\n    \\"disabled\\":false,\\n    \\"bindings\\":[\\n        // ... bindings here\\n        {\\n            \\"type\\": \\"bindingType\\",\\n            \\"direction\\": \\"in\\",\\n            \\"name\\": \\"myParamName\\",\\n            // ... more depending on binding\\n        }\\n    ]\\n}\\n```\\n\\nThe key thing to remember is that triggers and bindings have a `direction` property - triggers are always `in`, input bindings are `in` and output bindings are `out`. Some bindings can support a special `inout` direction. \\n\\nThe documentation has [code examples](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=javascript#supported-bindings&WT.mc_id=javascript-99907-ninarasi ) for bindings to popular Azure services. Here\'s an example of the bindings and trigger configuration for a [BlobStorage](https://docs.microsoft.com/azure/azure-functions/functions-bindings-storage-blob-input?tabs=in-process%2Cextensionv5&pivots=programming-language-javascript#example&WT.mc_id=javascript-99907-ninarasi ) use case.\\n\\n```js\\n// function.json configuration\\n\\n{\\n  \\"bindings\\": [\\n    {\\n      \\"queueName\\": \\"myqueue-items\\",\\n      \\"connection\\": \\"MyStorageConnectionAppSetting\\",\\n      \\"name\\": \\"myQueueItem\\",\\n      \\"type\\": \\"queueTrigger\\",\\n      \\"direction\\": \\"in\\"\\n    },\\n    {\\n      \\"name\\": \\"myInputBlob\\",\\n      \\"type\\": \\"blob\\",\\n      \\"path\\": \\"samples-workitems/{queueTrigger}\\",\\n      \\"connection\\": \\"MyStorageConnectionAppSetting\\",\\n      \\"direction\\": \\"in\\"\\n    },\\n    {\\n      \\"name\\": \\"myOutputBlob\\",\\n      \\"type\\": \\"blob\\",\\n      \\"path\\": \\"samples-workitems/{queueTrigger}-Copy\\",\\n      \\"connection\\": \\"MyStorageConnectionAppSetting\\",\\n      \\"direction\\": \\"out\\"\\n    }\\n  ],\\n  \\"disabled\\": false\\n}\\n```\\nThe code below shows the function implementation. In this scenario, the function is triggered by a _queue message_ carrying an _input payload_ with a blob name. In response, it copies that data to the resource associated with the _output binding_.\\n\\n```js\\n// function implementation\\n\\nmodule.exports = async function(context) {\\n    context.log(\'Node.js Queue trigger function processed\', context.bindings.myQueueItem);\\n    context.bindings.myOutputBlob = context.bindings.myInputBlob;\\n};\\n```\\n\\n\\n:::tip Concept: Custom Bindings\\n\\nWhat if we have a more complex scenario that requires bindings for non-supported resources? \\n:::\\n\\nThere is an option create custom bindings if necessary. We don\'t have time to dive into details here but definitely check out the [documentation](https://github.com/Azure/azure-webjobs-sdk/wiki/Creating-custom-input-and-output-bindings)\\n\\n---\\n\\n## 3. Durable Functions\\n\\nThis sounds great, right?. But now, let\'s talk about one challenge for Azure Functions. In the use cases so far, the functions are _stateless_ - they take inputs at runtime if necessary, and return output results if required. But they are otherwise self-contained, which is great for scalability!\\n\\nBut what if I needed to build more complex _workflows_ that need to store and transfer state, and complete operations in a reliable manner? [Durable Functions](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=csharp&WT.mc_id=javascript-99907-ninarasi ) are an extension of Azure Functions that makes _stateful workflows_ possible.\\n\\n:::tip Concept: Orchestrator Functions\\n\\nHow can I create workflows that coordinate functions?\\n:::\\n\\nDurable Functions use [orchestrator functions](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-orchestrations?tabs=csharp&WT.mc_id=javascript-99907-ninarasi ) to coordinate execution of other Durable functions within a given Functions app. These functions are _durable and reliable_. Later in this post, we\'ll talk briefly about some application patterns that showcase popular orchestration scenarios.\\n\\n:::tip Concept:  Entity Functions\\nHow do I persist and manage state across workflows?\\n:::\\n\\nEntity Functions provide explicit _state mangement_ for Durable Functions, defining operations to read and write state to _durable entities_. They are associated with a special _entity trigger_ for invocation. These are currently available only for a subset of programming languages so check to see if they are supported for your programming language of choice.\\n\\n:::tip USAGE: Application Patterns\\n:::\\n\\nDurable Functions are a fascinating topic that would require a separate, longer post, to do justice. For now, \\nlet\'s look at some [application patterns](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-entities?tabs=csharp&WT.mc_id=javascript-99907-ninarasi ) that showcase the value of these starting with the simplest one - [Function Chaining](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=csharp#chaining&WT.mc_id=javascript-99907-ninarasi ) as shown below:\\n\\n![Function Chaining](./img/function-chaining.png )\\n\\n Here, we want to execute a sequence of named functions _in a specific order_. As shown in the snippet below, the orchestrator function coordinates invocations on the given functions in the desired sequence - \\"chaining\\" inputs and outputs to establish the workflow. Take note of the `yield` keyword. This triggers a checkpoint, preserving the current state of the function for reliable operation.\\n\\n\\n```\\nconst df = require(\\"durable-functions\\");\\n\\nmodule.exports = df.orchestrator(function*(context) {\\n    try {\\n        const x = yield context.df.callActivity(\\"F1\\");\\n        const y = yield context.df.callActivity(\\"F2\\", x);\\n        const z = yield context.df.callActivity(\\"F3\\", y);\\n        return    yield context.df.callActivity(\\"F4\\", z);\\n    } catch (error) {\\n        // Error handling or compensation goes here.\\n    }\\n});\\n```\\n\\nOther application patterns for durable functions include:\\n * [Fan-out/fan-in](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=javascript#fan-in-out&WT.mc_id=javascript-99907-ninarasi )\\n * [Async HTTP APIs](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=javascript#async-http&WT.mc_id=javascript-99907-ninarasi )\\n * [Monitoring](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=javascript#monitoring&WT.mc_id=javascript-99907-ninarasi )\\n * [Human Interaction](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=javascript#human&WT.mc_id=javascript-99907-ninarasi )\\n * [Aggregator (stateful entities)](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview?tabs=javascript#aggregator&WT.mc_id=javascript-99907-ninarasi )\\n\\nThere\'s a lot more to explore but we won\'t have time to do that today. Definitely [check the documentation](https://docs.microsoft.com/azure/azure-functions/durable/?WT.mc_id=javascript-99907-ninarasi ) and take a minute to read the [comparison with Azure Logic Apps](https://docs.microsoft.com/azure/azure-functions/functions-compare-logic-apps-ms-flow-webjobs#compare-azure-functions-and-azure-logic-apps?WT.mc_id=javascript-99907-ninarasi ) to understand what each technology provides for serverless workflow automation.\\n\\n---\\n\\n## 4. Exercise\\n\\nThat was a lot of information to absorb! Thankfully, there are a lot of examples in the documentation that can help put these in context. Here are a couple of exercises you can do, to reinforce your understanding of these concepts.\\n\\n* Explore the [supported bindings](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=csharp#supported-bindings&WT.mc_id=javascript-99907-ninarasi ) for Azure Functions.\\n* Look at [code examples](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=javascript#bindings-code-examples&WT.mc_id=javascript-99907-ninarasi ), think of usage scenarios.\\n\\n---\\n\\n## 5. What\'s Next?\\n\\nThe goal for today was to give you a quick tour of key terminology and concepts related to Azure Functions. Tomorrow, we dive into _the developer experience_, starting with core tools for local development and ending by deploying our first Functions app.\\n\\nWant to do some prep work? Here are a few useful links:\\n- [Azure Functions Quickstart](https://docs.microsoft.com/azure/azure-functions/create-first-function-vs-code-node?WT.mc_id=javascript-99907-ninarasi )\\n- [Durable Functions Quickstart](https://docs.microsoft.com/azure/azure-functions/durable/quickstart-js-vscode)\\n- [Azure Functions VS Code Extension](https://docs.microsoft.com/azure/azure-functions/functions-develop-vs-code?tabs=csharp&WT.mc_id=javascript-99907-ninarasi )\\n- [Azure Functions Core Tools](https://docs.microsoft.com/azure/azure-functions/functions-triggers-bindings?tabs=javascript#bindings-code-examples&WT.mc_id=javascript-99907-ninarasi )\\n\\n\\n---\\n\\n## 6. Resources\\n* Developer Guide: [Azure Functions](https://docs.microsoft.com/azure/azure-functions/functions-reference?tabs=blob)\\n* Azure Functions: [Tutorials](https://docs.microsoft.com/azure/azure-functions/functions-twitter-email) and [Samples](https://docs.microsoft.com/samples/browse/?products=azure-functions&languages=javascript)\\n* Durable Functions: [Tutorials](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-sequence?tabs=javascript) and [Samples](https://docs.microsoft.com/samples/browse/?products=azure-functions&term=durable&terms=durable&languages=javascript) \\n* Self-Paced Learning: [MS Learn Modules](https://docs.microsoft.com/learn/browse/?products=azure-functions&filter-products=Functions)\\n* Video Playlists: [Azure Functions on YouTube ](https://www.youtube.com/c/AzureFunctions)\\n\\n---"},{"id":"01-kickoff","metadata":{"permalink":"/Cloud-Native/blog/01-kickoff","source":"@site/blog/2022-09-01/index.md","title":"01. It\'s 30DaysOfServerless!","description":"What We\'ll Cover","date":"2022-09-01T00:00:00.000Z","formattedDate":"September 1, 2022","tags":[{"label":"hello","permalink":"/Cloud-Native/blog/tags/hello"},{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"}],"readingTime":4.24,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"},{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://github.com/devanshidiaries.png","key":"devanshi"}],"frontMatter":{"slug":"01-kickoff","title":"01. It\'s 30DaysOfServerless!","authors":["nitya","devanshi"],"draft":false,"tags":["hello","serverless-september"],"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["azure","functions","serverless","concepts"]},"prevItem":{"title":"02. Learn Core Concepts","permalink":"/Cloud-Native/blog/02-functions-intro"},"nextItem":{"title":"Welcome Students!","permalink":"/Cloud-Native/blog/students"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" content=\\"https://azure.github.io/Cloud-Native/blog/01-kickoff\\" />\\n  <meta name=\\"twitter:title\\" content=\\"#01 - It\'s 30DaysOfServerless!\\" />\\n  <meta name=\\"twitter:description\\" content=\\"Join #ServerlessSeptember as we kickoff #30DaysOfServerless with a look at @AzureFunctions and more. Visit https://aka.ms/serverless-september\\" />\\n  <meta name=\\"twitter:image\\" content=\\"https://azure.github.io/Cloud-Native/assets/images/post-kickoff-4a04995b44f0cc4a784fb4ab5e29cf7c.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureStaticApps\\" /> \\n</head>\\n\\n\\n## What We\'ll Cover\\n * What is Serverless September? (6 initiatives)\\n * How can I _participate_? (3 actions)\\n * How can I _skill up_ (30 days)\\n * Who is behind this? (Team Contributors)\\n * How can _you_ contribute? (Custom Issues)\\n * **Exercise**: Take the [Cloud Skills Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi)!\\n * **Resources**: [#30DaysOfServerless Collection](https://aka.ms/30DaysOfServerless/collection).\\n\\n---\\n\\n![Serverless September](../../static/img/banners/post-kickoff.png)\\n\\n\\nWelcome to `Day 01` of [\ud83c\udf42 #ServerlessSeptember](https://aka.ms/serverless-september)! Today, we kick off a full month of content and activities to skill you up on all things Serverless on Azure with content, events, and community interactions! Read on to learn about what we have planned!\\n\\n---\\n\\n## Explore our initiatives\\n\\nWe have a number of initiatives planned for the month to help you learn and skill up on relevant technologies. Click on the links to visit the relevant pages for each. \\n\\n* [#30DaysOfServerless](/serverless-september/30DaysOfServerless) - 4 themed weeks of daily articles in a structured roadmap\\n* [Zero To Hero](/serverless-september/ZeroToHero) - 4-part series from Product Engineering teams on best practices\\n* [Serverless Hacks](/serverless-september/ServerlessHacks) - build a serverless tollbooth by solving 8 challenges - with help!\\n* [Cloud Skills Challenge](/serverless-september/30DaysOfServerless) - skill up by competing with peers to complete modules\\n* [Ask The Expert](/serverless-september/AskTheExpert/) - join live Q&A sessions with Product Engineering teams\\n* [Community Buzz](https://github.com/Azure/Cloud-Native/issues/new/choose) - participate by submitting questions, or contributing content\\n\\nWe\'ll go into more details about **#30DaysOfServerless** in this post - don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/blog/rss.xml) to the blog to get daily posts delivered directly to your preferred feed reader!\\n\\n---\\n\\n## Register for events!\\n\\nWhat are 3 things you can do today, to jumpstart your learning journey?\\n\\n * **Register** for live Q&A sessions (free, online)\\n    - Sep 15 - [Ask The Expert: Azure Functions](https://reactor.microsoft.com/reactor/events/17000/)\\n    - Sep 29 - [Ask the Expert: Azure Container Apps](https://reactor.microsoft.com/reactor/events/17000/)\\n  * **Register** for the [Cloud Skills Challenge](https://docs.microsoft.com/learn/challenges?id=b950cd7a-d456-46ab-81ba-3bd1ad86dc1c&WT.mc_id=javascript-99907-ninarasi) - 30 days to complete it!\\n * **Register** for the [Serverless Hacks Challenge](https://docs.microsoft.com/events/learn-events/reactor-serverlessseptember/?wt.mc_id=eventspg_16946_webpage_reactor&WT.mc_id=javascript-99907-ninarasi) office hours (weekly)\\n\\n![Serverless Hacks](../../static/img/banners/serverless-hacks.png)\\n\\n---\\n\\n## #30DaysOfServerless\\n\\n[#30DaysOfServerless](/serverless-september/30DaysOfServerless) is a month-long series of daily blog posts grouped into 4 themed weeks - taking you from core concepts to end-to-end solution examples in 30 days. Each article will be short (5-8 mins reading time) and provide exercises and resources to help you reinforce learnings and take next steps.\\n\\nThis series focuses on the [Serverless On Azure](https://azure.microsoft.com/solutions/serverless/?WT.mc_id=javascript-99907-ninarasi) learning journey in **four stages**, each building on the previous week to help you skill up in a beginner-friendly way:\\n * **Week 1:** Get started with serverless using [Azure Functions](https://docs.microsoft.com/azure/azure-functions/functions-overview?WT.mc_id=javascript-99907-ninarasi) \\n * **Week 2:** Build & deploy microservices with [Azure Container Apps](https://docs.microsoft.com/azure/container-apps/overview?WT.mc_id=javascript-99907-ninarasi) and [Dapr](https://dapr.io/?WT.mc_id=javascript-99907-ninarasi).\\n * **Week 3:** Streamline integrations using [Azure Logic Apps](https://docs.microsoft.com/azure/logic-apps/?WT.mc_id=javascript-99907-ninarasi) and [Azure Event Grid](https://docs.microsoft.com/azure/event-grid/overview?WT.mc_id=javascript-99907-ninarasi)\\n * **Week 4:** Develop End-to-End solutions with [Serverless on Azure](https://azure.microsoft.com/solutions/serverless/?WT.mc_id=javascript-99907-ninarasi)\\n\\n![](./img/banner.png)\\n\\nWe have a [tentative roadmap](/serverless-september/30DaysOfServerless) for the topics we hope to cover and will keep this updated as we go with links to actual articles as they get published.\\n\\n:::info Week 1: FOCUS ON FUNCTIONS \u26a1\ufe0f\\n\\nHere\'s a sneak peek at what we have planned for week 1. We\'ll start with a broad look at fundamentals, walkthrough examples for each targeted programming language, then wrap with a post that showcases the role of Azure Functions in powering different serverless scenarios.\\n\\n * Sep 02: Learn Core Concepts for Azure Functions\\n * Sep 03: Build and deploy your first Function\\n * Sep 04: Azure Functions - for Java Developers!\\n * Sep 05: Azure Functions - for JavaScript Developers!\\n * Sep 06: Azure Functions - for .NET Developers!\\n * Sep 07: Azure Functions - for Python Developers!\\n * Sep 08: Wrap: Azure Functions + Serverless on Azure\\n\\n:::\\n\\n---\\n\\n## Ways to Participate..\\n\\nWe hope you are as excited as we are, to jumpstart this journey. We want to make this a **useful, beginner-friendly** journey and we need your help!\\n\\nHere are the many ways you can participate:\\n\\n* **[Follow Azure on dev.to](https://dev.to/azure)** - we\'ll republish posts under [this series page](https://dev.to/nitya/series/19576) and welcome comments and feedback there!\\n* **[Discussions on GitHub](https://github.com/Azure/Cloud-Native/discussions)** - Use this if you have feedback for us (on how we can improve these resources), or want to chat with your peers about serverless topics.\\n* **[Custom Issues](https://github.com/Azure/Cloud-Native/issues/new/choose)** - just pick a template, create a new issue by filling in the requested details, and submit. You can use these to:\\n    - submit questions for **AskTheExpert** (live Q&A) ahead of time\\n    - submit your own articles or projects for community to learn from\\n    - share your **ServerlessHack** and get listed in our Hall Of Fame!\\n    - report bugs or share ideas for improvements\\n\\nHere\'s the list of custom issues currently defined.\\n\\n![Community Buzz](./img/community-buzz.png)\\n\\n\\n## Let\'s Get Started!\\n\\nNow you know everything! We hope you are as excited as we are to dive into a full month of active learning and doing! Don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/blog/rss.xml?WT.mc_id=javascript-99907-ninarasi) for updates in your favorite feed reader! **And look out for our first Azure Functions post tomorrow!**\\n\\n\\n---"},{"id":"students","metadata":{"permalink":"/Cloud-Native/blog/students","source":"@site/blog/2022-08-31/index.md","title":"Welcome Students!","description":"\u2728 Serverless September For Students","date":"2022-08-31T00:00:00.000Z","formattedDate":"August 31, 2022","tags":[{"label":"students","permalink":"/Cloud-Native/blog/tags/students"},{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"}],"readingTime":2.57,"hasTruncateMarker":false,"authors":[{"name":"Sara Gibbons","title":"Next Gen Experiences Advocate @Microsoft","url":"https://github.com/saragibby","imageURL":"https://github.com/saragibby.png","key":"sara"}],"frontMatter":{"slug":"students","title":"Welcome Students!","authors":["sara"],"draft":false,"tags":["students","serverless-september"]},"prevItem":{"title":"01. It\'s 30DaysOfServerless!","permalink":"/Cloud-Native/blog/01-kickoff"},"nextItem":{"title":"Hello, ServerlessSeptember","permalink":"/Cloud-Native/blog/welcome"}},"content":"## \u2728 Serverless September For Students\\n\\nMy love for the tech industry grows as it evolves. Not just for the new technologies to play with, but seeing how paths into a tech career continue to expand. Allowing so many new voices, ideas and perspectives to our industry. With [serverless computing](https://azure.microsoft.com/resources/cloud-computing-dictionary/what-is-serverless-computing/?WT.mc_id=academic-75239-sagibbon) removing barriers of entry for so many.\\n\\nIt\'s a reason I enjoy working with universities and students. I get to hear the excitement of learning, fresh ideas and perspectives from our student community. All you students are incredible! How you view serverless, and what it can do, so cool!  \\n\\nThis year for Serverless September we want to hear all the amazing ways our student community is learning and working with Azure Serverless, and have all new ways for you to participate. \\n\\n### Getting Started\\n\\nIf you don\'t already have an [Azure for Students](https://docs.microsoft.com/azure/education-hub/azure-dev-tools-teaching/azure-students-program?WT.mc_id=academic-75239-sagibbon) account you can easily get your **FREE** account created at [Azure for Students Sign up](https://azure.microsoft.com/free/students/?WT.mc_id=academic-75239-sagibbon).\\n\\nIf you are new to serverless, here are a couple links to get you started:\\n * [Build Cloud-Native Apps on Azure](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=academic-75239-sagibbon)\\n * [Go Serverless On Azure](https://azure.microsoft.com/solutions/serverless/?WT.mc_id=academic-75239-sagibbon)\\n\\n\\n### No Experience, No problem\\n\\nFor Serverless September we have planned beginner friendly content all month long. Covering such services as:\\n * [Azure Functions](https://docs.microsoft.com/azure/azure-functions/functions-overview?WT.mc_id=academic-75239-sagibbon)\\n * [Azure Container Apps](https://docs.microsoft.com/azure/container-apps/overview?WT.mc_id=academic-75239-sagibbon)\\n * [Distributed Application Runtime (dapr)](https://dapr.io/)\\n * [Azure Event Grid](https://docs.microsoft.com/azure/event-grid/?WT.mc_id=academic-75239-sagibbon)\\n * [Azure Logic Apps](https://docs.microsoft.com/azure/static-web-apps/?WT.mc_id=academic-75239-sagibbon)\\n * [Azure Static Web Apps](https://docs.microsoft.com/azure/logic-apps/?WT.mc_id=academic-75239-sagibbon)\\n\\nYou can follow [#30DaysOfServerles](https://azure.github.io/Cloud-Native/blog/) here on the blog for daily posts covering concepts, scenarios, and how to create end-to-end solutions. \\n\\nJoin the [Cloud Skills Challenge](https://azure.github.io/Cloud-Native/serverless-september/CloudSkills/) where we have selected a list of Learn Modules for you to go through at your own pace, including deploying a full stack application with [Azure Static Web Apps](https://docs.microsoft.com/azure/logic-apps/?WT.mc_id=academic-75239-sagibbon).\\n\\n\\n### Have A Question \\n\\nWe want to hear it! All month long we will have **Ask The Expert** sessions. [Submit your questions](https://github.com/Azure/Cloud-Native/issues/new?assignees=&labels=ask+the+expert&template=---ask-the-expert-.md&title=%5BAsk+The+Expert%5D++) at any time and will be be sure to get one of our Azure Serverless experts to get you an answer. \\n\\n### Share What You\'ve Created \\n\\nIf you have written a blog post, recorded a video, have an open source Azure Serverless project, we\'d love to see it! Here is some links for you to share your creations\\n\\n* [Written an article or recorded a video involving Azure Serverless](https://github.com/Azure/Cloud-Native/issues/new?assignees=&labels=&template=---community-buzz--share-technical-articles.md&title=)\\n* [Have an open source Serverless project you built](https://github.com/Azure/Cloud-Native/issues/new?assignees=&labels=&template=---community-showcase--share-code-projects.md&title=%5BShowcase+Submission%5D)\\n* [Crafted a Serverless Hack](https://github.com/Azure/Cloud-Native/issues/new?assignees=&labels=&template=---serverless-hacks--share-your-hack-.md&title=%5BServerless+Hacks%5D)\\n\\n## \ud83e\udded Explore Student Resources\\n\\n* [Microsoft Student Hub](https://docs.microsoft.com/learn/student-hub/?WT.mc_id=academic-75239-sagibbon) - highlight student focused resources across Microsoft\\n* [Microsoft Learn Student Ambassadors](https://studentambassadors.microsoft.com/?WT.mc_id=academic-75239-sagibbon) - our student focused community program\\n* [Imagine Cup](https://imaginecup.microsoft.com/Events?ocid=pre_web_ambassador_learnmore_all?WT.mc_id=academic-75239-sagibbon) - our annual student innovation competition\\n\\n## \u26a1\ufe0f Join us!\\n\\nMultiple teams across Microsoft are working to create Serverless September! They all want to hear from our incredible student community. We can\'t wait to share all the Serverless September resources and hear what you have learned and created. Here are some ways to keep up to date on all Serverless September activity:\\n\\n* **[Subscribe to this blog](https://azure.github.io/Cloud-Native/blog/rss.xml)** - get notified early when we publish!\\n* **[Follow Azure on dev.to](https://dev.to/azure)** - look for the #ServerlessSeptember series!\\n* **[Bookmark this site](https://aka.ms/serverless-september?WT.mc_id=academic-75239-sagibbon)** and check back regularly for updates."},{"id":"welcome","metadata":{"permalink":"/Cloud-Native/blog/welcome","source":"@site/blog/2022-08-17/index.md","title":"Hello, ServerlessSeptember","description":"\ud83c\udf42 It\'s September?","date":"2022-08-17T00:00:00.000Z","formattedDate":"August 17, 2022","tags":[{"label":"hello","permalink":"/Cloud-Native/blog/tags/hello"},{"label":"serverless-september","permalink":"/Cloud-Native/blog/tags/serverless-september"}],"readingTime":2.375,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"},{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://github.com/devanshidiaries.png","key":"devanshi"}],"frontMatter":{"slug":"welcome","title":"Hello, ServerlessSeptember","authors":["nitya","devanshi"],"draft":false,"tags":["hello","serverless-september"],"image":"../../static/img/banners/post-kickoff.png"},"prevItem":{"title":"Welcome Students!","permalink":"/Cloud-Native/blog/students"}},"content":"## \ud83c\udf42 It\'s September?\\n\\nWell, almost! September 1 is a few days away and I\'m excited! Why? Because it\'s the perfect time to revisit **#Serverless September**, a month of\\n> \\".. content-driven learning where experts and practitioners share their insights and tutorials on how to use serverless technologies effectively in today\'s ecosystems\\"\\n\\nIf the words look familiar, it\'s because I actually wrote them [2 years ago](https://dev.to/azure/serverlessseptember-just-5-things-you-need-to-know-3p9e) when we launched the 2020 edition of this series. You might even recall _this_ whimsical image I drew to capture the concept of September (fall) and Serverless (event-driven on-demand compute). Since then, a lot has happened in the serverless ecosystem!\\n\\n\\nYou can still browse the [2020 Content Collection](https://dev.to/azure/serverlessseptember-2020-content-collection-443k) to find great talks, articles and code samples to get started using Serverless on Azure. But read on to learn what\'s new!\\n\\n![](./img/2020-banner.png)\\n\\n\\n\\n\\n## \ud83e\uddd0 What\'s New?\\n\\nWell - quite a few things actually. This year, [Devanshi Joshi](https://twitter.com/devanshidiaries) and I expanded the original concept in a number of ways. Here\'s just a few of them that come to mind.\\n\\n### New Website\\n\\nThis year, we created _this_ website (shortcut: [https://aka.ms/serverless-september](https://aka.ms/serverless-september)) to serve as a permanent home for content in 2022 and beyond - making it a  canonical source for the `#serverless` posts we publish to  tech communities like [dev.to](https://dev.to/azure), [Azure Developer Community](https://techcommunity.microsoft.com/t5/azure-developer-community-blog/bg-p/AzureDevCommunityBlog?WT.mc_id=javascript-99907-ninarasi) and [Apps On Azure](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/bg-p/AppsonAzureBlog/label-name/Serverless?WT.mc_id=javascript-99907-ninarasi). We hope this also makes it easier for you to search for, or discover, current and past articles that support your learning journey!\\n\\nStart by bookmarking these two sites:\\n\\n * [Build Cloud-Native Apps on Azure](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-99907-ninarasi)\\n * [Go Serverless On Azure](https://azure.microsoft.com/solutions/serverless/?WT.mc_id=javascript-99907-ninarasi)\\n\\n\\n### More Options\\n\\nPrevious years focused on curating and sharing content authored by Microsoft and community contributors, showcasing serverless examples and best practices. This was perfect for those who already had experience with the core devtools and concepts.\\n\\nThis year, we wanted to combine _beginner-friendly_ options (for those just starting their serverless journey) with more _advanced insights_ (for those looking to skill up further). Here\'s a sneak peek at some of the initiatives we\'ve got planned!\\n\\n![](../../static/img/banners/post-kickoff.png)\\n\\nWe\'ll also explore the full spectrum of serverless - from Functions-as-a-Service (for granularity) to Containerization (for deployment) and Microservices (for scalability). Here are a few services and technologies you\'ll get to learn more about:\\n\\n * [Azure Functions](https://docs.microsoft.com/azure/azure-functions/functions-overview?WT.mc_id=javascript-99907-ninarasi)\\n * [Azure Container Apps](https://docs.microsoft.com/azure/container-apps/overview?WT.mc_id=javascript-99907-ninarasi)\\n * [Distributed Application Runtime (dapr)](https://dapr.io/?WT.mc_id=javascript-99907-ninarasi)\\n * [Azure Event Grid](https://docs.microsoft.com/azure/event-grid/?WT.mc_id=javascript-99907-ninarasi)\\n * [Azure Logic Apps](https://docs.microsoft.com/azure/static-web-apps/?WT.mc_id=javascript-99907-ninarasi)\\n * [Azure Static Web Apps](https://docs.microsoft.com/azure/logic-apps/?WT.mc_id=javascript-99907-ninarasi)\\n\\n\\n\\n\\n## \u26a1\ufe0f Join us!\\n\\nThis has been a labor of love from multiple teams at Microsoft! We can\'t wait to share all the resources that we hope will help _you_ skill up on all things Serverless this September! Here are a couple of ways to participate:\\n\\n* **[Subscribe to this blog](https://azure.github.io/Cloud-Native/blog/rss.xml)** - get notified early when we publish!\\n* **[Follow Azure on dev.to](https://dev.to/azure)** - look for the #ServerlessSeptember series!\\n* **[Bookmark this site](https://aka.ms/serverless-september)** and check back regularly for updates."}]}')}}]);