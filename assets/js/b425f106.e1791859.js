"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[70177],{53122:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var s=t(85893),a=t(11151);const o={slug:"fundamentals-day-5",title:"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes",authors:["steven"],draft:!1,hide_table_of_contents:!1,toc_min_heading_level:2,toc_max_heading_level:3,keywords:["scaling","kubernetes","aks","container-apps","cloud-native"],image:"https://azure.github.io/Cloud-Native/img/og/30-10.png",description:"Learning to Scale Pods and Nodes in Kubernetes on Azure",tags:["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},r=void 0,i={permalink:"/Cloud-Native/cnny-2023/fundamentals-day-5",source:"@site/blog-cnny/2023-02-03/scaling.md",title:"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes",description:"Learning to Scale Pods and Nodes in Kubernetes on Azure",date:"2023-02-03T00:00:00.000Z",formattedDate:"February 3, 2023",tags:[{label:"cloud-native",permalink:"/Cloud-Native/cnny-2023/tags/cloud-native"},{label:"30daysofcloudnative",permalink:"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{label:"zero-to-hero",permalink:"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{label:"ask-the-expert",permalink:"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{label:"azure-kubernetes-service",permalink:"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],readingTime:9.335,hasTruncateMarker:!1,authors:[{name:"Steven Murawski",title:"Principal Cloud Advocate",url:"https://github.com/smurawski",imageURL:"https://github.com/smurawski.png",key:"steven"}],frontMatter:{slug:"fundamentals-day-5",title:"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes",authors:["steven"],draft:!1,hide_table_of_contents:!1,toc_min_heading_level:2,toc_max_heading_level:3,keywords:["scaling","kubernetes","aks","container-apps","cloud-native"],image:"https://azure.github.io/Cloud-Native/img/og/30-10.png",description:"Learning to Scale Pods and Nodes in Kubernetes on Azure",tags:["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},unlisted:!1,prevItem:{title:"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims",permalink:"/Cloud-Native/cnny-2023/fundamentals-day-4"},nextItem:{title:"3-1. Bringing Your Application to Kubernetes - CI/CD",permalink:"/Cloud-Native/cnny-2023/bring-your-app-day-1"}},l={authorsImageUrls:[void 0]},c=[{value:"What We&#39;ll Cover",id:"what-well-cover",level:2},{value:"Scaling Our Application",id:"scaling-our-application",level:2},{value:"Scaling Pods",id:"scaling-pods",level:2},{value:"Manually Scale Pods",id:"manually-scale-pods",level:3},{value:"Autoscale Pods with the Horizontal Pod Autoscaler",id:"autoscale-pods-with-the-horizontal-pod-autoscaler",level:3},{value:"Application Architecture Considerations",id:"application-architecture-considerations",level:3},{value:"Scaling Nodes",id:"scaling-nodes",level:2},{value:"Manually Scale Nodes",id:"manually-scale-nodes",level:3},{value:"Autoscale Nodes with the Cluster Autoscaler",id:"autoscale-nodes-with-the-cluster-autoscaler",level:3},{value:"Scaling on Different Events",id:"scaling-on-different-events",level:2},{value:"Exercise",id:"exercise",level:2},{value:"Configure Horizontal Pod Autoscaler",id:"configure-horizontal-pod-autoscaler",level:3},{value:"Configure Cluster Autoscaler",id:"configure-cluster-autoscaler",level:3},{value:"Resources",id:"resources",level:2},{value:"Documentation",id:"documentation",level:3},{value:"Training",id:"training",level:3}];function u(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.a)(),...e.components},{Head:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t,{children:[(0,s.jsx)("meta",{name:"twitter:url",content:"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-5"}),(0,s.jsx)("meta",{name:"twitter:title",content:"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes"}),(0,s.jsx)("meta",{name:"twitter:description",content:"Learning to Scale Pods and Nodes in Kubernetes on Azure"}),(0,s.jsx)("meta",{name:"twitter:image",content:"https://azure.github.io/Cloud-Native/img/og/30-10.png"}),(0,s.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,s.jsx)("meta",{name:"twitter:creator",content:"@stevenmurawski"}),(0,s.jsx)("meta",{name:"twitter:site",content:"@AzureAdvocates"}),(0,s.jsx)("link",{rel:"canonical",href:"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-5"})]}),"\n",(0,s.jsxs)(n.p,{children:["Welcome to ",(0,s.jsx)(n.code,{children:"Day 5 of Week 2"})," of #CloudNativeNewYear!"]}),"\n",(0,s.jsx)(n.p,{children:"The theme for this week is Kubernetes fundamentals. Yesterday we talked about adding persistent storage to our deployment. Today we'll explore the topic of scaling pods and nodes in our Kubernetes cluster."}),"\n",(0,s.jsx)(n.admonition,{title:"Ask the Experts Thursday, February 9th at 9 AM PST",type:"tip",children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://aka.ms/cnny/watch-ate",children:"Watch our Q&A with Experts from the Azure Kubernetes Service product team!"})})}),"\n",(0,s.jsxs)(n.admonition,{title:"Catch the Replay of the Live Demo",type:"tip",children:[(0,s.jsx)(n.p,{children:"Watch the recorded demo and conversation about this week's topics."}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://aka.ms/cnny/week2-demo",children:"We were live on YouTube walking through today's (and the rest of this week's) demos"}),"."]})]}),"\n",(0,s.jsx)(n.h2,{id:"what-well-cover",children:"What We'll Cover"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Scaling Our Application"}),"\n",(0,s.jsx)(n.li,{children:"Scaling Pods"}),"\n",(0,s.jsx)(n.li,{children:"Scaling Nodes"}),"\n",(0,s.jsx)(n.li,{children:"Exercise"}),"\n",(0,s.jsx)(n.li,{children:"Resources"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"scaling-our-application",children:"Scaling Our Application"}),"\n",(0,s.jsxs)(n.p,{children:["One of our primary reasons to use a service like Kubernetes to orchestrate our workloads is the ability to scale.  We've approached scaling in a multitude of ways over the years, taking advantage of the ever-evolving levels of hardware and software. Kubernetes allows us to ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#manually-scale-pods-or-nodes",children:"scale our units of work, Pods"}),", and ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#cluster-autoscaler",children:"the Nodes they run on"}),".  This allows us to take advantage of both hardware and software scaling abilities.  Kubernetes can help improve the utilization of existing hardware (by scheduling Pods on Nodes that have resource capacity).  And, with the capabilities of virtualization and/or cloud hosting (or a bit more work, if you have a pool of physical machines), Kubernetes can expand (or contract) the number of Nodes capable of hosting Pods.  Scaling is primarily driven by resource utilization, but can be triggered by a variety of other sources thanks to projects like ",(0,s.jsx)(n.a,{href:"https://keda.sh/",children:"Kubernetes Event-driven Autoscaling (KEDA)"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"scaling-pods",children:"Scaling Pods"}),"\n",(0,s.jsxs)(n.p,{children:["Our first level of scaling is with our Pods. Earlier, when we worked on our deployment, we talked about how the Kubernetes would use the deployment configuration to ensure that we had the desired workloads running.  One thing we didn't explore was running more than one instance of a pod. We can define a number of replicas of a pod in our ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests",children:"Deployment"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"manually-scale-pods",children:"Manually Scale Pods"}),"\n",(0,s.jsx)(n.p,{children:"So, if we wanted to define more pods right at the start (or at any point really), we could update our deployment configuration file with the number of replicas and apply that configuration file."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yml",children:"spec:\n  replicas: 5\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Or we could use the ",(0,s.jsx)(n.code,{children:"kubectl scale"})," command to update the deployment with a number of pods to create."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl scale --replicas=5 deployment/azure-voting-app\n"})}),"\n",(0,s.jsx)(n.p,{children:"Both of these approaches modify the running configuration of our Kubernetes cluster and request that it ensure that we have that set number of replicas running.  Because this was a manual change, the Kubernetes cluster won't automatically increase or decrease the number of pods.  It'll just ensure that there are always the specified number of pods running."}),"\n",(0,s.jsx)(n.h3,{id:"autoscale-pods-with-the-horizontal-pod-autoscaler",children:"Autoscale Pods with the Horizontal Pod Autoscaler"}),"\n",(0,s.jsxs)(n.p,{children:["Another approach to scaling our pods is to allow the ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#horizontal-pod-autoscaler",children:"Horizontal Pod Autoscaler"})," to help us scale in response to resources being used by the pod.  This requires a bit more configuration up front.  When we define our pod in our deployment, we need to include resource requests and limits.  The requests help Kubernetes determine what nodes may have capacity for a new instance of a pod.  The limit tells us where the node should cap utilization for a particular instance of a pod.  For example, we'll update our deployment to request 0.25 CPU and set a limit of 0.5 CPU."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yml",children:"    spec:\n      containers:\n      - image: acrudavoz.azurecr.io/cnny2023/azure-voting-app-rust:ca4\n        name: azure-voting-app-rust\n        ports:\n        - containerPort: 8080\n        env:\n        - name: DATABASE_URL\n          value: postgres://postgres:mypassword@10.244.0.29\n        resources:\n          requests:\n            cpu: 250m\n          limits:\n            cpu: 500m\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Now that we've given Kubernetes an allowed range and an idea of what free resources a node should have to place new pods, we can set up autoscaling.  Because autoscaling is a persistent configuration, I like to define it in a configuration file that I'll be able to keep with the rest of my cluster configuration.  We'll use the ",(0,s.jsx)(n.code,{children:"kubectl"})," command to help us write the configuration file.  We'll request that Kubernetes watch our pods and when the average CPU utilization if 50% of the requested usage (in our case if it's using more than 0.375 CPU across the current number of pods), it can grow the number of pods serving requests up to 10.  If the utilization drops, Kubernetes will have the permission to deprovision pods down to the minimum (three in our example)."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl autoscale deployment azure-voting-app --cpu-percent=50 --min=3 --max=10 -o YAML --dry-run=client\n"})}),"\n",(0,s.jsx)(n.p,{children:"Which would give us:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yml",children:"apiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\nmetadata:\n  creationTimestamp: null\n  name: azure-voting-app\nspec:\n  maxReplicas: 10\n  minReplicas: 3\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: azure-voting-app\n  targetCPUUtilizationPercentage: 50\nstatus:\n  currentReplicas: 0\n  desiredReplicas: 0\n"})}),"\n",(0,s.jsx)(n.p,{children:"So, how often does the autoscaler check the metrics being monitored?  The autoscaler checks the Metrics API every 15 seconds, however the pods stats are only updated every 60 seconds.  This means that an autoscale event may be evaluated about once a minute.  Once an autoscale down event happens however, Kubernetes has a cooldown period to give the new pods a chance to distribute the workload and let the new metrics accumulate.  There is no delay on scale up events."}),"\n",(0,s.jsx)(n.h3,{id:"application-architecture-considerations",children:"Application Architecture Considerations"}),"\n",(0,s.jsxs)(n.p,{children:["We've focused in this example on our front end, which is an easier scaling story.  When we start talking about scaling our database layers or anything that deals with persistent storage or has primary/replica configuration requirements things get a bit more complicated. Some of these applications may have built-in leader election or ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/",children:"could use sidecars to help use existing features in Kubernetes to perform that function"}),".  For shared storage scenarios, ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/storage/persistent-volumes/",children:"persistent volumes"})," (or ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/cloud-adoption-framework/scenarios/app-platform/aks/storage?WT.mc_id=containers-84290-stmuraws",children:"persistent volumes with Azure"}),") can be of help, if the application knows how to play well with shared file access."]}),"\n",(0,s.jsx)(n.p,{children:"Ultimately, you know your application architecture and, while Kubernetes may not have an exact match to how you are doing things today, the underlying capability is probably there under a different name.  This abstraction allows you to more effectively use Kubernetes to operate a variety of workloads with the levels of controls you need."}),"\n",(0,s.jsx)(n.h2,{id:"scaling-nodes",children:"Scaling Nodes"}),"\n",(0,s.jsx)(n.p,{children:"We've looked at how to scale our pods, but that assumes we have enough resources in our existing pool of nodes to accomodate those scaling requests.  Kubernetes can also help scale our available nodes to ensure that our applications have the necessary resources to meet their performance requirements."}),"\n",(0,s.jsx)(n.h3,{id:"manually-scale-nodes",children:"Manually Scale Nodes"}),"\n",(0,s.jsx)(n.p,{children:"Manually scaling nodes isn't a direct function of Kubernetes, so your operating environment instructions may vary.  On Azure, it's pretty straight forward.  Using the Azure CLI (or other tools), we can tell our AKS cluster to scale up or scale down the number of nodes in our node pool."}),"\n",(0,s.jsx)(n.p,{children:"First, we'll check out how many nodes we currently have in our working environment."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl get nodes\n"})}),"\n",(0,s.jsx)(n.p,{children:"This will show us"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"azure-voting-app-rust \u276f  kubectl get nodes\nNAME                            STATUS   ROLES   AGE     VERSION\naks-pool0-37917684-vmss000000   Ready    agent   5d21h   v1.24.6\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then, we'll scale it up to three nodes."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"az aks scale --resource-group $ResourceGroup --name $AksName --node-count 3\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then, we'll check out how many nodes we now have in our working environment."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl get nodes\n"})}),"\n",(0,s.jsx)(n.p,{children:"Which returns:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"azure-voting-app-rust \u276f  kubectl get nodes\nNAME                            STATUS   ROLES   AGE     VERSION\naks-pool0-37917684-vmss000000   Ready    agent   5d21h   v1.24.6\naks-pool0-37917684-vmss000001   Ready    agent   5m27s   v1.24.6\naks-pool0-37917684-vmss000002   Ready    agent   5m10s   v1.24.6\n"})}),"\n",(0,s.jsx)(n.h3,{id:"autoscale-nodes-with-the-cluster-autoscaler",children:"Autoscale Nodes with the Cluster Autoscaler"}),"\n",(0,s.jsxs)(n.p,{children:["Things get more interesting when we start working with ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/cluster-autoscaler?WT.mc_id=containers-84290-stmuraws",children:"the Cluster Autoscaler"}),".  The Cluster Autoscaler watches for the inability of Kubernetes to schedule the required number of pods due to resource constraints (and a few other criteria like affinity/anti-affinity).  If there are insufficient resources available on the existing nodes, the autoscaler can provision new nodes into the nodepool.  Likewise, the autoscaler watches to see if the existing pods could be consolidated to a smaller set of nodes and can remove excess nodes."]}),"\n",(0,s.jsx)(n.p,{children:"Enabling the autoscaler is likewise an update that can be dependent on where and how your Kubernetes cluster is hosted. Azure makes it easy with a simple Azure CLI command."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"az aks update `\n  --resource-group $ResourceGroup `\n  --name $AksName `\n  --update-cluster-autoscaler `\n  --min-count 1 `\n  --max-count 5\n"})}),"\n",(0,s.jsxs)(n.p,{children:["There are a ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/cluster-autoscaler#using-the-autoscaler-profile?WT.mc_id=containers-84290-stmuraws",children:"variety of settings"})," that can be configured to tune how the autoscaler works."]}),"\n",(0,s.jsx)(n.h2,{id:"scaling-on-different-events",children:"Scaling on Different Events"}),"\n",(0,s.jsxs)(n.p,{children:["CPU and memory utilization are the primary drivers for the Horizontal Pod Autoscaler, but those might not be the best measures as to when you might want to scale workloads.  There are other options for scaling triggers and one of the more common plugins to help with that is the ",(0,s.jsx)(n.a,{href:"https://keda.sh/",children:"Kubernetes Event-driven Autoscaling (KEDA) project"}),".  The KEDA project makes it easy to plug in different event sources to help drive scaling.  ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/keda-about?WT.mc_id=containers-84290-stmuraws",children:"Find more information about using KEDA on AKS here."})]}),"\n",(0,s.jsx)(n.h2,{id:"exercise",children:"Exercise"}),"\n",(0,s.jsxs)(n.p,{children:["Let's try out the scaling configurations that we just walked through using ",(0,s.jsx)(n.a,{href:"https://aka.ms/azure-voting-app-rust",children:"our sample application"}),".  If you still have your environment from Day 1, you can use that."]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["\ud83d\udcdd NOTE: If you don't have an AKS cluster deployed, please head over to ",(0,s.jsx)(n.a,{href:"https://github.com/Azure-Samples/azure-voting-app-rust/tree/week2/day4",children:"Azure-Samples/azure-voting-app-rust"}),", clone the repo, and follow the instructions in the ",(0,s.jsx)(n.a,{href:"https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md",children:"README.md"})," to execute the Azure deployment and setup your ",(0,s.jsx)(n.code,{children:"kubectl"})," context. Check out ",(0,s.jsx)(n.a,{href:"/Cloud-Native/cnny-2023/fundamentals-day-1#setting-up-a-kubernetes-environment-in-azure",children:"the first post this week for more on the environment setup"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"configure-horizontal-pod-autoscaler",children:"Configure Horizontal Pod Autoscaler"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Edit ",(0,s.jsx)(n.code,{children:"./manifests/deployment-app.yaml"})," to include resource requests and limits."]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yml",children:"        resources:\n          requests:\n            cpu: 250m\n          limits:\n            cpu: 500m\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Apply the updated deployment configuration."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl apply -f ./manifests/deployment-app.yaml\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Create the horizontal pod autoscaler configuration and apply it"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl autoscale deployment azure-voting-app --cpu-percent=50 --min=3 --max=10 -o YAML --dry-run=client > ./manifests/scaler-app.yaml\nkubectl apply -f ./manifests/scaler-app.yaml\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Check to see your pods scale out to the minimum."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl get pods\n"})}),"\n",(0,s.jsx)(n.h3,{id:"configure-cluster-autoscaler",children:"Configure Cluster Autoscaler"}),"\n",(0,s.jsx)(n.p,{children:"Configuring the basic behavior of the Cluster Autoscaler is a bit simpler.  We just need to run the Azure CLI command to enable the autoscaler and define our lower and upper limits."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Check the current nodes available (should be 1)."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl get nodes\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Update the cluster to enable the autoscaler"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"az aks update `\n  --resource-group $ResourceGroup `\n  --name $AksName `\n  --update-cluster-autoscaler `\n  --min-count 2 `\n  --max-count 5\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Check to see the current number of nodes (should be 2 now)."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-powershell",children:"kubectl get nodes\n"})}),"\n",(0,s.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,s.jsxs)(n.admonition,{title:"Take the Cloud Skills Challenge!",type:"tip",children:[(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356",children:"Enroll"})," in the Cloud Skills Challenge!"]}),(0,s.jsx)(n.p,{children:"Don't miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native."})]}),"\n",(0,s.jsx)(n.h3,{id:"documentation",children:"Documentation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#manually-scale-pods-or-nodes",children:"Manually Scaling Pods and Nodes"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests",children:"Deployments"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#horizontal-pod-autoscaler",children:"Horizontal Pod Autoscaler"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/",children:"Leader Election in Kubernetes"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/storage/persistent-volumes/",children:"Persistent Volumes"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/cloud-adoption-framework/scenarios/app-platform/aks/storage?WT.mc_id=containers-84290-stmuraws",children:"Persistent Volumes with Azure"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/cluster-autoscaler?WT.mc_id=containers-84290-stmuraws",children:"Cluster Autoscaler"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/cluster-autoscaler#using-the-autoscaler-profile?WT.mc_id=containers-84290-stmuraws",children:"Cluster Autoscaler Profile Settings"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://keda.sh/",children:"Kubernetes Event-driven Autoscaling (KEDA) project"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/aks/keda-about?WT.mc_id=containers-84290-stmuraws",children:"KEDA on AKS"})}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"training",children:"Training"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/training/modules/aks-application-autoscaling-native?WT.mc_id=containers-84290-stmuraws",children:"Application scalability on AKS with HorizontalPodAutoscalers"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/training/modules/aks-cluster-autoscaling?WT.mc_id=containers-84290-stmuraws",children:"Cluster Autoscaling with AKS"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/training/modules/aks-app-scale-keda?WT.mc_id=containers-84290-stmuraws",children:"Scale container applications in Azure Kubernetes Services using KEDA"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>i,a:()=>r});var s=t(67294);const a={},o=s.createContext(a);function r(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);