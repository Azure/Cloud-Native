"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[42267],{41196:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"bring-your-app-day-2","metadata":{"permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-2","source":"@site/blog-cnny/2023-02-07/index.md","title":"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration","description":"Learn how to optimize your Kubernetes environment by implementing ConfigMaps for environment variable management, Azure Files for persistent storage, and Azure Workload Identity plus Azure Key Vault for secure secret management.","date":"2023-02-07T00:00:00.000Z","formattedDate":"February 7, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"configmaps","permalink":"/Cloud-Native/cnny-2023/tags/configmaps"},{"label":"persistent-storage","permalink":"/Cloud-Native/cnny-2023/tags/persistent-storage"},{"label":"secrets-management","permalink":"/Cloud-Native/cnny-2023/tags/secrets-management"},{"label":"workload-identity","permalink":"/Cloud-Native/cnny-2023/tags/workload-identity"}],"readingTime":11.115,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"bring-your-app-day-2","title":"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","configmaps","persistent-volumes","secrets","azure-files","azure-key-vault","azure-workload-identity","best-practices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-12.png","description":"Learn how to optimize your Kubernetes environment by implementing ConfigMaps for environment variable management, Azure Files for persistent storage, and Azure Workload Identity plus Azure Key Vault for secure secret management.","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","configmaps","persistent-storage","secrets-management","workload-identity"]},"nextItem":{"title":"3-1. Bringing Your Application to Kubernetes - CI/CD","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-1"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-2\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Learn how to optimize your Kubernetes environment by implementing ConfigMaps for environment variable management, Azure Files for persistent storage, and Azure Workload Identity plus Azure Key Vault for secure secret management.\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-12.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@pauldotyu\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-2\\" />\\n</head>\\n\\nWelcome to `Day 2 of Week 3` of #CloudNativeNewYear!\\n\\nThe theme for this week is Bringing Your Application to Kubernetes. Yesterday we talked about getting an existing application running in Kubernetes with a full pipeline in GitHub Actions. Today we\'ll evaluate our sample application\'s configuration, storage, and networking requirements and implement using Kubernetes and Azure resources.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Join us for a live Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/ateonlearn)\\n\\n:::\\n\\n:::tip Friday, February 10th at 11 AM PST\\n\\nJoin us for a live demo and let us answer your questions.\\n\\n[We\'ll be live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/live-coding).  Join us Friday, February 10th and bring your questions!\\n\\n:::\\n\\n## What We\'ll Cover\\n\\n* Gather requirements\\n* Implement environment variables using ConfigMaps\\n* Implement persistent volumes using Azure Files\\n* Implement secrets using Azure Key Vault\\n* Re-package deployments\\n* Conclusion\\n* Resources\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n:::caution \\n\\nBefore you begin, make sure you\'ve gone through yesterday\'s [post](../2023-02-06/index.md) to set up your AKS cluster.\\n\\n:::\\n\\n## Gather requirements\\n\\nThe eShopOnWeb application is written in .NET 7 and has two major pieces of functionality. The web UI is where customers can browse and shop. The web UI also includes an admin portal for managing the product catalog. This admin portal, is packaged as a WebAssembly application and relies on a separate REST API service. Both the web UI and the REST API connect to the same SQL Server container.\\n\\nLooking through the source code which can be found [here](https://github.com/Azure-Samples/eShopOnAKS/tree/main/src) we can identify requirements for configs, persistent storage, and secrets.\\n\\n### Database server\\n\\n* Need to store the password for the `sa` account as a secure secret\\n* Need persistent storage volume for data directory\\n* Need to inject environment variables for SQL Server license type and EULA acceptance\\n\\n### Web UI and REST API service\\n\\n* Need to store database connection string as a secure secret\\n* Need to inject ASP.NET environment variables to override app settings\\n* Need persistent storage volume for ASP.NET key storage\\n\\n## Implement environment variables using ConfigMaps\\n\\nConfigMaps are relatively straight-forward to create. If you were following along with the examples last week, this should be review \ud83d\ude09\\n\\nCreate a ConfigMap to store database environment variables.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: mssql-settings\\ndata:\\n  MSSQL_PID: Developer\\n  ACCEPT_EULA: \\"Y\\"\\nEOF\\n```\\n\\nCreate another ConfigMap to store ASP.NET environment variables.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: aspnet-settings\\ndata:\\n  ASPNETCORE_ENVIRONMENT: Development\\nEOF\\n```\\n\\n## Implement persistent volumes using Azure Files\\n\\nSimilar to last week, we\'ll take advantage of storage classes built into AKS. For our SQL Server data, we\'ll use the `azurefile-csi-premium` storage class and leverage an [Azure Files](https://learn.microsoft.com/azure/storage/files/storage-files-introduction?WT.mc_id=containers-84290-pauyu) resource as our PersistentVolume.\\n\\nCreate a PersistentVolumeClaim (PVC) for persisting SQL Server data.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: mssql-data\\nspec:\\n  accessModes:\\n  - ReadWriteMany\\n  storageClassName: azurefile-csi-premium\\n  resources:\\n    requests:\\n      storage: 5Gi\\nEOF\\n```\\n\\nCreate another PVC for persisting ASP.NET data.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: aspnet-data\\nspec:\\n  accessModes:\\n  - ReadWriteMany\\n  storageClassName: azurefile-csi-premium\\n  resources:\\n    requests:\\n      storage: 5Gi\\nEOF\\n```\\n\\n## Implement secrets using Azure Key Vault\\n\\nIt\'s a well known fact that Kubernetes secretes are not really secrets. They\'re just base64-encoded values and not secure, especially if malicious users have access to your Kubernetes cluster. \\n\\nIn a production scenario, you will want to leverage an external vault like [Azure Key Vault](https://azure.microsoft.com/products/key-vault?WT.mc_id=containers-84290-pauyu) or [HashiCorp Vault](https://www.vaultproject.io/) to encrypt and store secrets.\\n\\nWith AKS, we can enable the [Secrets Store CSI driver](https://secrets-store-csi-driver.sigs.k8s.io/) add-on which will allow us to leverage Azure Key Vault.\\n\\n```bash\\n# Set some variables\\nRG_NAME=<YOUR_RESOURCE_GROUP_NAME>\\nAKS_NAME=<YOUR_AKS_CLUSTER_NAME>\\nACR_NAME=<YOUR_ACR_NAME>\\n\\naz aks enable-addons \\\\\\n  --addons azure-keyvault-secrets-provider \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RG_NAME\\n```\\n\\nWith the add-on enabled, you should see `aks-secrets-store-csi-driver` and `aks-secrets-store-provider-azure` resources installed on each node in your Kubernetes cluster. \\n\\nRun the command below to verify.\\n\\n```bash\\nkubectl get pods \\\\\\n  --namespace kube-system \\\\\\n  --selector \'app in (secrets-store-csi-driver, secrets-store-provider-azure)\'\\n```\\n\\nThe Secrets Store CSI driver allows us to use secret stores via Container Storage Interface (CSI) volumes. This provider offers capabilities such as mounting and syncing between the secure vault and Kubernetes Secrets. On AKS, the [Azure Key Vault Provider for Secrets Store CSI Driver](https://azure.github.io/secrets-store-csi-driver-provider-azure/docs/) enables integration with [Azure Key Vault](https://learn.microsoft.com/azure/key-vault/general/overview?WT.mc_id=containers-84290-pauyu).\\n\\nYou may not have an Azure Key Vault created yet, so let\'s create one and add some secrets to it.\\n\\n```bash\\nAKV_NAME=$(az keyvault create \\\\\\n  --name akv-eshop$RANDOM \\\\\\n  --resource-group $RG_NAME \\\\\\n  --query name -o tsv)\\n\\n# Database server password\\naz keyvault secret set \\\\\\n  --vault-name $AKV_NAME \\\\\\n  --name mssql-password \\\\\\n  --value \\"@someThingComplicated1234\\"\\n\\n# Catalog database connection string\\naz keyvault secret set \\\\\\n  --vault-name $AKV_NAME \\\\\\n  --name mssql-connection-catalog \\\\\\n  --value \\"Server=db;Database=Microsoft.eShopOnWeb.CatalogDb;User Id=sa;Password=@someThingComplicated1234;TrustServerCertificate=True;\\"\\n\\n# Identity database connection string\\naz keyvault secret set \\\\\\n  --vault-name $AKV_NAME \\\\\\n  --name mssql-connection-identity \\\\\\n  --value \\"Server=db;Database=Microsoft.eShopOnWeb.Identity;User Id=sa;Password=@someThingComplicated1234;TrustServerCertificate=True;\\"\\n```\\n\\n### Pods authentication using Azure Workload Identity\\n\\nIn order for our Pods to retrieve secrets from Azure Key Vault, we\'ll need to set up a way for the Pod to authenticate against Azure AD. This can be achieved by implementing the new [Azure Workload Identity](https://learn.microsoft.com/azure/aks/workload-identity-overview?WT.mc_id=containers-84290-pauyu) feature of AKS.\\n\\n:::info\\n\\nAt the time of this writing, the workload identity feature of AKS is in Preview.\\n\\n:::\\n\\nThe workload identity feature within AKS allows us to leverage native Kubernetes resources and link a [Kubernetes ServiceAccount](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/) to an [Azure Managed Identity](https://learn.microsoft.com/azure/active-directory/managed-identities-azure-resources/overview?WT.mc_id=containers-84290-pauyu) to authenticate against [Azure AD](https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis?WT.mc_id=containers-84290-pauyu).\\n\\nFor the authentication flow, our Kubernetes cluster will act as an Open ID Connect (OIDC) issuer and will be able issue identity tokens to ServiceAccounts which will be assigned to our Pods.\\n\\nThe Azure Managed Identity will be granted permission to access secrets in our Azure Key Vault and with the ServiceAccount being assigned to our Pods, they will be able to retrieve our secrets.\\n\\nFor more information on how the authentication mechanism all works, check out this [doc](https://azure.github.io/azure-workload-identity/docs/introduction.html#how-it-works).\\n\\nTo implement all this, start by enabling the new preview feature for AKS.\\n\\n```bash\\naz feature register \\\\\\n  --namespace \\"Microsoft.ContainerService\\" \\\\\\n  --name \\"EnableWorkloadIdentityPreview\\"\\n```\\n\\n:::caution\\n\\nThis can take several minutes to complete.\\n\\n:::\\n\\nCheck the status and ensure the `state` shows `Regestered` before moving forward.\\n\\n```bash\\naz feature show \\\\\\n  --namespace \\"Microsoft.ContainerService\\" \\\\\\n  --name \\"EnableWorkloadIdentityPreview\\"\\n```\\n\\nUpdate your AKS cluster to enable the workload identity feature and enable the OIDC issuer endpoint.\\n\\n```bash\\naz aks update \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RG_NAME \\\\\\n  --enable-workload-identity \\\\\\n  --enable-oidc-issuer \\n```\\n\\nCreate an Azure Managed Identity and retrieve its client ID.\\n\\n```bash\\nMANAGED_IDENTITY_CLIENT_ID=$(az identity create \\\\\\n  --name aks-workload-identity \\\\\\n  --resource-group $RG_NAME \\\\\\n  --subscription $(az account show --query id -o tsv) \\\\\\n  --query \'clientId\' -o tsv)\\n```\\n\\nCreate the Kubernetes ServiceAccount.\\n\\n```bash\\n# Set namespace (this must align with the namespace that your app is deployed into)\\nSERVICE_ACCOUNT_NAMESPACE=default\\n\\n# Set the service account name\\nSERVICE_ACCOUNT_NAME=eshop-serviceaccount\\n\\n# Create the service account\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: ServiceAccount\\nmetadata:\\n  annotations:\\n    azure.workload.identity/client-id: ${MANAGED_IDENTITY_CLIENT_ID}\\n  labels:\\n    azure.workload.identity/use: \\"true\\"\\n  name: ${SERVICE_ACCOUNT_NAME}\\n  namespace: ${SERVICE_ACCOUNT_NAMESPACE}\\nEOF\\n```\\n\\n:::info\\n\\nNote to enable this `ServiceAccount` to work with Azure Workload Identity, you must annotate the resource with `azure.workload.identity/client-id`, and add a label of `azure.workload.identity/use: \\"true\\"`\\n\\n:::\\n\\nThat was a lot... Let\'s review what we just did.\\n\\nWe have an Azure Managed Identity (object in Azure AD), an OIDC issuer URL (endpoint in our Kubernetes cluster), and a Kubernetes ServiceAccount.\\n\\nThe next step is to \\"tie\\" these components together and establish a [Federated Identity Credential](https://learn.microsoft.com/graph/api/resources/federatedidentitycredentials-overview?WT.mc_id=containers-84290-pauyu&view=graph-rest-1.0) so that Azure AD can trust authentication requests from your Kubernetes cluster.\\n\\n:::info\\n\\nThis identity federation can be established between Azure AD any Kubernetes cluster; not just AKS \ud83e\udd17\\n\\n:::\\n\\nTo establish the federated credential, we\'ll need the OIDC issuer URL, and a subject which points to your Kubernetes ServiceAccount.\\n\\n```bash\\n# Get the OIDC issuer URL\\nOIDC_ISSUER_URL=$(az aks show \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RG_NAME \\\\\\n  --query \\"oidcIssuerProfile.issuerUrl\\" -o tsv)\\n\\n# Set the subject name using this format: `system:serviceaccount:<YOUR_SERVICE_ACCOUNT_NAMESPACE>:<YOUR_SERVICE_ACCOUNT_NAME>`\\nSUBJECT=system:serviceaccount:$SERVICE_ACCOUNT_NAMESPACE:$SERVICE_ACCOUNT_NAME\\n\\naz identity federated-credential create \\\\\\n  --name aks-federated-credential \\\\\\n  --identity-name aks-workload-identity \\\\\\n  --resource-group $RG_NAME \\\\\\n  --issuer $OIDC_ISSUER_URL \\\\\\n  --subject $SUBJECT\\n```\\n\\nWith the authentication components set, we can now create a [SecretProviderClass](https://secrets-store-csi-driver.sigs.k8s.io/getting-started/usage.html) which includes details about the Azure Key Vault, the secrets to pull out from the vault, and identity used to access the vault.\\n\\n```bash\\n# Get the tenant id for the key vault\\nTENANT_ID=$(az keyvault show \\\\\\n  --name $AKV_NAME \\\\\\n  --resource-group $RG_NAME \\\\\\n  --query properties.tenantId -o tsv)\\n\\n# Create the secret provider for azure key vault\\nkubectl apply -f - <<EOF\\napiVersion: secrets-store.csi.x-k8s.io/v1\\nkind: SecretProviderClass\\nmetadata:\\n  name: eshop-azure-keyvault\\nspec:\\n  provider: azure\\n  parameters:\\n    usePodIdentity: \\"false\\"\\n    useVMManagedIdentity: \\"false\\"   \\n    clientID: \\"${MANAGED_IDENTITY_CLIENT_ID}\\"\\n    keyvaultName: \\"${AKV_NAME}\\"\\n    cloudName: \\"\\"\\n    objects:  |\\n      array:\\n        - |\\n          objectName: mssql-password\\n          objectType: secret\\n          objectVersion: \\"\\"\\n        - |\\n          objectName: mssql-connection-catalog\\n          objectType: secret\\n          objectVersion: \\"\\"\\n        - |\\n          objectName: mssql-connection-identity\\n          objectType: secret\\n          objectVersion: \\"\\"\\n    tenantId: \\"${TENANT_ID}\\"\\n  secretObjects:\\n  - secretName: eshop-secrets\\n    type: Opaque\\n    data:\\n      - objectName: mssql-password\\n        key: mssql-password\\n      - objectName: mssql-connection-catalog\\n        key: mssql-connection-catalog\\n      - objectName: mssql-connection-identity\\n        key: mssql-connection-identity\\nEOF\\n```\\n\\nFinally, lets grant the Azure Managed Identity permissions to retrieve secrets from the Azure Key Vault.\\n\\n```bash\\naz keyvault set-policy \\\\\\n  --name $AKV_NAME \\\\\\n  --secret-permissions get \\\\\\n  --spn $MANAGED_IDENTITY_CLIENT_ID\\n```\\n\\n## Re-package deployments\\n\\nUpdate your database deployment to load environment variables from our ConfigMap, attach the PVC and SecretProviderClass as volumes, mount the volumes into the Pod, and use the ServiceAccount to retrieve secrets.\\n\\nAdditionally, you may notice the database Pod is set to use `fsGroup:10001` as part of the `securityContext`. This is required as the MSSQL container runs using a non-root account called `mssql` and this account has the proper permissions to read/write data at the `/var/opt/mssql` mount path.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: db\\n  labels:\\n    app: db\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: db\\n  template:\\n    metadata:\\n      labels:\\n        app: db\\n    spec:\\n      securityContext:\\n        fsGroup: 10001\\n      serviceAccountName: ${SERVICE_ACCOUNT_NAME}\\n      containers:\\n        - name: db\\n          image: mcr.microsoft.com/mssql/server:2019-latest\\n          ports:\\n            - containerPort: 1433\\n          envFrom:\\n            - configMapRef:\\n                name: mssql-settings\\n          env:\\n            - name: MSSQL_SA_PASSWORD\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-password\\n          resources: {}\\n          volumeMounts:\\n            - name: mssqldb\\n              mountPath: /var/opt/mssql\\n            - name: eshop-secrets\\n              mountPath: \\"/mnt/secrets-store\\"\\n              readOnly: true\\n      volumes:\\n        - name: mssqldb\\n          persistentVolumeClaim:\\n            claimName: mssql-data\\n        - name: eshop-secrets\\n          csi:\\n            driver: secrets-store.csi.k8s.io\\n            readOnly: true\\n            volumeAttributes:\\n              secretProviderClass: eshop-azure-keyvault\\nEOF\\n```\\n\\nWe\'ll update the API and Web deployments in a similar way.\\n\\n```bash\\n# Set the image tag\\nIMAGE_TAG=<YOUR_IMAGE_TAG>\\n\\n# API deployment\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: api\\n  labels:\\n    app: api\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: api\\n  template:\\n    metadata:\\n      labels:\\n        app: api\\n    spec:\\n      serviceAccount: ${SERVICE_ACCOUNT_NAME}\\n      containers:\\n        - name: api\\n          image: ${ACR_NAME}.azurecr.io/api:${IMAGE_TAG}\\n          ports:\\n            - containerPort: 80\\n          envFrom:\\n            - configMapRef:\\n                name: aspnet-settings\\n          env:\\n            - name: ConnectionStrings__CatalogConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-catalog\\n            - name: ConnectionStrings__IdentityConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-identity\\n          resources: {}\\n          volumeMounts:\\n            - name: aspnet\\n              mountPath: ~/.aspnet/https:/root/.aspnet/https:ro\\n            - name: eshop-secrets\\n              mountPath: \\"/mnt/secrets-store\\"\\n              readOnly: true\\n      volumes:\\n        - name: aspnet\\n          persistentVolumeClaim:\\n            claimName: aspnet-data\\n        - name: eshop-secrets\\n          csi:\\n            driver: secrets-store.csi.k8s.io\\n            readOnly: true\\n            volumeAttributes:\\n                secretProviderClass: eshop-azure-keyvault\\nEOF\\n\\n## Web deployment\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: web\\n  labels:\\n    app: web\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: web\\n  template:\\n    metadata:\\n      labels:\\n        app: web\\n    spec:\\n      serviceAccount: ${SERVICE_ACCOUNT_NAME}\\n      containers:\\n        - name: web\\n          image: ${ACR_NAME}.azurecr.io/web:${IMAGE_TAG}\\n          ports:\\n            - containerPort: 80\\n          envFrom:\\n            - configMapRef:\\n                name: aspnet-settings\\n          env:\\n            - name: ConnectionStrings__CatalogConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-catalog\\n            - name: ConnectionStrings__IdentityConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-identity\\n          resources: {}\\n          volumeMounts:\\n            - name: aspnet\\n              mountPath: ~/.aspnet/https:/root/.aspnet/https:ro\\n            - name: eshop-secrets\\n              mountPath: \\"/mnt/secrets-store\\"\\n              readOnly: true\\n      volumes:\\n        - name: aspnet\\n          persistentVolumeClaim:\\n            claimName: aspnet-data\\n        - name: eshop-secrets\\n          csi:\\n            driver: secrets-store.csi.k8s.io\\n            readOnly: true\\n            volumeAttributes:\\n                secretProviderClass: eshop-azure-keyvault\\nEOF\\n```\\n\\nIf all went well with your deployment updates, you should be able to browse to your website and buy some merchandise again \ud83e\udd73\\n\\n```bash\\necho \\"http://$(kubectl get service web -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\n## Conclusion\\n\\nAlthough there is no visible changes on with our website, we\'ve made a ton of changes on the Kubernetes backend to make this application much more secure and resilient.\\n\\nWe used a combination of Kubernetes resources and AKS-specific features to achieve our goal of securing our secrets and ensuring data is not lost on container crashes and restarts.\\n\\nTo learn more about the components we leveraged here today, checkout the resources and additional tutorials listed below. \\n\\nYou can also find manifests with all the changes made in today\'s post in the [Azure-Samples/eShopOnAKS](https://github.com/Azure-Samples/eShopOnAKS/tree/week3/day2) repository.\\n\\nSee you in the next post!\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Quickstart: Deploy a SQL Server container with Azure Kubernetes Services (AKS)](https://learn.microsoft.com/sql/linux/quickstart-sql-server-containers-kubernetes?WT.mc_id=containers-84290-pauyu&view=sql-server-ver16)\\n* [Secrets Store CSI Driver](https://secrets-store-csi-driver.sigs.k8s.io/)\\n* [Azure Key Vault Provider for Secrets Store CSI Driver](https://azure.github.io/secrets-store-csi-driver-provider-azure/docs/)\\n* [Azure/azure-workload-identity](https://github.com/Azure/azure-workload-identity)\\n* [Azure AD Workload Identity](https://azure.github.io/azure-workload-identity/docs/introduction.html)\\n* [Tutorial: Use a workload identity with an application on Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/learn/tutorial-kubernetes-workload-identity?WT.mc_id=containers-84290-pauyu)"},{"id":"bring-your-app-day-1","metadata":{"permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-1","source":"@site/blog-cnny/2023-02-06/index.md","title":"3-1. Bringing Your Application to Kubernetes - CI/CD","description":"Taking a existing application, containerizing it, and publishing to Kubernetes in GitHub Actions.","date":"2023-02-06T00:00:00.000Z","formattedDate":"February 6, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":13.12,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"bring-your-app-day-1","title":"3-1. Bringing Your Application to Kubernetes - CI/CD","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["pods","deployments","kubernetes","aks","container-apps","cloud-native","github-actions","ci-cd"],"image":"https://azure.github.io/Cloud-Native/img/og/30-11.png","description":"Taking a existing application, containerizing it, and publishing to Kubernetes in GitHub Actions.","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-2"},"nextItem":{"title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-5"}},"content":"<head>\\n  <meta name=\\"twitter:url\\"\\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-1\\" />\\n  <meta name=\\"twitter:title\\"\\n    content=\\"3-1. Bringing Your Application to Kubernetes - CI/CD\\" />\\n  <meta name=\\"twitter:description\\"\\n    content=\\"Taking a existing application, containerizing it, and publishing to Kubernetes in GitHub Actions.\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-11.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\"\\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" />\\n  <link rel=\\"canonical\\"\\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-1\\" />\\n</head>\\n\\nWelcome to `Day 1 of Week 3` of #CloudNativeNewYear!\\n\\nThe theme for this week is Bringing Your Application to Kubernetes. Last we talked about Kubernetes Fundamentals. Today we\'ll explore getting an existing application running in Kubernetes with a full pipeline in GitHub Actions.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Join us for a live Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/ateonlearn)\\n\\n:::\\n\\n:::tip Friday, February 10th at 11 AM PST\\n\\nJoin us for a live demo and let us answer your questions.\\n\\n[We\'ll be live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/live-coding).  Join us Friday, February 10th and bring your questions!\\n\\n:::\\n\\n## What We\'ll Cover\\n * Our Application\\n * Adding Some Infrastructure as Code\\n * Building and Publishing a Container Image\\n * Deploying to Kubernetes\\n * Summary\\n * Resources\\n\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n## Our Application\\n\\nThis week we\'ll be taking an exisiting application - something similar to a typical line of business application - and setting it up to run in Kubernetes.  Over the course of the week, we\'ll address different concerns.  Today we\'ll focus on updating our CI/CD process to handle standing up (or validating that we have) an [Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws) environment, building and publishing container images for our web site and API server, and getting those services running in Kubernetes.\\n\\nThe application we\'ll be starting with is [eShopOnWeb](https://github.com/Azure-Samples/eShopOnAKS).  This application has a web site and API which are backed by a SQL Server instance.  It\'s built in .NET 7, so it\'s cross-platform.\\n\\n:::info\\nFor the enterprising among you, you may notice that there are a number of different eShopOn* variants on GitHub, including [eShopOnContainers](https://github.com/dotnet-architecture/eShopOnContainers).  We aren\'t using that example as it\'s more of an end state than a starting place. Afterwards, feel free to check out that example as what this solution could look like as a series of microservices.\\n:::\\n\\n## Adding Some Infrastructure as Code\\n\\n[Just like last week](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure), we need to stand up an AKS environment.  This week, however, rather than running commands in our own shell, we\'ll set up GitHub Actions to do that for us.\\n\\nThere is a **LOT** of plumbing in this section, **but** once it\'s set up, it\'ll make our lives a lot easier.  This section ensures that we have an environment to deploy our application into configured the way we want.  We can easily extend this to accomodate multiple environments or add additional microservices with minimal new effort.\\n\\n### Federated Identity\\n\\nSetting up a federated identity will allow us a more securable and auditable way of accessing Azure from GitHub Actions.  For more about setting up a federated identity, Microsoft Learn has the details on [connecting GitHub Actions to Azure](https://learn.microsoft.com/azure/developer/github/connect-from-azure?tabs=azure-portal%2Cwindows&WT.mc_id=containers-84290-stmuraws).\\n\\nHere, we\'ll just walk through the setup of the identity and configure GitHub to use that idenity to deploy our AKS environment and interact with our Azure Container Registry.\\n\\nThe examples will use PowerShell, but a Bash version of the setup commands is available in the [week3/day1 branch](https://github.com/Azure-Samples/eShopOnAKS/tree/week3/day1).\\n\\n#### Prerequisites\\n\\nTo follow along, you\'ll need:\\n\\n* a GitHub account\\n* an Azure Subscription\\n* the Azure CLI\\n* and the Git CLI.\\n\\nYou\'ll need to fork the [source repository](https://github.com/Azure-Samples/eShopOnAKS) under your GitHub user or organization where you can manage secrets and GitHub Actions.\\n\\nIt would be helpful to have the [GitHub CLI](https://cli.github.com/), but it\'s not required.\\n\\n#### Set Up Some Defaults\\n\\nYou will need to update one or more of the variables (your user or organization, what branch you want to work off of, and possibly the Azure AD application name if there is a conflict).\\n\\n```powershell\\n# Replace the gitHubOrganizationName value\\n# with the user or organization you forked\\n# the repository under.\\n\\n$githubOrganizationName = \'Azure-Samples\'\\n$githubRepositoryName  = \'eShopOnAKS\'\\n$branchName = \'week3/day1\'\\n$applicationName = \'cnny-week3-day1\'\\n```\\n\\n#### Create an Azure AD Application\\n\\nNext, we need to create an Azure AD application.\\n\\n```powershell\\n# Create an Azure AD application\\n$aksDeploymentApplication = New-AzADApplication -DisplayName $applicationName\\n```\\n\\n#### Set Up Federation for that Azure AD Application\\n\\nAnd configure that application to allow federated credential requests from our GitHub repository for a particular branch.\\n\\n```powershell\\n# Create a federated identity credential for the application\\nNew-AzADAppFederatedCredential `\\n   -Name $applicationName `\\n   -ApplicationObjectId $aksDeploymentApplication.Id `\\n   -Issuer \'https://token.actions.githubusercontent.com\' `\\n   -Audience \'api://AzureADTokenExchange\' `\\n   -Subject \\"repo:$($githubOrganizationName)/$($githubRepositoryName):ref:refs/heads/$branchName\\"\\n```\\n\\n#### Create a Service Principal for the Azure AD Application\\n\\nOnce the application has been created, we need a service principal tied to that application.  The service principal can be granted rights in Azure.\\n\\n```powershell\\n# Create a service principal for the application\\nNew-AzADServicePrincipal -AppId $($aksDeploymentApplication.AppId)\\n```\\n\\n### Give that Service Principal Rights to Azure Resources\\n\\nBecause our Bicep deployment exists at the subscription level and we are creating role assignments, we need to give it Owner rights. If we changed the scope of the deployment to just a resource group, we could apply more scoped permissions.\\n\\n```powershell\\n$azureContext = Get-AzContext\\nNew-AzRoleAssignment `\\n   -ApplicationId $($aksDeploymentApplication.AppId) `\\n   -RoleDefinitionName Owner `\\n   -Scope $azureContext.Subscription.Id\\n```\\n\\n#### Add Secrets to GitHub Repository\\n\\nIf you have the GitHub CLI, you can use that right from your shell to set the secrets needed.\\n\\n```powershell\\ngh secret set AZURE_CLIENT_ID --body $aksDeploymentApplication.AppId\\ngh secret set AZURE_TENANT_ID --body $azureContext.Tenant.Id\\ngh secret set AZURE_SUBSCRIPTION_ID --body $azureContext.Subscription.Id\\n```\\n\\nOtherwise, you can create them through the web interface like I did in the Learn Live event below.\\n\\n:::info\\nIt may look like the whole video will play, but it\'ll stop after configuring the secrets in GitHub (after about 9 minutes)\\n\\nThe video shows creating the Azure AD application, service principals, and configuring the federated identity in Azure AD and GitHub.\\n:::\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/sZ0Z-4r08so?start=1613&end=2124\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n### Creating a Bicep Deployment\\n\\n#### Resuable Workflows\\n\\nWe\'ll create our Bicep deployment in a [reusable workflows](https://docs.github.com/actions/using-workflows/reusing-workflows).  What are they?  The previous link has the documentation or the video below has [my colleague Brandon Martinez](https://twitter.com/brandonmartinez) and I talking about them.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/sZ0Z-4r08so?start=1065&end=1524\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\nThis workflow is basically [the same deployment](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure) we did in last week\'s series, just in GitHub Actions.\\n\\nStart by creating a file called `deploy_aks.yml` in the `.github/workflows` directory with the below contents.\\n\\n```yml\\nname: deploy\\n\\non:\\n  workflow_call:\\n    inputs:\\n      resourceGroupName:\\n        required: true\\n        type: string\\n    secrets:\\n      AZURE_CLIENT_ID:\\n        required: true\\n      AZURE_TENANT_ID:\\n        required: true\\n      AZURE_SUBSCRIPTION_ID:\\n        required: true\\n    outputs:\\n      containerRegistryName:\\n        description: Container Registry Name\\n        value: ${{ jobs.deploy.outputs.containerRegistryName }}\\n      containerRegistryUrl:\\n        description: Container Registry Login Url\\n        value: ${{ jobs.deploy.outputs.containerRegistryUrl }}\\n      resourceGroupName:\\n        description: Resource Group Name\\n        value: ${{ jobs.deploy.outputs.resourceGroupName }}\\n      aksName:\\n        description: Azure Kubernetes Service Cluster Name\\n        value: ${{ jobs.deploy.outputs.aksName }}\\n\\npermissions:\\n  id-token: write\\n  contents: read\\n\\njobs:\\n  validate:\\n    runs-on: ubuntu-latest\\n    steps:\\n    - uses: actions/checkout@v2\\n    - uses: azure/login@v1\\n      name: Sign in to Azure\\n      with:\\n        client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n        tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n    - uses: azure/arm-deploy@v1\\n      name: Run preflight validation\\n      with:\\n        deploymentName: ${{ github.run_number }}\\n        scope: subscription\\n        region: eastus\\n        template: ./deploy/main.bicep\\n        parameters: >\\n          resourceGroup=${{ inputs.resourceGroupName }}\\n        deploymentMode: Validate\\n\\n  deploy:\\n    needs: validate\\n    runs-on: ubuntu-latest\\n    outputs:\\n      containerRegistryName: ${{ steps.deploy.outputs.acr_name }}\\n      containerRegistryUrl: ${{ steps.deploy.outputs.acr_login_server_url }}\\n      resourceGroupName: ${{ steps.deploy.outputs.resource_group_name }}\\n      aksName: ${{ steps.deploy.outputs.aks_name }}\\n    steps:\\n    - uses: actions/checkout@v2\\n    - uses: azure/login@v1\\n      name: Sign in to Azure\\n      with:\\n        client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n        tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n    - uses: azure/arm-deploy@v1\\n      id: deploy\\n      name: Deploy Bicep file\\n      with:\\n        failOnStdErr: false\\n        deploymentName: ${{ github.run_number }}\\n        scope: subscription\\n        region: eastus\\n        template: ./deploy/main.bicep\\n        parameters: >\\n          resourceGroup=${{ inputs.resourceGroupName }}\\n```\\n\\n### Adding the Bicep Deployment\\n\\nOnce we have the Bicep deployment workflow, we can add it to the primary build definition in `.github/workflows/dotnetcore.yml`\\n\\n#### Permissions\\n\\nFirst, we need to add a permissions block to let the workflow request our Azure AD token.  This can go towards the top of the YAML file (I started it on line 5).\\n\\n```yml\\npermissions:\\n  id-token: write\\n  contents: read\\n```\\n\\n#### Deploy AKS Job\\n\\nNext, we\'ll add a reference to our reusable workflow.  This will go after the `build` job.\\n\\n```yml\\n  deploy_aks:\\n    needs: [build]\\n    uses: ./.github/workflows/deploy_aks.yml\\n    with:\\n      resourceGroupName: \'cnny-week3\'\\n    secrets:\\n      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\\n      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\\n      AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n```\\n\\n## Building and Publishing a Container Image\\n\\nNow that we have our target environment in place and an Azure Container Registry, we can build and publish our container images.\\n\\n### Add a Reusable Workflow\\n\\nFirst, we\'ll create a new file for our reusable workflow at `.github/workflows/publish_container_image.yml`.\\n\\nWe\'ll start the file with a name, the parameters it needs to run, and the permissions requirements for the federated identity request.\\n\\n```yml\\nname: Publish Container Images\\n\\non: \\n  workflow_call:\\n    inputs:\\n      containerRegistryName:\\n        required: true\\n        type: string\\n      containerRegistryUrl:\\n        required: true\\n        type: string\\n      githubSha:\\n        required: true\\n        type: string\\n    secrets:\\n      AZURE_CLIENT_ID:\\n        required: true\\n      AZURE_TENANT_ID:\\n        required: true\\n      AZURE_SUBSCRIPTION_ID:\\n        required: true\\n\\npermissions:\\n  id-token: write\\n  contents: read\\n```\\n\\n#### Build the Container Images\\n\\nOur next step is to build the two container images we\'ll need for the application, the website and the API.  We\'ll build the container images on our build worker and tag it with the git SHA, so there\'ll be a direct tie between the point in time in our codebase and the container images that represent it.\\n\\n```yml\\njobs:\\n  publish_container_image:\\n    runs-on: ubuntu-latest\\n\\n    steps:\\n    - uses: actions/checkout@v2\\n    - name: docker build\\n      run: |\\n        docker build . -f src/Web/Dockerfile -t ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha }}\\n        docker build . -f src/PublicApi/Dockerfile -t ${{ inputs.containerRegistryUrl }}/api:${{ inputs.githubSha}}\\n```\\n\\n#### Scan the Container Images\\n\\nBefore we publish those container images, we\'ll scan them for vulnerabilities and best practice violations.  We can add these two steps (one scan for each image).\\n\\n```yml\\n    - name: scan web container image\\n      uses: Azure/container-scan@v0\\n      with:\\n        image-name: ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha}}\\n    - name: scan api container image\\n      uses: Azure/container-scan@v0\\n      with:\\n        image-name: ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha}}\\n```\\n\\nThe container images provided have a few items that\'ll be found. We can create an allowed list at `.github/containerscan/allowedlist.yaml` to define vulnerabilities or best practice violations that we\'ll explictly allow to **not** fail our build.\\n\\n```yml\\ngeneral:\\n  vulnerabilities:\\n    - CVE-2022-29458\\n    - CVE-2022-3715\\n    - CVE-2022-1304\\n    - CVE-2021-33560\\n    - CVE-2020-16156\\n    - CVE-2019-8457\\n    - CVE-2018-8292\\n  bestPracticeViolations:\\n    - CIS-DI-0001\\n    - CIS-DI-0005  \\n    - CIS-DI-0006 \\n    - CIS-DI-0008  \\n```\\n\\n#### Publish the Container Images\\n\\nFinally, we\'ll log in to Azure, then log in to our Azure Container Registry, and push our images.\\n\\n```yml\\n    - uses: azure/login@v1\\n      name: Sign in to Azure\\n      with:\\n        client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n        tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n    - name: acr login \\n      run: az acr login --name ${{ inputs.containerRegistryName  }}\\n    - name: docker push\\n      run: |\\n        docker push ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha}}\\n        docker push ${{ inputs.containerRegistryUrl }}/api:${{ inputs.githubSha}}\\n```\\n\\n### Update the Build With the Image Build and Publish\\n\\nNow that we have our reusable workflow to create and publish our container images, we can include that in our primary build defnition at `.github/workflows/dotnetcore.yml`.\\n\\n```yml\\n  publish_container_image:\\n    needs: [deploy_aks]\\n    uses: ./.github/workflows/publish_container_image.yml\\n    with:\\n      containerRegistryName: ${{ needs.deploy_aks.outputs.containerRegistryName }}\\n      containerRegistryUrl: ${{ needs.deploy_aks.outputs.containerRegistryUrl }}\\n      githubSha: ${{ github.sha }}\\n    secrets:\\n      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\\n      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\\n      AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n```\\n\\n## Deploying to Kubernetes\\n\\nFinally, we\'ve gotten enough set up that a commit to the target branch will:\\n\\n* build and test our application code\\n* set up (or validate) our AKS and ACR environment\\n* and create, scan, and publish our container images to ACR\\n\\nOur last step will be to deploy our application to Kubernetes.  We\'ll use the basic building blocks we worked with last week, [deployments](../2023-01-30/PodsAndDeployments.md#creating-the-deployment) and [services](../2023-01-31/index.md#exposing-pods-via-service).\\n\\n### Starting the Reusable Workflow to Deploy to AKS\\n\\nWe\'ll start our workflow with our parameters that we need, as well as the permissions to access the token to log in to Azure.\\n\\nWe\'ll check out our code, then log in to Azure, and use the `az` CLI to get credentials for our AKS cluster.\\n\\n```yml\\nname: deploy_to_aks\\n\\non:\\n  workflow_call:\\n    inputs:\\n      aksName:\\n        required: true\\n        type: string\\n      resourceGroupName:\\n        required: true\\n        type: string\\n      containerRegistryUrl:\\n        required: true\\n        type: string\\n      githubSha:\\n        required: true\\n        type: string\\n    secrets:\\n      AZURE_CLIENT_ID:\\n        required: true\\n      AZURE_TENANT_ID:\\n        required: true\\n      AZURE_SUBSCRIPTION_ID:\\n        required: true\\n\\npermissions:\\n  id-token: write\\n  contents: read\\n\\njobs:\\n  deploy:\\n    runs-on: ubuntu-latest\\n    steps:  \\n      - uses: actions/checkout@v2\\n      - uses: azure/login@v1\\n        name: Sign in to Azure\\n        with:\\n          client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n          tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n      - name: Get AKS Credentials\\n        run: |\\n          az aks get-credentials --resource-group ${{ inputs.resourceGroupName }} --name ${{ inputs.aksName }}\\n```\\n\\n### Edit the Deployment For Our Current Image Tag\\n\\nLet\'s add the Kubernetes manifests to our repo.  This post is long enough, so you can find the content for the manifests folder [in the manifests folder in the source repo under the `week3/day1` branch](https://github.com/Azure-Samples/eShopOnAKS/tree/week3/day1/manifests).\\n\\n:::tip\\nIf you only forked the main branch of the source repo, you can easily get the updated manifests by using the following `git` commands:\\n\\n```powershell\\ngit remote add upstream https://github.com/Azure-Samples/eShopOnAks\\ngit fetch upstream week3/day1\\ngit checkout upstream/week3/day1 manifests\\n```\\n\\nThis will make the `week3/day1` branch available locally and then we can update the manifests directory to match the state of that branch.\\n:::\\n\\nThe deployments and the service defintions should be familiar from last week\'s content (but not the same).  This week, however, there\'s a new file in the manifests - `./manifests/kustomization.yaml`\\n\\nThis file helps us more dynamically edit our kubernetes manifests and support is baked right in to the `kubectl` command.\\n\\n#### Kustomize Definition\\n\\n[Kustomize](https://kustomize.io/) allows us to specify specific resource manifests and areas of that manifest to replace.  We\'ve put some placeholders in our file as well, so we can replace those for each run of our CI/CD system.\\n\\nIn `./manifests/kustomization.yaml` you will see:\\n\\n```yml\\nresources:\\n- deployment-api.yaml\\n- deployment-web.yaml\\n\\n# Change the image name and version\\nimages:\\n- name: notavalidregistry.azurecr.io/api:v0.1.0\\n  newName: <YOUR_ACR_SERVER>/api\\n  newTag: <YOUR_IMAGE_TAG>\\n- name: notavalidregistry.azurecr.io/web:v0.1.0\\n  newName: <YOUR_ACR_SERVER>/web\\n  newTag: <YOUR_IMAGE_TAG>\\n```\\n\\n#### Replacing Values in our Build\\n\\nNow, we encounter a little problem - our deployment files need to know the tag and ACR server.  We can do a bit of `sed` magic to edit the file on the fly.\\n\\nIn `.github/workflows/deploy_to_aks.yml`, we\'ll add:\\n\\n```yml\\n      - name: replace_placeholders_with_current_run\\n        run: |\\n          sed -i \\"s/<YOUR_ACR_SERVER>/${{ inputs.containerRegistryUrl }}/g\\" ./manifests/kustomization.yaml\\n          sed -i \\"s/<YOUR_IMAGE_TAG>/${{ inputs.githubSha }}/g\\" ./manifests/kustomization.yaml\\n```\\n\\n### Deploying the Manifests\\n\\nWe have our manifests in place and our `kustomization.yaml` file (with commands to update it at runtime) ready to go, we can deploy our manifests.\\n\\nFirst, we\'ll deploy our database (deployment and service).\\nNext, we\'ll use the `-k` parameter on `kubectl` to tell it to look for a `kustomize` configuration, transform the requested manifests and apply those.\\nFinally, we apply the service defintions for the web and API deployments.\\n\\n```yml\\n        run: |\\n          kubectl apply -f ./manifests/deployment-db.yaml \\\\\\n                        -f ./manifests/service-db.yaml\\n          kubectl apply -k ./manifests\\n          kubectl apply -f ./manifests/service-api.yaml \\\\\\n                        -f ./manifests/service-web.yaml\\n```\\n\\n## Summary\\n\\nWe\'ve covered a lot of ground in today\'s post.  We set up federated credentials with GitHub.  Then we added reusable workflows to deploy an AKS environment and build/scan/publish our container images, and then to deploy them into our AKS environment.\\n\\nThis sets us up to start making changes to our application and Kubernetes configuration and have those changes automatically validated and deployed by our CI/CD system.  Tomorrow, we\'ll look at updating our application environment with runtime configuration, persistent storage, and more.\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws)\\n* [Reusable workflows in GitHub Actions](https://docs.github.com/actions/using-workflows/reusing-workflows)\\n* [Connecting GitHub Actions to Azure](https://learn.microsoft.com/azure/developer/github/connect-from-azure?tabs=azure-portal%2Cwindows&WT.mc_id=containers-84290-stmuraws)\\n* [Kustomize](https://kustomize.io/)\\n* [GitHub CLI](https://cli.github.com/)\\n* [eShopOnAKS](https://github.com/Azure-Samples/eShopOnAKS)"},{"id":"fundamentals-day-5","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-5","source":"@site/blog-cnny/2023-02-03/scaling.md","title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","description":"Learning to Scale Pods and Nodes in Kubernetes on Azure","date":"2023-02-03T00:00:00.000Z","formattedDate":"February 3, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":9.36,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"fundamentals-day-5","title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["scaling","kubernetes","aks","container-apps","cloud-native"],"image":"https://azure.github.io/Cloud-Native/img/og/30-10.png","description":"Learning to Scale Pods and Nodes in Kubernetes on Azure","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"3-1. Bringing Your Application to Kubernetes - CI/CD","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-1"},"nextItem":{"title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-4"}},"content":"<head>\\n  <meta name=\\"twitter:url\\"\\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-5\\" />\\n  <meta name=\\"twitter:title\\"\\n    content=\\"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes\\" />\\n  <meta name=\\"twitter:description\\"\\n    content=\\"Learning to Scale Pods and Nodes in Kubernetes on Azure\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-10.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\"\\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" />\\n  <link rel=\\"canonical\\"\\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-5\\" />\\n</head>\\n\\nWelcome to `Day 5 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Yesterday we talked about adding persistent storage to our deployment. Today we\'ll explore the topic of scaling pods and nodes in our Kubernetes cluster.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Join us for a live Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/ateonlearn)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nJoin us for a live demo and let us answer your questions.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n * Scaling Our Application\\n * Scaling Pods\\n * Scaling Nodes\\n * Exercise\\n * Resources\\n\\n\\n## Scaling Our Application\\n\\nOne of our primary reasons to use a service like Kubernetes to orchestrate our workloads is the ability to scale.  We\'ve approached scaling in a multitude of ways over the years, taking advantage of the ever-evolving levels of hardware and software. Kubernetes allows us to [scale our units of work, Pods](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#manually-scale-pods-or-nodes), and [the Nodes they run on](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#cluster-autoscaler).  This allows us to take advantage of both hardware and software scaling abilities.  Kubernetes can help improve the utilization of existing hardware (by scheduling Pods on Nodes that have resource capacity).  And, with the capabilities of virtualization and/or cloud hosting (or a bit more work, if you have a pool of physical machines), Kubernetes can expand (or contract) the number of Nodes capable of hosting Pods.  Scaling is primarily driven by resource utilization, but can be triggered by a variety of other sources thanks to projects like [Kubernetes Event-driven Autoscaling (KEDA)](https://keda.sh/).\\n\\n## Scaling Pods\\n\\nOur first level of scaling is with our Pods. Earlier, when we worked on our deployment, we talked about how the Kubernetes would use the deployment configuration to ensure that we had the desired workloads running.  One thing we didn\'t explore was running more than one instance of a pod. We can define a number of replicas of a pod in our [Deployment](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests).\\n\\n### Manually Scale Pods\\n\\nSo, if we wanted to define more pods right at the start (or at any point really), we could update our deployment configuration file with the number of replicas and apply that configuration file.\\n\\n```yml\\nspec:\\n  replicas: 5\\n```\\n\\nOr we could use the `kubectl scale` command to update the deployment with a number of pods to create.\\n\\n```powershell\\nkubectl scale --replicas=5 deployment/azure-voting-app\\n```\\n\\nBoth of these approaches modify the running configuration of our Kubernetes cluster and request that it ensure that we have that set number of replicas running.  Because this was a manual change, the Kubernetes cluster won\'t automatically increase or decrease the number of pods.  It\'ll just ensure that there are always the specified number of pods running.\\n\\n### Autoscale Pods with the Horizontal Pod Autoscaler\\n\\nAnother approach to scaling our pods is to allow the [Horizontal Pod Autoscaler](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#horizontal-pod-autoscaler) to help us scale in response to resources being used by the pod.  This requires a bit more configuration up front.  When we define our pod in our deployment, we need to include resource requests and limits.  The requests help Kubernetes determine what nodes may have capacity for a new instance of a pod.  The limit tells us where the node should cap utilization for a particular instance of a pod.  For example, we\'ll update our deployment to request 0.25 CPU and set a limit of 0.5 CPU.\\n\\n```yml\\n    spec:\\n      containers:\\n      - image: acrudavoz.azurecr.io/cnny2023/azure-voting-app-rust:ca4\\n        name: azure-voting-app-rust\\n        ports:\\n        - containerPort: 8080\\n        env:\\n        - name: DATABASE_URL\\n          value: postgres://postgres:mypassword@10.244.0.29\\n        resources:\\n          requests:\\n            cpu: 250m\\n          limits:\\n            cpu: 500m\\n```\\n\\nNow that we\'ve given Kubernetes an allowed range and an idea of what free resources a node should have to place new pods, we can set up autoscaling.  Because autoscaling is a persistent configuration, I like to define it in a configuration file that I\'ll be able to keep with the rest of my cluster configuration.  We\'ll use the `kubectl` command to help us write the configuration file.  We\'ll request that Kubernetes watch our pods and when the average CPU utilization if 50% of the requested usage (in our case if it\'s using more than 0.375 CPU across the current number of pods), it can grow the number of pods serving requests up to 10.  If the utilization drops, Kubernetes will have the permission to deprovision pods down to the minimum (three in our example).\\n\\n```powershell\\nkubectl autoscale deployment azure-voting-app --cpu-percent=50 --min=3 --max=10 -o YAML --dry-run=client\\n```\\n\\nWhich would give us:\\n\\n```yml\\napiVersion: autoscaling/v1\\nkind: HorizontalPodAutoscaler\\nmetadata:\\n  creationTimestamp: null\\n  name: azure-voting-app\\nspec:\\n  maxReplicas: 10\\n  minReplicas: 3\\n  scaleTargetRef:\\n    apiVersion: apps/v1\\n    kind: Deployment\\n    name: azure-voting-app\\n  targetCPUUtilizationPercentage: 50\\nstatus:\\n  currentReplicas: 0\\n  desiredReplicas: 0\\n```\\n\\nSo, how often does the autoscaler check the metrics being monitored?  The autoscaler checks the Metrics API every 15 seconds, however the pods stats are only updated every 60 seconds.  This means that an autoscale event may be evaluated about once a minute.  Once an autoscale down event happens however, Kubernetes has a cooldown period to give the new pods a chance to distribute the workload and let the new metrics accumulate.  There is no delay on scale up events.\\n\\n### Application Architecture Considerations\\n\\nWe\'ve focused in this example on our front end, which is an easier scaling story.  When we start talking about scaling our database layers or anything that deals with persistent storage or has primary/replica configuration requirements things get a bit more complicated. Some of these applications may have built-in leader election or [could use sidecars to help use existing features in Kubernetes to perform that function](https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/).  For shared storage scenarios, [persistent volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) (or [persistent volumes with Azure](https://learn.microsoft.com/azure/cloud-adoption-framework/scenarios/app-platform/aks/storage?WT.mc_id=containers-84290-stmuraws)) can be of help, if the application knows how to play well with shared file access.\\n\\nUltimately, you know your application architecture and, while Kubernetes may not have an exact match to how you are doing things today, the underlying capability is probably there under a different name.  This abstraction allows you to more effectively use Kubernetes to operate a variety of workloads with the levels of controls you need.\\n\\n## Scaling Nodes\\n\\nWe\'ve looked at how to scale our pods, but that assumes we have enough resources in our existing pool of nodes to accomodate those scaling requests.  Kubernetes can also help scale our available nodes to ensure that our applications have the necessary resources to meet their performance requirements.\\n\\n### Manually Scale Nodes\\n\\nManually scaling nodes isn\'t a direct function of Kubernetes, so your operating environment instructions may vary.  On Azure, it\'s pretty straight forward.  Using the Azure CLI (or other tools), we can tell our AKS cluster to scale up or scale down the number of nodes in our node pool.\\n\\nFirst, we\'ll check out how many nodes we currently have in our working environment.\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\nThis will show us\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get nodes\\nNAME                            STATUS   ROLES   AGE     VERSION\\naks-pool0-37917684-vmss000000   Ready    agent   5d21h   v1.24.6\\n```\\n\\n\\nThen, we\'ll scale it up to three nodes.\\n\\n```powershell\\naz aks scale --resource-group $ResourceGroup --name $AksName --node-count 3\\n```\\n\\nThen, we\'ll check out how many nodes we now have in our working environment.\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\nWhich returns:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get nodes\\nNAME                            STATUS   ROLES   AGE     VERSION\\naks-pool0-37917684-vmss000000   Ready    agent   5d21h   v1.24.6\\naks-pool0-37917684-vmss000001   Ready    agent   5m27s   v1.24.6\\naks-pool0-37917684-vmss000002   Ready    agent   5m10s   v1.24.6\\n```\\n\\n### Autoscale Nodes with the Cluster Autoscaler\\n\\nThings get more interesting when we start working with [the Cluster Autoscaler](https://learn.microsoft.com/azure/aks/cluster-autoscaler?WT.mc_id=containers-84290-stmuraws).  The Cluster Autoscaler watches for the inability of Kubernetes to schedule the required number of pods due to resource constraints (and a few other criteria like affinity/anti-affinity).  If there are insufficient resources available on the existing nodes, the autoscaler can provision new nodes into the nodepool.  Likewise, the autoscaler watches to see if the existing pods could be consolidated to a smaller set of nodes and can remove excess nodes.\\n\\nEnabling the autoscaler is likewise an update that can be dependent on where and how your Kubernetes cluster is hosted. Azure makes it easy with a simple Azure CLI command.\\n\\n```powershell\\naz aks update `\\n  --resource-group $ResourceGroup `\\n  --name $AksName `\\n  --update-cluster-autoscaler `\\n  --min-count 1 `\\n  --max-count 5\\n```\\n\\nThere are a [variety of settings](https://learn.microsoft.com/azure/aks/cluster-autoscaler#using-the-autoscaler-profile?WT.mc_id=containers-84290-stmuraws) that can be configured to tune how the autoscaler works.\\n\\n## Scaling on Different Events\\n\\nCPU and memory utilization are the primary drivers for the Horizontal Pod Autoscaler, but those might not be the best measures as to when you might want to scale workloads.  There are other options for scaling triggers and one of the more common plugins to help with that is the [Kubernetes Event-driven Autoscaling (KEDA) project](https://keda.sh/).  The KEDA project makes it easy to plug in different event sources to help drive scaling.  [Find more information about using KEDA on AKS here.](https://learn.microsoft.com/azure/aks/keda-about?WT.mc_id=containers-84290-stmuraws)\\n\\n## Exercise\\n\\nLet\'s try out the scaling configurations that we just walked through using [our sample application](https://aka.ms/azure-voting-app-rust).  If you still have your environment from Day 1, you can use that. \\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/week2/day4), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context. Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n### Configure Horizontal Pod Autoscaler\\n\\n* Edit `./manifests/deployment-app.yaml` to include resource requests and limits.\\n\\n```yml\\n        resources:\\n          requests:\\n            cpu: 250m\\n          limits:\\n            cpu: 500m\\n```\\n\\n* Apply the updated deployment configuration.\\n\\n```powershell\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\n* Create the horizontal pod autoscaler configuration and apply it\\n\\n```powershell\\nkubectl autoscale deployment azure-voting-app --cpu-percent=50 --min=3 --max=10 -o YAML --dry-run=client > ./manifests/scaler-app.yaml\\nkubectl apply -f ./manifests/scaler-app.yaml\\n```\\n\\n* Check to see your pods scale out to the minimum.\\n\\n```powershell\\nkubectl get pods\\n```\\n\\n### Configure Cluster Autoscaler\\n\\nConfiguring the basic behavior of the Cluster Autoscaler is a bit simpler.  We just need to run the Azure CLI command to enable the autoscaler and define our lower and upper limits.\\n\\n* Check the current nodes available (should be 1).\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\n* Update the cluster to enable the autoscaler\\n\\n```powershell\\naz aks update `\\n  --resource-group $ResourceGroup `\\n  --name $AksName `\\n  --update-cluster-autoscaler `\\n  --min-count 2 `\\n  --max-count 5\\n```\\n\\n* Check to see the current number of nodes (should be 2 now).\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n### Documentation\\n\\n* [Manually Scaling Pods and Nodes](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#manually-scale-pods-or-nodes)\\n* [Deployments](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests)\\n* [Horizontal Pod Autoscaler](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#horizontal-pod-autoscaler)\\n* [Leader Election in Kubernetes](https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/)\\n* [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)\\n* [Persistent Volumes with Azure](https://learn.microsoft.com/azure/cloud-adoption-framework/scenarios/app-platform/aks/storage?WT.mc_id=containers-84290-stmuraws)\\n* [Cluster Autoscaler](https://learn.microsoft.com/azure/aks/cluster-autoscaler?WT.mc_id=containers-84290-stmuraws)\\n* [Cluster Autoscaler Profile Settings](https://learn.microsoft.com/azure/aks/cluster-autoscaler#using-the-autoscaler-profile?WT.mc_id=containers-84290-stmuraws)\\n* [Kubernetes Event-driven Autoscaling (KEDA) project](https://keda.sh/)\\n* [KEDA on AKS](https://learn.microsoft.com/azure/aks/keda-about?WT.mc_id=containers-84290-stmuraws)\\n\\n### Training\\n\\n* [Application scalability on AKS with HorizontalPodAutoscalers](https://learn.microsoft.com/training/modules/aks-application-autoscaling-native?WT.mc_id=containers-84290-stmuraws)\\n* [Cluster Autoscaling with AKS](https://learn.microsoft.com/training/modules/aks-cluster-autoscaling?WT.mc_id=containers-84290-stmuraws)\\n* [Scale container applications in Azure Kubernetes Services using KEDA](https://learn.microsoft.com/training/modules/aks-app-scale-keda?WT.mc_id=containers-84290-stmuraws)"},{"id":"fundamentals-day-4","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-4","source":"@site/blog-cnny/2023-02-02/index.md","title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","description":"A Step-by-Step Guide using Kubernetes Persistent Volumes, Persistent Volume Claims, and Storage Classes","date":"2023-02-02T00:00:00.000Z","formattedDate":"February 2, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"persistent-volumes","permalink":"/Cloud-Native/cnny-2023/tags/persistent-volumes"},{"label":"persistent-volume-claims","permalink":"/Cloud-Native/cnny-2023/tags/persistent-volume-claims"}],"readingTime":7.915,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"fundamentals-day-4","title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","storage"],"image":"https://azure.github.io/Cloud-Native/img/og/30-09.png","description":"A Step-by-Step Guide using Kubernetes Persistent Volumes, Persistent Volume Claims, and Storage Classes","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","persistent-volumes","persistent-volume-claims"]},"prevItem":{"title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-5"},"nextItem":{"title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-3"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-4\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"A Step-by-Step Guide using Kubernetes Persistent Volumes, Persistent Volume Claims, and Storage Classes\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-09.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@pauldotyu\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-4\\" />\\n</head>\\n\\nWelcome to `Day 4 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Yesterday we talked about how to set app configurations and secrets at runtime using Kubernetes ConfigMaps and Secrets. Today we\'ll explore the topic of persistent storage on Kubernetes and show you can leverage Persistent Volumes and Persistent Volume Claims to ensure your PostgreSQL data can survive container restarts.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Join us for a live Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/ateonlearn)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nJoin us for a live demo and let us answer your questions.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n\\n* Containers are ephemeral\\n* Persistent storage on Kubernetes\\n* Persistent storage on AKS\\n* Takeaways\\n* Resources\\n\\n## Containers are ephemeral\\n\\nIn our sample application, the frontend UI writes vote values to a backend PostgreSQL database. By default the database container stores its data on the container\'s local file system, so there will be data loss when the pod is re-deployed or crashes as containers are meant to start with a clean slate each time.\\n\\nLet\'s re-deploy our sample app and experience the problem first hand.\\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/week2/day3), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context. Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n```bash\\nkubectl apply -f ./manifests\\n```\\n\\nWait for the `azure-voting-app` service to be assigned a public IP then browse to the website and submit some votes. Use the command below to print the URL to the terminal.\\n\\n```bash\\necho \\"http://$(kubectl get ingress azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\nNow, let\'s delete the pods and watch Kubernetes do what it does best... that is, re-schedule pods.\\n\\n```bash\\n# wait for the pod to come up then ctrl+c to stop watching\\nkubectl delete --all pod --wait=false && kubectl get po -w\\n```\\n\\nOnce the pods have been recovered, reload the website and confirm the vote tally has been reset to zero.\\n\\nWe need to fix this so that the data outlives the container.\\n\\n## Persistent storage on Kubernetes\\n\\nIn order for application data to survive crashes and restarts, you must implement [Persistent Volumes and Persistent Volume Claims](https://kubernetes.io/docs/concepts/storage/persistent-volumes/).\\n\\nA persistent volume represents storage that is available to the cluster. Storage volumes can be provisioned manually by an administrator or dynamically using [Container Storage Interface (CSI)](https://kubernetes.io/docs/concepts/storage/volumes/#csi) and [storage classes](https://kubernetes.io/docs/concepts/storage/storage-classes/), which includes information on how to provision CSI volumes.\\n\\nWhen a user needs to add persistent storage to their application, a persistent volume claim is made to allocate chunks of storage from the volume. This \\"claim\\" includes things like volume mode (e.g., file system or block storage), the amount of storage to allocate, the [access mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes), and optionally a storage class. Once a persistent volume claim has been deployed, users can add the volume to the pod and [mount it in a container](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#claims-as-volumes).\\n\\nIn the next section, we\'ll demonstrate how to enable persistent storage on AKS.\\n\\n## Persistent storage on AKS\\n\\nWith AKS, [CSI drivers](https://learn.microsoft.com/azure/aks/csi-storage-drivers?WT.mc_id=containers-84290-pauyu) and [storage classes](https://learn.microsoft.com/azure/aks/concepts-storage?WT.mc_id=containers-84290-pauyu#storage-classes) are pre-deployed into your cluster. This allows you to natively use [Azure Disks](https://learn.microsoft.com/azure/aks/azure-disk-csi?WT.mc_id=containers-84290-pauyu), [Azure Files](https://learn.microsoft.com/azure/aks/azure-files-csi?WT.mc_id=containers-84290-pauyu), and [Azure Blob Storage](https://learn.microsoft.com/azure/aks/azure-blob-csi?WT.mc_id=containers-84290-pauyu) as persistent volumes. You can either bring your own Azure storage account and use it with AKS or have AKS provision an Azure storage account for you.\\n\\nTo view the Storage CSI drivers that have been enabled in your AKS cluster, run the following command.\\n\\n```bash\\naz aks show \\\\\\n  --name <YOUR_AKS_NAME> \\\\\\n  --resource-group <YOUR_AKS_RESOURCE_GROUP> \\\\\\n  --query storageProfile\\n```\\n\\nYou should see output that looks like this.\\n\\n```json\\n{\\n  \\"blobCsiDriver\\": null,\\n  \\"diskCsiDriver\\": {\\n    \\"enabled\\": true,\\n    \\"version\\": \\"v1\\"\\n  },\\n  \\"fileCsiDriver\\": {\\n    \\"enabled\\": true\\n  },\\n  \\"snapshotController\\": {\\n    \\"enabled\\": true\\n  }\\n}\\n```\\n\\nTo view the storage classes that have been installed in your cluster, run the following command.\\n\\n```bash\\nkubectl get storageclass\\n```\\n\\nWorkload requirements will dictate which CSI driver and storage class you will need to use. \\n\\nIf you need block storage, then you should use the `blobCsiDriver`. The driver may not be enabled by default but you can enable it by following instructions which can be found in the [Resources](#resources) section below.\\n\\nIf you need file storage you should leverage either `diskCsiDriver` or `fileCsiDriver`. The decision between these two boils down to whether or not you need to have the underlying storage accessible by one pod or multiple pods. It is important to note that `diskCsiDriver` currently supports access from a single pod only. Therefore, if you need data to be accessible by multiple pods at the same time, then you should opt for `fileCsiDriver`.\\n\\nFor our PostgreSQL deployment, we\'ll use the `diskCsiDriver` and have AKS create an Azure Disk resource for us. There is no need to create a PV resource, all we need to do to is create a PVC using the `managed-csi-premium` storage class.\\n\\nRun the following command to create the PVC.\\n\\n```bash\\nkubectl apply -f - <<EOF            \\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: pvc-azuredisk\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  resources:\\n    requests:\\n      storage: 10Gi\\n  storageClassName: managed-csi-premium\\nEOF\\n```\\n\\nWhen you check the PVC resource, you\'ll notice the `STATUS` is set to `Pending`. It will be set to `Bound` once the volume is mounted in the PostgreSQL container.\\n\\n```bash\\nkubectl get persistentvolumeclaim\\n```\\n\\nLet\'s delete the `azure-voting-db` deployment.\\n\\n```bash\\nkubectl delete deploy azure-voting-db\\n```\\n\\nNext, we need to apply an updated deployment manifest which includes our PVC.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    app: azure-voting-db\\n  name: azure-voting-db\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: azure-voting-db\\n  strategy: {}\\n  template:\\n    metadata:\\n      creationTimestamp: null\\n      labels:\\n        app: azure-voting-db\\n    spec:\\n      containers:\\n      - image: postgres:15.0-alpine\\n        name: postgres\\n        ports:\\n        - containerPort: 5432\\n        env:\\n        - name: POSTGRES_PASSWORD\\n          valueFrom:\\n            secretKeyRef:\\n              name: azure-voting-secret\\n              key: POSTGRES_PASSWORD\\n        resources: {}\\n        volumeMounts:\\n        - name: mypvc\\n          mountPath: \\"/var/lib/postgresql/data\\"\\n          subPath: \\"data\\"\\n      volumes:\\n      - name: mypvc\\n        persistentVolumeClaim:\\n          claimName: pvc-azuredisk\\nEOF\\n```\\n\\nIn the manifest above, you\'ll see that we are mounting a new volume called `mypvc` (the name can be whatever you want) in the pod which points to a PVC named `pvc-azuredisk`. With the volume in place, we can mount it in the container by referencing the name of the volume  `mypvc` and setting the mount path to `/var/lib/postgresql/data` (which is the [default path](https://www.postgresql.org/docs/9.1/storage-file-layout.html)).\\n\\n> \ud83d\udca1 IMPORTANT: When mounting a volume into a non-empty subdirectory, you must add [`subPath`](https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath) to the volume mount and point it to a subdirectory in the volume rather than mounting at root. In our case, when Azure Disk is formatted, it leaves a `lost+found` directory as documented [here](https://learn.microsoft.com/troubleshoot/azure/azure-kubernetes/could-not-change-permissions-azure-files?WT.mc_id=containers-84290-pauyu).\\n\\nWatch the pods and wait for the `STATUS` to show `Running` and the pod\'s `READY` status shows `1/1`.\\n\\n```bash\\n# wait for the pod to come up then ctrl+c to stop watching\\nkubectl get po -w\\n```\\n\\nVerify that the `STATUS` of the PVC is now set to `Bound`\\n\\n```bash\\nkubectl get persistentvolumeclaim\\n```\\n\\nWith the new database container running, let\'s restart the application pod, wait for the pod\'s `READY` status to show `1/1`, then head back over to our web browser and submit a few votes.\\n\\n```bash\\nkubectl delete pod -lapp=azure-voting-app --wait=false && kubectl get po -lapp=azure-voting-app -w\\n```\\n\\nNow the moment of truth... let\'s rip out the pods again, wait for the pods to be re-scheduled, and confirm our vote counts remain in tact.\\n\\n```bash\\nkubectl delete --all pod --wait=false && kubectl get po -w\\n```\\n\\nIf you navigate back to the website, you\'ll find the vote are still there \ud83c\udf89\\n\\n## Takeaways\\n\\nBy design, containers are meant to be ephemeral and stateless workloads are ideal on Kubernetes. However, there will come a time when your data needs to outlive the container. To persist data in your Kubernetes workloads, you need to leverage PV, PVC, and optionally storage classes. In our demo scenario, we leveraged CSI drivers built into AKS and created a PVC using pre-installed storage classes. From there, we updated the database deployment to mount the PVC in the container and AKS did the rest of the work in provisioning the underlying Azure Disk. If the built-in storage classes does not fit your needs; for example, you need to change the `ReclaimPolicy` or change the SKU for the Azure resource, then you can [create your own custom storage class](https://learn.microsoft.com/azure/aks/azure-disk-csi#create-a-custom-storage-class?WT.mc_id=containers-84290-pauyu) and configure it just the way you need it \ud83d\ude0a\\n\\nWe\'ll revisit this topic again next week but in the meantime, check out some of the resources listed below to learn more.\\n\\nSee you in the next post!\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Kubernetes: Volumes](https://kubernetes.io/docs/concepts/storage/volumes/)\\n* [Kubernetes: Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)\\n* [Container Storage Interface (CSI) for Kubernetes](https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/)\\n* [Container Storage Interface (CSI) drivers on Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/csi-storage-drivers?WT.mc_id=containers-84290-pauyu)\\n* [Enable CSI driver on a new or existing AKS cluster](https://learn.microsoft.com/azure/aks/azure-blob-csi?WT.mc_id=containers-84290-pauyu&tabs=NFS#enable-csi-driver-on-a-new-or-existing-aks-cluster)\\n* [AKS: Volumes](https://learn.microsoft.com/azure/aks/concepts-storage?WT.mc_id=containers-84290-pauyu#volumes)\\n* [AKS: Storage Classes](https://learn.microsoft.com/azure/aks/concepts-storage?WT.mc_id=containers-84290-pauyu#storage-classes)\\n* [AKS: Built-in Storage Classes](https://learn.microsoft.com/azure/aks/azure-disks-dynamic-pv?WT.mc_id=containers-84290-pauyu#built-in-storage-classes)"},{"id":"fundamentals-day-3","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-3","source":"@site/blog-cnny/2023-02-01/index.md","title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","description":"Working with ConfigMaps and Secrets in Kubernetes","date":"2023-02-01T00:00:00.000Z","formattedDate":"February 1, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":5.86,"hasTruncateMarker":false,"authors":[{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"}],"frontMatter":{"slug":"fundamentals-day-3","title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","authors":["josh"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["kubernetes","container-apps","secrets","configuration"],"image":"https://azure.github.io/Cloud-Native/img/og/30-08.png","description":"Working with ConfigMaps and Secrets in Kubernetes","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-4"},"nextItem":{"title":"2-2. Kubernetes Fundamentals - Services and Ingress","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-2"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-3\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Working with ConfigMaps and Secrets in Kubernetes\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-08.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@joshduffney\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-3\\" />\\n</head>\\n\\nWelcome to `Day 3 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Yesterday we talked about Services and Ingress. Today we\'ll explore the topic of passing configuration and secrets to our applications in Kubernetes with ConfigMaps and Secrets.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Join us for a live Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/ateonlearn)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nJoin us for a live demo and let us answer your questions.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n * Decouple configurations with ConfigMaps and Secerts\\n * Passing Environment Data with ConfigMaps and Secrets\\n * Conclusion\\n\\n## Decouple configurations with ConfigMaps and Secerts\\n\\nA ConfigMap is a Kubernetes object that decouples configuration data from pod definitions. Kubernetes secerts are similar, but were designed to decouple senstive information. \\n\\nSeparating the configuration and secerts from your application promotes better organization and security of your Kubernetes environment. It also enables you to share the same configuration and different secerts across multiple pods and deployments which can simplify scaling and management. Using ConfigMaps and Secerts in Kubernetes is a best practice that can help to improve the scalability, security, and maintainability of your cluster.\\n\\nBy the end of this tutorial, you\'ll have added a Kubernetes ConfigMap and Secret to the Azure Voting deployment.\\n\\n## Passing Environment Data with ConfigMaps and Secrets\\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/week2/day2), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context. Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n### Create the ConfigMap\\n\\nConfigMaps can be used in one of two ways; as environment variables or volumes. \\n\\nFor this tutorial you\'ll use a ConfigMap to create three environment variables inside the pod; DATABASE_SERVER, FISRT_VALUE, and SECOND_VALUE. The DATABASE_SERVER provides part of connection string to a Postgres. FIRST_VALUE and SECOND_VALUE are configuration options that change what voting options the application presents to the users.\\n\\nFollow the below steps to create a new ConfigMap:\\n\\n1. Create a YAML file named \'config-map.yaml\'. In this file, specify the environment variables for the application.\\n\\n    ```yaml\\n    apiVersion: v1\\n    kind: ConfigMap\\n    metadata:\\n      name: azure-voting-config\\n    data:\\n      DATABASE_SERVER: azure-voting-db\\n      FIRST_VALUE: \\"Go\\"\\n      SECOND_VALUE: \\"Rust\\"\\n    ```\\n\\n2. Create the config map in your Kubernetes cluster by running the following command:\\n    \\n    ```bash\\n    kubectl create -f config-map.yaml\\n    ```\\n\\n### Create the Secret\\n\\nThe `deployment-db.yaml` and `deployment-app.yaml` are Kubernetes manifests that deploy the Azure Voting App. Currently, those deployment manifests contain the environment variables `POSTGRES_PASSWORD` and `DATABASE_PASSWORD` with the value stored as plain text. Your task is to replace that environment variable with a Kubernetes Secret.\\n\\nCreate a Secret running the following commands:\\n\\n1. Encode `mypassword`.\\n\\n    ```bash\\n    echo -n \\"mypassword\\" | base64\\n    ```\\n\\n2. Create a YAML file named `secret.yaml`. In this file, add `POSTGRES_PASSWORD` as the key and the encoded value returned above under as the value in the data section.\\n\\n    ```yml\\n    apiVersion: v1\\n    kind: Secret\\n    metadata:\\n      name: azure-voting-secret\\n    type: Opaque\\n    data:\\n      POSTGRES_PASSWORD: bXlwYXNzd29yZA==\\n    ```\\n\\n3. Create the Secret in your Kubernetes cluster by running the following command:\\n\\n    ```bash\\n    kubectl create -f secret.yaml\\n    ```\\n\\n> [!WARNING]\\n> base64 encoding is a simple and widely supported way to obscure plaintext data, it is not secure, as it can easily be decoded. If you want to store sensitive data like password, you should use a more secure method like encrypting with a Key Management Service (KMS) before storing it in the Secret.\\n\\n### Modify the app deployment manifest\\n\\nWith the ConfigMap and Secert both created the next step is to replace the environment variables provided in the application deployment manuscript with the values stored in the ConfigMap and the Secert.\\n\\nComplete the following steps to add the ConfigMap and Secert to the deployment mainifest:\\n\\n1. Open the Kubernetes manifest file `deployment-app.yaml`. \\n\\n2. In the containers section, add an `envFrom` section and upate the `env` section.\\n\\n    ```yaml\\n    envFrom:\\n    - configMapRef:\\n        name: azure-voting-config\\n    env:\\n    - name: DATABASE_PASSWORD\\n      valueFrom:\\n        secretKeyRef:\\n          name: azure-voting-secret\\n          key: POSTGRES_PASSWORD\\n    ```\\n\\n    Using `envFrom` exposes all the values witin the ConfigMap as environment variables. Making it so you don\'t have to list them individually. \\n\\n3. Save the changes to the deployment manifest file.\\n\\n4. Apply the changes to the deployment by running the following command:\\n\\n    ```bash\\n    kubectl apply -f deployment-app.yaml\\n    ```\\n\\n### Modify the database deployment manifest \\n\\nNext, update the database deployment manifest and replace the plain text environment variable with the Kubernetes Secert.\\n\\n1. Open the `deployment-db.yaml`.\\n2. To add the secret to the deployment, replace the _env_ section with the following code:\\n\\n    ```yml\\n    env:\\n    - name: POSTGRES_PASSWORD\\n      valueFrom:\\n        secretKeyRef:\\n          name: azure-voting-secret\\n          key: POSTGRES_PASSWORD\\n    ```\\n\\n3. Apply the updated manifest.\\n\\n    ```bash\\n    kubectl apply -f deployment-db.yaml\\n    ```\\n\\n### Verify the ConfigMap and output environment variables\\n\\nVerify that the ConfigMap was added to your deploy by running the following command:\\n\\n    ```bash\\n    kubectl describe deployment azure-voting-app\\n    ```\\n\\nBrowse the output until you find the `envFrom` section with the config map reference. \\n\\nYou can also verify that the environment variables from the config map are being passed to the container by running the command `kubectl exec -it <pod-name> -- printenv`. This command will show you all the environment variables passed to the pod including the one from configmap.\\n\\nBy following these steps, you will have successfully added a config map to the Azure Voting App Kubernetes deployment, and the environment variables defined in the config map will be passed to the container running in the pod.\\n\\n### Verify the Secret and describe the deployment\\n\\nOnce the secret has been created you can verify it exists by running the following command:\\n\\n```bash\\nkubectl get secrets\\n```\\n\\nYou can view additional information, such as labels, annotations, type, and the Data by running kubectl describe:\\n\\n```bash\\nkubectl describe secret azure-voting-secret\\n```\\n\\nBy default, the describe command doesn\'t output the encoded value, but if you output the results as JSON or YAML you\'ll be able to see the secret\'s encoded value.\\n\\n```bash\\n kubectl get secret azure-voting-secret -o json\\n```\\n\\n## Conclusion\\n\\nIn conclusion, using ConfigMaps and Secrets in Kubernetes can help to improve the scalability, security, and maintainability of your cluster. By decoupling configuration data and sensitive information from pod definitions, you can promote better organization and security in your Kubernetes environment. Additionally, separating these elements allows for sharing the same configuration and different secrets across multiple pods and deployments, simplifying scaling and management.\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::"},{"id":"fundamentals-day-2","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-2","source":"@site/blog-cnny/2023-01-31/index.md","title":"2-2. Kubernetes Fundamentals - Services and Ingress","description":"A Step-by-Step Guide using Kubernetes Service and Ingress Resources on AKS","date":"2023-01-31T00:00:00.000Z","formattedDate":"January 31, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"service","permalink":"/Cloud-Native/cnny-2023/tags/service"},{"label":"ingress","permalink":"/Cloud-Native/cnny-2023/tags/ingress"}],"readingTime":10.2,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"fundamentals-day-2","title":"2-2. Kubernetes Fundamentals - Services and Ingress","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","serivce","ingress"],"image":"https://azure.github.io/Cloud-Native/img/og/30-07.png","description":"A Step-by-Step Guide using Kubernetes Service and Ingress Resources on AKS","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","service","ingress"]},"prevItem":{"title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-3"},"nextItem":{"title":"2-1. Kubernetes Fundamentals - Pods and Deployments","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-1"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-2\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"2-2. Kubernetes Fundamentals - Services and Ingress\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"A Step-by-Step Guide using Kubernetes Service and Ingress Resources on AKS\\"  />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-07.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@pauldotyu\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-2\\" />\\n</head>\\n\\nWelcome to `Day 2 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is #Kubernetes fundamentals. Yesterday we talked about how to deploy a containerized web app workload to Azure Kubernetes Service (AKS). Today we\'ll explore the topic of services and ingress and walk through the steps of making our containers accessible both internally as well as over the internet so that you can share it with the world \ud83d\ude0a\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Join us for a live Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/ateonlearn)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nJoin us for a live demo and let us answer your questions.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n\\n* Exposing Pods via Service\\n* Exposing Services via Ingress\\n* Takeaways\\n* Resources\\n\\n## Exposing Pods via Service\\n\\nThere are a few ways to expose your pod in Kubernetes. One way is to take an imperative approach and use the `kubectl expose` command. This is probably the quickest way to achieve your goal but it isn\'t the best way. A better way to expose your pod by taking a declarative approach by creating a [services](https://learn.microsoft.com/azure/aks/concepts-network?WT.mc_id=containers-84290-pauyu#services) manifest file and deploying it using the `kubectl apply` command.\\n\\nDon\'t worry if you are unsure of how to make this manifest, we\'ll use `kubectl` to help generate it.\\n\\nFirst, let\'s ensure we have the database deployed on our AKS cluster.\\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/main), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context.  Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n```bash\\nkubectl apply -f ./manifests/deployment-db.yaml\\n```\\n\\nNext, let\'s deploy the application. If you are following along from yesterday\'s content, there isn\'t anything you need to change; however, if you are deploy the app from scratch, you\'ll need to modify the `deployment-app.yaml` manifest and update it with your image tag and database pod\'s IP address.\\n\\n```bash\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\nNow, let\'s expose the database using a service so that we can leverage Kubernetes\' built-in service discovery to be able to reference it by name; not pod IP. Run the following command.\\n\\n```bash\\nkubectl expose deployment azure-voting-db \\\\\\n  --port=5432 \\\\\\n  --target-port=5432\\n```\\n\\nWith the database exposed using service, we can update the app deployment manifest to use the service name instead of pod IP. This way, if the pod ever gets assigned a new IP, we don\'t have to worry about updating the IP each time and redeploying our web application. Kubernetes has internal service discovery mechanism in place that allows us to reference a service by its name.\\n\\nLet\'s make an update to the manifest. Replace the environment variable for `DATABASE_SERVER` with the following:\\n\\n```yml\\n- name: DATABASE_SERVER\\n  value: azure-voting-db\\n```\\n\\nRe-deploy the app with the updated configuration.\\n\\n```bash\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\nOne service down, one to go. Run the following command to expose the web application.\\n\\n```bash\\nkubectl expose deployment azure-voting-app \\\\\\n  --type=LoadBalancer \\\\\\n  --port=80 \\\\\\n  --target-port=8080\\n```\\n\\nNotice the `--type` argument has a value of `LoadBalancer`. This service type is implemented by the `cloud-controller-manager` which is part of the Kubernetes control plane. When using a managed Kubernetes cluster such as Azure Kubernetes Service, a [public standard load balancer](https://learn.microsoft.com/azure/aks/load-balancer-standard?WT.mc_id=containers-84290-pauyu#use-the-public-standard-load-balancer) will be able to provisioned when the service type is set to `LoadBalancer`. The load balancer will also have a public IP assigned which will make your deployment publicly available.\\n\\nKubernetes supports four [service types](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types):\\n\\n* **ClusterIP**: this is the default and limits service access to internal traffic within the cluster\\n* **NodePort**: this assigns a port mapping on the node\'s IP address and allows traffic from the virtual network (outside the cluster)\\n* **LoadBalancer**: as mentioned above, this creates a cloud-based load balancer\\n* **ExternalName**: this is used in special case scenarios where you want to map a service to an external DNS name\\n\\n> \ud83d\udcdd NOTE: When exposing a web application to the internet, allowing external users to connect to your **Service** directly is not the best approach. Instead, you should use an **Ingress**, which we\'ll cover in the next section.\\n\\nNow, let\'s confirm you can reach the web app from the internet. You can use the following command to print the URL to your terminal.\\n\\n```bash\\necho \\"http://$(kubectl get service azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\nGreat! The `kubectl expose` command gets the job done, but as mentioned above, it is not the best method of exposing deployments. It is better to expose deployments declaratively using a [service](https://kubernetes.io/docs/concepts/services-networking/service/) manifest, so let\'s delete the services and redeploy using manifests.\\n\\n```bash\\nkubectl delete service azure-voting-db azure-voting-app\\n```\\n\\nTo use `kubectl` to generate our manifest file, we can use the same `kubectl expose` command that we ran earlier but this time, we\'ll include  `--output=yaml` and `--dry-run=client`. This will instruct the command to output the manifest that would be sent to the `kube-api` server in YAML format to the terminal.\\n\\nGenerate the manifest for the database service.\\n\\n```bash\\nkubectl expose deployment azure-voting-db \\\\\\n  --type=ClusterIP \\\\\\n  --port=5432 \\\\\\n  --target-port=5432 \\\\\\n  --output=yaml \\\\\\n  --dry-run=client > ./manifests/service-db.yaml\\n```\\n\\nGenerate the manifest for the application service.\\n\\n```bash\\nkubectl expose deployment azure-voting-app \\\\\\n  --type=LoadBalancer \\\\\\n  --port=80 \\\\\\n  --target-port=8080 \\\\\\n  --output=yaml \\\\\\n  --dry-run=client > ./manifests/service-app.yaml\\n```\\n\\nThe command above redirected the YAML output to your manifests directory. Here is what the web application service looks like.\\n\\n```yml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    app: azure-voting-app\\n  name: azure-voting-app\\nspec:\\n  ports:\\n  - port: 80\\n    protocol: TCP\\n    targetPort: 8080\\n  selector:\\n    app: azure-voting-app\\n  type: LoadBalancer\\nstatus:\\n  loadBalancer: {}\\n```\\n\\n> \ud83d\udca1 TIP: To view the schema of any `api-resource` in Kubernetes, you can use the `kubectl explain` command. In this case the `kubectl explain service` command will tell us exactly what each of these fields do.\\n\\nRe-deploy the services using the new service manifests.\\n\\n```bash\\nkubectl apply -f ./manifests/service-db.yaml -f ./manifests/service-app.yaml\\n\\n# You should see TYPE is set to LoadBalancer and the EXTERNAL-IP is set\\nkubectl get service azure-voting-db azure-voting-app\\n```\\n\\nConfirm again that our application is accessible again. Run the following command to print the URL to the terminal.\\n\\n```bash\\necho \\"http://$(kubectl get service azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\nThat was easy, right? We just exposed both of our pods using Kubernetes services. The database only needs to be accessible from within the cluster so `ClusterIP` is perfect for that. For the web application, we specified the type to be `LoadBalancer` so that we can access the application over the public internet.\\n\\nBut wait... remember that if you want to expose web applications over the public internet, a Service with a public IP is not the best way; the better approach is to use an Ingress resource.\\n\\n## Exposing Services via Ingress\\n\\nIf you read through the Kubernetes documentation on [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/#what-is-ingress) you will see a diagram that depicts the Ingress sitting in front of the Service resource with a routing rule between it. In order to use Ingress, you need to deploy an Ingress Controller and it can be configured with many routing rules to forward traffic to one or many backend services. So effectively, an Ingress is a load balancer for your Services.\\n\\nWith that said, we no longer need a service type of `LoadBalancer` since the service does not need to be accessible from the internet. It only needs to be accessible from the Ingress Controller (internal to the cluster) so we can change the service type to `ClusterIP`.\\n\\nUpdate your `service.yaml` file to look like this:\\n\\n```yaml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    app: azure-voting-app\\n  name: azure-voting-app\\nspec:\\n  ports:\\n  - port: 80\\n    protocol: TCP\\n    targetPort: 8080\\n  selector:\\n    app: azure-voting-app\\n```\\n\\n> \ud83d\udcdd NOTE: The default service type is ClusterIP so we can omit the `type` altogether.\\n\\nRe-apply the app service manifest.\\n\\n```bash\\nkubectl apply -f ./manifests/service-app.yaml\\n\\n# You should see TYPE set to ClusterIP and EXTERNAL-IP set to <none>\\nkubectl get service azure-voting-app\\n```\\n\\nNext, we need to install an [Ingress Controller](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/). There are quite a few options, and the Kubernetes-maintained [NGINX Ingress Controller](https://github.com/kubernetes/ingress-nginx) is commonly deployed.\\n\\nYou could install this manually by following [these instructions](https://kubernetes.github.io/ingress-nginx/deploy/#azure), but if you do that you\'ll be responsible for maintaining and supporting the resource.\\n\\nI like to take advantage of free maintenance and support when I can get it, so I\'ll opt to use the [Web Application Routing add-on for AKS](https://learn.microsoft.com/azure/aks/web-app-routing?WT.mc_id=containers-84290-pauyu&tabs=without-osm).\\n\\n> \ud83d\udca1 TIP: Whenever you install an AKS add-on, it will be maintained and fully supported by Azure Support.\\n\\nEnable the web application routing add-on in our AKS cluster with the following command.\\n\\n```bash\\naz aks addon enable \\\\\\n  --name <YOUR_AKS_NAME> \\\\\\n  --resource-group <YOUR_AKS_RESOURCE_GROUP>\\n  --addon web_application_routing\\n```\\n\\n> \u26a0\ufe0f WARNING: This command can take a few minutes to complete\\n\\nNow, let\'s use the same approach we took in creating our service to create our Ingress resource. Run the following command to generate the Ingress manifest.\\n\\n```bash\\nkubectl create ingress azure-voting-app \\\\\\n  --class=webapprouting.kubernetes.azure.com \\\\\\n  --rule=\\"/*=azure-voting-app:80\\" \\\\\\n  --output yaml \\\\\\n  --dry-run=client > ./manifests/ingress.yaml\\n```\\n\\nThe `--class=webapprouting.kubernetes.azure.com` option activates the AKS web application routing add-on. This AKS add-on can also integrate with other Azure services such as [Azure DNS](https://learn.microsoft.com/azure/dns/dns-overview?WT.mc_id=containers-84290-pauyu) and [Azure Key Vault](https://learn.microsoft.com/azure/key-vault/general/overview?WT.mc_id=containers-84290-pauyu) for TLS certificate management and this special class makes it all work.\\n\\nThe `--rule=\\"/*=azure-voting-app:80\\"` option looks confusing but we can use `kubectl` again to help us understand how to format the value for the option.\\n\\n```bash\\nkubectl create ingress --help\\n```\\n\\nIn the output you will see the following:\\n\\n```text\\n--rule=[]:\\n    Rule in format host/path=service:port[,tls=secretname]. Paths containing the leading character \'*\' are\\n    considered pathType=Prefix. tls argument is optional.\\n```\\n\\nIt expects a `host` and `path` separated by a forward-slash, then expects the backend `service` name and `port` separated by a colon. We\'re not using a hostname for this demo so we can omit it. For the path, an asterisk is used to specify a wildcard path prefix.\\n\\nSo, the value of `/*=azure-voting-app:80` creates a routing rule for all paths following the domain (or in our case since we don\'t have a hostname specified, the IP) to route traffic to our `azure-voting-app` backend service on port `80`.\\n\\n> \ud83d\udcdd NOTE: Configuring the hostname and TLS is outside the scope of this demo but please visit this URL https://bit.ly/aks-webapp-routing for an in-depth hands-on lab centered around Web Application Routing on AKS.\\n\\nYour `ingress.yaml` file should look like this:\\n\\n```yaml\\napiVersion: networking.k8s.io/v1\\nkind: Ingress\\nmetadata:\\n  creationTimestamp: null\\n  name: azure-voting-app\\nspec:\\n  ingressClassName: webapprouting.kubernetes.azure.com\\n  rules:\\n  - http:\\n      paths:\\n      - backend:\\n          service:\\n            name: azure-voting-app\\n            port:\\n              number: 80\\n        path: /\\n        pathType: Prefix\\nstatus:\\n  loadBalancer: {}\\n```\\n\\nApply the app ingress manifest.\\n\\n```bash\\nkubectl apply -f ./manifests/ingress.yaml\\n```\\n\\nValidate the web application is available from the internet again. You can run the following command to print the URL to the terminal.\\n\\n```bash\\necho \\"http://$(kubectl get ingress azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\n## Takeaways\\n\\nExposing your applications both internally and externally can be easily achieved using Service and Ingress resources respectively. If your service is HTTP or HTTPS based and needs to be accessible from outsie the cluster, use Ingress with an internal Service (i.e., ClusterIP or NodePort); otherwise, use the Service resource.  If your TCP-based Service needs to be publicly accessible, you set the type to LoadBalancer to expose a public IP for it. To learn more about these resources, please visit the links listed below.\\n\\nLastly, if you are unsure how to begin writing your service manifest, you can use `kubectl` and have it do most of the work for you \ud83e\udd73\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Services](https://learn.microsoft.com/azure/aks/concepts-network?WT.mc_id=containers-84290-pauyu#services)\\n* [Ingress Controllers](https://learn.microsoft.com/azure/aks/concepts-network?WT.mc_id=containers-84290-pauyu#ingress-controllers)\\n* [Hands-on Lab: Web Application Routing on AKS](https://aka.ms/aks-webapp-routing-lab)\\n* [How-to Guide: Ingress Controller in AKS](https://learn.microsoft.com/azure/aks/ingress-basic??WT.mc_id=containers-84290-pauyu&tabs=azure-cli)"},{"id":"fundamentals-day-1","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-1","source":"@site/blog-cnny/2023-01-30/PodsAndDeployments.md","title":"2-1. Kubernetes Fundamentals - Pods and Deployments","description":"The theme for this week is Kubernetes fundamentals. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.","date":"2023-01-30T00:00:00.000Z","formattedDate":"January 30, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":13.185,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"fundamentals-day-1","title":"2-1. Kubernetes Fundamentals - Pods and Deployments","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["pods","deployments","kubernetes","aks","container-apps","cloud-native"],"image":"https://azure.github.io/Cloud-Native/img/og/30-06.png","description":"The theme for this week is Kubernetes fundamentals. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"2-2. Kubernetes Fundamentals - Services and Ingress","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-2"},"nextItem":{"title":"1-5. Exploring Cloud-Native Options","permalink":"/Cloud-Native/cnny-2023/explore-options"}},"content":"<head>\\n  <meta name=\\"twitter:url\\"\\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-1\\" />\\n  <meta name=\\"twitter:title\\"\\n    content=\\"2-1. Kubernetes Fundamentals - Pods and Deployments\\" />\\n  <meta name=\\"twitter:description\\"\\n    content=\\"The theme for this week is Kubernetes fundamentals. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-06.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\"\\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" />\\n  <link rel=\\"canonical\\"\\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-1\\" />\\n</head>\\n\\nWelcome to `Day #1 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Last week we talked about Cloud Native architectures and the Cloud Native landscape. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Join us for a live Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/ateonlearn)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nJoin us for a live demo and let us answer your questions.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n * Setting Up A Kubernetes Environment in Azure\\n * Running Containers in Kubernetes Pods\\n * Making the Pods Resilient with Deployments\\n * Exercise\\n * Resources\\n\\n## Setting Up A Kubernetes Environment in Azure\\n\\nFor this week, we\'ll be working with a simple app - [the Azure Voting App](https://aka.ms/azure-voting-app-rust). My teammate [Paul Yu](https://github.com/pauldotyu) ported the app to Rust and we tweaked it a bit to let us highlight some of the basic features of Kubernetes.\\n\\nYou should be able to replicate this in just about any Kubernetes environment, but we\'ll use [Azure Kubernetes Service](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws) (AKS) as our working environment for this week.\\n\\nTo make it easier to get started, there\'s a [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?WT.mc_id=containers-84290-stmuraws&tabs=bicep) template to deploy an AKS cluster, an Azure Container Registry (ACR) (to host our container image), and connect the two so that we can easily deploy our application.\\n\\n### Step 0 - Prerequisites\\n\\nThere are a few things you\'ll need if you want to work through this and the following examples this week.\\n\\nRequired:\\n\\n* Git (and probably a GitHub account if you want to persist your work outside of your computer)\\n* Azure CLI\\n* An Azure subscription (if you want to follow along with the Azure steps)\\n* Kubectl (the command line tool for managing Kubernetes)\\n\\nHelpful:\\n\\n* Visual Studio Code (or equivalent editor)\\n\\n### Step 1 - Clone the application repository\\n\\nFirst, I forked [the source repository](https://aka.ms/azure-voting-app-rust) to my account.\\n\\n```powershell\\n$GitHubOrg = \'smurawski\' # Replace this with your GitHub account name or org name\\ngit clone \\"https://github.com/$GitHubOrg/azure-voting-app-rust\\"\\ncd azure-voting-app-rust\\n```\\n\\nLeave your shell opened with your current location inside the application repository.\\n\\n### Step 2 - Set up AKS\\n\\nRunning the template deployment from the demo script (I\'m using the PowerShell example in [cnny23-week2-day1.ps1](https://aka.ms/azure-voting-app-rust/setup-powershell), but there\'s a Bash variant at [cnny23-week2-day1.sh](https://aka.ms/azure-voting-app-rust/setup-bash)) stands up the environment.  The second, third, and fourth commands take some of the output from the Bicep deployment to set up for later commands, so don\'t close out your shell after you run these commands.\\n\\n```powershell\\naz deployment sub create --template-file ./deploy/main.bicep --location eastus --parameters \'resourceGroup=cnny-week2\'\\n$AcrName = az deployment sub show --name main --query \'properties.outputs.acr_name.value\' -o tsv\\n$AksName = az deployment sub show --name main --query \'properties.outputs.aks_name.value\' -o tsv\\n$ResourceGroup = az deployment sub show --name main --query \'properties.outputs.resource_group_name.value\' -o tsv\\n\\naz aks get-credentials --resource-group $ResourceGroup --name $AksName\\n```\\n\\n### Step 3 - Build our application container\\n\\nSince we have an Azure Container Registry set up, I\'ll use ACR Build Tasks to build and store my container image.\\n\\n```powershell\\naz acr build --registry $AcrName --% --image cnny2023/azure-voting-app-rust:{{.Run.ID}} .\\n$BuildTag = az acr repository show-tags `\\n                              --name $AcrName `\\n                              --repository cnny2023/azure-voting-app-rust `\\n                              --orderby time_desc `\\n                              --query \'[0]\' -o tsv\\n```\\n\\n:::tip\\nWondering what the `--%` is in the first command line?  That tells the PowerShell interpreter to pass the input after it \\"as is\\" to the command without parsing/evaluating it. Otherwise, PowerShell messes a bit with the templated `{{.Run.ID}}` bit.\\n:::\\n\\n## Running Containers in Kubernetes Pods\\n\\nNow that we have our AKS cluster and application image ready to go, let\'s look into how Kubernetes runs containers.\\n\\nIf you\'ve been in tech for any length of time, you\'ve seen that every framework, runtime, orchestrator, etc.. can have their own naming scheme for their concepts. So let\'s get into some of what Kubernetes calls things.\\n\\n### The Pod\\n\\nA container running in Kubernetes is called a [Pod](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#pods). A Pod is basically a running container on a [Node](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#nodes-and-node-pools) or VM. It can be more. For example you can run multiple containers and specify some funky configuration, but we\'ll keep it simple for now - add the complexity when you need it.\\n\\nOur Pod definition can be created via the `kubectl` command imperatively from arguments or declaratively from a configuration file.  We\'ll do a little of both.  We\'ll use the `kubectl` command to help us write our configuration files.  Kubernetes configuration files are YAML, so having an editor that supports and can help you syntax check YAML is really helpful.\\n\\n### Creating a Pod Definition\\n\\nLet\'s create a few Pod definitions.  Our application requires two containers to get working - the application and a database.\\n\\nLet\'s create the database Pod first.  And before you comment, the configuration isn\'t secure nor best practice.  We\'ll fix that later this week.  For now, let\'s focus on getting up and running.\\n\\nThis is a trick I learned from one of my teammates - Paul.  By using the `--output yaml` and `--dry-run=client` options, we can have the command help us write our YAML.  And with a bit of output redirection, we can stash it safely in a file for later use.\\n\\n```powershell\\nkubectl run azure-voting-db `\\n            --image \\"postgres:15.0-alpine\\" `\\n            --env \\"POSTGRES_PASSWORD=mypassword\\" `\\n            --output yaml `\\n            --dry-run=client > manifests/pod-db.yaml\\n```\\n\\nThis creates a file that looks like:\\n\\n```yml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    run: azure-voting-db\\n  name: azure-voting-db\\nspec:\\n  containers:\\n  - env:\\n    - name: POSTGRES_PASSWORD\\n      value: mypassword\\n    image: postgres:15.0-alpine\\n    name: azure-voting-db\\n    resources: {}\\n  dnsPolicy: ClusterFirst\\n  restartPolicy: Always\\nstatus: {}\\n```\\n\\nThe file, when supplied to the Kubernetes API, will identify what kind of resource to create, the API version to use, and the details of the container (as well as an environment variable to be supplied).\\n\\nWe\'ll get that container image started with the `kubectl` command.  Because the details of what to create are in the file, we don\'t need to specify much else to the `kubectl` command but the path to the file.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-db.yaml\\n```\\n\\nI\'m going to need the IP address of the Pod, so that my application can connect to it, so we can use `kubectl` to get some information about our pod.  By default, `kubectl get pod` only displays certain information but it retrieves a lot more.  We can use the [JSONPath syntax](https://kubernetes.io/docs/reference/kubectl/jsonpath/) to index into the response and get the information you want.\\n\\n:::tip\\n\\nTo see what you can get, I usually run the `kubectl` command with the output type (`-o JSON`) of JSON and then I can find where the data I want is and create my JSONPath query to get it.\\n\\n:::\\n\\n```powershell,\\n$DB_IP = kubectl get pod azure-voting-db -o jsonpath=\'{.status.podIP}\'\\n```\\n\\nNow, let\'s create our Pod definition for our application.  We\'ll use the same technique as before.\\n\\n```powershell\\nkubectl run azure-voting-app `\\n            --image \\"$AcrName.azurecr.io/cnny2023/azure-voting-app-rust:$BuildTag\\" `\\n            --env \\"DATABASE_SERVER=$DB_IP\\" `\\n            --env \\"DATABASE_PASSWORD=mypassword`\\n            --output yaml `\\n            --dry-run=client > manifests/pod-app.yaml\\n```\\n\\nThat command gets us a similar YAML file to the database container - you can see [the full file here](https://github.com/azure-samples/azure-voting-app-rust/blob/week2/day1/manifests/pod-app.yaml)\\n\\nLet\'s get our application container running.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-app.yaml\\n```\\n\\n### Now that the Application is Running\\n\\nWe can check the status of our Pods with:\\n\\n```powershell\\nkubectl get pods\\n```\\n\\nAnd we should see something like:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME               READY   STATUS    RESTARTS   AGE\\nazure-voting-app   1/1     Running   0          36s\\nazure-voting-db    1/1     Running   0          84s\\n```\\n\\nOnce our pod is running, we can check to make sure everything is working by letting `kubectl` proxy network connections to our Pod running the application. If we get the voting web page, we\'ll know the application found the database and we can start voting!\\n\\n```powershell\\nkubectl port-forward pod/azure-voting-app 8080:8080\\n```\\n\\n![Azure voting website in a browser with three buttons, one for Dogs, one for Cats, and one for Reset.  The counter is Dogs - 0 and Cats - 0.](../../static/img/cnny23/azure_voting_app.png)\\n\\nWhen you are done voting, you can stop the port forwarding by using Control-C to break the command.\\n\\n### Clean Up\\n\\nLet\'s clean up after ourselves and see if we can\'t get Kubernetes to help us keep our application running.  We can use the same configuration files to ensure that Kubernetes only removes what we want removed.\\n\\n```powershell\\nkubectl delete -f ./manifests/pod-app.yaml\\nkubectl delete -f ./manifests/pod-db.yaml\\n```\\n\\n### Summary - Pods\\n\\nA Pod is the most basic unit of work inside Kubernetes. Once the Pod is deleted, it\'s gone.  That leads us to our next topic (and final topic for today.)\\n\\n## Making the Pods Resilient with Deployments\\n\\nWe\'ve seen how easy it is to deploy a Pod and get our containers running on Nodes in our Kubernetes cluster.  But there\'s a problem with that.  Let\'s illustrate it.\\n\\n### Breaking Stuff\\n\\n#### Setting Back Up\\n\\nFirst, let\'s redeploy our application environment.  We\'ll start with our application container.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-db.yaml\\nkubectl get pod azure-voting-db -o jsonpath=\'{.status.podIP}\'\\n```\\n\\nThe second command will report out the new IP Address for our database container.  Let\'s open `./manifests/pod-app.yaml` and update the container IP to our new one.\\n\\n```yml\\n- name: DATABASE_SERVER\\n  value: YOUR_NEW_IP_HERE\\n```\\n\\nThen we can deploy the application with the information it needs to find its database.  We\'ll also list out our pods to see what is running.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-app.yaml\\nkubectl get pods\\n```\\n\\nFeel free to look back and use the port forwarding trick to make sure your app is running if you\'d like.\\n\\n#### Knocking It Down\\n\\nThe first thing we\'ll try to break is our application pod.  Let\'s delete it.\\n\\n```powershell\\nkubectl delete pod azure-voting-app\\n```\\n\\nThen, we\'ll check our pod\'s status:\\n\\n```powershell\\nkubectl get pods\\n```\\n\\nWhich should show something like:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME              READY   STATUS    RESTARTS   AGE\\nazure-voting-db   1/1     Running   0          50s\\n```\\n\\nWe should be able to recreate our application pod deployment with no problem, since it has the current database IP address and nothing else depends on it.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-app.yaml\\n```\\n\\nAgain, feel free to do some fun port forwarding and check your site is running.\\n\\n#### Uncomfortable Truths\\n\\nHere\'s where it gets a bit stickier, what if we delete the database container?\\n\\nIf we delete our database container and recreate it, it\'ll likely have a new IP address, which would force us to update our application configuration.  We\'ll look at some solutions for these problems in the next three posts this week.\\n\\nBecause our database problem is a bit tricky, we\'ll primarily focus on making our application layer more resilient and prepare our database layer for those other techniques over the next few days.\\n\\nLet\'s clean back up and look into making things more resilient.\\n\\n```powershell\\nkubectl delete -f ./manifests/pod-app.yaml\\nkubectl delete -f ./manifests/pod-db.yaml\\n```\\n\\n### The Deployment\\n\\nOne of the reasons you may want to use Kubernetes is it\'s ability to orchestrate workloads.  Part of that orchestration includes being able to ensure that certain workloads are running (regardless of what Node they might be on).\\n\\nWe saw that we could delete our application pod and then restart it from the manifest with little problem.  It just meant that we had to run a command to restart it.  We can use the [Deployment](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests) in Kubernetes to tell the orchestrator to ensure we have our application pod running.\\n\\nThe Deployment also can encompass a lot of extra configuration - controlling how many containers of a particular type should be running, how upgrades of container images should proceed, and more.\\n\\n#### Creating the Deployment\\n\\nFirst, we\'ll create a Deployment for our database. We\'ll use a technique similar to what we did for the Pod, with just a bit of difference.\\n\\n```powershell\\nkubectl create deployment azure-voting-db `\\n                            --image \\"postgres:15.0-alpine\\" `\\n                            --port 5432 `\\n                            --output yaml `\\n                            --dry-run=client > manifests/deployment-db.yaml\\n```\\n\\nUnlike our Pod definition creation, we can\'t pass in environment variable configuration from the command line.  We\'ll have to edit the YAML file to add that.\\n\\nSo, let\'s open `./manifests/deployment-db.yaml` in our editor and add the following in the `spec/containers` configuration.\\n\\n```yml\\n        env:\\n        - name: POSTGRES_PASSWORD\\n          value: \\"mypassword\\"\\n```\\n\\nYour file should look like this [deployment-db.yaml](https://github.com/azure-samples/azure-voting-app-rust/blob/week2/day1/manifests/deployment-db.yaml).\\n\\nOnce we have our configuration file updated, we can deploy our database container image.\\n\\n```powershell\\nkubectl apply -f ./manifests/deployment-db.yaml\\n```\\n\\nFor our application, we\'ll use the same technique.\\n\\n```powershell\\nkubectl create deployment azure-voting-app `\\n                        --image \\"$AcrName.azurecr.io/cnny2023/azure-voting-app-rust:$BuildTag\\" `\\n                        --port 8080 `\\n                        --output yaml `\\n                        --dry-run=client > manifests/deployment-app.yaml\\n```\\n\\nNext, we\'ll need to add an environment variable to the generated configuration.  We\'ll also need the new IP address for the database deployment.\\n\\nPreviously, we named the pod and were able to ask for the IP address with `kubectl` and a bit of JSONPath. Now, the deployment created the pod for us, so there\'s a bit of random in the naming.  Check out:\\n\\n```powershell\\nkubectl get pods\\n```\\n\\nShould return something like:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME                               READY   STATUS    RESTARTS   AGE\\nazure-voting-db-686d758fbf-8jnq8   1/1     Running   0          7s\\n```\\n\\nWe can either ask for the IP with the new pod name, or we can use a [selector](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors) to find our desired pod.\\n\\n```powershell\\nkubectl get pod --selector app=azure-voting-db -o jsonpath=\'{.items[0].status.podIP}\'\\n```\\n\\nNow, we can update our application deployment configuration file with:\\n\\n```yml\\n        env:\\n        - name: DATABASE_SERVER\\n          value: YOUR_NEW_IP_HERE\\n        - name: DATABASE_PASSWORD\\n          value: mypassword\\n```\\n\\nYour file should look like this [deployment-app.yaml](https://github.com/azure-samples/azure-voting-app-rust/blob/week2/day1/manifests/deployment-app.yaml) (but with IPs and image names matching your environment).\\n\\nAfter we save those changes, we can deploy our application.\\n\\n```powershell\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\nLet\'s test the resilience of our app now. First, we\'ll delete the pod running our application, then we\'ll check to make sure Kubernetes restarted our application pod.\\n\\n```powershell\\nkubectl get pods\\n```\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME                                READY   STATUS    RESTARTS   AGE\\nazure-voting-app-56c9ccc89d-skv7x   1/1     Running   0          71s\\nazure-voting-db-686d758fbf-8jnq8    1/1     Running   0          12m\\n```\\n\\n```powershell\\nkubectl delete pod azure-voting-app-56c9ccc89d-skv7x\\nkubectl get pods\\n```\\n\\n```\\nazure-voting-app-rust \u276f  kubectl delete pod azure-voting-app-56c9ccc89d-skv7x\\n>> kubectl get pods\\npod \\"azure-voting-app-56c9ccc89d-skv7x\\" deleted\\nNAME                                READY   STATUS    RESTARTS   AGE\\nazure-voting-app-56c9ccc89d-2b5mx   1/1     Running   0          2s\\nazure-voting-db-686d758fbf-8jnq8    1/1     Running   0          14m\\n```\\n\\n:::info\\nYour Pods will likely have different identifiers at the end, so adjust your commands to match the names in your environment.\\n:::\\n\\nAs you can see, by the time the `kubectl get pods` command was run, Kubernetes had already spun up a new pod for the application container image.  Thanks Kubernetes!\\n\\n### Clean up\\n\\nSince we can\'t just delete the pods, we have to delete the deployments.\\n\\n```powershell\\nkubectl delete -f ./manifests/deployment-app.yaml\\nkubectl delete -f ./manifests/deployment-db.yaml\\n```\\n\\n### Summary - Deployments\\n\\nDeployments allow us to create more durable configuration for the workloads we deploy into Kubernetes. As we dig deeper, we\'ll discover more capabilities the deployments offer. Check out the Resources below for more.\\n\\n## Exercise\\n\\nIf you want to try these steps, head over to [the source repository](https://aka.ms/azure-voting-app-rust), fork it, clone it locally, and give it a spin!\\n\\nYou can check your manifests against the manifests in the `week2/day1` [branch of the source repository](https://github.com/azure-samples/azure-voting-app-rust/tree/week2/day1/manifests).\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n### Documentation\\n\\n* [Azure Kubernetes Service](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws)\\n* [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?WT.mc_id=containers-84290-stmuraws&tabs=bicep)\\n* [Azure Voting App in Rust](https://aka.ms/azure-voting-app-rust)\\n* [Pods](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#pods).\\n* [Nodes](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#nodes-and-node-pools)\\n* [kubectl](https://kubernetes.io/docs/reference/kubectl/kubectl/)\\n* [JSONPath syntax](https://kubernetes.io/docs/reference/kubectl/jsonpath/)\\n* [Deployment](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests)\\n* [Labels and Selectors](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors)\\n\\n### Training\\n\\n* [Learning Path - Introduction to Kubernetes on Azure](https://learn.microsoft.com/training/paths/intro-to-kubernetes-on-azure/?WT.mc_id=containers-84290-stmuraws)"},{"id":"explore-options","metadata":{"permalink":"/Cloud-Native/cnny-2023/explore-options","source":"@site/blog-cnny/2023-01-27/explore-options.md","title":"1-5. Exploring Cloud-Native Options","description":"There are many cloud-native technologies - but which are the best fit for your projects?","date":"2023-01-27T00:00:00.000Z","formattedDate":"January 27, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":5.55,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://pbs.twimg.com/profile_images/1493684068227055617/iC9r8v6Z_400x400.jpg","key":"cory"}],"frontMatter":{"slug":"explore-options","title":"1-5. Exploring Cloud-Native Options","authors":["cory"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloud-native","containers","decision-tree","kubernetes","serverless","microservices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-05.png","description":"There are many cloud-native technologies - but which are the best fit for your projects?","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"2-1. Kubernetes Fundamentals - Pods and Deployments","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-1"},"nextItem":{"title":"1-4. Microservices 101","permalink":"/Cloud-Native/cnny-2023/microservices-101"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/explore-options\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Serverless Container Options\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Explore technology and tooling options for building and deploying your Cloud-native solution\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-05.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@cskimming\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/explore-options\\" />\\n</head>\\n\\nWe are excited to be wrapping up our first week of #CloudNativeNewYear! This week, we have tried to set the stage by covering the fundamentals of cloud-native practices and technologies, including primers on [containerization](https://azure.github.io/Cloud-Native/cnny-2023/containers-101/), [microservices](https://azure.github.io/Cloud-Native/cnny-2023/microservices-101), and [Kubernetes](https://azure.github.io/Cloud-Native/cnny-2023/Kubernetes-101).  \\n\\n:::tip Don\'t forget to sign up for the the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n\\n:::\\n\\nToday, we will do a brief recap of some of these technologies and provide some basic guidelines for when it is optimal to use each. \\n\\n---\\n\\n## What We\'ll Cover\\n* To Containerize or not to Containerize?\\n* The power of Kubernetes\\n* Where does Serverless fit? \\n* Resources\\n* What\'s coming next!\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n---\\n\\n:::info Just joining us now? Check out these other Week 1 posts:\\n\\n * [Cloud-native fundamentals](https://azure.github.io/Cloud-Native/cnny-2023/cloud-native-fundamentals)\\n * [Containers 101](https://azure.github.io/Cloud-Native/cnny-2023/containers-101)\\n * [Microservices 101](https://azure.github.io/Cloud-Native/cnny-2023/microservices-101)\\n * [Kubernetes 101](https://azure.github.io/Cloud-Native/cnny-2023/Kubernetes-101)\\n \\n:::\\n\\n--- \\n## To Containerize or not to Containerize? \\n\\nAs mentioned in our Containers 101 post earlier this week, containers can provide several benefits over traditional virtualization methods, which has made them popular within the software development community. Containers provide a consistent and predictable runtime environment, which can help reduce the risk of compatibility issues and simplify the deployment process. Additionally, containers can improve resource efficiency by allowing multiple applications to run on the same host while isolating their dependencies. \\n\\nSome types of apps that are a particularly good fit for containerization include: \\n\\n1.\\t**Microservices:** Containers are particularly well-suited for microservices-based applications, as they can be used to isolate and deploy individual components of the system. This allows for more flexibility and scalability in the deployment process.\\n2.\\t**Stateless applications:** Applications that do not maintain state across multiple sessions, such as web applications, are well-suited for containers. Containers can be easily scaled up or down as needed and replaced with new instances, without losing data.\\n3.\\t**Portable applications:** Applications that need to be deployed in different environments, such as on-premises, in the cloud, or on edge devices, can benefit from containerization. The consistent and portable runtime environment of containers can make it easier to move the application between different environments.\\n4.\\t**Legacy applications:** Applications that are built using older technologies or that have compatibility issues can be containerized to run in an isolated environment, without impacting other applications or the host system.\\n5.\\t**Dev and testing environments:** Containerization can be used to create isolated development and testing environments, which can be easily created and destroyed as needed.\\n\\nWhile there are many types of applications that can benefit from a containerized approach, it\'s worth noting that containerization is not **always** the best option, and it\'s important to weigh the benefits and trade-offs before deciding to containerize an application. Additionally, some types of applications may not be a good fit for containers including:\\n\\n* Apps that require full access to host resources: Containers are isolated from the host system, so if an application needs direct access to hardware resources such as GPUs or specialized devices, it might not work well in a containerized environment.\\n* Apps that require low-level system access: If an application requires deep access to the underlying operating system, it may not be suitable for running in a container.\\n* Applications that have specific OS dependencies: Apps that have specific dependencies on a certain version of an operating system or libraries may not be able to run in a container.\\n* Stateful applications: Apps that maintain state across multiple sessions, such as databases, may not be well suited for containers. Containers are ephemeral by design, so the data stored inside a container may not persist between restarts.\\n\\nThe good news is that some of these limitations can be overcome with the use of specialized containerization technologies such as Kubernetes, and by carefully designing the architecture of the application. \\n\\n---\\n## The power of Kubernetes\\n\\nSpeaking of Kubernetes...\\n\\nKubernetes is a powerful tool for managing and deploying containerized applications in production environments, particularly for applications that need to scale, handle large numbers of requests, or run in multi-cloud or hybrid environments.\\n\\nKubernetes is well-suited for a wide variety of applications, but it is particularly well-suited for the following types of applications:\\n\\n1.\\t**Microservices-based applications:** Kubernetes provides a powerful set of tools for managing and deploying microservices-based applications, making it easy to scale, update, and manage the individual components of the application.\\n2.\\t**Stateful applications:** Kubernetes provides support for stateful applications through the use of Persistent Volumes and StatefulSets, allowing for applications that need to maintain state across multiple instances. \\n3.\\t**Large-scale, highly-available systems:** Kubernetes provides built-in support for scaling, self-healing, and rolling updates, making it an ideal choice for large-scale, highly-available systems that need to handle large numbers of users and requests.\\n4.\\t**Multi-cloud and hybrid environments:** Kubernetes can be used to deploy and manage applications across multiple cloud providers and on-premises environments, making it a good choice for organizations that want to take advantage of the benefits of multiple cloud providers or that need to deploy applications in a hybrid environment.\\n\\n:::info New to Kubernetes?\\n\\nCatch [A Quickstart Guide to Kubernetes Concepts](https://info.microsoft.com/ww-ondemand-a-quickstart-guide-to-kubernetes-concepts.html?lcid=en-us) on demand, now!\\n\\n:::\\n\\n---\\n# Where does Serverless fit in? \\n\\nServerless is a cloud computing model where the cloud provider (like Azure) is responsible for executing a piece of code by dynamically allocating the resources. With serverless, you only pay for the exact amount of compute time that you use, rather than paying for a fixed amount of resources. This can lead to significant cost savings, particularly for applications with variable or unpredictable workloads.\\n\\nServerless is commonly used for building applications like web or mobile apps, IoT, data processing, and real-time streaming - apps where the workloads are variable and high scalability is required.\\nIt\'s important to note that serverless is not a replacement for all types of workloads - it\'s best suited for stateless, short-lived and small-scale workloads.\\n\\nFor a detailed look into the world of Serverless and lots of great learning content, revisit [#30DaysofServerless](https://azure.github.io/Cloud-Native/serverless-september/30DaysOfServerless/).\\n\\n---\\n## Resources\\n* **Register** for the [Cloud Skills Challenge](https://aka.ms/Challenge) - 30 days to complete it!\\n* **Learning Resources**: [#30DaysOfCloudNative Collection](https://aka.ms/CNNY/collection)\\n* **eBook:** [Cloud Native Infrastructure with Azure](https://azure.microsoft.com/resources/cloud-native-infrastructure-with-microsoft-azure/?WT.mc_id=javascript-74010-ninarasi)\\n* **eBook:** [Cloud-native Architecture Mapbook](https://azure.microsoft.com/resources/azure-cloud-native-architecture-mapbook/?WT.mc_id=javascript-74010-ninarasi)\\n\\n---\\n## What\'s up next in #CloudNativeNewYear?\\n\\nWeek 1 has been all about the fundamentals of cloud-native. Next week, the team will be diving in to application deployment with Azure Kubernetes Service. Don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml?WT.mc_id=javascript-74010-ninarasi) to the blog to get daily posts delivered directly to your favorite feed reader!\\n\\n---"},{"id":"microservices-101","metadata":{"permalink":"/Cloud-Native/cnny-2023/microservices-101","source":"@site/blog-cnny/2023-01-26/30days.md","title":"1-4. Microservices 101","description":"What are Microservices? Why are they a core pillar for Cloud-native and how does Kubernetes help in their deployment?","date":"2023-01-26T00:00:00.000Z","formattedDate":"January 26, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"microservices","permalink":"/Cloud-Native/cnny-2023/tags/microservices"}],"readingTime":5.265,"hasTruncateMarker":false,"authors":[{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"}],"frontMatter":{"slug":"microservices-101","title":"1-4. Microservices 101","authors":["josh"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps","microservices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-04.png","description":"What are Microservices? Why are they a core pillar for Cloud-native and how does Kubernetes help in their deployment?","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service","microservices"]},"prevItem":{"title":"1-5. Exploring Cloud-Native Options","permalink":"/Cloud-Native/cnny-2023/explore-options"},"nextItem":{"title":"1-3. Kubernetes 101","permalink":"/Cloud-Native/cnny-2023/Kubernetes-101"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/microservices-101\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Microservices 101\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"What are Microservices? Why are they a core pillar for Cloud-native and how does Kubernetes help in their deployment?\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-04.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@joshduffney\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/microservices-101\\" />\\n</head>\\n\\nWelcome to `Day 4 of Week 1` of #CloudNativeNewYear!\\n\\nThis week we\'ll focus on advanced topics and best practices for Cloud-Native practitioners, kicking off with this post on _Serverless Container Options_ with Azure. We\'ll look at technologies, tools and best practices that range from managed services like Azure Kubernetes Service, to options allowing finer granularity of control and oversight.\\n\\n\\n## What We\'ll Cover\\n * What is Microservice Architecture? \\n * How do you design a Microservice? \\n * What challenges do Microservices introduce?\\n * Conclusion\\n * Resources\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n---\\n\\nMicroservices are a modern way of designing and building software that increases deployment velocity by decomposing an application into small autonomous services that can be deployed independently. \\n\\nBy deploying loosely coupled microservices your applications can be developed, deployed, and scaled independently. Because each service is independent, it can be updated or replaced without having to worry about the impact on the rest of the application. This means that if a bug is found in one service, it can be fixed without having to redeploy the entire application. All of which gives an organization the ability to deliver value to their customers faster. \\n\\nIn this article, we will explore the basics of microservices architecture, its benefits and challenges, and how it can help improve the development, deployment, and maintenance of software applications. \\n\\n## What is Microservice Architecture? \\n\\nBefore explaining what Microservice architecture is, it\u2019s important to understand what problems microservices aim to address. \\n\\nTraditional software development is centered around building monolithic applications. Monolithic applications are built as a single, large codebase. Meaning your code is tightly coupled causing the monolithic app to suffer from the following: \\n\\n**Too much Complexity:** Monolithic applications can become complex and difficult to understand and maintain as they grow. This can make it hard to identify and fix bugs and add new features. \\n\\n**Difficult to Scale:** Monolithic applications can be difficult to scale as they often have a single point of failure, which can cause the whole application to crash if a service fails. \\n\\n**Slow Deployment:** Deploying a monolithic application can be risky and time-consuming, as a small change in one part of the codebase can affect the entire application. \\n\\nMicroservice architecture (often called microservices) is an architecture style that addresses the challenges created by Monolithic applications. Microservices architecture is a way of designing and building software applications as a collection of small, independent services that communicate with each other through APIs. This allows for faster development and deployment cycles, as well as easier scaling and maintenance than is possible with a monolithic application. \\n\\n## How do you design a Microservice? \\n\\nBuilding applications with Microservices architecture requires a different approach. Microservices architecture focuses on business capabilities rather than technical layers, such as data access or messaging. Doing so requires that you shift your focus away from the technical stack and model your applications based upon the various domains that exist within the business. \\n\\nDomain-driven design (DDD) is a way to design software by focusing on the business needs. You can use Domain-driven design as a framework that guides the development of well-designed microservices by building services that encapsulate knowledge in each domain and abstract that knowledge from clients. \\n\\nIn Domain-driven design you start by modeling the business domain and creating a domain model. A domain model is an abstract model of the business model that distills and organizes a domain of knowledge and provides a common language for developers and domain experts. It\u2019s the resulting domain model that microservices a best suited to be built around because it helps establish a well-defined boundary between external systems and other internal applications. \\n\\nIn short, before you begin designing microservices, start by mapping the functions of the business and their connections to create a domain model for the microservice(s) to be built around. \\n\\n \\n## What challenges do Microservices introduce? \\n\\nMicroservices solve a lot of problems and have several advantages, but the grass isn\u2019t always greener on the other side. \\n\\nOne of the key challenges of microservices is managing communication between services. Because services are independent, they need to communicate with each other through APIs. This can be complex and difficult to manage, especially as the number of services grows. To address this challenge, it is important to have a clear API design, with well-defined inputs and outputs for each service. It is also important to have a system for managing and monitoring communication between services, to ensure that everything is running smoothly.  \\n\\nAnother challenge of microservices is managing the deployment and scaling of services. Because each service is independent, it needs to be deployed and scaled separately from the rest of the application. This can be complex and difficult to manage, especially as the number of services grows. To address this challenge, it is important to have a clear and consistent deployment process, with well-defined steps for deploying and scaling each service. Furthermore, it is advisable to host them on a system with self-healing capabilities to reduce operational burden. \\n\\nIt is also important to have a system for monitoring and managing the deployment and scaling of services, to ensure optimal performance.  \\n\\nEach of these challenges has created fertile ground for tooling and process that exists in the cloud-native ecosystem. Kubernetes, CI CD, and other DevOps practices are part of the package of adopting the microservices architecture. \\n\\n## Conclusion \\n\\nIn summary, microservices architecture focuses on software applications as a collection of small, independent services that communicate with each other over well-defined APIs. \\n\\nThe main advantages of microservices include:\\n* increased flexibility and scalability per microservice, \\n* efficient resource utilization (with help from a container orchestrator like Kubernetes), \\n* and faster development cycles. \\n\\nContinue following along with this series to see how you can use Kubernetes to help adopt microservices patterns in your own environments!\\n\\n## Resources \\n\\n* [Microservice Applications](https://azure.microsoft.com/solutions/microservice-applications?WT.mc_id=containers-84290-stmuraws)\\n* [Microservices architecture design - Azure Architecture Center | Microsoft Learn](https://learn.microsoft.com/azure/architecture/microservices?WT.mc_id=containers-84290-stmuraws)\\n* [Design a microservices architecture - Azure Architecture Center | Microsoft Learn](https://learn.microsoft.com/azure/architecture/microservices/design?WT.mc_id=containers-84290-stmuraws)\\n* [Domain analysis for microservices - Azure Architecture Center | Microsoft Learn](https://learn.microsoft.com/azure/architecture/microservices/model/domain-analysis?WT.mc_id=containers-84290-stmuraws)"},{"id":"Kubernetes-101","metadata":{"permalink":"/Cloud-Native/cnny-2023/Kubernetes-101","source":"@site/blog-cnny/2023-01-25/30days.md","title":"1-3. Kubernetes 101","description":"What is Kubernetes? And why is it so ubiquitous in Cloud-native solutions?","date":"2023-01-25T00:00:00.000Z","formattedDate":"January 25, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":2.385,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"Kubernetes-101","title":"1-3. Kubernetes 101","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps"],"image":"https://azure.github.io/Cloud-Native/img/og/30-03.png","description":"What is Kubernetes? And why is it so ubiquitous in Cloud-native solutions?","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"1-4. Microservices 101","permalink":"/Cloud-Native/cnny-2023/microservices-101"},"nextItem":{"title":"1-2. Containers 101","permalink":"/Cloud-Native/cnny-2023/containers-101"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/kubernetes-101\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Kubernetes 101\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"What is Kubernetes? And why is it so ubiquitous in Cloud-native solutions?\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-03.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/kubernetes-101\\" />\\n</head>\\n\\nWelcome to `Day 3 of Week 1` of #CloudNativeNewYear!\\n\\nThis week we\'ll focus on what Kubernetes is.\\n\\n## What We\'ll Cover\\n * Introduction\\n * What is Kubernetes? (Video)\\n * How does Kubernetes Work? (Video)\\n * Conclusion\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n---\\n\\n:::tip REGISTER & LEARN: KUBERNETES 101\\n\\nInterested in a dive into Kubernetes and a chance to talk to experts? \\n\\n\ud83c\udf99: Join us **Jan 26 @1pm PST** \\n[by registering here](https://info.microsoft.com/ww-landing-a-quickstart-guide-to-kubernetes-concepts.html?WT.mc_id=containers-84290-stmuraws)\\n\\nHere\'s what you will learn:\\n * Key concepts and core principles of Kubernetes.\\n * How to deploy, scale and manage containerized workloads.\\n * Live Demo of the concepts explained\\n * How to get started with Azure Kubernetes Service for free.\\n\\n**Start your free Azure Kubernetes Trial Today!!**: [aka.ms/TryAKS](https://aka.ms/TryAKS)\\n\\n:::\\n\\n## Introduction\\n\\nKubernetes is an open source container orchestration engine that can help with automated deployment, scaling, and management of our applications.\\n\\nKubernetes takes physical (or virtual) resources and provides a consistent API over them, bringing a consistency to the management and runtime experience for our applications.  Kubernetes provides us with a number of capabilities such as:\\n\\n* Container scheduling\\n* Service discovery and load balancing\\n* Storage orchestration\\n* Automated rollouts and rollbacks\\n* Automatic bin packing\\n* Self-healing\\n* Secret and configuration management\\n\\nWe\'ll learn more about most of these topics as we progress through Cloud Native New Year.\\n\\n## What is Kubernetes?\\n\\nLet\'s hear from Brendan Burns, one of the founders of Kubernetes as to what Kubernetes actually is.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/q1PcAawa4Bg\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n## How does Kubernetes Work?\\n\\nAnd Brendan shares a bit more with us about how Kubernetes works.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/daVUONZqn88\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n## Conclusion\\n\\nKubernetes allows us to deploy and manage our applications effectively and consistently. \\n\\nBy providing a consistent API across many of the concerns our applications have, like load balancing, networking, storage, and compute, Kubernetes improves both our ability to build and ship new software. \\n\\nThere are standards for the applications to depend on for resources needed. Deployments, metrics, and logs are provided in a standardized fashion allowing more effecient operations across our application environments. \\n\\nAnd since Kubernetes is an open source platform, it can be found in just about every type of operating environment - cloud, virtual machines, physical hardware, shared data centers, even small devices like Rasberry Pi\'s!\\n\\nWant to learn more?  [Join us for a webinar on Kubernetes Concepts (or catch the playback) on Thursday, January 26th at 1 PM PST](https://info.microsoft.com/ww-landing-a-quickstart-guide-to-kubernetes-concepts.html?WT.mc_id=containers-84290-stmuraws) and watch for the rest of this series right here!"},{"id":"containers-101","metadata":{"permalink":"/Cloud-Native/cnny-2023/containers-101","source":"@site/blog-cnny/2023-01-24/30days.md","title":"1-2. Containers 101","description":"Let\'s dive into the various technologies behind Cloud Native development, starting with Containers.","date":"2023-01-24T00:00:00.000Z","formattedDate":"January 24, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"containers","permalink":"/Cloud-Native/cnny-2023/tags/containers"}],"readingTime":3.965,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"},{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"},{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"}],"frontMatter":{"slug":"containers-101","title":"1-2. Containers 101","authors":["steven","paul","josh"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps"],"image":"https://azure.github.io/Cloud-Native/img/og/30-02.png","description":"Let\'s dive into the various technologies behind Cloud Native development, starting with Containers.","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service","containers"]},"prevItem":{"title":"1-3. Kubernetes 101","permalink":"/Cloud-Native/cnny-2023/Kubernetes-101"},"nextItem":{"title":"1-1. Cloud-native Fundamentals","permalink":"/Cloud-Native/cnny-2023/cloud-native-fundamentals"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/containers-101\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Container 101\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Let\'s dive into the various technologies behind Cloud Native development, starting with Containers.\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-02.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/containers-101\\" />\\n</head>\\n\\nWelcome to `Day 2 of Week 1` of #CloudNativeNewYear!\\n\\nToday, we\'ll focus on building an understanding of containers.\\n\\n## What We\'ll Cover\\n * Introduction\\n * How do Containers Work?\\n * Why are Containers Becoming so Popular?\\n * Conclusion\\n * Resources\\n * Learning Path\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n---\\n\\n:::tip REGISTER & LEARN: KUBERNETES 101\\n\\nInterested in a dive into Kubernetes and a chance to talk to experts? \\n\\n\ud83c\udf99: Join us **Jan 26 @1pm PST** \\n[by registering here](https://info.microsoft.com/ww-landing-a-quickstart-guide-to-kubernetes-concepts.html?lcid=en-us)\\n\\nHere\'s what you will learn:\\n * Key concepts and core principles of Kubernetes.\\n * How to deploy, scale and manage containerized workloads.\\n * Live Demo of the concepts explained\\n * How to get started with Azure Kubernetes Service for free.\\n\\n**Start your free Azure Kubernetes Trial Today!!**: [aka.ms/TryAKS](https://aka.ms/TryAKS)\\n\\n:::\\n\\n## Introduction \\n\\n \\n\\nIn the beginning, we deployed our applications onto physical servers.  We only had a certain number of those servers, so often they hosted multiple applications.  This led to some problems when those applications shared dependencies.  Upgrading one application could break another application on the same server.  \\n\\nEnter virtualization.  Virtualization allowed us to run our applications in an isolated operating system instance.  This removed much of the risk of updating shared dependencies.  However, it increased our overhead since we had to run a full operating system for each application environment. \\n\\nTo address the challenges created by virtualization, containerization was created to improve isolation without duplicating kernel level resources. Containers provide efficient and consistent deployment and runtime experiences for our applications and have become very popular as a way of packaging and distributing applications. \\n\\n \\n \\n## How do Containers Work? \\n\\nContainers build on two capabilities in the Linux operating system, namespaces and cgroups.  These constructs allow the operating system to provide isolation to a process or group of processes, keeping their access to filesystem resources separate and providing controls on resource utilization.  This, combined with tooling to help package, deploy, and run container images has led to their popularity in today\u2019s operating environment.  This provides us our isolation without the overhead of additional operating system resources. \\n\\nWhen a container host is deployed on an operating system, it works at scheduling the access to the OS (operating systems) components. This is done by providing a logical isolated group that can contain processes for a given application, called a namespace. The container host then manages /schedules access from the namespace to the host OS.  The container host then uses cgroups to allocate compute resources. Together, the container host with the help of cgroups and namespaces can schedule multiple applications to access host OS resources.  \\n\\nOverall, this gives the illusion of virtualizing the host OS, where each application gets its own OS. In actuality, all the applications are running on the same operating system and sharing the same kernel as the container host. \\n \\n## Why is Containerization so Popular? \\n \\nContainers are popular in the software development industry because they provide several benefits over traditional virtualization methods. Some of these benefits include: \\n \\n* **Portability**: Containers make it easy to move an application from one environment to another without having to worry about compatibility issues or missing dependencies. \\n* **Isolation**: Containers provide a level of isolation between the application and the host system, which means that the application running in the container cannot access the host system\'s resources. \\n* **Scalability**: Containers make it easy to scale an application up or down as needed, which is useful for applications that experience a lot of traffic or need to handle a lot of data. \\n* **Resource Efficiency**: Containers are more resource-efficient than traditional virtualization methods because they don\'t require a full operating system to be running on each virtual machine. \\n* **Cost-Effective**: Containers are more cost-effective than traditional virtualization methods because they don\'t require expensive hardware or licensing fees. \\n \\n\\n## Conclusion \\n \\nContainers are a powerful technology that allows developers to package and deploy applications in a portable and isolated environment. This technology is becoming increasingly popular in the world of software development and is being used by many companies and organizations to improve their application deployment and management processes. With the benefits of portability, isolation, scalability, resource efficiency, and cost-effectiveness, containers are definitely worth considering for your next application development project. \\n\\n \\nContainerizing applications is a key step in modernizing them, and there are many other patterns that can be adopted to achieve cloud-native architectures, including using serverless platforms, Kubernetes, and implementing DevOps practices. \\n\\n## Resources \\n\\n* [What are Containers](https://azure.microsoft.com/resources/cloud-computing-dictionary/what-is-a-container/?WT.mc_id=containers-84290-stmuraws) \\n* [Containerizing .NET Applications](https://learn.microsoft.com/dotnet/architecture/microservices/container-docker-introduction/?WT.mc_id=containers-84290-stmuraws) \\n \\n \\n## Learning Path \\n\\n* [Introduction to Docker Containers](https://learn.microsoft.com/training/modules/intro-to-docker-containers/?WT.mc_id=containers-84290-stmuraws)"},{"id":"cloud-native-fundamentals","metadata":{"permalink":"/Cloud-Native/cnny-2023/cloud-native-fundamentals","source":"@site/blog-cnny/2023-01-23/cloud-native-fundamentals.md","title":"1-1. Cloud-native Fundamentals","description":"The fundamentals of Cloud-native!","date":"2023-01-23T00:00:00.000Z","formattedDate":"January 23, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":4.06,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://pbs.twimg.com/profile_images/1493684068227055617/iC9r8v6Z_400x400.jpg","key":"cory"}],"frontMatter":{"slug":"cloud-native-fundamentals","title":"1-1. Cloud-native Fundamentals","authors":["cory"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloud-native","containers","decision-tree","kubernetes"],"image":"https://azure.github.io/Cloud-Native/img/og/30-01.png","description":"The fundamentals of Cloud-native!","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"1-2. Containers 101","permalink":"/Cloud-Native/cnny-2023/containers-101"},"nextItem":{"title":"Kicking Off 30DaysOfCloudNative!","permalink":"/Cloud-Native/cnny-2023/cnny-kickoff"}},"content":"Welcome to `Week 1` of #CloudNativeNewYear!\\n\\n\\n![Cloud-native New Year](../../static/img/cnny23/cnny-event-card.png)\\n\\nYou will often hear the term \\"cloud-native\\" when discussing modern application development, but even a quick online search will return a huge number of articles, tweets, and web pages with a variety of definitions. So, what does cloud-native actually mean? Also, what makes an application a *cloud-native application* versus a \\"regular\\" application? \\n\\nToday, we will address these questions and more as we kickstart our learning journey (and our new year!) with an introductory dive into the wonderful world of cloud-native. \\n\\n---\\n\\n## What We\'ll Cover\\n * What is cloud-native? \\n * What is a cloud-native application?\\n * The benefits of cloud-native\\n * The five pillars of cloud-native \\n * **Exercise**: Take the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n\\n---\\n\\n## 1. What is cloud-native? \\n\\nThe term \\"cloud-native\\" can seem pretty self-evident (yes, hello, native to the cloud?), and in a way, it is. \\nWhile there are lots of definitions of cloud-native floating around, at it\'s core, cloud-native simply refers to a modern approach to building software that takes advantage of cloud services and environments. This includes using cloud-native technologies, such as containers, microservices, and serverless, and following best practices for deploying, scaling, and managing applications in a cloud environment.\\n\\n:::info **Official definition** from the [Cloud Native Computing Foundation](https://www.cncf.io/):\\n*Cloud-native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.*\\n\\n*These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.* [Source](https://github.com/cncf/foundation/blob/main/charter.md)\\n:::\\n\\n---\\n\\n## 2. So, what exactly is a cloud-native application? \\n Cloud-native applications are *specifically* designed to take advantage of the scalability, resiliency, and distributed nature of modern cloud infrastructure.  But how does this differ from a \\"traditional\\" application?\\n\\nTraditional applications are generally been built, tested, and deployed as a single, monolithic unit.  The monolithic nature of this type of architecture creates close dependencies between components.  This complexity and interweaving only increases as an application grows and can make it difficult to evolve (not to mention troubleshoot) and challenging to operate over time. \\n\\nTo contrast, in cloud-native architectures the application components are decomposed into loosely coupled services, rather than built and deployed as one block of code. This decomposition into multiple self-contained services enables teams to manage complexity and improve the speed, agility, and scale of software delivery. Many small parts enables teams to make targeted updates, deliver new features, and fix any issues without leading to broader service disruption. \\n\\n---\\n\\n## 3. The benefits of cloud-native\\nCloud-native architectures can bring many benefits to an organization, including: \\n\\n1. **Scalability:** easily scale up or down based on demand, allowing organizations to adjust their resource usage and costs as needed.\\n2. **Flexibility:** deploy and run on any cloud platform, and easily move between clouds and on-premises environments.\\n3. **High-availability:** techniques such as redundancy, self-healing, and automatic failover help ensure that cloud-native applications are designed to be highly-available and fault tolerant.\\n4. **Reduced costs:** take advantage of the pay-as-you-go model of cloud computing, reducing the need for expensive infrastructure investments.\\n5. **Improved security:** tap in to cloud security features, such as encryption and identity management, to improve the security of the application.\\n6. **Increased agility:** easily add new features or services to your applications to meet changing business needs and market demand.\\n\\n---\\n\\n## 4. The pillars of cloud-native\\n\\nThere are five areas that are generally cited as the core building blocks of cloud-native architecture: \\n\\n1.\\t[Microservices](https://learn.microsoft.com/devops/deliver/what-are-microservices): Breaking down monolithic applications into smaller, independent, and loosely-coupled services that can be developed, deployed, and scaled independently.\\n2.\\tContainers: Packaging software in lightweight, portable, and self-sufficient containers that can run consistently across different environments.\\n3.\\tAutomation: Using automation tools and DevOps processes to manage and operate the cloud-native infrastructure and applications, including deployment, scaling, monitoring, and self-healing.\\n4.\\tService discovery: Using service discovery mechanisms, such as APIs & service meshes, to enable services to discover and communicate with each other.\\n5.\\tObservability: Collecting and analyzing data from the infrastructure and applications to understand and optimize the performance, behavior, and health of the system.\\n\\nThese can (and should!) be used in combination to deliver cloud-native solutions that are highly scalable, flexible, and available. \\n\\n:::info WHAT\'S NEXT\\n\\nStay tuned, as we will be diving deeper into these topics in the coming weeks:\\n\\n* **Jan 24**: Containers 101\\n* **Jan 25**: Adopting Microservices with Kubernetes\\n* **Jan 26**: Kubernetes 101\\n* **Jan 27**: Exploring your Cloud-native Options\\n:::\\n\\n---\\n\\n## Resources\\n\\n* **Register** for the [Cloud Skills Challenge](https://aka.ms/Challenge) - 30 days to complete it!\\n* **Resources**: [#30DaysOfCloudNative Collection](https://aka.ms/CNNY/collection)\\n* **eBook:** [Cloud Native Infrastructure with Azure](https://azure.microsoft.com/resources/cloud-native-infrastructure-with-microsoft-azure/)\\n\\n---\\n\\nDon\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml?WT.mc_id=javascript-74010-ninarasi) to the blog to get daily posts delivered directly to your favorite feed reader!\\n\\n---"},{"id":"cnny-kickoff","metadata":{"permalink":"/Cloud-Native/cnny-2023/cnny-kickoff","source":"@site/blog-cnny/2023-01-22/30days.md","title":"Kicking Off 30DaysOfCloudNative!","description":"Let\'s  kick-off Cloud Native New Year with #30DaysOfCloudNative","date":"2023-01-22T00:00:00.000Z","formattedDate":"January 22, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":3.175,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://pbs.twimg.com/profile_images/1493684068227055617/iC9r8v6Z_400x400.jpg","key":"cory"},{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://pbs.twimg.com/profile_images/1520928730230652928/00BaK5xn_400x400.jpg","key":"devanshi"},{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"},{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"}],"frontMatter":{"slug":"cnny-kickoff","title":"Kicking Off 30DaysOfCloudNative!","authors":["cory","devanshi","steven","nitya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps"],"image":"https://azure.github.io/Cloud-Native/img/og/30-00.png","description":"Let\'s  kick-off Cloud Native New Year with #30DaysOfCloudNative","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"prevItem":{"title":"1-1. Cloud-native Fundamentals","permalink":"/Cloud-Native/cnny-2023/cloud-native-fundamentals"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/cnny-kickoff\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Kicking off Cloud Native New Year 2023\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Let\'s  kick-off Cloud Native New Year with #30DaysOfCloudNative\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-00.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@nitya\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/cnny-kickoff\\" />\\n</head>\\n\\nWelcome to the `Kick-off Post` for #30DaysOfCloudNative - one of the core initiatives within #CloudNativeNewYear! Over the next four weeks, join us as we take you from fundamentals to functional usage of Cloud-native technologies, one blog post at a time! Read on to learn a little bit about this initiative and what you can expect to learn from this journey!\\n\\n\\n## What We\'ll Cover\\n * What is Cloud-native New Year? (3 initiatives)\\n * How can I _skill up_ (30 days)\\n * Who is behind this? (Team Contributors)\\n * **Exercise**: Take the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n * **Resources**: [#30DaysOfCloudNative Collection](https://aka.ms/CNNY/collection).\\n\\n---\\n\\n![Cloud-native New Year](../../static/img/cnny23/cnny-event-card.png)\\n\\n\\nWelcome to `Week 01` of [ \ud83e\udd73 #CloudNativeNewYear ](https://aka.ms/CNNY)! Today, we kick off a full month of content and activities to skill you up on all things Cloud-native on Azure with content, events, and community interactions! Read on to learn about what we have planned!\\n\\n---\\n\\n## Explore our initiatives\\n\\nWe have a number of initiatives planned for the month to help you learn and skill up on relevant technologies. Click on the links to visit the relevant pages for each. \\n\\n* [#30DaysOfCloudNative](/Cloud-Native/cnny-2023/) - 4 themed weeks of daily articles in a structured roadmap\\n* [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge) - skill up by competing with peers to complete modules\\n* [Ask The Expert](https://aka.ms/CNNY/ate) - join live Q&A sessions with Product Engineering teams\\n\\nWe\'ll go into more details about **#30DaysOfCloudNative** in this post - don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml) to the blog to get daily posts delivered directly to your preferred feed reader!\\n\\n---\\n\\n## Register for events!\\n\\nWhat are 3 things you can do today, to jumpstart your learning journey?\\n\\n * **Register** for live Q&A sessions (free, online) \\n    - Feb 9 - [Ask The Expert: Azure Kubernetes Service (PDT)](https://aka.ms/ATE0209/RSVP)\\n    - Feb 10 - [Ask the Expert: Azure Kubernetes Service (SGT)](https://aka.ms/ATE0209/APAC-RSVP)\\n  * **Register** for the [Cloud Skills Challenge](https://aka.ms/Challenge) - 30 days to complete it!\\n\\n---\\n\\n## #30DaysOfCloudNative\\n\\n[#30DaysOfCloudNative](https://azure.github.io/Cloud-Native/New-Year/) is a month-long series of daily blog posts grouped into 4 themed weeks - taking you from core concepts to end-to-end solution examples in 30 days. Each article will be short (5-8 mins reading time) and provide exercises and resources to help you reinforce learnings and take next steps.\\n\\nThis series focuses on the [Cloud-native On Azure](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-74010-ninarasi) learning journey in **four stages**, each building on the previous week to help you skill up in a beginner-friendly way:\\n * **Week 1:** Get started with [Cloud-native Concepts](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-74010-ninarasi) \\n * **Week 2:** Build & deploy [Kubernetes Apps on cloud](https://azure.microsoft.com/solutions/kubernetes-on-azure/?WT.mc_id=javascript-74010-ninarasi).\\n * **Week 3:** Migrate your applications to [Azure Kubernetes Service](https://azure.microsoft.com/products/kubernetes-service/?WT.mc_id=javascript-74010-ninarasi).\\n * **Week 4:** Go from Code to Containers to Cloud with [Cloud-native solutions](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-74010-ninarasi)\\n\\n![](./img/banner.png)\\n\\nWe have a tentative weekly-themed roadmap for the topics we hope to cover and will keep this updated as we go with links to actual articles as they get published.\\n\\n:::info Week 1: FOCUS ON CLOUD-NATIVE FUNDAMENTALS\\n\\nHere\'s a sneak peek at the week 1 schedule. We\'ll start with a broad review of cloud-native fundamentals and walkthrough the core concepts of microservices, containers and Kubernetes.\\n\\n * **Jan 23**: Learn Core Concepts for Cloud-native\\n * **Jan 24**: Container 101\\n * **Jan 25**: Adopting Microservices with Kubernetes\\n * **Jan 26**: Kubernetes 101\\n * **Jan 27**: Exploring your Cloud Native Options\\n\\n:::\\n\\n---\\n\\n\\n## Let\'s Get Started!\\n\\nNow you know everything! We hope you are as excited as we are to dive into a full month of active learning and doing! Don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml?WT.mc_id=javascript-74010-ninarasi) for updates in your favorite feed reader! **And look out for our first Cloud-native Fundamentals post on January 23rd!**\\n\\n\\n---"}]}')}}]);