"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[42267],{87986:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"cnny-kickoff","metadata":{"permalink":"/Cloud-Native/cnny-2023/cnny-kickoff","source":"@site/blog-cnny/2023-01-22/30days.md","title":"Kicking Off 30DaysOfCloudNative!","description":"Let\'s  kick-off Cloud Native New Year with #30DaysOfCloudNative","date":"2023-01-22T00:00:00.000Z","formattedDate":"January 22, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":3.18,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://github.com/CSKIMM.png","key":"cory"},{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://github.com/devanshidiaries.png","key":"devanshi"},{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"},{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"}],"frontMatter":{"slug":"cnny-kickoff","title":"Kicking Off 30DaysOfCloudNative!","authors":["cory","devanshi","steven","nitya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps"],"image":"https://azure.github.io/Cloud-Native/img/og/30-00.png","description":"Let\'s  kick-off Cloud Native New Year with #30DaysOfCloudNative","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"nextItem":{"title":"1-1. Cloud-native Fundamentals","permalink":"/Cloud-Native/cnny-2023/cloud-native-fundamentals"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/cnny-kickoff\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Kicking off Cloud Native New Year 2023\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Let\'s  kick-off Cloud Native New Year with #30DaysOfCloudNative\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-00.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@nitya\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/cnny-kickoff\\" />\\n</head>\\n\\nWelcome to the `Kick-off Post` for #30DaysOfCloudNative - one of the core initiatives within #CloudNativeNewYear! Over the next four weeks, join us as we take you from fundamentals to functional usage of Cloud-native technologies, one blog post at a time! Read on to learn a little bit about this initiative and what you can expect to learn from this journey!\\n\\n\\n## What We\'ll Cover\\n * What is Cloud-native New Year? (3 initiatives)\\n * How can I _skill up_ (30 days)\\n * Who is behind this? (Team Contributors)\\n * **Exercise**: Take the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n * **Resources**: [#30DaysOfCloudNative Collection](https://aka.ms/CNNY/collection).\\n\\n---\\n\\n![Cloud-native New Year](../../static/img/cnny23/cnny-event-card.png)\\n\\n\\nWelcome to `Week 01` of [ \ud83e\udd73 #CloudNativeNewYear ](https://aka.ms/CNNY)! Today, we kick off a full month of content and activities to skill you up on all things Cloud-native on Azure with content, events, and community interactions! Read on to learn about what we have planned!\\n\\n---\\n\\n## Explore our initiatives\\n\\nWe have a number of initiatives planned for the month to help you learn and skill up on relevant technologies. Click on the links to visit the relevant pages for each. \\n\\n* [#30DaysOfCloudNative](/Cloud-Native/cnny-2023/) - 4 themed weeks of daily articles in a structured roadmap\\n* [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge) - skill up by competing with peers to complete modules\\n* [Ask The Expert](https://aka.ms/cnny/watch-ate) - watch the recorded Q&A sessions with Product Engineering teams\\n\\nWe\'ll go into more details about **#30DaysOfCloudNative** in this post - don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml) to the blog to get daily posts delivered directly to your preferred feed reader!\\n\\n---\\n\\n## Register for events!\\n\\nWhat are 3 things you can do today, to jumpstart your learning journey?\\n\\n * **Register** for live Q&A sessions (free, online) \\n    - Feb 9 - [Ask The Expert: Azure Kubernetes Service (PDT)](https://aka.ms/ATE0209/RSVP)\\n    - Feb 10 - [Ask the Expert: Azure Kubernetes Service (SGT)](https://aka.ms/ATE0209/APAC-RSVP)\\n  * **Register** for the [Cloud Skills Challenge](https://aka.ms/Challenge) - 30 days to complete it!\\n\\n---\\n\\n## #30DaysOfCloudNative\\n\\n[#30DaysOfCloudNative](https://azure.github.io/Cloud-Native/New-Year/) is a month-long series of daily blog posts grouped into 4 themed weeks - taking you from core concepts to end-to-end solution examples in 30 days. Each article will be short (5-8 mins reading time) and provide exercises and resources to help you reinforce learnings and take next steps.\\n\\nThis series focuses on the [Cloud-native On Azure](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-99907-ninarasi) learning journey in **four stages**, each building on the previous week to help you skill up in a beginner-friendly way:\\n * **Week 1:** Get started with [Cloud-native Concepts](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-99907-ninarasi) \\n * **Week 2:** Build & deploy [Kubernetes Apps on cloud](https://azure.microsoft.com/solutions/kubernetes-on-azure/?WT.mc_id=javascript-99907-ninarasi).\\n * **Week 3:** Migrate your applications to [Azure Kubernetes Service](https://azure.microsoft.com/products/kubernetes-service/?WT.mc_id=javascript-99907-ninarasi).\\n * **Week 4:** Go from Code to Containers to Cloud with [Cloud-native solutions](https://azure.microsoft.com/solutions/cloud-native-apps/?WT.mc_id=javascript-99907-ninarasi)\\n\\n![](./img/banner.png)\\n\\nWe have a tentative weekly-themed roadmap for the topics we hope to cover and will keep this updated as we go with links to actual articles as they get published.\\n\\n:::info Week 1: FOCUS ON CLOUD-NATIVE FUNDAMENTALS\\n\\nHere\'s a sneak peek at the week 1 schedule. We\'ll start with a broad review of cloud-native fundamentals and walkthrough the core concepts of microservices, containers and Kubernetes.\\n\\n * **Jan 23**: Learn Core Concepts for Cloud-native\\n * **Jan 24**: Container 101\\n * **Jan 25**: Adopting Microservices with Kubernetes\\n * **Jan 26**: Kubernetes 101\\n * **Jan 27**: Exploring your Cloud Native Options\\n\\n:::\\n\\n---\\n\\n\\n## Let\'s Get Started!\\n\\nNow you know everything! We hope you are as excited as we are to dive into a full month of active learning and doing! Don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml?WT.mc_id=javascript-99907-ninarasi) for updates in your favorite feed reader! **And look out for our first Cloud-native Fundamentals post on January 23rd!**\\n\\n\\n---"},{"id":"cloud-native-fundamentals","metadata":{"permalink":"/Cloud-Native/cnny-2023/cloud-native-fundamentals","source":"@site/blog-cnny/2023-01-23/cloud-native-fundamentals.md","title":"1-1. Cloud-native Fundamentals","description":"The fundamentals of Cloud-native!","date":"2023-01-23T00:00:00.000Z","formattedDate":"January 23, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":4.06,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://github.com/CSKIMM.png","key":"cory"}],"frontMatter":{"slug":"cloud-native-fundamentals","title":"1-1. Cloud-native Fundamentals","authors":["cory"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloud-native","containers","decision-tree","kubernetes"],"image":"https://azure.github.io/Cloud-Native/img/og/30-01.png","description":"The fundamentals of Cloud-native!","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"Kicking Off 30DaysOfCloudNative!","permalink":"/Cloud-Native/cnny-2023/cnny-kickoff"},"nextItem":{"title":"1-2. Containers 101","permalink":"/Cloud-Native/cnny-2023/containers-101"}},"content":"Welcome to `Week 1` of #CloudNativeNewYear!\\n\\n\\n![Cloud-native New Year](../../static/img/cnny23/cnny-event-card.png)\\n\\nYou will often hear the term \\"cloud-native\\" when discussing modern application development, but even a quick online search will return a huge number of articles, tweets, and web pages with a variety of definitions. So, what does cloud-native actually mean? Also, what makes an application a *cloud-native application* versus a \\"regular\\" application? \\n\\nToday, we will address these questions and more as we kickstart our learning journey (and our new year!) with an introductory dive into the wonderful world of cloud-native. \\n\\n---\\n\\n## What We\'ll Cover\\n * What is cloud-native? \\n * What is a cloud-native application?\\n * The benefits of cloud-native\\n * The five pillars of cloud-native \\n * **Exercise**: Take the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n\\n---\\n\\n## 1. What is cloud-native? \\n\\nThe term \\"cloud-native\\" can seem pretty self-evident (yes, hello, native to the cloud?), and in a way, it is. \\nWhile there are lots of definitions of cloud-native floating around, at it\'s core, cloud-native simply refers to a modern approach to building software that takes advantage of cloud services and environments. This includes using cloud-native technologies, such as containers, microservices, and serverless, and following best practices for deploying, scaling, and managing applications in a cloud environment.\\n\\n:::info **Official definition** from the [Cloud Native Computing Foundation](https://www.cncf.io/):\\n*Cloud-native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.*\\n\\n*These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.* [Source](https://github.com/cncf/foundation/blob/main/charter.md)\\n:::\\n\\n---\\n\\n## 2. So, what exactly is a cloud-native application? \\n Cloud-native applications are *specifically* designed to take advantage of the scalability, resiliency, and distributed nature of modern cloud infrastructure.  But how does this differ from a \\"traditional\\" application?\\n\\nTraditional applications are generally been built, tested, and deployed as a single, monolithic unit.  The monolithic nature of this type of architecture creates close dependencies between components.  This complexity and interweaving only increases as an application grows and can make it difficult to evolve (not to mention troubleshoot) and challenging to operate over time. \\n\\nTo contrast, in cloud-native architectures the application components are decomposed into loosely coupled services, rather than built and deployed as one block of code. This decomposition into multiple self-contained services enables teams to manage complexity and improve the speed, agility, and scale of software delivery. Many small parts enables teams to make targeted updates, deliver new features, and fix any issues without leading to broader service disruption. \\n\\n---\\n\\n## 3. The benefits of cloud-native\\nCloud-native architectures can bring many benefits to an organization, including: \\n\\n1. **Scalability:** easily scale up or down based on demand, allowing organizations to adjust their resource usage and costs as needed.\\n2. **Flexibility:** deploy and run on any cloud platform, and easily move between clouds and on-premises environments.\\n3. **High-availability:** techniques such as redundancy, self-healing, and automatic failover help ensure that cloud-native applications are designed to be highly-available and fault tolerant.\\n4. **Reduced costs:** take advantage of the pay-as-you-go model of cloud computing, reducing the need for expensive infrastructure investments.\\n5. **Improved security:** tap in to cloud security features, such as encryption and identity management, to improve the security of the application.\\n6. **Increased agility:** easily add new features or services to your applications to meet changing business needs and market demand.\\n\\n---\\n\\n## 4. The pillars of cloud-native\\n\\nThere are five areas that are generally cited as the core building blocks of cloud-native architecture: \\n\\n1.\\t[Microservices](https://learn.microsoft.com/devops/deliver/what-are-microservices): Breaking down monolithic applications into smaller, independent, and loosely-coupled services that can be developed, deployed, and scaled independently.\\n2.\\tContainers: Packaging software in lightweight, portable, and self-sufficient containers that can run consistently across different environments.\\n3.\\tAutomation: Using automation tools and DevOps processes to manage and operate the cloud-native infrastructure and applications, including deployment, scaling, monitoring, and self-healing.\\n4.\\tService discovery: Using service discovery mechanisms, such as APIs & service meshes, to enable services to discover and communicate with each other.\\n5.\\tObservability: Collecting and analyzing data from the infrastructure and applications to understand and optimize the performance, behavior, and health of the system.\\n\\nThese can (and should!) be used in combination to deliver cloud-native solutions that are highly scalable, flexible, and available. \\n\\n:::info WHAT\'S NEXT\\n\\nStay tuned, as we will be diving deeper into these topics in the coming weeks:\\n\\n* **Jan 24**: Containers 101\\n* **Jan 25**: Adopting Microservices with Kubernetes\\n* **Jan 26**: Kubernetes 101\\n* **Jan 27**: Exploring your Cloud-native Options\\n:::\\n\\n---\\n\\n## Resources\\n\\n* **Register** for the [Cloud Skills Challenge](https://aka.ms/Challenge) - 30 days to complete it!\\n* **Resources**: [#30DaysOfCloudNative Collection](https://aka.ms/CNNY/collection)\\n* **eBook:** [Cloud Native Infrastructure with Azure](https://azure.microsoft.com/resources/cloud-native-infrastructure-with-microsoft-azure/)\\n\\n---\\n\\nDon\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml?WT.mc_id=javascript-99907-ninarasi) to the blog to get daily posts delivered directly to your favorite feed reader!\\n\\n---"},{"id":"containers-101","metadata":{"permalink":"/Cloud-Native/cnny-2023/containers-101","source":"@site/blog-cnny/2023-01-24/30days.md","title":"1-2. Containers 101","description":"Let\'s dive into the various technologies behind Cloud Native development, starting with Containers.","date":"2023-01-24T00:00:00.000Z","formattedDate":"January 24, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"containers","permalink":"/Cloud-Native/cnny-2023/tags/containers"}],"readingTime":3.965,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"},{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"},{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"}],"frontMatter":{"slug":"containers-101","title":"1-2. Containers 101","authors":["steven","paul","josh"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps"],"image":"https://azure.github.io/Cloud-Native/img/og/30-02.png","description":"Let\'s dive into the various technologies behind Cloud Native development, starting with Containers.","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service","containers"]},"unlisted":false,"prevItem":{"title":"1-1. Cloud-native Fundamentals","permalink":"/Cloud-Native/cnny-2023/cloud-native-fundamentals"},"nextItem":{"title":"1-3. Kubernetes 101","permalink":"/Cloud-Native/cnny-2023/Kubernetes-101"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/containers-101\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Container 101\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Let\'s dive into the various technologies behind Cloud Native development, starting with Containers.\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-02.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/containers-101\\" />\\n</head>\\n\\nWelcome to `Day 2 of Week 1` of #CloudNativeNewYear!\\n\\nToday, we\'ll focus on building an understanding of containers.\\n\\n## What We\'ll Cover\\n * Introduction\\n * How do Containers Work?\\n * Why are Containers Becoming so Popular?\\n * Conclusion\\n * Resources\\n * Learning Path\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n---\\n\\n:::tip REGISTER & LEARN: KUBERNETES 101\\n\\nInterested in a dive into Kubernetes and a chance to talk to experts? \\n\\n\ud83c\udf99: Join us **Jan 26 @1pm PST** \\n[by registering here](https://info.microsoft.com/ww-landing-a-quickstart-guide-to-kubernetes-concepts.html?lcid=en-us)\\n\\nHere\'s what you will learn:\\n * Key concepts and core principles of Kubernetes.\\n * How to deploy, scale and manage containerized workloads.\\n * Live Demo of the concepts explained\\n * How to get started with Azure Kubernetes Service for free.\\n\\n**Start your free Azure Kubernetes Trial Today!!**: [aka.ms/TryAKS](https://aka.ms/TryAKS)\\n\\n:::\\n\\n## Introduction \\n\\n \\n\\nIn the beginning, we deployed our applications onto physical servers.  We only had a certain number of those servers, so often they hosted multiple applications.  This led to some problems when those applications shared dependencies.  Upgrading one application could break another application on the same server.  \\n\\nEnter virtualization.  Virtualization allowed us to run our applications in an isolated operating system instance.  This removed much of the risk of updating shared dependencies.  However, it increased our overhead since we had to run a full operating system for each application environment. \\n\\nTo address the challenges created by virtualization, containerization was created to improve isolation without duplicating kernel level resources. Containers provide efficient and consistent deployment and runtime experiences for our applications and have become very popular as a way of packaging and distributing applications. \\n\\n \\n \\n## How do Containers Work? \\n\\nContainers build on two capabilities in the Linux operating system, namespaces and cgroups.  These constructs allow the operating system to provide isolation to a process or group of processes, keeping their access to filesystem resources separate and providing controls on resource utilization.  This, combined with tooling to help package, deploy, and run container images has led to their popularity in today\u2019s operating environment.  This provides us our isolation without the overhead of additional operating system resources. \\n\\nWhen a container host is deployed on an operating system, it works at scheduling the access to the OS (operating systems) components. This is done by providing a logical isolated group that can contain processes for a given application, called a namespace. The container host then manages /schedules access from the namespace to the host OS.  The container host then uses cgroups to allocate compute resources. Together, the container host with the help of cgroups and namespaces can schedule multiple applications to access host OS resources.  \\n\\nOverall, this gives the illusion of virtualizing the host OS, where each application gets its own OS. In actuality, all the applications are running on the same operating system and sharing the same kernel as the container host. \\n \\n## Why is Containerization so Popular? \\n \\nContainers are popular in the software development industry because they provide several benefits over traditional virtualization methods. Some of these benefits include: \\n \\n* **Portability**: Containers make it easy to move an application from one environment to another without having to worry about compatibility issues or missing dependencies. \\n* **Isolation**: Containers provide a level of isolation between the application and the host system, which means that the application running in the container cannot access the host system\'s resources. \\n* **Scalability**: Containers make it easy to scale an application up or down as needed, which is useful for applications that experience a lot of traffic or need to handle a lot of data. \\n* **Resource Efficiency**: Containers are more resource-efficient than traditional virtualization methods because they don\'t require a full operating system to be running on each virtual machine. \\n* **Cost-Effective**: Containers are more cost-effective than traditional virtualization methods because they don\'t require expensive hardware or licensing fees. \\n \\n\\n## Conclusion \\n \\nContainers are a powerful technology that allows developers to package and deploy applications in a portable and isolated environment. This technology is becoming increasingly popular in the world of software development and is being used by many companies and organizations to improve their application deployment and management processes. With the benefits of portability, isolation, scalability, resource efficiency, and cost-effectiveness, containers are definitely worth considering for your next application development project. \\n\\n \\nContainerizing applications is a key step in modernizing them, and there are many other patterns that can be adopted to achieve cloud-native architectures, including using serverless platforms, Kubernetes, and implementing DevOps practices. \\n\\n## Resources \\n\\n* [What are Containers](https://azure.microsoft.com/resources/cloud-computing-dictionary/what-is-a-container/?WT.mc_id=containers-84290-stmuraws) \\n* [Containerizing .NET Applications](https://learn.microsoft.com/dotnet/architecture/microservices/container-docker-introduction/?WT.mc_id=containers-84290-stmuraws) \\n \\n \\n## Learning Path \\n\\n* [Introduction to Docker Containers](https://learn.microsoft.com/training/modules/intro-to-docker-containers/?WT.mc_id=containers-84290-stmuraws)"},{"id":"Kubernetes-101","metadata":{"permalink":"/Cloud-Native/cnny-2023/Kubernetes-101","source":"@site/blog-cnny/2023-01-25/30days.md","title":"1-3. Kubernetes 101","description":"What is Kubernetes? And why is it so ubiquitous in Cloud-native solutions?","date":"2023-01-25T00:00:00.000Z","formattedDate":"January 25, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":2.385,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"Kubernetes-101","title":"1-3. Kubernetes 101","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps"],"image":"https://azure.github.io/Cloud-Native/img/og/30-03.png","description":"What is Kubernetes? And why is it so ubiquitous in Cloud-native solutions?","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"1-2. Containers 101","permalink":"/Cloud-Native/cnny-2023/containers-101"},"nextItem":{"title":"1-4. Microservices 101","permalink":"/Cloud-Native/cnny-2023/microservices-101"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/kubernetes-101\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Kubernetes 101\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"What is Kubernetes? And why is it so ubiquitous in Cloud-native solutions?\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-03.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/kubernetes-101\\" />\\n</head>\\n\\nWelcome to `Day 3 of Week 1` of #CloudNativeNewYear!\\n\\nThis week we\'ll focus on what Kubernetes is.\\n\\n## What We\'ll Cover\\n * Introduction\\n * What is Kubernetes? (Video)\\n * How does Kubernetes Work? (Video)\\n * Conclusion\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n---\\n\\n:::tip REGISTER & LEARN: KUBERNETES 101\\n\\nInterested in a dive into Kubernetes and a chance to talk to experts? \\n\\n\ud83c\udf99: Join us **Jan 26 @1pm PST** \\n[by registering here](https://info.microsoft.com/ww-landing-a-quickstart-guide-to-kubernetes-concepts.html?WT.mc_id=containers-84290-stmuraws)\\n\\nHere\'s what you will learn:\\n * Key concepts and core principles of Kubernetes.\\n * How to deploy, scale and manage containerized workloads.\\n * Live Demo of the concepts explained\\n * How to get started with Azure Kubernetes Service for free.\\n\\n**Start your free Azure Kubernetes Trial Today!!**: [aka.ms/TryAKS](https://aka.ms/TryAKS)\\n\\n:::\\n\\n## Introduction\\n\\nKubernetes is an open source container orchestration engine that can help with automated deployment, scaling, and management of our applications.\\n\\nKubernetes takes physical (or virtual) resources and provides a consistent API over them, bringing a consistency to the management and runtime experience for our applications.  Kubernetes provides us with a number of capabilities such as:\\n\\n* Container scheduling\\n* Service discovery and load balancing\\n* Storage orchestration\\n* Automated rollouts and rollbacks\\n* Automatic bin packing\\n* Self-healing\\n* Secret and configuration management\\n\\nWe\'ll learn more about most of these topics as we progress through Cloud Native New Year.\\n\\n## What is Kubernetes?\\n\\nLet\'s hear from Brendan Burns, one of the founders of Kubernetes as to what Kubernetes actually is.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/q1PcAawa4Bg\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n## How does Kubernetes Work?\\n\\nAnd Brendan shares a bit more with us about how Kubernetes works.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/daVUONZqn88\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n## Conclusion\\n\\nKubernetes allows us to deploy and manage our applications effectively and consistently. \\n\\nBy providing a consistent API across many of the concerns our applications have, like load balancing, networking, storage, and compute, Kubernetes improves both our ability to build and ship new software. \\n\\nThere are standards for the applications to depend on for resources needed. Deployments, metrics, and logs are provided in a standardized fashion allowing more effecient operations across our application environments. \\n\\nAnd since Kubernetes is an open source platform, it can be found in just about every type of operating environment - cloud, virtual machines, physical hardware, shared data centers, even small devices like Rasberry Pi\'s!\\n\\nWant to learn more?  [Join us for a webinar on Kubernetes Concepts (or catch the playback) on Thursday, January 26th at 1 PM PST](https://info.microsoft.com/ww-landing-a-quickstart-guide-to-kubernetes-concepts.html?WT.mc_id=containers-84290-stmuraws) and watch for the rest of this series right here!"},{"id":"microservices-101","metadata":{"permalink":"/Cloud-Native/cnny-2023/microservices-101","source":"@site/blog-cnny/2023-01-26/30days.md","title":"1-4. Microservices 101","description":"What are Microservices? Why are they a core pillar for Cloud-native and how does Kubernetes help in their deployment?","date":"2023-01-26T00:00:00.000Z","formattedDate":"January 26, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"microservices","permalink":"/Cloud-Native/cnny-2023/tags/microservices"}],"readingTime":5.265,"hasTruncateMarker":false,"authors":[{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"}],"frontMatter":{"slug":"microservices-101","title":"1-4. Microservices 101","authors":["josh"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps","microservices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-04.png","description":"What are Microservices? Why are they a core pillar for Cloud-native and how does Kubernetes help in their deployment?","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service","microservices"]},"unlisted":false,"prevItem":{"title":"1-3. Kubernetes 101","permalink":"/Cloud-Native/cnny-2023/Kubernetes-101"},"nextItem":{"title":"1-5. Exploring Cloud-Native Options","permalink":"/Cloud-Native/cnny-2023/explore-options"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/microservices-101\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Microservices 101\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"What are Microservices? Why are they a core pillar for Cloud-native and how does Kubernetes help in their deployment?\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-04.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@joshduffney\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/microservices-101\\" />\\n</head>\\n\\nWelcome to `Day 4 of Week 1` of #CloudNativeNewYear!\\n\\nThis week we\'ll focus on advanced topics and best practices for Cloud-Native practitioners, kicking off with this post on _Serverless Container Options_ with Azure. We\'ll look at technologies, tools and best practices that range from managed services like Azure Kubernetes Service, to options allowing finer granularity of control and oversight.\\n\\n\\n## What We\'ll Cover\\n * What is Microservice Architecture? \\n * How do you design a Microservice? \\n * What challenges do Microservices introduce?\\n * Conclusion\\n * Resources\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n---\\n\\nMicroservices are a modern way of designing and building software that increases deployment velocity by decomposing an application into small autonomous services that can be deployed independently. \\n\\nBy deploying loosely coupled microservices your applications can be developed, deployed, and scaled independently. Because each service is independent, it can be updated or replaced without having to worry about the impact on the rest of the application. This means that if a bug is found in one service, it can be fixed without having to redeploy the entire application. All of which gives an organization the ability to deliver value to their customers faster. \\n\\nIn this article, we will explore the basics of microservices architecture, its benefits and challenges, and how it can help improve the development, deployment, and maintenance of software applications. \\n\\n## What is Microservice Architecture? \\n\\nBefore explaining what Microservice architecture is, it\u2019s important to understand what problems microservices aim to address. \\n\\nTraditional software development is centered around building monolithic applications. Monolithic applications are built as a single, large codebase. Meaning your code is tightly coupled causing the monolithic app to suffer from the following: \\n\\n**Too much Complexity:** Monolithic applications can become complex and difficult to understand and maintain as they grow. This can make it hard to identify and fix bugs and add new features. \\n\\n**Difficult to Scale:** Monolithic applications can be difficult to scale as they often have a single point of failure, which can cause the whole application to crash if a service fails. \\n\\n**Slow Deployment:** Deploying a monolithic application can be risky and time-consuming, as a small change in one part of the codebase can affect the entire application. \\n\\nMicroservice architecture (often called microservices) is an architecture style that addresses the challenges created by Monolithic applications. Microservices architecture is a way of designing and building software applications as a collection of small, independent services that communicate with each other through APIs. This allows for faster development and deployment cycles, as well as easier scaling and maintenance than is possible with a monolithic application. \\n\\n## How do you design a Microservice? \\n\\nBuilding applications with Microservices architecture requires a different approach. Microservices architecture focuses on business capabilities rather than technical layers, such as data access or messaging. Doing so requires that you shift your focus away from the technical stack and model your applications based upon the various domains that exist within the business. \\n\\nDomain-driven design (DDD) is a way to design software by focusing on the business needs. You can use Domain-driven design as a framework that guides the development of well-designed microservices by building services that encapsulate knowledge in each domain and abstract that knowledge from clients. \\n\\nIn Domain-driven design you start by modeling the business domain and creating a domain model. A domain model is an abstract model of the business model that distills and organizes a domain of knowledge and provides a common language for developers and domain experts. It\u2019s the resulting domain model that microservices a best suited to be built around because it helps establish a well-defined boundary between external systems and other internal applications. \\n\\nIn short, before you begin designing microservices, start by mapping the functions of the business and their connections to create a domain model for the microservice(s) to be built around. \\n\\n \\n## What challenges do Microservices introduce? \\n\\nMicroservices solve a lot of problems and have several advantages, but the grass isn\u2019t always greener on the other side. \\n\\nOne of the key challenges of microservices is managing communication between services. Because services are independent, they need to communicate with each other through APIs. This can be complex and difficult to manage, especially as the number of services grows. To address this challenge, it is important to have a clear API design, with well-defined inputs and outputs for each service. It is also important to have a system for managing and monitoring communication between services, to ensure that everything is running smoothly.  \\n\\nAnother challenge of microservices is managing the deployment and scaling of services. Because each service is independent, it needs to be deployed and scaled separately from the rest of the application. This can be complex and difficult to manage, especially as the number of services grows. To address this challenge, it is important to have a clear and consistent deployment process, with well-defined steps for deploying and scaling each service. Furthermore, it is advisable to host them on a system with self-healing capabilities to reduce operational burden. \\n\\nIt is also important to have a system for monitoring and managing the deployment and scaling of services, to ensure optimal performance.  \\n\\nEach of these challenges has created fertile ground for tooling and process that exists in the cloud-native ecosystem. Kubernetes, CI CD, and other DevOps practices are part of the package of adopting the microservices architecture. \\n\\n## Conclusion \\n\\nIn summary, microservices architecture focuses on software applications as a collection of small, independent services that communicate with each other over well-defined APIs. \\n\\nThe main advantages of microservices include:\\n* increased flexibility and scalability per microservice, \\n* efficient resource utilization (with help from a container orchestrator like Kubernetes), \\n* and faster development cycles. \\n\\nContinue following along with this series to see how you can use Kubernetes to help adopt microservices patterns in your own environments!\\n\\n## Resources \\n\\n* [Microservice Applications](https://azure.microsoft.com/solutions/microservice-applications?WT.mc_id=containers-84290-stmuraws)\\n* [Microservices architecture design - Azure Architecture Center | Microsoft Learn](https://learn.microsoft.com/azure/architecture/microservices?WT.mc_id=containers-84290-stmuraws)\\n* [Design a microservices architecture - Azure Architecture Center | Microsoft Learn](https://learn.microsoft.com/azure/architecture/microservices/design?WT.mc_id=containers-84290-stmuraws)\\n* [Domain analysis for microservices - Azure Architecture Center | Microsoft Learn](https://learn.microsoft.com/azure/architecture/microservices/model/domain-analysis?WT.mc_id=containers-84290-stmuraws)"},{"id":"explore-options","metadata":{"permalink":"/Cloud-Native/cnny-2023/explore-options","source":"@site/blog-cnny/2023-01-27/explore-options.md","title":"1-5. Exploring Cloud-Native Options","description":"There are many cloud-native technologies - but which are the best fit for your projects?","date":"2023-01-27T00:00:00.000Z","formattedDate":"January 27, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":5.55,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://github.com/CSKIMM.png","key":"cory"}],"frontMatter":{"slug":"explore-options","title":"1-5. Exploring Cloud-Native Options","authors":["cory"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloud-native","containers","decision-tree","kubernetes","serverless","microservices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-05.png","description":"There are many cloud-native technologies - but which are the best fit for your projects?","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"1-4. Microservices 101","permalink":"/Cloud-Native/cnny-2023/microservices-101"},"nextItem":{"title":"2-1. Kubernetes Fundamentals - Pods and Deployments","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-1"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/explore-options\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Serverless Container Options\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Explore technology and tooling options for building and deploying your Cloud-native solution\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-05.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@cskimming\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/explore-options\\" />\\n</head>\\n\\nWe are excited to be wrapping up our first week of #CloudNativeNewYear! This week, we have tried to set the stage by covering the fundamentals of cloud-native practices and technologies, including primers on [containerization](https://azure.github.io/Cloud-Native/cnny-2023/containers-101/), [microservices](https://azure.github.io/Cloud-Native/cnny-2023/microservices-101), and [Kubernetes](https://azure.github.io/Cloud-Native/cnny-2023/Kubernetes-101).  \\n\\n:::tip Don\'t forget to sign up for the the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n\\n:::\\n\\nToday, we will do a brief recap of some of these technologies and provide some basic guidelines for when it is optimal to use each. \\n\\n---\\n\\n## What We\'ll Cover\\n* To Containerize or not to Containerize?\\n* The power of Kubernetes\\n* Where does Serverless fit? \\n* Resources\\n* What\'s coming next!\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n---\\n\\n:::info Just joining us now? Check out these other Week 1 posts:\\n\\n * [Cloud-native fundamentals](https://azure.github.io/Cloud-Native/cnny-2023/cloud-native-fundamentals)\\n * [Containers 101](https://azure.github.io/Cloud-Native/cnny-2023/containers-101)\\n * [Microservices 101](https://azure.github.io/Cloud-Native/cnny-2023/microservices-101)\\n * [Kubernetes 101](https://azure.github.io/Cloud-Native/cnny-2023/Kubernetes-101)\\n \\n:::\\n\\n--- \\n## To Containerize or not to Containerize? \\n\\nAs mentioned in our Containers 101 post earlier this week, containers can provide several benefits over traditional virtualization methods, which has made them popular within the software development community. Containers provide a consistent and predictable runtime environment, which can help reduce the risk of compatibility issues and simplify the deployment process. Additionally, containers can improve resource efficiency by allowing multiple applications to run on the same host while isolating their dependencies. \\n\\nSome types of apps that are a particularly good fit for containerization include: \\n\\n1.\\t**Microservices:** Containers are particularly well-suited for microservices-based applications, as they can be used to isolate and deploy individual components of the system. This allows for more flexibility and scalability in the deployment process.\\n2.\\t**Stateless applications:** Applications that do not maintain state across multiple sessions, such as web applications, are well-suited for containers. Containers can be easily scaled up or down as needed and replaced with new instances, without losing data.\\n3.\\t**Portable applications:** Applications that need to be deployed in different environments, such as on-premises, in the cloud, or on edge devices, can benefit from containerization. The consistent and portable runtime environment of containers can make it easier to move the application between different environments.\\n4.\\t**Legacy applications:** Applications that are built using older technologies or that have compatibility issues can be containerized to run in an isolated environment, without impacting other applications or the host system.\\n5.\\t**Dev and testing environments:** Containerization can be used to create isolated development and testing environments, which can be easily created and destroyed as needed.\\n\\nWhile there are many types of applications that can benefit from a containerized approach, it\'s worth noting that containerization is not **always** the best option, and it\'s important to weigh the benefits and trade-offs before deciding to containerize an application. Additionally, some types of applications may not be a good fit for containers including:\\n\\n* Apps that require full access to host resources: Containers are isolated from the host system, so if an application needs direct access to hardware resources such as GPUs or specialized devices, it might not work well in a containerized environment.\\n* Apps that require low-level system access: If an application requires deep access to the underlying operating system, it may not be suitable for running in a container.\\n* Applications that have specific OS dependencies: Apps that have specific dependencies on a certain version of an operating system or libraries may not be able to run in a container.\\n* Stateful applications: Apps that maintain state across multiple sessions, such as databases, may not be well suited for containers. Containers are ephemeral by design, so the data stored inside a container may not persist between restarts.\\n\\nThe good news is that some of these limitations can be overcome with the use of specialized containerization technologies such as Kubernetes, and by carefully designing the architecture of the application. \\n\\n---\\n## The power of Kubernetes\\n\\nSpeaking of Kubernetes...\\n\\nKubernetes is a powerful tool for managing and deploying containerized applications in production environments, particularly for applications that need to scale, handle large numbers of requests, or run in multi-cloud or hybrid environments.\\n\\nKubernetes is well-suited for a wide variety of applications, but it is particularly well-suited for the following types of applications:\\n\\n1.\\t**Microservices-based applications:** Kubernetes provides a powerful set of tools for managing and deploying microservices-based applications, making it easy to scale, update, and manage the individual components of the application.\\n2.\\t**Stateful applications:** Kubernetes provides support for stateful applications through the use of Persistent Volumes and StatefulSets, allowing for applications that need to maintain state across multiple instances. \\n3.\\t**Large-scale, highly-available systems:** Kubernetes provides built-in support for scaling, self-healing, and rolling updates, making it an ideal choice for large-scale, highly-available systems that need to handle large numbers of users and requests.\\n4.\\t**Multi-cloud and hybrid environments:** Kubernetes can be used to deploy and manage applications across multiple cloud providers and on-premises environments, making it a good choice for organizations that want to take advantage of the benefits of multiple cloud providers or that need to deploy applications in a hybrid environment.\\n\\n:::info New to Kubernetes?\\n\\nCatch [A Quickstart Guide to Kubernetes Concepts](https://info.microsoft.com/ww-ondemand-a-quickstart-guide-to-kubernetes-concepts.html?lcid=en-us) on demand, now!\\n\\n:::\\n\\n---\\n# Where does Serverless fit in? \\n\\nServerless is a cloud computing model where the cloud provider (like Azure) is responsible for executing a piece of code by dynamically allocating the resources. With serverless, you only pay for the exact amount of compute time that you use, rather than paying for a fixed amount of resources. This can lead to significant cost savings, particularly for applications with variable or unpredictable workloads.\\n\\nServerless is commonly used for building applications like web or mobile apps, IoT, data processing, and real-time streaming - apps where the workloads are variable and high scalability is required.\\nIt\'s important to note that serverless is not a replacement for all types of workloads - it\'s best suited for stateless, short-lived and small-scale workloads.\\n\\nFor a detailed look into the world of Serverless and lots of great learning content, revisit [#30DaysofServerless](https://azure.github.io/Cloud-Native/serverless-september/30DaysOfServerless/).\\n\\n---\\n## Resources\\n* **Register** for the [Cloud Skills Challenge](https://aka.ms/Challenge) - 30 days to complete it!\\n* **Learning Resources**: [#30DaysOfCloudNative Collection](https://aka.ms/CNNY/collection)\\n* **eBook:** [Cloud Native Infrastructure with Azure](https://azure.microsoft.com/resources/cloud-native-infrastructure-with-microsoft-azure/?WT.mc_id=javascript-99907-ninarasi)\\n* **eBook:** [Cloud-native Architecture Mapbook](https://azure.microsoft.com/resources/azure-cloud-native-architecture-mapbook/?WT.mc_id=javascript-99907-ninarasi)\\n\\n---\\n## What\'s up next in #CloudNativeNewYear?\\n\\nWeek 1 has been all about the fundamentals of cloud-native. Next week, the team will be diving in to application deployment with Azure Kubernetes Service. Don\'t forget to [subscribe](https://azure.github.io/Cloud-Native/cnny-2023/rss.xml?WT.mc_id=javascript-99907-ninarasi) to the blog to get daily posts delivered directly to your favorite feed reader!\\n\\n---"},{"id":"fundamentals-day-1","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-1","source":"@site/blog-cnny/2023-01-30/PodsAndDeployments.md","title":"2-1. Kubernetes Fundamentals - Pods and Deployments","description":"The theme for this week is Kubernetes fundamentals. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.","date":"2023-01-30T00:00:00.000Z","formattedDate":"January 30, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":13.16,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"fundamentals-day-1","title":"2-1. Kubernetes Fundamentals - Pods and Deployments","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["pods","deployments","kubernetes","aks","container-apps","cloud-native"],"image":"https://azure.github.io/Cloud-Native/img/og/30-06.png","description":"The theme for this week is Kubernetes fundamentals. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"1-5. Exploring Cloud-Native Options","permalink":"/Cloud-Native/cnny-2023/explore-options"},"nextItem":{"title":"2-2. Kubernetes Fundamentals - Services and Ingress","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-2"}},"content":"<head>\\n  <meta name=\\"twitter:url\\"\\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-1\\" />\\n  <meta name=\\"twitter:title\\"\\n    content=\\"2-1. Kubernetes Fundamentals - Pods and Deployments\\" />\\n  <meta name=\\"twitter:description\\"\\n    content=\\"The theme for this week is Kubernetes fundamentals. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-06.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\"\\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" />\\n  <link rel=\\"canonical\\"\\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-1\\" />\\n</head>\\n\\nWelcome to `Day #1 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Last week we talked about Cloud Native architectures and the Cloud Native landscape. Today we\'ll explore the topic of Pods and Deployments in Kubernetes.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n * Setting Up A Kubernetes Environment in Azure\\n * Running Containers in Kubernetes Pods\\n * Making the Pods Resilient with Deployments\\n * Exercise\\n * Resources\\n\\n## Setting Up A Kubernetes Environment in Azure\\n\\nFor this week, we\'ll be working with a simple app - [the Azure Voting App](https://aka.ms/azure-voting-app-rust). My teammate [Paul Yu](https://github.com/pauldotyu) ported the app to Rust and we tweaked it a bit to let us highlight some of the basic features of Kubernetes.\\n\\nYou should be able to replicate this in just about any Kubernetes environment, but we\'ll use [Azure Kubernetes Service](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws) (AKS) as our working environment for this week.\\n\\nTo make it easier to get started, there\'s a [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?WT.mc_id=containers-84290-stmuraws&tabs=bicep) template to deploy an AKS cluster, an Azure Container Registry (ACR) (to host our container image), and connect the two so that we can easily deploy our application.\\n\\n### Step 0 - Prerequisites\\n\\nThere are a few things you\'ll need if you want to work through this and the following examples this week.\\n\\nRequired:\\n\\n* Git (and probably a GitHub account if you want to persist your work outside of your computer)\\n* Azure CLI\\n* An Azure subscription (if you want to follow along with the Azure steps)\\n* Kubectl (the command line tool for managing Kubernetes)\\n\\nHelpful:\\n\\n* Visual Studio Code (or equivalent editor)\\n\\n### Step 1 - Clone the application repository\\n\\nFirst, I forked [the source repository](https://aka.ms/azure-voting-app-rust) to my account.\\n\\n```powershell\\n$GitHubOrg = \'smurawski\' # Replace this with your GitHub account name or org name\\ngit clone \\"https://github.com/$GitHubOrg/azure-voting-app-rust\\"\\ncd azure-voting-app-rust\\n```\\n\\nLeave your shell opened with your current location inside the application repository.\\n\\n### Step 2 - Set up AKS\\n\\nRunning the template deployment from the demo script (I\'m using the PowerShell example in [cnny23-week2-day1.ps1](https://aka.ms/azure-voting-app-rust/setup-powershell), but there\'s a Bash variant at [cnny23-week2-day1.sh](https://aka.ms/azure-voting-app-rust/setup-bash)) stands up the environment.  The second, third, and fourth commands take some of the output from the Bicep deployment to set up for later commands, so don\'t close out your shell after you run these commands.\\n\\n```powershell\\naz deployment sub create --template-file ./deploy/main.bicep --location eastus --parameters \'resourceGroup=cnny-week2\'\\n$AcrName = az deployment sub show --name main --query \'properties.outputs.acr_name.value\' -o tsv\\n$AksName = az deployment sub show --name main --query \'properties.outputs.aks_name.value\' -o tsv\\n$ResourceGroup = az deployment sub show --name main --query \'properties.outputs.resource_group_name.value\' -o tsv\\n\\naz aks get-credentials --resource-group $ResourceGroup --name $AksName\\n```\\n\\n### Step 3 - Build our application container\\n\\nSince we have an Azure Container Registry set up, I\'ll use ACR Build Tasks to build and store my container image.\\n\\n```powershell\\naz acr build --registry $AcrName --% --image cnny2023/azure-voting-app-rust:{{.Run.ID}} .\\n$BuildTag = az acr repository show-tags `\\n                              --name $AcrName `\\n                              --repository cnny2023/azure-voting-app-rust `\\n                              --orderby time_desc `\\n                              --query \'[0]\' -o tsv\\n```\\n\\n:::tip\\nWondering what the `--%` is in the first command line?  That tells the PowerShell interpreter to pass the input after it \\"as is\\" to the command without parsing/evaluating it. Otherwise, PowerShell messes a bit with the templated `{{.Run.ID}}` bit.\\n:::\\n\\n## Running Containers in Kubernetes Pods\\n\\nNow that we have our AKS cluster and application image ready to go, let\'s look into how Kubernetes runs containers.\\n\\nIf you\'ve been in tech for any length of time, you\'ve seen that every framework, runtime, orchestrator, etc.. can have their own naming scheme for their concepts. So let\'s get into some of what Kubernetes calls things.\\n\\n### The Pod\\n\\nA container running in Kubernetes is called a [Pod](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#pods). A Pod is basically a running container on a [Node](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#nodes-and-node-pools) or VM. It can be more. For example you can run multiple containers and specify some funky configuration, but we\'ll keep it simple for now - add the complexity when you need it.\\n\\nOur Pod definition can be created via the `kubectl` command imperatively from arguments or declaratively from a configuration file.  We\'ll do a little of both.  We\'ll use the `kubectl` command to help us write our configuration files.  Kubernetes configuration files are YAML, so having an editor that supports and can help you syntax check YAML is really helpful.\\n\\n### Creating a Pod Definition\\n\\nLet\'s create a few Pod definitions.  Our application requires two containers to get working - the application and a database.\\n\\nLet\'s create the database Pod first.  And before you comment, the configuration isn\'t secure nor best practice.  We\'ll fix that later this week.  For now, let\'s focus on getting up and running.\\n\\nThis is a trick I learned from one of my teammates - Paul.  By using the `--output yaml` and `--dry-run=client` options, we can have the command help us write our YAML.  And with a bit of output redirection, we can stash it safely in a file for later use.\\n\\n```powershell\\nkubectl run azure-voting-db `\\n            --image \\"postgres:15.0-alpine\\" `\\n            --env \\"POSTGRES_PASSWORD=mypassword\\" `\\n            --output yaml `\\n            --dry-run=client > manifests/pod-db.yaml\\n```\\n\\nThis creates a file that looks like:\\n\\n```yml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    run: azure-voting-db\\n  name: azure-voting-db\\nspec:\\n  containers:\\n  - env:\\n    - name: POSTGRES_PASSWORD\\n      value: mypassword\\n    image: postgres:15.0-alpine\\n    name: azure-voting-db\\n    resources: {}\\n  dnsPolicy: ClusterFirst\\n  restartPolicy: Always\\nstatus: {}\\n```\\n\\nThe file, when supplied to the Kubernetes API, will identify what kind of resource to create, the API version to use, and the details of the container (as well as an environment variable to be supplied).\\n\\nWe\'ll get that container image started with the `kubectl` command.  Because the details of what to create are in the file, we don\'t need to specify much else to the `kubectl` command but the path to the file.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-db.yaml\\n```\\n\\nI\'m going to need the IP address of the Pod, so that my application can connect to it, so we can use `kubectl` to get some information about our pod.  By default, `kubectl get pod` only displays certain information but it retrieves a lot more.  We can use the [JSONPath syntax](https://kubernetes.io/docs/reference/kubectl/jsonpath/) to index into the response and get the information you want.\\n\\n:::tip\\n\\nTo see what you can get, I usually run the `kubectl` command with the output type (`-o JSON`) of JSON and then I can find where the data I want is and create my JSONPath query to get it.\\n\\n:::\\n\\n```powershell,\\n$DB_IP = kubectl get pod azure-voting-db -o jsonpath=\'{.status.podIP}\'\\n```\\n\\nNow, let\'s create our Pod definition for our application.  We\'ll use the same technique as before.\\n\\n```powershell\\nkubectl run azure-voting-app `\\n            --image \\"$AcrName.azurecr.io/cnny2023/azure-voting-app-rust:$BuildTag\\" `\\n            --env \\"DATABASE_SERVER=$DB_IP\\" `\\n            --env \\"DATABASE_PASSWORD=mypassword`\\n            --output yaml `\\n            --dry-run=client > manifests/pod-app.yaml\\n```\\n\\nThat command gets us a similar YAML file to the database container - you can see [the full file here](https://github.com/azure-samples/azure-voting-app-rust/blob/week2/day1/manifests/pod-app.yaml)\\n\\nLet\'s get our application container running.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-app.yaml\\n```\\n\\n### Now that the Application is Running\\n\\nWe can check the status of our Pods with:\\n\\n```powershell\\nkubectl get pods\\n```\\n\\nAnd we should see something like:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME               READY   STATUS    RESTARTS   AGE\\nazure-voting-app   1/1     Running   0          36s\\nazure-voting-db    1/1     Running   0          84s\\n```\\n\\nOnce our pod is running, we can check to make sure everything is working by letting `kubectl` proxy network connections to our Pod running the application. If we get the voting web page, we\'ll know the application found the database and we can start voting!\\n\\n```powershell\\nkubectl port-forward pod/azure-voting-app 8080:8080\\n```\\n\\n![Azure voting website in a browser with three buttons, one for Dogs, one for Cats, and one for Reset.  The counter is Dogs - 0 and Cats - 0.](../../static/img/cnny23/azure_voting_app.png)\\n\\nWhen you are done voting, you can stop the port forwarding by using Control-C to break the command.\\n\\n### Clean Up\\n\\nLet\'s clean up after ourselves and see if we can\'t get Kubernetes to help us keep our application running.  We can use the same configuration files to ensure that Kubernetes only removes what we want removed.\\n\\n```powershell\\nkubectl delete -f ./manifests/pod-app.yaml\\nkubectl delete -f ./manifests/pod-db.yaml\\n```\\n\\n### Summary - Pods\\n\\nA Pod is the most basic unit of work inside Kubernetes. Once the Pod is deleted, it\'s gone.  That leads us to our next topic (and final topic for today.)\\n\\n## Making the Pods Resilient with Deployments\\n\\nWe\'ve seen how easy it is to deploy a Pod and get our containers running on Nodes in our Kubernetes cluster.  But there\'s a problem with that.  Let\'s illustrate it.\\n\\n### Breaking Stuff\\n\\n#### Setting Back Up\\n\\nFirst, let\'s redeploy our application environment.  We\'ll start with our application container.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-db.yaml\\nkubectl get pod azure-voting-db -o jsonpath=\'{.status.podIP}\'\\n```\\n\\nThe second command will report out the new IP Address for our database container.  Let\'s open `./manifests/pod-app.yaml` and update the container IP to our new one.\\n\\n```yml\\n- name: DATABASE_SERVER\\n  value: YOUR_NEW_IP_HERE\\n```\\n\\nThen we can deploy the application with the information it needs to find its database.  We\'ll also list out our pods to see what is running.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-app.yaml\\nkubectl get pods\\n```\\n\\nFeel free to look back and use the port forwarding trick to make sure your app is running if you\'d like.\\n\\n#### Knocking It Down\\n\\nThe first thing we\'ll try to break is our application pod.  Let\'s delete it.\\n\\n```powershell\\nkubectl delete pod azure-voting-app\\n```\\n\\nThen, we\'ll check our pod\'s status:\\n\\n```powershell\\nkubectl get pods\\n```\\n\\nWhich should show something like:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME              READY   STATUS    RESTARTS   AGE\\nazure-voting-db   1/1     Running   0          50s\\n```\\n\\nWe should be able to recreate our application pod deployment with no problem, since it has the current database IP address and nothing else depends on it.\\n\\n```powershell\\nkubectl apply -f ./manifests/pod-app.yaml\\n```\\n\\nAgain, feel free to do some fun port forwarding and check your site is running.\\n\\n#### Uncomfortable Truths\\n\\nHere\'s where it gets a bit stickier, what if we delete the database container?\\n\\nIf we delete our database container and recreate it, it\'ll likely have a new IP address, which would force us to update our application configuration.  We\'ll look at some solutions for these problems in the next three posts this week.\\n\\nBecause our database problem is a bit tricky, we\'ll primarily focus on making our application layer more resilient and prepare our database layer for those other techniques over the next few days.\\n\\nLet\'s clean back up and look into making things more resilient.\\n\\n```powershell\\nkubectl delete -f ./manifests/pod-app.yaml\\nkubectl delete -f ./manifests/pod-db.yaml\\n```\\n\\n### The Deployment\\n\\nOne of the reasons you may want to use Kubernetes is it\'s ability to orchestrate workloads.  Part of that orchestration includes being able to ensure that certain workloads are running (regardless of what Node they might be on).\\n\\nWe saw that we could delete our application pod and then restart it from the manifest with little problem.  It just meant that we had to run a command to restart it.  We can use the [Deployment](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests) in Kubernetes to tell the orchestrator to ensure we have our application pod running.\\n\\nThe Deployment also can encompass a lot of extra configuration - controlling how many containers of a particular type should be running, how upgrades of container images should proceed, and more.\\n\\n#### Creating the Deployment\\n\\nFirst, we\'ll create a Deployment for our database. We\'ll use a technique similar to what we did for the Pod, with just a bit of difference.\\n\\n```powershell\\nkubectl create deployment azure-voting-db `\\n                            --image \\"postgres:15.0-alpine\\" `\\n                            --port 5432 `\\n                            --output yaml `\\n                            --dry-run=client > manifests/deployment-db.yaml\\n```\\n\\nUnlike our Pod definition creation, we can\'t pass in environment variable configuration from the command line.  We\'ll have to edit the YAML file to add that.\\n\\nSo, let\'s open `./manifests/deployment-db.yaml` in our editor and add the following in the `spec/containers` configuration.\\n\\n```yml\\n        env:\\n        - name: POSTGRES_PASSWORD\\n          value: \\"mypassword\\"\\n```\\n\\nYour file should look like this [deployment-db.yaml](https://github.com/azure-samples/azure-voting-app-rust/blob/week2/day1/manifests/deployment-db.yaml).\\n\\nOnce we have our configuration file updated, we can deploy our database container image.\\n\\n```powershell\\nkubectl apply -f ./manifests/deployment-db.yaml\\n```\\n\\nFor our application, we\'ll use the same technique.\\n\\n```powershell\\nkubectl create deployment azure-voting-app `\\n                        --image \\"$AcrName.azurecr.io/cnny2023/azure-voting-app-rust:$BuildTag\\" `\\n                        --port 8080 `\\n                        --output yaml `\\n                        --dry-run=client > manifests/deployment-app.yaml\\n```\\n\\nNext, we\'ll need to add an environment variable to the generated configuration.  We\'ll also need the new IP address for the database deployment.\\n\\nPreviously, we named the pod and were able to ask for the IP address with `kubectl` and a bit of JSONPath. Now, the deployment created the pod for us, so there\'s a bit of random in the naming.  Check out:\\n\\n```powershell\\nkubectl get pods\\n```\\n\\nShould return something like:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME                               READY   STATUS    RESTARTS   AGE\\nazure-voting-db-686d758fbf-8jnq8   1/1     Running   0          7s\\n```\\n\\nWe can either ask for the IP with the new pod name, or we can use a [selector](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors) to find our desired pod.\\n\\n```powershell\\nkubectl get pod --selector app=azure-voting-db -o jsonpath=\'{.items[0].status.podIP}\'\\n```\\n\\nNow, we can update our application deployment configuration file with:\\n\\n```yml\\n        env:\\n        - name: DATABASE_SERVER\\n          value: YOUR_NEW_IP_HERE\\n        - name: DATABASE_PASSWORD\\n          value: mypassword\\n```\\n\\nYour file should look like this [deployment-app.yaml](https://github.com/azure-samples/azure-voting-app-rust/blob/week2/day1/manifests/deployment-app.yaml) (but with IPs and image names matching your environment).\\n\\nAfter we save those changes, we can deploy our application.\\n\\n```powershell\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\nLet\'s test the resilience of our app now. First, we\'ll delete the pod running our application, then we\'ll check to make sure Kubernetes restarted our application pod.\\n\\n```powershell\\nkubectl get pods\\n```\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get pods\\nNAME                                READY   STATUS    RESTARTS   AGE\\nazure-voting-app-56c9ccc89d-skv7x   1/1     Running   0          71s\\nazure-voting-db-686d758fbf-8jnq8    1/1     Running   0          12m\\n```\\n\\n```powershell\\nkubectl delete pod azure-voting-app-56c9ccc89d-skv7x\\nkubectl get pods\\n```\\n\\n```\\nazure-voting-app-rust \u276f  kubectl delete pod azure-voting-app-56c9ccc89d-skv7x\\n>> kubectl get pods\\npod \\"azure-voting-app-56c9ccc89d-skv7x\\" deleted\\nNAME                                READY   STATUS    RESTARTS   AGE\\nazure-voting-app-56c9ccc89d-2b5mx   1/1     Running   0          2s\\nazure-voting-db-686d758fbf-8jnq8    1/1     Running   0          14m\\n```\\n\\n:::info\\nYour Pods will likely have different identifiers at the end, so adjust your commands to match the names in your environment.\\n:::\\n\\nAs you can see, by the time the `kubectl get pods` command was run, Kubernetes had already spun up a new pod for the application container image.  Thanks Kubernetes!\\n\\n### Clean up\\n\\nSince we can\'t just delete the pods, we have to delete the deployments.\\n\\n```powershell\\nkubectl delete -f ./manifests/deployment-app.yaml\\nkubectl delete -f ./manifests/deployment-db.yaml\\n```\\n\\n### Summary - Deployments\\n\\nDeployments allow us to create more durable configuration for the workloads we deploy into Kubernetes. As we dig deeper, we\'ll discover more capabilities the deployments offer. Check out the Resources below for more.\\n\\n## Exercise\\n\\nIf you want to try these steps, head over to [the source repository](https://aka.ms/azure-voting-app-rust), fork it, clone it locally, and give it a spin!\\n\\nYou can check your manifests against the manifests in the `week2/day1` [branch of the source repository](https://github.com/azure-samples/azure-voting-app-rust/tree/week2/day1/manifests).\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n### Documentation\\n\\n* [Azure Kubernetes Service](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws)\\n* [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?WT.mc_id=containers-84290-stmuraws&tabs=bicep)\\n* [Azure Voting App in Rust](https://aka.ms/azure-voting-app-rust)\\n* [Pods](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#pods).\\n* [Nodes](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#nodes-and-node-pools)\\n* [kubectl](https://kubernetes.io/docs/reference/kubectl/kubectl/)\\n* [JSONPath syntax](https://kubernetes.io/docs/reference/kubectl/jsonpath/)\\n* [Deployment](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests)\\n* [Labels and Selectors](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors)\\n\\n### Training\\n\\n* [Learning Path - Introduction to Kubernetes on Azure](https://learn.microsoft.com/training/paths/intro-to-kubernetes-on-azure/?WT.mc_id=containers-84290-stmuraws)"},{"id":"fundamentals-day-2","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-2","source":"@site/blog-cnny/2023-01-31/index.md","title":"2-2. Kubernetes Fundamentals - Services and Ingress","description":"A Step-by-Step Guide using Kubernetes Service and Ingress Resources on AKS","date":"2023-01-31T00:00:00.000Z","formattedDate":"January 31, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"service","permalink":"/Cloud-Native/cnny-2023/tags/service"},{"label":"ingress","permalink":"/Cloud-Native/cnny-2023/tags/ingress"}],"readingTime":10.175,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"fundamentals-day-2","title":"2-2. Kubernetes Fundamentals - Services and Ingress","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","serivce","ingress"],"image":"https://azure.github.io/Cloud-Native/img/og/30-07.png","description":"A Step-by-Step Guide using Kubernetes Service and Ingress Resources on AKS","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","service","ingress"]},"unlisted":false,"prevItem":{"title":"2-1. Kubernetes Fundamentals - Pods and Deployments","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-1"},"nextItem":{"title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-3"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-2\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"2-2. Kubernetes Fundamentals - Services and Ingress\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"A Step-by-Step Guide using Kubernetes Service and Ingress Resources on AKS\\"  />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-07.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@pauldotyu\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-2\\" />\\n</head>\\n\\nWelcome to `Day 2 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is #Kubernetes fundamentals. Yesterday we talked about how to deploy a containerized web app workload to Azure Kubernetes Service (AKS). Today we\'ll explore the topic of services and ingress and walk through the steps of making our containers accessible both internally as well as over the internet so that you can share it with the world \ud83d\ude0a\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n\\n* Exposing Pods via Service\\n* Exposing Services via Ingress\\n* Takeaways\\n* Resources\\n\\n## Exposing Pods via Service\\n\\nThere are a few ways to expose your pod in Kubernetes. One way is to take an imperative approach and use the `kubectl expose` command. This is probably the quickest way to achieve your goal but it isn\'t the best way. A better way to expose your pod by taking a declarative approach by creating a [services](https://learn.microsoft.com/azure/aks/concepts-network?WT.mc_id=containers-84290-pauyu#services) manifest file and deploying it using the `kubectl apply` command.\\n\\nDon\'t worry if you are unsure of how to make this manifest, we\'ll use `kubectl` to help generate it.\\n\\nFirst, let\'s ensure we have the database deployed on our AKS cluster.\\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/main), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context.  Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n```bash\\nkubectl apply -f ./manifests/deployment-db.yaml\\n```\\n\\nNext, let\'s deploy the application. If you are following along from yesterday\'s content, there isn\'t anything you need to change; however, if you are deploy the app from scratch, you\'ll need to modify the `deployment-app.yaml` manifest and update it with your image tag and database pod\'s IP address.\\n\\n```bash\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\nNow, let\'s expose the database using a service so that we can leverage Kubernetes\' built-in service discovery to be able to reference it by name; not pod IP. Run the following command.\\n\\n```bash\\nkubectl expose deployment azure-voting-db \\\\\\n  --port=5432 \\\\\\n  --target-port=5432\\n```\\n\\nWith the database exposed using service, we can update the app deployment manifest to use the service name instead of pod IP. This way, if the pod ever gets assigned a new IP, we don\'t have to worry about updating the IP each time and redeploying our web application. Kubernetes has internal service discovery mechanism in place that allows us to reference a service by its name.\\n\\nLet\'s make an update to the manifest. Replace the environment variable for `DATABASE_SERVER` with the following:\\n\\n```yml\\n- name: DATABASE_SERVER\\n  value: azure-voting-db\\n```\\n\\nRe-deploy the app with the updated configuration.\\n\\n```bash\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\nOne service down, one to go. Run the following command to expose the web application.\\n\\n```bash\\nkubectl expose deployment azure-voting-app \\\\\\n  --type=LoadBalancer \\\\\\n  --port=80 \\\\\\n  --target-port=8080\\n```\\n\\nNotice the `--type` argument has a value of `LoadBalancer`. This service type is implemented by the `cloud-controller-manager` which is part of the Kubernetes control plane. When using a managed Kubernetes cluster such as Azure Kubernetes Service, a [public standard load balancer](https://learn.microsoft.com/azure/aks/load-balancer-standard?WT.mc_id=containers-84290-pauyu#use-the-public-standard-load-balancer) will be able to provisioned when the service type is set to `LoadBalancer`. The load balancer will also have a public IP assigned which will make your deployment publicly available.\\n\\nKubernetes supports four [service types](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types):\\n\\n* **ClusterIP**: this is the default and limits service access to internal traffic within the cluster\\n* **NodePort**: this assigns a port mapping on the node\'s IP address and allows traffic from the virtual network (outside the cluster)\\n* **LoadBalancer**: as mentioned above, this creates a cloud-based load balancer\\n* **ExternalName**: this is used in special case scenarios where you want to map a service to an external DNS name\\n\\n> \ud83d\udcdd NOTE: When exposing a web application to the internet, allowing external users to connect to your **Service** directly is not the best approach. Instead, you should use an **Ingress**, which we\'ll cover in the next section.\\n\\nNow, let\'s confirm you can reach the web app from the internet. You can use the following command to print the URL to your terminal.\\n\\n```bash\\necho \\"http://$(kubectl get service azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\nGreat! The `kubectl expose` command gets the job done, but as mentioned above, it is not the best method of exposing deployments. It is better to expose deployments declaratively using a [service](https://kubernetes.io/docs/concepts/services-networking/service/) manifest, so let\'s delete the services and redeploy using manifests.\\n\\n```bash\\nkubectl delete service azure-voting-db azure-voting-app\\n```\\n\\nTo use `kubectl` to generate our manifest file, we can use the same `kubectl expose` command that we ran earlier but this time, we\'ll include  `--output=yaml` and `--dry-run=client`. This will instruct the command to output the manifest that would be sent to the `kube-api` server in YAML format to the terminal.\\n\\nGenerate the manifest for the database service.\\n\\n```bash\\nkubectl expose deployment azure-voting-db \\\\\\n  --type=ClusterIP \\\\\\n  --port=5432 \\\\\\n  --target-port=5432 \\\\\\n  --output=yaml \\\\\\n  --dry-run=client > ./manifests/service-db.yaml\\n```\\n\\nGenerate the manifest for the application service.\\n\\n```bash\\nkubectl expose deployment azure-voting-app \\\\\\n  --type=LoadBalancer \\\\\\n  --port=80 \\\\\\n  --target-port=8080 \\\\\\n  --output=yaml \\\\\\n  --dry-run=client > ./manifests/service-app.yaml\\n```\\n\\nThe command above redirected the YAML output to your manifests directory. Here is what the web application service looks like.\\n\\n```yml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    app: azure-voting-app\\n  name: azure-voting-app\\nspec:\\n  ports:\\n  - port: 80\\n    protocol: TCP\\n    targetPort: 8080\\n  selector:\\n    app: azure-voting-app\\n  type: LoadBalancer\\nstatus:\\n  loadBalancer: {}\\n```\\n\\n> \ud83d\udca1 TIP: To view the schema of any `api-resource` in Kubernetes, you can use the `kubectl explain` command. In this case the `kubectl explain service` command will tell us exactly what each of these fields do.\\n\\nRe-deploy the services using the new service manifests.\\n\\n```bash\\nkubectl apply -f ./manifests/service-db.yaml -f ./manifests/service-app.yaml\\n\\n# You should see TYPE is set to LoadBalancer and the EXTERNAL-IP is set\\nkubectl get service azure-voting-db azure-voting-app\\n```\\n\\nConfirm again that our application is accessible again. Run the following command to print the URL to the terminal.\\n\\n```bash\\necho \\"http://$(kubectl get service azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\nThat was easy, right? We just exposed both of our pods using Kubernetes services. The database only needs to be accessible from within the cluster so `ClusterIP` is perfect for that. For the web application, we specified the type to be `LoadBalancer` so that we can access the application over the public internet.\\n\\nBut wait... remember that if you want to expose web applications over the public internet, a Service with a public IP is not the best way; the better approach is to use an Ingress resource.\\n\\n## Exposing Services via Ingress\\n\\nIf you read through the Kubernetes documentation on [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/#what-is-ingress) you will see a diagram that depicts the Ingress sitting in front of the Service resource with a routing rule between it. In order to use Ingress, you need to deploy an Ingress Controller and it can be configured with many routing rules to forward traffic to one or many backend services. So effectively, an Ingress is a load balancer for your Services.\\n\\nWith that said, we no longer need a service type of `LoadBalancer` since the service does not need to be accessible from the internet. It only needs to be accessible from the Ingress Controller (internal to the cluster) so we can change the service type to `ClusterIP`.\\n\\nUpdate your `service.yaml` file to look like this:\\n\\n```yaml\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    app: azure-voting-app\\n  name: azure-voting-app\\nspec:\\n  ports:\\n  - port: 80\\n    protocol: TCP\\n    targetPort: 8080\\n  selector:\\n    app: azure-voting-app\\n```\\n\\n> \ud83d\udcdd NOTE: The default service type is ClusterIP so we can omit the `type` altogether.\\n\\nRe-apply the app service manifest.\\n\\n```bash\\nkubectl apply -f ./manifests/service-app.yaml\\n\\n# You should see TYPE set to ClusterIP and EXTERNAL-IP set to <none>\\nkubectl get service azure-voting-app\\n```\\n\\nNext, we need to install an [Ingress Controller](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/). There are quite a few options, and the Kubernetes-maintained [NGINX Ingress Controller](https://github.com/kubernetes/ingress-nginx) is commonly deployed.\\n\\nYou could install this manually by following [these instructions](https://kubernetes.github.io/ingress-nginx/deploy/#azure), but if you do that you\'ll be responsible for maintaining and supporting the resource.\\n\\nI like to take advantage of free maintenance and support when I can get it, so I\'ll opt to use the [Web Application Routing add-on for AKS](https://learn.microsoft.com/azure/aks/web-app-routing?WT.mc_id=containers-84290-pauyu&tabs=without-osm).\\n\\n> \ud83d\udca1 TIP: Whenever you install an AKS add-on, it will be maintained and fully supported by Azure Support.\\n\\nEnable the web application routing add-on in our AKS cluster with the following command.\\n\\n```bash\\naz aks addon enable \\\\\\n  --name <YOUR_AKS_NAME> \\\\\\n  --resource-group <YOUR_AKS_RESOURCE_GROUP>\\n  --addon web_application_routing\\n```\\n\\n> \u26a0\ufe0f WARNING: This command can take a few minutes to complete\\n\\nNow, let\'s use the same approach we took in creating our service to create our Ingress resource. Run the following command to generate the Ingress manifest.\\n\\n```bash\\nkubectl create ingress azure-voting-app \\\\\\n  --class=webapprouting.kubernetes.azure.com \\\\\\n  --rule=\\"/*=azure-voting-app:80\\" \\\\\\n  --output yaml \\\\\\n  --dry-run=client > ./manifests/ingress.yaml\\n```\\n\\nThe `--class=webapprouting.kubernetes.azure.com` option activates the AKS web application routing add-on. This AKS add-on can also integrate with other Azure services such as [Azure DNS](https://learn.microsoft.com/azure/dns/dns-overview?WT.mc_id=containers-84290-pauyu) and [Azure Key Vault](https://learn.microsoft.com/azure/key-vault/general/overview?WT.mc_id=containers-84290-pauyu) for TLS certificate management and this special class makes it all work.\\n\\nThe `--rule=\\"/*=azure-voting-app:80\\"` option looks confusing but we can use `kubectl` again to help us understand how to format the value for the option.\\n\\n```bash\\nkubectl create ingress --help\\n```\\n\\nIn the output you will see the following:\\n\\n```text\\n--rule=[]:\\n    Rule in format host/path=service:port[,tls=secretname]. Paths containing the leading character \'*\' are\\n    considered pathType=Prefix. tls argument is optional.\\n```\\n\\nIt expects a `host` and `path` separated by a forward-slash, then expects the backend `service` name and `port` separated by a colon. We\'re not using a hostname for this demo so we can omit it. For the path, an asterisk is used to specify a wildcard path prefix.\\n\\nSo, the value of `/*=azure-voting-app:80` creates a routing rule for all paths following the domain (or in our case since we don\'t have a hostname specified, the IP) to route traffic to our `azure-voting-app` backend service on port `80`.\\n\\n> \ud83d\udcdd NOTE: Configuring the hostname and TLS is outside the scope of this demo but please visit this URL https://bit.ly/aks-webapp-routing for an in-depth hands-on lab centered around Web Application Routing on AKS.\\n\\nYour `ingress.yaml` file should look like this:\\n\\n```yaml\\napiVersion: networking.k8s.io/v1\\nkind: Ingress\\nmetadata:\\n  creationTimestamp: null\\n  name: azure-voting-app\\nspec:\\n  ingressClassName: webapprouting.kubernetes.azure.com\\n  rules:\\n  - http:\\n      paths:\\n      - backend:\\n          service:\\n            name: azure-voting-app\\n            port:\\n              number: 80\\n        path: /\\n        pathType: Prefix\\nstatus:\\n  loadBalancer: {}\\n```\\n\\nApply the app ingress manifest.\\n\\n```bash\\nkubectl apply -f ./manifests/ingress.yaml\\n```\\n\\nValidate the web application is available from the internet again. You can run the following command to print the URL to the terminal.\\n\\n```bash\\necho \\"http://$(kubectl get ingress azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\n## Takeaways\\n\\nExposing your applications both internally and externally can be easily achieved using Service and Ingress resources respectively. If your service is HTTP or HTTPS based and needs to be accessible from outsie the cluster, use Ingress with an internal Service (i.e., ClusterIP or NodePort); otherwise, use the Service resource.  If your TCP-based Service needs to be publicly accessible, you set the type to LoadBalancer to expose a public IP for it. To learn more about these resources, please visit the links listed below.\\n\\nLastly, if you are unsure how to begin writing your service manifest, you can use `kubectl` and have it do most of the work for you \ud83e\udd73\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Services](https://learn.microsoft.com/azure/aks/concepts-network?WT.mc_id=containers-84290-pauyu#services)\\n* [Ingress Controllers](https://learn.microsoft.com/azure/aks/concepts-network?WT.mc_id=containers-84290-pauyu#ingress-controllers)\\n* [Hands-on Lab: Web Application Routing on AKS](https://aka.ms/aks-webapp-routing-lab)\\n* [How-to Guide: Ingress Controller in AKS](https://learn.microsoft.com/azure/aks/ingress-basic??WT.mc_id=containers-84290-pauyu&tabs=azure-cli)"},{"id":"fundamentals-day-3","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-3","source":"@site/blog-cnny/2023-02-01/index.md","title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","description":"Working with ConfigMaps and Secrets in Kubernetes","date":"2023-02-01T00:00:00.000Z","formattedDate":"February 1, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":5.835,"hasTruncateMarker":false,"authors":[{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"}],"frontMatter":{"slug":"fundamentals-day-3","title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","authors":["josh"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["kubernetes","container-apps","secrets","configuration"],"image":"https://azure.github.io/Cloud-Native/img/og/30-08.png","description":"Working with ConfigMaps and Secrets in Kubernetes","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"2-2. Kubernetes Fundamentals - Services and Ingress","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-2"},"nextItem":{"title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-4"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-3\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Working with ConfigMaps and Secrets in Kubernetes\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-08.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@joshduffney\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-3\\" />\\n</head>\\n\\nWelcome to `Day 3 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Yesterday we talked about Services and Ingress. Today we\'ll explore the topic of passing configuration and secrets to our applications in Kubernetes with ConfigMaps and Secrets.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n * Decouple configurations with ConfigMaps and Secerts\\n * Passing Environment Data with ConfigMaps and Secrets\\n * Conclusion\\n\\n## Decouple configurations with ConfigMaps and Secerts\\n\\nA ConfigMap is a Kubernetes object that decouples configuration data from pod definitions. Kubernetes secerts are similar, but were designed to decouple senstive information. \\n\\nSeparating the configuration and secerts from your application promotes better organization and security of your Kubernetes environment. It also enables you to share the same configuration and different secerts across multiple pods and deployments which can simplify scaling and management. Using ConfigMaps and Secerts in Kubernetes is a best practice that can help to improve the scalability, security, and maintainability of your cluster.\\n\\nBy the end of this tutorial, you\'ll have added a Kubernetes ConfigMap and Secret to the Azure Voting deployment.\\n\\n## Passing Environment Data with ConfigMaps and Secrets\\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/week2/day2), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context. Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n### Create the ConfigMap\\n\\nConfigMaps can be used in one of two ways; as environment variables or volumes. \\n\\nFor this tutorial you\'ll use a ConfigMap to create three environment variables inside the pod; DATABASE_SERVER, FISRT_VALUE, and SECOND_VALUE. The DATABASE_SERVER provides part of connection string to a Postgres. FIRST_VALUE and SECOND_VALUE are configuration options that change what voting options the application presents to the users.\\n\\nFollow the below steps to create a new ConfigMap:\\n\\n1. Create a YAML file named \'config-map.yaml\'. In this file, specify the environment variables for the application.\\n\\n    ```yaml\\n    apiVersion: v1\\n    kind: ConfigMap\\n    metadata:\\n      name: azure-voting-config\\n    data:\\n      DATABASE_SERVER: azure-voting-db\\n      FIRST_VALUE: \\"Go\\"\\n      SECOND_VALUE: \\"Rust\\"\\n    ```\\n\\n2. Create the config map in your Kubernetes cluster by running the following command:\\n    \\n    ```bash\\n    kubectl create -f config-map.yaml\\n    ```\\n\\n### Create the Secret\\n\\nThe `deployment-db.yaml` and `deployment-app.yaml` are Kubernetes manifests that deploy the Azure Voting App. Currently, those deployment manifests contain the environment variables `POSTGRES_PASSWORD` and `DATABASE_PASSWORD` with the value stored as plain text. Your task is to replace that environment variable with a Kubernetes Secret.\\n\\nCreate a Secret running the following commands:\\n\\n1. Encode `mypassword`.\\n\\n    ```bash\\n    echo -n \\"mypassword\\" | base64\\n    ```\\n\\n2. Create a YAML file named `secret.yaml`. In this file, add `POSTGRES_PASSWORD` as the key and the encoded value returned above under as the value in the data section.\\n\\n    ```yml\\n    apiVersion: v1\\n    kind: Secret\\n    metadata:\\n      name: azure-voting-secret\\n    type: Opaque\\n    data:\\n      POSTGRES_PASSWORD: bXlwYXNzd29yZA==\\n    ```\\n\\n3. Create the Secret in your Kubernetes cluster by running the following command:\\n\\n    ```bash\\n    kubectl create -f secret.yaml\\n    ```\\n\\n> [!WARNING]\\n> base64 encoding is a simple and widely supported way to obscure plaintext data, it is not secure, as it can easily be decoded. If you want to store sensitive data like password, you should use a more secure method like encrypting with a Key Management Service (KMS) before storing it in the Secret.\\n\\n### Modify the app deployment manifest\\n\\nWith the ConfigMap and Secert both created the next step is to replace the environment variables provided in the application deployment manuscript with the values stored in the ConfigMap and the Secert.\\n\\nComplete the following steps to add the ConfigMap and Secert to the deployment mainifest:\\n\\n1. Open the Kubernetes manifest file `deployment-app.yaml`. \\n\\n2. In the containers section, add an `envFrom` section and upate the `env` section.\\n\\n    ```yaml\\n    envFrom:\\n    - configMapRef:\\n        name: azure-voting-config\\n    env:\\n    - name: DATABASE_PASSWORD\\n      valueFrom:\\n        secretKeyRef:\\n          name: azure-voting-secret\\n          key: POSTGRES_PASSWORD\\n    ```\\n\\n    Using `envFrom` exposes all the values witin the ConfigMap as environment variables. Making it so you don\'t have to list them individually. \\n\\n3. Save the changes to the deployment manifest file.\\n\\n4. Apply the changes to the deployment by running the following command:\\n\\n    ```bash\\n    kubectl apply -f deployment-app.yaml\\n    ```\\n\\n### Modify the database deployment manifest \\n\\nNext, update the database deployment manifest and replace the plain text environment variable with the Kubernetes Secert.\\n\\n1. Open the `deployment-db.yaml`.\\n2. To add the secret to the deployment, replace the _env_ section with the following code:\\n\\n    ```yml\\n    env:\\n    - name: POSTGRES_PASSWORD\\n      valueFrom:\\n        secretKeyRef:\\n          name: azure-voting-secret\\n          key: POSTGRES_PASSWORD\\n    ```\\n\\n3. Apply the updated manifest.\\n\\n    ```bash\\n    kubectl apply -f deployment-db.yaml\\n    ```\\n\\n### Verify the ConfigMap and output environment variables\\n\\nVerify that the ConfigMap was added to your deploy by running the following command:\\n\\n    ```bash\\n    kubectl describe deployment azure-voting-app\\n    ```\\n\\nBrowse the output until you find the `envFrom` section with the config map reference. \\n\\nYou can also verify that the environment variables from the config map are being passed to the container by running the command `kubectl exec -it <pod-name> -- printenv`. This command will show you all the environment variables passed to the pod including the one from configmap.\\n\\nBy following these steps, you will have successfully added a config map to the Azure Voting App Kubernetes deployment, and the environment variables defined in the config map will be passed to the container running in the pod.\\n\\n### Verify the Secret and describe the deployment\\n\\nOnce the secret has been created you can verify it exists by running the following command:\\n\\n```bash\\nkubectl get secrets\\n```\\n\\nYou can view additional information, such as labels, annotations, type, and the Data by running kubectl describe:\\n\\n```bash\\nkubectl describe secret azure-voting-secret\\n```\\n\\nBy default, the describe command doesn\'t output the encoded value, but if you output the results as JSON or YAML you\'ll be able to see the secret\'s encoded value.\\n\\n```bash\\n kubectl get secret azure-voting-secret -o json\\n```\\n\\n## Conclusion\\n\\nIn conclusion, using ConfigMaps and Secrets in Kubernetes can help to improve the scalability, security, and maintainability of your cluster. By decoupling configuration data and sensitive information from pod definitions, you can promote better organization and security in your Kubernetes environment. Additionally, separating these elements allows for sharing the same configuration and different secrets across multiple pods and deployments, simplifying scaling and management.\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::"},{"id":"fundamentals-day-4","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-4","source":"@site/blog-cnny/2023-02-02/index.md","title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","description":"A Step-by-Step Guide using Kubernetes Persistent Volumes, Persistent Volume Claims, and Storage Classes","date":"2023-02-02T00:00:00.000Z","formattedDate":"February 2, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"persistent-volumes","permalink":"/Cloud-Native/cnny-2023/tags/persistent-volumes"},{"label":"persistent-volume-claims","permalink":"/Cloud-Native/cnny-2023/tags/persistent-volume-claims"}],"readingTime":7.89,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"fundamentals-day-4","title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","storage"],"image":"https://azure.github.io/Cloud-Native/img/og/30-09.png","description":"A Step-by-Step Guide using Kubernetes Persistent Volumes, Persistent Volume Claims, and Storage Classes","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","persistent-volumes","persistent-volume-claims"]},"unlisted":false,"prevItem":{"title":"2-3. Kubernetes Fundamentals - ConfigMaps and Secrets","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-3"},"nextItem":{"title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-5"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-4\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"A Step-by-Step Guide using Kubernetes Persistent Volumes, Persistent Volume Claims, and Storage Classes\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-09.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@pauldotyu\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-4\\" />\\n</head>\\n\\nWelcome to `Day 4 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Yesterday we talked about how to set app configurations and secrets at runtime using Kubernetes ConfigMaps and Secrets. Today we\'ll explore the topic of persistent storage on Kubernetes and show you can leverage Persistent Volumes and Persistent Volume Claims to ensure your PostgreSQL data can survive container restarts.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n\\n* Containers are ephemeral\\n* Persistent storage on Kubernetes\\n* Persistent storage on AKS\\n* Takeaways\\n* Resources\\n\\n## Containers are ephemeral\\n\\nIn our sample application, the frontend UI writes vote values to a backend PostgreSQL database. By default the database container stores its data on the container\'s local file system, so there will be data loss when the pod is re-deployed or crashes as containers are meant to start with a clean slate each time.\\n\\nLet\'s re-deploy our sample app and experience the problem first hand.\\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/week2/day3), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context. Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n```bash\\nkubectl apply -f ./manifests\\n```\\n\\nWait for the `azure-voting-app` service to be assigned a public IP then browse to the website and submit some votes. Use the command below to print the URL to the terminal.\\n\\n```bash\\necho \\"http://$(kubectl get ingress azure-voting-app -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\nNow, let\'s delete the pods and watch Kubernetes do what it does best... that is, re-schedule pods.\\n\\n```bash\\n# wait for the pod to come up then ctrl+c to stop watching\\nkubectl delete --all pod --wait=false && kubectl get po -w\\n```\\n\\nOnce the pods have been recovered, reload the website and confirm the vote tally has been reset to zero.\\n\\nWe need to fix this so that the data outlives the container.\\n\\n## Persistent storage on Kubernetes\\n\\nIn order for application data to survive crashes and restarts, you must implement [Persistent Volumes and Persistent Volume Claims](https://kubernetes.io/docs/concepts/storage/persistent-volumes/).\\n\\nA persistent volume represents storage that is available to the cluster. Storage volumes can be provisioned manually by an administrator or dynamically using [Container Storage Interface (CSI)](https://kubernetes.io/docs/concepts/storage/volumes/#csi) and [storage classes](https://kubernetes.io/docs/concepts/storage/storage-classes/), which includes information on how to provision CSI volumes.\\n\\nWhen a user needs to add persistent storage to their application, a persistent volume claim is made to allocate chunks of storage from the volume. This \\"claim\\" includes things like volume mode (e.g., file system or block storage), the amount of storage to allocate, the [access mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes), and optionally a storage class. Once a persistent volume claim has been deployed, users can add the volume to the pod and [mount it in a container](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#claims-as-volumes).\\n\\nIn the next section, we\'ll demonstrate how to enable persistent storage on AKS.\\n\\n## Persistent storage on AKS\\n\\nWith AKS, [CSI drivers](https://learn.microsoft.com/azure/aks/csi-storage-drivers?WT.mc_id=containers-84290-pauyu) and [storage classes](https://learn.microsoft.com/azure/aks/concepts-storage?WT.mc_id=containers-84290-pauyu#storage-classes) are pre-deployed into your cluster. This allows you to natively use [Azure Disks](https://learn.microsoft.com/azure/aks/azure-disk-csi?WT.mc_id=containers-84290-pauyu), [Azure Files](https://learn.microsoft.com/azure/aks/azure-files-csi?WT.mc_id=containers-84290-pauyu), and [Azure Blob Storage](https://learn.microsoft.com/azure/aks/azure-blob-csi?WT.mc_id=containers-84290-pauyu) as persistent volumes. You can either bring your own Azure storage account and use it with AKS or have AKS provision an Azure storage account for you.\\n\\nTo view the Storage CSI drivers that have been enabled in your AKS cluster, run the following command.\\n\\n```bash\\naz aks show \\\\\\n  --name <YOUR_AKS_NAME> \\\\\\n  --resource-group <YOUR_AKS_RESOURCE_GROUP> \\\\\\n  --query storageProfile\\n```\\n\\nYou should see output that looks like this.\\n\\n```json\\n{\\n  \\"blobCsiDriver\\": null,\\n  \\"diskCsiDriver\\": {\\n    \\"enabled\\": true,\\n    \\"version\\": \\"v1\\"\\n  },\\n  \\"fileCsiDriver\\": {\\n    \\"enabled\\": true\\n  },\\n  \\"snapshotController\\": {\\n    \\"enabled\\": true\\n  }\\n}\\n```\\n\\nTo view the storage classes that have been installed in your cluster, run the following command.\\n\\n```bash\\nkubectl get storageclass\\n```\\n\\nWorkload requirements will dictate which CSI driver and storage class you will need to use. \\n\\nIf you need block storage, then you should use the `blobCsiDriver`. The driver may not be enabled by default but you can enable it by following instructions which can be found in the [Resources](#resources) section below.\\n\\nIf you need file storage you should leverage either `diskCsiDriver` or `fileCsiDriver`. The decision between these two boils down to whether or not you need to have the underlying storage accessible by one pod or multiple pods. It is important to note that `diskCsiDriver` currently supports access from a single pod only. Therefore, if you need data to be accessible by multiple pods at the same time, then you should opt for `fileCsiDriver`.\\n\\nFor our PostgreSQL deployment, we\'ll use the `diskCsiDriver` and have AKS create an Azure Disk resource for us. There is no need to create a PV resource, all we need to do to is create a PVC using the `managed-csi-premium` storage class.\\n\\nRun the following command to create the PVC.\\n\\n```bash\\nkubectl apply -f - <<EOF            \\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: pvc-azuredisk\\nspec:\\n  accessModes:\\n    - ReadWriteOnce\\n  resources:\\n    requests:\\n      storage: 10Gi\\n  storageClassName: managed-csi-premium\\nEOF\\n```\\n\\nWhen you check the PVC resource, you\'ll notice the `STATUS` is set to `Pending`. It will be set to `Bound` once the volume is mounted in the PostgreSQL container.\\n\\n```bash\\nkubectl get persistentvolumeclaim\\n```\\n\\nLet\'s delete the `azure-voting-db` deployment.\\n\\n```bash\\nkubectl delete deploy azure-voting-db\\n```\\n\\nNext, we need to apply an updated deployment manifest which includes our PVC.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  creationTimestamp: null\\n  labels:\\n    app: azure-voting-db\\n  name: azure-voting-db\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: azure-voting-db\\n  strategy: {}\\n  template:\\n    metadata:\\n      creationTimestamp: null\\n      labels:\\n        app: azure-voting-db\\n    spec:\\n      containers:\\n      - image: postgres:15.0-alpine\\n        name: postgres\\n        ports:\\n        - containerPort: 5432\\n        env:\\n        - name: POSTGRES_PASSWORD\\n          valueFrom:\\n            secretKeyRef:\\n              name: azure-voting-secret\\n              key: POSTGRES_PASSWORD\\n        resources: {}\\n        volumeMounts:\\n        - name: mypvc\\n          mountPath: \\"/var/lib/postgresql/data\\"\\n          subPath: \\"data\\"\\n      volumes:\\n      - name: mypvc\\n        persistentVolumeClaim:\\n          claimName: pvc-azuredisk\\nEOF\\n```\\n\\nIn the manifest above, you\'ll see that we are mounting a new volume called `mypvc` (the name can be whatever you want) in the pod which points to a PVC named `pvc-azuredisk`. With the volume in place, we can mount it in the container by referencing the name of the volume  `mypvc` and setting the mount path to `/var/lib/postgresql/data` (which is the [default path](https://www.postgresql.org/docs/9.1/storage-file-layout.html)).\\n\\n> \ud83d\udca1 IMPORTANT: When mounting a volume into a non-empty subdirectory, you must add [`subPath`](https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath) to the volume mount and point it to a subdirectory in the volume rather than mounting at root. In our case, when Azure Disk is formatted, it leaves a `lost+found` directory as documented [here](https://learn.microsoft.com/troubleshoot/azure/azure-kubernetes/could-not-change-permissions-azure-files?WT.mc_id=containers-84290-pauyu).\\n\\nWatch the pods and wait for the `STATUS` to show `Running` and the pod\'s `READY` status shows `1/1`.\\n\\n```bash\\n# wait for the pod to come up then ctrl+c to stop watching\\nkubectl get po -w\\n```\\n\\nVerify that the `STATUS` of the PVC is now set to `Bound`\\n\\n```bash\\nkubectl get persistentvolumeclaim\\n```\\n\\nWith the new database container running, let\'s restart the application pod, wait for the pod\'s `READY` status to show `1/1`, then head back over to our web browser and submit a few votes.\\n\\n```bash\\nkubectl delete pod -lapp=azure-voting-app --wait=false && kubectl get po -lapp=azure-voting-app -w\\n```\\n\\nNow the moment of truth... let\'s rip out the pods again, wait for the pods to be re-scheduled, and confirm our vote counts remain in tact.\\n\\n```bash\\nkubectl delete --all pod --wait=false && kubectl get po -w\\n```\\n\\nIf you navigate back to the website, you\'ll find the vote are still there \ud83c\udf89\\n\\n## Takeaways\\n\\nBy design, containers are meant to be ephemeral and stateless workloads are ideal on Kubernetes. However, there will come a time when your data needs to outlive the container. To persist data in your Kubernetes workloads, you need to leverage PV, PVC, and optionally storage classes. In our demo scenario, we leveraged CSI drivers built into AKS and created a PVC using pre-installed storage classes. From there, we updated the database deployment to mount the PVC in the container and AKS did the rest of the work in provisioning the underlying Azure Disk. If the built-in storage classes does not fit your needs; for example, you need to change the `ReclaimPolicy` or change the SKU for the Azure resource, then you can [create your own custom storage class](https://learn.microsoft.com/azure/aks/azure-disk-csi#create-a-custom-storage-class?WT.mc_id=containers-84290-pauyu) and configure it just the way you need it \ud83d\ude0a\\n\\nWe\'ll revisit this topic again next week but in the meantime, check out some of the resources listed below to learn more.\\n\\nSee you in the next post!\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Kubernetes: Volumes](https://kubernetes.io/docs/concepts/storage/volumes/)\\n* [Kubernetes: Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)\\n* [Container Storage Interface (CSI) for Kubernetes](https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/)\\n* [Container Storage Interface (CSI) drivers on Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/csi-storage-drivers?WT.mc_id=containers-84290-pauyu)\\n* [Enable CSI driver on a new or existing AKS cluster](https://learn.microsoft.com/azure/aks/azure-blob-csi?WT.mc_id=containers-84290-pauyu&tabs=NFS#enable-csi-driver-on-a-new-or-existing-aks-cluster)\\n* [AKS: Volumes](https://learn.microsoft.com/azure/aks/concepts-storage?WT.mc_id=containers-84290-pauyu#volumes)\\n* [AKS: Storage Classes](https://learn.microsoft.com/azure/aks/concepts-storage?WT.mc_id=containers-84290-pauyu#storage-classes)\\n* [AKS: Built-in Storage Classes](https://learn.microsoft.com/azure/aks/azure-disks-dynamic-pv?WT.mc_id=containers-84290-pauyu#built-in-storage-classes)"},{"id":"fundamentals-day-5","metadata":{"permalink":"/Cloud-Native/cnny-2023/fundamentals-day-5","source":"@site/blog-cnny/2023-02-03/scaling.md","title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","description":"Learning to Scale Pods and Nodes in Kubernetes on Azure","date":"2023-02-03T00:00:00.000Z","formattedDate":"February 3, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":9.335,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"fundamentals-day-5","title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["scaling","kubernetes","aks","container-apps","cloud-native"],"image":"https://azure.github.io/Cloud-Native/img/og/30-10.png","description":"Learning to Scale Pods and Nodes in Kubernetes on Azure","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"2-4. Kubernetes Fundamentals - Volumes, Mounts, and Claims","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-4"},"nextItem":{"title":"3-1. Bringing Your Application to Kubernetes - CI/CD","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-1"}},"content":"<head>\\n  <meta name=\\"twitter:url\\"\\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-5\\" />\\n  <meta name=\\"twitter:title\\"\\n    content=\\"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes\\" />\\n  <meta name=\\"twitter:description\\"\\n    content=\\"Learning to Scale Pods and Nodes in Kubernetes on Azure\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-10.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\"\\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" />\\n  <link rel=\\"canonical\\"\\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-5\\" />\\n</head>\\n\\nWelcome to `Day 5 of Week 2` of #CloudNativeNewYear!\\n\\nThe theme for this week is Kubernetes fundamentals. Yesterday we talked about adding persistent storage to our deployment. Today we\'ll explore the topic of scaling pods and nodes in our Kubernetes cluster.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Catch the Replay of the Live Demo\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week2-demo).  \\n\\n:::\\n\\n## What We\'ll Cover\\n * Scaling Our Application\\n * Scaling Pods\\n * Scaling Nodes\\n * Exercise\\n * Resources\\n\\n\\n## Scaling Our Application\\n\\nOne of our primary reasons to use a service like Kubernetes to orchestrate our workloads is the ability to scale.  We\'ve approached scaling in a multitude of ways over the years, taking advantage of the ever-evolving levels of hardware and software. Kubernetes allows us to [scale our units of work, Pods](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#manually-scale-pods-or-nodes), and [the Nodes they run on](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#cluster-autoscaler).  This allows us to take advantage of both hardware and software scaling abilities.  Kubernetes can help improve the utilization of existing hardware (by scheduling Pods on Nodes that have resource capacity).  And, with the capabilities of virtualization and/or cloud hosting (or a bit more work, if you have a pool of physical machines), Kubernetes can expand (or contract) the number of Nodes capable of hosting Pods.  Scaling is primarily driven by resource utilization, but can be triggered by a variety of other sources thanks to projects like [Kubernetes Event-driven Autoscaling (KEDA)](https://keda.sh/).\\n\\n## Scaling Pods\\n\\nOur first level of scaling is with our Pods. Earlier, when we worked on our deployment, we talked about how the Kubernetes would use the deployment configuration to ensure that we had the desired workloads running.  One thing we didn\'t explore was running more than one instance of a pod. We can define a number of replicas of a pod in our [Deployment](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests).\\n\\n### Manually Scale Pods\\n\\nSo, if we wanted to define more pods right at the start (or at any point really), we could update our deployment configuration file with the number of replicas and apply that configuration file.\\n\\n```yml\\nspec:\\n  replicas: 5\\n```\\n\\nOr we could use the `kubectl scale` command to update the deployment with a number of pods to create.\\n\\n```powershell\\nkubectl scale --replicas=5 deployment/azure-voting-app\\n```\\n\\nBoth of these approaches modify the running configuration of our Kubernetes cluster and request that it ensure that we have that set number of replicas running.  Because this was a manual change, the Kubernetes cluster won\'t automatically increase or decrease the number of pods.  It\'ll just ensure that there are always the specified number of pods running.\\n\\n### Autoscale Pods with the Horizontal Pod Autoscaler\\n\\nAnother approach to scaling our pods is to allow the [Horizontal Pod Autoscaler](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#horizontal-pod-autoscaler) to help us scale in response to resources being used by the pod.  This requires a bit more configuration up front.  When we define our pod in our deployment, we need to include resource requests and limits.  The requests help Kubernetes determine what nodes may have capacity for a new instance of a pod.  The limit tells us where the node should cap utilization for a particular instance of a pod.  For example, we\'ll update our deployment to request 0.25 CPU and set a limit of 0.5 CPU.\\n\\n```yml\\n    spec:\\n      containers:\\n      - image: acrudavoz.azurecr.io/cnny2023/azure-voting-app-rust:ca4\\n        name: azure-voting-app-rust\\n        ports:\\n        - containerPort: 8080\\n        env:\\n        - name: DATABASE_URL\\n          value: postgres://postgres:mypassword@10.244.0.29\\n        resources:\\n          requests:\\n            cpu: 250m\\n          limits:\\n            cpu: 500m\\n```\\n\\nNow that we\'ve given Kubernetes an allowed range and an idea of what free resources a node should have to place new pods, we can set up autoscaling.  Because autoscaling is a persistent configuration, I like to define it in a configuration file that I\'ll be able to keep with the rest of my cluster configuration.  We\'ll use the `kubectl` command to help us write the configuration file.  We\'ll request that Kubernetes watch our pods and when the average CPU utilization if 50% of the requested usage (in our case if it\'s using more than 0.375 CPU across the current number of pods), it can grow the number of pods serving requests up to 10.  If the utilization drops, Kubernetes will have the permission to deprovision pods down to the minimum (three in our example).\\n\\n```powershell\\nkubectl autoscale deployment azure-voting-app --cpu-percent=50 --min=3 --max=10 -o YAML --dry-run=client\\n```\\n\\nWhich would give us:\\n\\n```yml\\napiVersion: autoscaling/v1\\nkind: HorizontalPodAutoscaler\\nmetadata:\\n  creationTimestamp: null\\n  name: azure-voting-app\\nspec:\\n  maxReplicas: 10\\n  minReplicas: 3\\n  scaleTargetRef:\\n    apiVersion: apps/v1\\n    kind: Deployment\\n    name: azure-voting-app\\n  targetCPUUtilizationPercentage: 50\\nstatus:\\n  currentReplicas: 0\\n  desiredReplicas: 0\\n```\\n\\nSo, how often does the autoscaler check the metrics being monitored?  The autoscaler checks the Metrics API every 15 seconds, however the pods stats are only updated every 60 seconds.  This means that an autoscale event may be evaluated about once a minute.  Once an autoscale down event happens however, Kubernetes has a cooldown period to give the new pods a chance to distribute the workload and let the new metrics accumulate.  There is no delay on scale up events.\\n\\n### Application Architecture Considerations\\n\\nWe\'ve focused in this example on our front end, which is an easier scaling story.  When we start talking about scaling our database layers or anything that deals with persistent storage or has primary/replica configuration requirements things get a bit more complicated. Some of these applications may have built-in leader election or [could use sidecars to help use existing features in Kubernetes to perform that function](https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/).  For shared storage scenarios, [persistent volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) (or [persistent volumes with Azure](https://learn.microsoft.com/azure/cloud-adoption-framework/scenarios/app-platform/aks/storage?WT.mc_id=containers-84290-stmuraws)) can be of help, if the application knows how to play well with shared file access.\\n\\nUltimately, you know your application architecture and, while Kubernetes may not have an exact match to how you are doing things today, the underlying capability is probably there under a different name.  This abstraction allows you to more effectively use Kubernetes to operate a variety of workloads with the levels of controls you need.\\n\\n## Scaling Nodes\\n\\nWe\'ve looked at how to scale our pods, but that assumes we have enough resources in our existing pool of nodes to accomodate those scaling requests.  Kubernetes can also help scale our available nodes to ensure that our applications have the necessary resources to meet their performance requirements.\\n\\n### Manually Scale Nodes\\n\\nManually scaling nodes isn\'t a direct function of Kubernetes, so your operating environment instructions may vary.  On Azure, it\'s pretty straight forward.  Using the Azure CLI (or other tools), we can tell our AKS cluster to scale up or scale down the number of nodes in our node pool.\\n\\nFirst, we\'ll check out how many nodes we currently have in our working environment.\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\nThis will show us\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get nodes\\nNAME                            STATUS   ROLES   AGE     VERSION\\naks-pool0-37917684-vmss000000   Ready    agent   5d21h   v1.24.6\\n```\\n\\n\\nThen, we\'ll scale it up to three nodes.\\n\\n```powershell\\naz aks scale --resource-group $ResourceGroup --name $AksName --node-count 3\\n```\\n\\nThen, we\'ll check out how many nodes we now have in our working environment.\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\nWhich returns:\\n\\n```\\nazure-voting-app-rust \u276f  kubectl get nodes\\nNAME                            STATUS   ROLES   AGE     VERSION\\naks-pool0-37917684-vmss000000   Ready    agent   5d21h   v1.24.6\\naks-pool0-37917684-vmss000001   Ready    agent   5m27s   v1.24.6\\naks-pool0-37917684-vmss000002   Ready    agent   5m10s   v1.24.6\\n```\\n\\n### Autoscale Nodes with the Cluster Autoscaler\\n\\nThings get more interesting when we start working with [the Cluster Autoscaler](https://learn.microsoft.com/azure/aks/cluster-autoscaler?WT.mc_id=containers-84290-stmuraws).  The Cluster Autoscaler watches for the inability of Kubernetes to schedule the required number of pods due to resource constraints (and a few other criteria like affinity/anti-affinity).  If there are insufficient resources available on the existing nodes, the autoscaler can provision new nodes into the nodepool.  Likewise, the autoscaler watches to see if the existing pods could be consolidated to a smaller set of nodes and can remove excess nodes.\\n\\nEnabling the autoscaler is likewise an update that can be dependent on where and how your Kubernetes cluster is hosted. Azure makes it easy with a simple Azure CLI command.\\n\\n```powershell\\naz aks update `\\n  --resource-group $ResourceGroup `\\n  --name $AksName `\\n  --update-cluster-autoscaler `\\n  --min-count 1 `\\n  --max-count 5\\n```\\n\\nThere are a [variety of settings](https://learn.microsoft.com/azure/aks/cluster-autoscaler#using-the-autoscaler-profile?WT.mc_id=containers-84290-stmuraws) that can be configured to tune how the autoscaler works.\\n\\n## Scaling on Different Events\\n\\nCPU and memory utilization are the primary drivers for the Horizontal Pod Autoscaler, but those might not be the best measures as to when you might want to scale workloads.  There are other options for scaling triggers and one of the more common plugins to help with that is the [Kubernetes Event-driven Autoscaling (KEDA) project](https://keda.sh/).  The KEDA project makes it easy to plug in different event sources to help drive scaling.  [Find more information about using KEDA on AKS here.](https://learn.microsoft.com/azure/aks/keda-about?WT.mc_id=containers-84290-stmuraws)\\n\\n## Exercise\\n\\nLet\'s try out the scaling configurations that we just walked through using [our sample application](https://aka.ms/azure-voting-app-rust).  If you still have your environment from Day 1, you can use that. \\n\\n> \ud83d\udcdd NOTE: If you don\'t have an AKS cluster deployed, please head over to [Azure-Samples/azure-voting-app-rust](https://github.com/Azure-Samples/azure-voting-app-rust/tree/week2/day4), clone the repo, and follow the instructions in the [README.md](https://github.com/Azure-Samples/azure-voting-app-rust/blob/main/README.md) to execute the Azure deployment and setup your `kubectl` context. Check out [the first post this week for more on the environment setup](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure).\\n\\n### Configure Horizontal Pod Autoscaler\\n\\n* Edit `./manifests/deployment-app.yaml` to include resource requests and limits.\\n\\n```yml\\n        resources:\\n          requests:\\n            cpu: 250m\\n          limits:\\n            cpu: 500m\\n```\\n\\n* Apply the updated deployment configuration.\\n\\n```powershell\\nkubectl apply -f ./manifests/deployment-app.yaml\\n```\\n\\n* Create the horizontal pod autoscaler configuration and apply it\\n\\n```powershell\\nkubectl autoscale deployment azure-voting-app --cpu-percent=50 --min=3 --max=10 -o YAML --dry-run=client > ./manifests/scaler-app.yaml\\nkubectl apply -f ./manifests/scaler-app.yaml\\n```\\n\\n* Check to see your pods scale out to the minimum.\\n\\n```powershell\\nkubectl get pods\\n```\\n\\n### Configure Cluster Autoscaler\\n\\nConfiguring the basic behavior of the Cluster Autoscaler is a bit simpler.  We just need to run the Azure CLI command to enable the autoscaler and define our lower and upper limits.\\n\\n* Check the current nodes available (should be 1).\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\n* Update the cluster to enable the autoscaler\\n\\n```powershell\\naz aks update `\\n  --resource-group $ResourceGroup `\\n  --name $AksName `\\n  --update-cluster-autoscaler `\\n  --min-count 2 `\\n  --max-count 5\\n```\\n\\n* Check to see the current number of nodes (should be 2 now).\\n\\n```powershell\\nkubectl get nodes\\n```\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n### Documentation\\n\\n* [Manually Scaling Pods and Nodes](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#manually-scale-pods-or-nodes)\\n* [Deployments](https://learn.microsoft.com/azure/aks/concepts-clusters-workloads?WT.mc_id=containers-84290-stmuraws#deployments-and-yaml-manifests)\\n* [Horizontal Pod Autoscaler](https://learn.microsoft.com/azure/aks/concepts-scale?WT.mc_id=containers-84290-stmuraws#horizontal-pod-autoscaler)\\n* [Leader Election in Kubernetes](https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/)\\n* [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)\\n* [Persistent Volumes with Azure](https://learn.microsoft.com/azure/cloud-adoption-framework/scenarios/app-platform/aks/storage?WT.mc_id=containers-84290-stmuraws)\\n* [Cluster Autoscaler](https://learn.microsoft.com/azure/aks/cluster-autoscaler?WT.mc_id=containers-84290-stmuraws)\\n* [Cluster Autoscaler Profile Settings](https://learn.microsoft.com/azure/aks/cluster-autoscaler#using-the-autoscaler-profile?WT.mc_id=containers-84290-stmuraws)\\n* [Kubernetes Event-driven Autoscaling (KEDA) project](https://keda.sh/)\\n* [KEDA on AKS](https://learn.microsoft.com/azure/aks/keda-about?WT.mc_id=containers-84290-stmuraws)\\n\\n### Training\\n\\n* [Application scalability on AKS with HorizontalPodAutoscalers](https://learn.microsoft.com/training/modules/aks-application-autoscaling-native?WT.mc_id=containers-84290-stmuraws)\\n* [Cluster Autoscaling with AKS](https://learn.microsoft.com/training/modules/aks-cluster-autoscaling?WT.mc_id=containers-84290-stmuraws)\\n* [Scale container applications in Azure Kubernetes Services using KEDA](https://learn.microsoft.com/training/modules/aks-app-scale-keda?WT.mc_id=containers-84290-stmuraws)"},{"id":"bring-your-app-day-1","metadata":{"permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-1","source":"@site/blog-cnny/2023-02-06/index.md","title":"3-1. Bringing Your Application to Kubernetes - CI/CD","description":"Taking a existing application, containerizing it, and publishing to Kubernetes in GitHub Actions.","date":"2023-02-06T00:00:00.000Z","formattedDate":"February 6, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":13.095,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"bring-your-app-day-1","title":"3-1. Bringing Your Application to Kubernetes - CI/CD","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["pods","deployments","kubernetes","aks","container-apps","cloud-native","github-actions","ci-cd"],"image":"https://azure.github.io/Cloud-Native/img/og/30-11.png","description":"Taking a existing application, containerizing it, and publishing to Kubernetes in GitHub Actions.","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"2-5. Kubernetes Fundamentals - Scaling Pods and Nodes","permalink":"/Cloud-Native/cnny-2023/fundamentals-day-5"},"nextItem":{"title":"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-2"}},"content":"<head>\\n  <meta name=\\"twitter:url\\"\\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-1\\" />\\n  <meta name=\\"twitter:title\\"\\n    content=\\"3-1. Bringing Your Application to Kubernetes - CI/CD\\" />\\n  <meta name=\\"twitter:description\\"\\n    content=\\"Taking a existing application, containerizing it, and publishing to Kubernetes in GitHub Actions.\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-11.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\"\\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" />\\n  <link rel=\\"canonical\\"\\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-1\\" />\\n</head>\\n\\nWelcome to `Day 1 of Week 3` of #CloudNativeNewYear!\\n\\nThe theme for this week is Bringing Your Application to Kubernetes. Last we talked about Kubernetes Fundamentals. Today we\'ll explore getting an existing application running in Kubernetes with a full pipeline in GitHub Actions.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Friday, February 10th at 11 AM PST\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week3-demo).  Join us Friday, February 10th and bring your questions!\\n\\n:::\\n\\n## What We\'ll Cover\\n * Our Application\\n * Adding Some Infrastructure as Code\\n * Building and Publishing a Container Image\\n * Deploying to Kubernetes\\n * Summary\\n * Resources\\n\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n## Our Application\\n\\nThis week we\'ll be taking an exisiting application - something similar to a typical line of business application - and setting it up to run in Kubernetes.  Over the course of the week, we\'ll address different concerns.  Today we\'ll focus on updating our CI/CD process to handle standing up (or validating that we have) an [Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws) environment, building and publishing container images for our web site and API server, and getting those services running in Kubernetes.\\n\\nThe application we\'ll be starting with is [eShopOnWeb](https://github.com/Azure-Samples/eShopOnAKS).  This application has a web site and API which are backed by a SQL Server instance.  It\'s built in .NET 7, so it\'s cross-platform.\\n\\n:::info\\nFor the enterprising among you, you may notice that there are a number of different eShopOn* variants on GitHub, including [eShopOnContainers](https://github.com/dotnet-architecture/eShopOnContainers).  We aren\'t using that example as it\'s more of an end state than a starting place. Afterwards, feel free to check out that example as what this solution could look like as a series of microservices.\\n:::\\n\\n## Adding Some Infrastructure as Code\\n\\n[Just like last week](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure), we need to stand up an AKS environment.  This week, however, rather than running commands in our own shell, we\'ll set up GitHub Actions to do that for us.\\n\\nThere is a **LOT** of plumbing in this section, **but** once it\'s set up, it\'ll make our lives a lot easier.  This section ensures that we have an environment to deploy our application into configured the way we want.  We can easily extend this to accomodate multiple environments or add additional microservices with minimal new effort.\\n\\n### Federated Identity\\n\\nSetting up a federated identity will allow us a more securable and auditable way of accessing Azure from GitHub Actions.  For more about setting up a federated identity, Microsoft Learn has the details on [connecting GitHub Actions to Azure](https://learn.microsoft.com/azure/developer/github/connect-from-azure?tabs=azure-portal%2Cwindows&WT.mc_id=containers-84290-stmuraws).\\n\\nHere, we\'ll just walk through the setup of the identity and configure GitHub to use that idenity to deploy our AKS environment and interact with our Azure Container Registry.\\n\\nThe examples will use PowerShell, but a Bash version of the setup commands is available in the [week3/day1 branch](https://github.com/Azure-Samples/eShopOnAKS/tree/week3/day1).\\n\\n#### Prerequisites\\n\\nTo follow along, you\'ll need:\\n\\n* a GitHub account\\n* an Azure Subscription\\n* the Azure CLI\\n* and the Git CLI.\\n\\nYou\'ll need to fork the [source repository](https://github.com/Azure-Samples/eShopOnAKS) under your GitHub user or organization where you can manage secrets and GitHub Actions.\\n\\nIt would be helpful to have the [GitHub CLI](https://cli.github.com/), but it\'s not required.\\n\\n#### Set Up Some Defaults\\n\\nYou will need to update one or more of the variables (your user or organization, what branch you want to work off of, and possibly the Azure AD application name if there is a conflict).\\n\\n```powershell\\n# Replace the gitHubOrganizationName value\\n# with the user or organization you forked\\n# the repository under.\\n\\n$githubOrganizationName = \'Azure-Samples\'\\n$githubRepositoryName  = \'eShopOnAKS\'\\n$branchName = \'week3/day1\'\\n$applicationName = \'cnny-week3-day1\'\\n```\\n\\n#### Create an Azure AD Application\\n\\nNext, we need to create an Azure AD application.\\n\\n```powershell\\n# Create an Azure AD application\\n$aksDeploymentApplication = New-AzADApplication -DisplayName $applicationName\\n```\\n\\n#### Set Up Federation for that Azure AD Application\\n\\nAnd configure that application to allow federated credential requests from our GitHub repository for a particular branch.\\n\\n```powershell\\n# Create a federated identity credential for the application\\nNew-AzADAppFederatedCredential `\\n   -Name $applicationName `\\n   -ApplicationObjectId $aksDeploymentApplication.Id `\\n   -Issuer \'https://token.actions.githubusercontent.com\' `\\n   -Audience \'api://AzureADTokenExchange\' `\\n   -Subject \\"repo:$($githubOrganizationName)/$($githubRepositoryName):ref:refs/heads/$branchName\\"\\n```\\n\\n#### Create a Service Principal for the Azure AD Application\\n\\nOnce the application has been created, we need a service principal tied to that application.  The service principal can be granted rights in Azure.\\n\\n```powershell\\n# Create a service principal for the application\\nNew-AzADServicePrincipal -AppId $($aksDeploymentApplication.AppId)\\n```\\n\\n### Give that Service Principal Rights to Azure Resources\\n\\nBecause our Bicep deployment exists at the subscription level and we are creating role assignments, we need to give it Owner rights. If we changed the scope of the deployment to just a resource group, we could apply more scoped permissions.\\n\\n```powershell\\n$azureContext = Get-AzContext\\nNew-AzRoleAssignment `\\n   -ApplicationId $($aksDeploymentApplication.AppId) `\\n   -RoleDefinitionName Owner `\\n   -Scope $azureContext.Subscription.Id\\n```\\n\\n#### Add Secrets to GitHub Repository\\n\\nIf you have the GitHub CLI, you can use that right from your shell to set the secrets needed.\\n\\n```powershell\\ngh secret set AZURE_CLIENT_ID --body $aksDeploymentApplication.AppId\\ngh secret set AZURE_TENANT_ID --body $azureContext.Tenant.Id\\ngh secret set AZURE_SUBSCRIPTION_ID --body $azureContext.Subscription.Id\\n```\\n\\nOtherwise, you can create them through the web interface like I did in the Learn Live event below.\\n\\n:::info\\nIt may look like the whole video will play, but it\'ll stop after configuring the secrets in GitHub (after about 9 minutes)\\n\\nThe video shows creating the Azure AD application, service principals, and configuring the federated identity in Azure AD and GitHub.\\n:::\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/sZ0Z-4r08so?start=1613&end=2124\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n### Creating a Bicep Deployment\\n\\n#### Resuable Workflows\\n\\nWe\'ll create our Bicep deployment in a [reusable workflows](https://docs.github.com/actions/using-workflows/reusing-workflows).  What are they?  The previous link has the documentation or the video below has [my colleague Brandon Martinez](https://twitter.com/brandonmartinez) and I talking about them.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/sZ0Z-4r08so?start=1065&end=1524\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\nThis workflow is basically [the same deployment](../2023-01-30/PodsAndDeployments.md#setting-up-a-kubernetes-environment-in-azure) we did in last week\'s series, just in GitHub Actions.\\n\\nStart by creating a file called `deploy_aks.yml` in the `.github/workflows` directory with the below contents.\\n\\n```yml\\nname: deploy\\n\\non:\\n  workflow_call:\\n    inputs:\\n      resourceGroupName:\\n        required: true\\n        type: string\\n    secrets:\\n      AZURE_CLIENT_ID:\\n        required: true\\n      AZURE_TENANT_ID:\\n        required: true\\n      AZURE_SUBSCRIPTION_ID:\\n        required: true\\n    outputs:\\n      containerRegistryName:\\n        description: Container Registry Name\\n        value: ${{ jobs.deploy.outputs.containerRegistryName }}\\n      containerRegistryUrl:\\n        description: Container Registry Login Url\\n        value: ${{ jobs.deploy.outputs.containerRegistryUrl }}\\n      resourceGroupName:\\n        description: Resource Group Name\\n        value: ${{ jobs.deploy.outputs.resourceGroupName }}\\n      aksName:\\n        description: Azure Kubernetes Service Cluster Name\\n        value: ${{ jobs.deploy.outputs.aksName }}\\n\\npermissions:\\n  id-token: write\\n  contents: read\\n\\njobs:\\n  validate:\\n    runs-on: ubuntu-latest\\n    steps:\\n    - uses: actions/checkout@v2\\n    - uses: azure/login@v1\\n      name: Sign in to Azure\\n      with:\\n        client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n        tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n    - uses: azure/arm-deploy@v1\\n      name: Run preflight validation\\n      with:\\n        deploymentName: ${{ github.run_number }}\\n        scope: subscription\\n        region: eastus\\n        template: ./deploy/main.bicep\\n        parameters: >\\n          resourceGroup=${{ inputs.resourceGroupName }}\\n        deploymentMode: Validate\\n\\n  deploy:\\n    needs: validate\\n    runs-on: ubuntu-latest\\n    outputs:\\n      containerRegistryName: ${{ steps.deploy.outputs.acr_name }}\\n      containerRegistryUrl: ${{ steps.deploy.outputs.acr_login_server_url }}\\n      resourceGroupName: ${{ steps.deploy.outputs.resource_group_name }}\\n      aksName: ${{ steps.deploy.outputs.aks_name }}\\n    steps:\\n    - uses: actions/checkout@v2\\n    - uses: azure/login@v1\\n      name: Sign in to Azure\\n      with:\\n        client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n        tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n    - uses: azure/arm-deploy@v1\\n      id: deploy\\n      name: Deploy Bicep file\\n      with:\\n        failOnStdErr: false\\n        deploymentName: ${{ github.run_number }}\\n        scope: subscription\\n        region: eastus\\n        template: ./deploy/main.bicep\\n        parameters: >\\n          resourceGroup=${{ inputs.resourceGroupName }}\\n```\\n\\n### Adding the Bicep Deployment\\n\\nOnce we have the Bicep deployment workflow, we can add it to the primary build definition in `.github/workflows/dotnetcore.yml`\\n\\n#### Permissions\\n\\nFirst, we need to add a permissions block to let the workflow request our Azure AD token.  This can go towards the top of the YAML file (I started it on line 5).\\n\\n```yml\\npermissions:\\n  id-token: write\\n  contents: read\\n```\\n\\n#### Deploy AKS Job\\n\\nNext, we\'ll add a reference to our reusable workflow.  This will go after the `build` job.\\n\\n```yml\\n  deploy_aks:\\n    needs: [build]\\n    uses: ./.github/workflows/deploy_aks.yml\\n    with:\\n      resourceGroupName: \'cnny-week3\'\\n    secrets:\\n      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\\n      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\\n      AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n```\\n\\n## Building and Publishing a Container Image\\n\\nNow that we have our target environment in place and an Azure Container Registry, we can build and publish our container images.\\n\\n### Add a Reusable Workflow\\n\\nFirst, we\'ll create a new file for our reusable workflow at `.github/workflows/publish_container_image.yml`.\\n\\nWe\'ll start the file with a name, the parameters it needs to run, and the permissions requirements for the federated identity request.\\n\\n```yml\\nname: Publish Container Images\\n\\non: \\n  workflow_call:\\n    inputs:\\n      containerRegistryName:\\n        required: true\\n        type: string\\n      containerRegistryUrl:\\n        required: true\\n        type: string\\n      githubSha:\\n        required: true\\n        type: string\\n    secrets:\\n      AZURE_CLIENT_ID:\\n        required: true\\n      AZURE_TENANT_ID:\\n        required: true\\n      AZURE_SUBSCRIPTION_ID:\\n        required: true\\n\\npermissions:\\n  id-token: write\\n  contents: read\\n```\\n\\n#### Build the Container Images\\n\\nOur next step is to build the two container images we\'ll need for the application, the website and the API.  We\'ll build the container images on our build worker and tag it with the git SHA, so there\'ll be a direct tie between the point in time in our codebase and the container images that represent it.\\n\\n```yml\\njobs:\\n  publish_container_image:\\n    runs-on: ubuntu-latest\\n\\n    steps:\\n    - uses: actions/checkout@v2\\n    - name: docker build\\n      run: |\\n        docker build . -f src/Web/Dockerfile -t ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha }}\\n        docker build . -f src/PublicApi/Dockerfile -t ${{ inputs.containerRegistryUrl }}/api:${{ inputs.githubSha}}\\n```\\n\\n#### Scan the Container Images\\n\\nBefore we publish those container images, we\'ll scan them for vulnerabilities and best practice violations.  We can add these two steps (one scan for each image).\\n\\n```yml\\n    - name: scan web container image\\n      uses: Azure/container-scan@v0\\n      with:\\n        image-name: ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha}}\\n    - name: scan api container image\\n      uses: Azure/container-scan@v0\\n      with:\\n        image-name: ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha}}\\n```\\n\\nThe container images provided have a few items that\'ll be found. We can create an allowed list at `.github/containerscan/allowedlist.yaml` to define vulnerabilities or best practice violations that we\'ll explictly allow to **not** fail our build.\\n\\n```yml\\ngeneral:\\n  vulnerabilities:\\n    - CVE-2022-29458\\n    - CVE-2022-3715\\n    - CVE-2022-1304\\n    - CVE-2021-33560\\n    - CVE-2020-16156\\n    - CVE-2019-8457\\n    - CVE-2018-8292\\n  bestPracticeViolations:\\n    - CIS-DI-0001\\n    - CIS-DI-0005  \\n    - CIS-DI-0006 \\n    - CIS-DI-0008  \\n```\\n\\n#### Publish the Container Images\\n\\nFinally, we\'ll log in to Azure, then log in to our Azure Container Registry, and push our images.\\n\\n```yml\\n    - uses: azure/login@v1\\n      name: Sign in to Azure\\n      with:\\n        client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n        tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n    - name: acr login \\n      run: az acr login --name ${{ inputs.containerRegistryName  }}\\n    - name: docker push\\n      run: |\\n        docker push ${{ inputs.containerRegistryUrl }}/web:${{ inputs.githubSha}}\\n        docker push ${{ inputs.containerRegistryUrl }}/api:${{ inputs.githubSha}}\\n```\\n\\n### Update the Build With the Image Build and Publish\\n\\nNow that we have our reusable workflow to create and publish our container images, we can include that in our primary build defnition at `.github/workflows/dotnetcore.yml`.\\n\\n```yml\\n  publish_container_image:\\n    needs: [deploy_aks]\\n    uses: ./.github/workflows/publish_container_image.yml\\n    with:\\n      containerRegistryName: ${{ needs.deploy_aks.outputs.containerRegistryName }}\\n      containerRegistryUrl: ${{ needs.deploy_aks.outputs.containerRegistryUrl }}\\n      githubSha: ${{ github.sha }}\\n    secrets:\\n      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}\\n      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}\\n      AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n```\\n\\n## Deploying to Kubernetes\\n\\nFinally, we\'ve gotten enough set up that a commit to the target branch will:\\n\\n* build and test our application code\\n* set up (or validate) our AKS and ACR environment\\n* and create, scan, and publish our container images to ACR\\n\\nOur last step will be to deploy our application to Kubernetes.  We\'ll use the basic building blocks we worked with last week, [deployments](../2023-01-30/PodsAndDeployments.md#creating-the-deployment) and [services](../2023-01-31/index.md#exposing-pods-via-service).\\n\\n### Starting the Reusable Workflow to Deploy to AKS\\n\\nWe\'ll start our workflow with our parameters that we need, as well as the permissions to access the token to log in to Azure.\\n\\nWe\'ll check out our code, then log in to Azure, and use the `az` CLI to get credentials for our AKS cluster.\\n\\n```yml\\nname: deploy_to_aks\\n\\non:\\n  workflow_call:\\n    inputs:\\n      aksName:\\n        required: true\\n        type: string\\n      resourceGroupName:\\n        required: true\\n        type: string\\n      containerRegistryUrl:\\n        required: true\\n        type: string\\n      githubSha:\\n        required: true\\n        type: string\\n    secrets:\\n      AZURE_CLIENT_ID:\\n        required: true\\n      AZURE_TENANT_ID:\\n        required: true\\n      AZURE_SUBSCRIPTION_ID:\\n        required: true\\n\\npermissions:\\n  id-token: write\\n  contents: read\\n\\njobs:\\n  deploy:\\n    runs-on: ubuntu-latest\\n    steps:  \\n      - uses: actions/checkout@v2\\n      - uses: azure/login@v1\\n        name: Sign in to Azure\\n        with:\\n          client-id: ${{ secrets.AZURE_CLIENT_ID }}\\n          tenant-id: ${{ secrets.AZURE_TENANT_ID }}\\n          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}\\n      - name: Get AKS Credentials\\n        run: |\\n          az aks get-credentials --resource-group ${{ inputs.resourceGroupName }} --name ${{ inputs.aksName }}\\n```\\n\\n### Edit the Deployment For Our Current Image Tag\\n\\nLet\'s add the Kubernetes manifests to our repo.  This post is long enough, so you can find the content for the manifests folder [in the manifests folder in the source repo under the `week3/day1` branch](https://github.com/Azure-Samples/eShopOnAKS/tree/week3/day1/manifests).\\n\\n:::tip\\nIf you only forked the main branch of the source repo, you can easily get the updated manifests by using the following `git` commands:\\n\\n```powershell\\ngit remote add upstream https://github.com/Azure-Samples/eShopOnAks\\ngit fetch upstream week3/day1\\ngit checkout upstream/week3/day1 manifests\\n```\\n\\nThis will make the `week3/day1` branch available locally and then we can update the manifests directory to match the state of that branch.\\n:::\\n\\nThe deployments and the service defintions should be familiar from last week\'s content (but not the same).  This week, however, there\'s a new file in the manifests - `./manifests/kustomization.yaml`\\n\\nThis file helps us more dynamically edit our kubernetes manifests and support is baked right in to the `kubectl` command.\\n\\n#### Kustomize Definition\\n\\n[Kustomize](https://kustomize.io/) allows us to specify specific resource manifests and areas of that manifest to replace.  We\'ve put some placeholders in our file as well, so we can replace those for each run of our CI/CD system.\\n\\nIn `./manifests/kustomization.yaml` you will see:\\n\\n```yml\\nresources:\\n- deployment-api.yaml\\n- deployment-web.yaml\\n\\n# Change the image name and version\\nimages:\\n- name: notavalidregistry.azurecr.io/api:v0.1.0\\n  newName: <YOUR_ACR_SERVER>/api\\n  newTag: <YOUR_IMAGE_TAG>\\n- name: notavalidregistry.azurecr.io/web:v0.1.0\\n  newName: <YOUR_ACR_SERVER>/web\\n  newTag: <YOUR_IMAGE_TAG>\\n```\\n\\n#### Replacing Values in our Build\\n\\nNow, we encounter a little problem - our deployment files need to know the tag and ACR server.  We can do a bit of `sed` magic to edit the file on the fly.\\n\\nIn `.github/workflows/deploy_to_aks.yml`, we\'ll add:\\n\\n```yml\\n      - name: replace_placeholders_with_current_run\\n        run: |\\n          sed -i \\"s/<YOUR_ACR_SERVER>/${{ inputs.containerRegistryUrl }}/g\\" ./manifests/kustomization.yaml\\n          sed -i \\"s/<YOUR_IMAGE_TAG>/${{ inputs.githubSha }}/g\\" ./manifests/kustomization.yaml\\n```\\n\\n### Deploying the Manifests\\n\\nWe have our manifests in place and our `kustomization.yaml` file (with commands to update it at runtime) ready to go, we can deploy our manifests.\\n\\nFirst, we\'ll deploy our database (deployment and service).\\nNext, we\'ll use the `-k` parameter on `kubectl` to tell it to look for a `kustomize` configuration, transform the requested manifests and apply those.\\nFinally, we apply the service defintions for the web and API deployments.\\n\\n```yml\\n        run: |\\n          kubectl apply -f ./manifests/deployment-db.yaml \\\\\\n                        -f ./manifests/service-db.yaml\\n          kubectl apply -k ./manifests\\n          kubectl apply -f ./manifests/service-api.yaml \\\\\\n                        -f ./manifests/service-web.yaml\\n```\\n\\n## Summary\\n\\nWe\'ve covered a lot of ground in today\'s post.  We set up federated credentials with GitHub.  Then we added reusable workflows to deploy an AKS environment and build/scan/publish our container images, and then to deploy them into our AKS environment.\\n\\nThis sets us up to start making changes to our application and Kubernetes configuration and have those changes automatically validated and deployed by our CI/CD system.  Tomorrow, we\'ll look at updating our application environment with runtime configuration, persistent storage, and more.\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=containers-84290-stmuraws)\\n* [Reusable workflows in GitHub Actions](https://docs.github.com/actions/using-workflows/reusing-workflows)\\n* [Connecting GitHub Actions to Azure](https://learn.microsoft.com/azure/developer/github/connect-from-azure?tabs=azure-portal%2Cwindows&WT.mc_id=containers-84290-stmuraws)\\n* [Kustomize](https://kustomize.io/)\\n* [GitHub CLI](https://cli.github.com/)\\n* [eShopOnAKS](https://github.com/Azure-Samples/eShopOnAKS)"},{"id":"bring-your-app-day-2","metadata":{"permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-2","source":"@site/blog-cnny/2023-02-07/index.md","title":"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration","description":"Learn how to optimize your Kubernetes environment by implementing ConfigMaps for environment variable management, Azure Files for persistent storage, and Azure Workload Identity plus Azure Key Vault for secure secret management.","date":"2023-02-07T00:00:00.000Z","formattedDate":"February 7, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"configmaps","permalink":"/Cloud-Native/cnny-2023/tags/configmaps"},{"label":"persistent-storage","permalink":"/Cloud-Native/cnny-2023/tags/persistent-storage"},{"label":"secrets-management","permalink":"/Cloud-Native/cnny-2023/tags/secrets-management"},{"label":"workload-identity","permalink":"/Cloud-Native/cnny-2023/tags/workload-identity"}],"readingTime":11.09,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"bring-your-app-day-2","title":"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","configmaps","persistent-volumes","secrets","azure-files","azure-key-vault","azure-workload-identity","best-practices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-12.png","description":"Learn how to optimize your Kubernetes environment by implementing ConfigMaps for environment variable management, Azure Files for persistent storage, and Azure Workload Identity plus Azure Key Vault for secure secret management.","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","configmaps","persistent-storage","secrets-management","workload-identity"]},"unlisted":false,"prevItem":{"title":"3-1. Bringing Your Application to Kubernetes - CI/CD","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-1"},"nextItem":{"title":"3-3. Bringing Your Application to Kubernetes - Opening your Application with Ingress","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-3"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-2\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Learn how to optimize your Kubernetes environment by implementing ConfigMaps for environment variable management, Azure Files for persistent storage, and Azure Workload Identity plus Azure Key Vault for secure secret management.\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-12.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@pauldotyu\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-2\\" />\\n</head>\\n\\nWelcome to `Day 2 of Week 3` of #CloudNativeNewYear!\\n\\nThe theme for this week is Bringing Your Application to Kubernetes. Yesterday we talked about getting an existing application running in Kubernetes with a full pipeline in GitHub Actions. Today we\'ll evaluate our sample application\'s configuration, storage, and networking requirements and implement using Kubernetes and Azure resources.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Friday, February 10th at 11 AM PST\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week3-demo).  Join us Friday, February 10th and bring your questions!\\n\\n:::\\n\\n## What We\'ll Cover\\n\\n* Gather requirements\\n* Implement environment variables using ConfigMaps\\n* Implement persistent volumes using Azure Files\\n* Implement secrets using Azure Key Vault\\n* Re-package deployments\\n* Conclusion\\n* Resources\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n:::caution \\n\\nBefore you begin, make sure you\'ve gone through yesterday\'s [post](../2023-02-06/index.md) to set up your AKS cluster.\\n\\n:::\\n\\n## Gather requirements\\n\\nThe eShopOnWeb application is written in .NET 7 and has two major pieces of functionality. The web UI is where customers can browse and shop. The web UI also includes an admin portal for managing the product catalog. This admin portal, is packaged as a WebAssembly application and relies on a separate REST API service. Both the web UI and the REST API connect to the same SQL Server container.\\n\\nLooking through the source code which can be found [here](https://github.com/Azure-Samples/eShopOnAKS/tree/main/src) we can identify requirements for configs, persistent storage, and secrets.\\n\\n### Database server\\n\\n* Need to store the password for the `sa` account as a secure secret\\n* Need persistent storage volume for data directory\\n* Need to inject environment variables for SQL Server license type and EULA acceptance\\n\\n### Web UI and REST API service\\n\\n* Need to store database connection string as a secure secret\\n* Need to inject ASP.NET environment variables to override app settings\\n* Need persistent storage volume for ASP.NET key storage\\n\\n## Implement environment variables using ConfigMaps\\n\\nConfigMaps are relatively straight-forward to create. If you were following along with the examples last week, this should be review \ud83d\ude09\\n\\nCreate a ConfigMap to store database environment variables.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: mssql-settings\\ndata:\\n  MSSQL_PID: Developer\\n  ACCEPT_EULA: \\"Y\\"\\nEOF\\n```\\n\\nCreate another ConfigMap to store ASP.NET environment variables.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: aspnet-settings\\ndata:\\n  ASPNETCORE_ENVIRONMENT: Development\\nEOF\\n```\\n\\n## Implement persistent volumes using Azure Files\\n\\nSimilar to last week, we\'ll take advantage of storage classes built into AKS. For our SQL Server data, we\'ll use the `azurefile-csi-premium` storage class and leverage an [Azure Files](https://learn.microsoft.com/azure/storage/files/storage-files-introduction?WT.mc_id=containers-84290-pauyu) resource as our PersistentVolume.\\n\\nCreate a PersistentVolumeClaim (PVC) for persisting SQL Server data.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: mssql-data\\nspec:\\n  accessModes:\\n  - ReadWriteMany\\n  storageClassName: azurefile-csi-premium\\n  resources:\\n    requests:\\n      storage: 5Gi\\nEOF\\n```\\n\\nCreate another PVC for persisting ASP.NET data.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\n  name: aspnet-data\\nspec:\\n  accessModes:\\n  - ReadWriteMany\\n  storageClassName: azurefile-csi-premium\\n  resources:\\n    requests:\\n      storage: 5Gi\\nEOF\\n```\\n\\n## Implement secrets using Azure Key Vault\\n\\nIt\'s a well known fact that Kubernetes secretes are not really secrets. They\'re just base64-encoded values and not secure, especially if malicious users have access to your Kubernetes cluster. \\n\\nIn a production scenario, you will want to leverage an external vault like [Azure Key Vault](https://azure.microsoft.com/products/key-vault?WT.mc_id=containers-84290-pauyu) or [HashiCorp Vault](https://www.vaultproject.io/) to encrypt and store secrets.\\n\\nWith AKS, we can enable the [Secrets Store CSI driver](https://secrets-store-csi-driver.sigs.k8s.io/) add-on which will allow us to leverage Azure Key Vault.\\n\\n```bash\\n# Set some variables\\nRG_NAME=<YOUR_RESOURCE_GROUP_NAME>\\nAKS_NAME=<YOUR_AKS_CLUSTER_NAME>\\nACR_NAME=<YOUR_ACR_NAME>\\n\\naz aks enable-addons \\\\\\n  --addons azure-keyvault-secrets-provider \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RG_NAME\\n```\\n\\nWith the add-on enabled, you should see `aks-secrets-store-csi-driver` and `aks-secrets-store-provider-azure` resources installed on each node in your Kubernetes cluster. \\n\\nRun the command below to verify.\\n\\n```bash\\nkubectl get pods \\\\\\n  --namespace kube-system \\\\\\n  --selector \'app in (secrets-store-csi-driver, secrets-store-provider-azure)\'\\n```\\n\\nThe Secrets Store CSI driver allows us to use secret stores via Container Storage Interface (CSI) volumes. This provider offers capabilities such as mounting and syncing between the secure vault and Kubernetes Secrets. On AKS, the [Azure Key Vault Provider for Secrets Store CSI Driver](https://azure.github.io/secrets-store-csi-driver-provider-azure/docs/) enables integration with [Azure Key Vault](https://learn.microsoft.com/azure/key-vault/general/overview?WT.mc_id=containers-84290-pauyu).\\n\\nYou may not have an Azure Key Vault created yet, so let\'s create one and add some secrets to it.\\n\\n```bash\\nAKV_NAME=$(az keyvault create \\\\\\n  --name akv-eshop$RANDOM \\\\\\n  --resource-group $RG_NAME \\\\\\n  --query name -o tsv)\\n\\n# Database server password\\naz keyvault secret set \\\\\\n  --vault-name $AKV_NAME \\\\\\n  --name mssql-password \\\\\\n  --value \\"@someThingComplicated1234\\"\\n\\n# Catalog database connection string\\naz keyvault secret set \\\\\\n  --vault-name $AKV_NAME \\\\\\n  --name mssql-connection-catalog \\\\\\n  --value \\"Server=db;Database=Microsoft.eShopOnWeb.CatalogDb;User Id=sa;Password=@someThingComplicated1234;TrustServerCertificate=True;\\"\\n\\n# Identity database connection string\\naz keyvault secret set \\\\\\n  --vault-name $AKV_NAME \\\\\\n  --name mssql-connection-identity \\\\\\n  --value \\"Server=db;Database=Microsoft.eShopOnWeb.Identity;User Id=sa;Password=@someThingComplicated1234;TrustServerCertificate=True;\\"\\n```\\n\\n### Pods authentication using Azure Workload Identity\\n\\nIn order for our Pods to retrieve secrets from Azure Key Vault, we\'ll need to set up a way for the Pod to authenticate against Azure AD. This can be achieved by implementing the new [Azure Workload Identity](https://learn.microsoft.com/azure/aks/workload-identity-overview?WT.mc_id=containers-84290-pauyu) feature of AKS.\\n\\n:::info\\n\\nAt the time of this writing, the workload identity feature of AKS is in Preview.\\n\\n:::\\n\\nThe workload identity feature within AKS allows us to leverage native Kubernetes resources and link a [Kubernetes ServiceAccount](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/) to an [Azure Managed Identity](https://learn.microsoft.com/azure/active-directory/managed-identities-azure-resources/overview?WT.mc_id=containers-84290-pauyu) to authenticate against [Azure AD](https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis?WT.mc_id=containers-84290-pauyu).\\n\\nFor the authentication flow, our Kubernetes cluster will act as an Open ID Connect (OIDC) issuer and will be able issue identity tokens to ServiceAccounts which will be assigned to our Pods.\\n\\nThe Azure Managed Identity will be granted permission to access secrets in our Azure Key Vault and with the ServiceAccount being assigned to our Pods, they will be able to retrieve our secrets.\\n\\nFor more information on how the authentication mechanism all works, check out this [doc](https://azure.github.io/azure-workload-identity/docs/introduction.html#how-it-works).\\n\\nTo implement all this, start by enabling the new preview feature for AKS.\\n\\n```bash\\naz feature register \\\\\\n  --namespace \\"Microsoft.ContainerService\\" \\\\\\n  --name \\"EnableWorkloadIdentityPreview\\"\\n```\\n\\n:::caution\\n\\nThis can take several minutes to complete.\\n\\n:::\\n\\nCheck the status and ensure the `state` shows `Regestered` before moving forward.\\n\\n```bash\\naz feature show \\\\\\n  --namespace \\"Microsoft.ContainerService\\" \\\\\\n  --name \\"EnableWorkloadIdentityPreview\\"\\n```\\n\\nUpdate your AKS cluster to enable the workload identity feature and enable the OIDC issuer endpoint.\\n\\n```bash\\naz aks update \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RG_NAME \\\\\\n  --enable-workload-identity \\\\\\n  --enable-oidc-issuer \\n```\\n\\nCreate an Azure Managed Identity and retrieve its client ID.\\n\\n```bash\\nMANAGED_IDENTITY_CLIENT_ID=$(az identity create \\\\\\n  --name aks-workload-identity \\\\\\n  --resource-group $RG_NAME \\\\\\n  --subscription $(az account show --query id -o tsv) \\\\\\n  --query \'clientId\' -o tsv)\\n```\\n\\nCreate the Kubernetes ServiceAccount.\\n\\n```bash\\n# Set namespace (this must align with the namespace that your app is deployed into)\\nSERVICE_ACCOUNT_NAMESPACE=default\\n\\n# Set the service account name\\nSERVICE_ACCOUNT_NAME=eshop-serviceaccount\\n\\n# Create the service account\\nkubectl apply -f - <<EOF\\napiVersion: v1\\nkind: ServiceAccount\\nmetadata:\\n  annotations:\\n    azure.workload.identity/client-id: ${MANAGED_IDENTITY_CLIENT_ID}\\n  labels:\\n    azure.workload.identity/use: \\"true\\"\\n  name: ${SERVICE_ACCOUNT_NAME}\\n  namespace: ${SERVICE_ACCOUNT_NAMESPACE}\\nEOF\\n```\\n\\n:::info\\n\\nNote to enable this `ServiceAccount` to work with Azure Workload Identity, you must annotate the resource with `azure.workload.identity/client-id`, and add a label of `azure.workload.identity/use: \\"true\\"`\\n\\n:::\\n\\nThat was a lot... Let\'s review what we just did.\\n\\nWe have an Azure Managed Identity (object in Azure AD), an OIDC issuer URL (endpoint in our Kubernetes cluster), and a Kubernetes ServiceAccount.\\n\\nThe next step is to \\"tie\\" these components together and establish a [Federated Identity Credential](https://learn.microsoft.com/graph/api/resources/federatedidentitycredentials-overview?WT.mc_id=containers-84290-pauyu&view=graph-rest-1.0) so that Azure AD can trust authentication requests from your Kubernetes cluster.\\n\\n:::info\\n\\nThis identity federation can be established between Azure AD any Kubernetes cluster; not just AKS \ud83e\udd17\\n\\n:::\\n\\nTo establish the federated credential, we\'ll need the OIDC issuer URL, and a subject which points to your Kubernetes ServiceAccount.\\n\\n```bash\\n# Get the OIDC issuer URL\\nOIDC_ISSUER_URL=$(az aks show \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RG_NAME \\\\\\n  --query \\"oidcIssuerProfile.issuerUrl\\" -o tsv)\\n\\n# Set the subject name using this format: `system:serviceaccount:<YOUR_SERVICE_ACCOUNT_NAMESPACE>:<YOUR_SERVICE_ACCOUNT_NAME>`\\nSUBJECT=system:serviceaccount:$SERVICE_ACCOUNT_NAMESPACE:$SERVICE_ACCOUNT_NAME\\n\\naz identity federated-credential create \\\\\\n  --name aks-federated-credential \\\\\\n  --identity-name aks-workload-identity \\\\\\n  --resource-group $RG_NAME \\\\\\n  --issuer $OIDC_ISSUER_URL \\\\\\n  --subject $SUBJECT\\n```\\n\\nWith the authentication components set, we can now create a [SecretProviderClass](https://secrets-store-csi-driver.sigs.k8s.io/getting-started/usage.html) which includes details about the Azure Key Vault, the secrets to pull out from the vault, and identity used to access the vault.\\n\\n```bash\\n# Get the tenant id for the key vault\\nTENANT_ID=$(az keyvault show \\\\\\n  --name $AKV_NAME \\\\\\n  --resource-group $RG_NAME \\\\\\n  --query properties.tenantId -o tsv)\\n\\n# Create the secret provider for azure key vault\\nkubectl apply -f - <<EOF\\napiVersion: secrets-store.csi.x-k8s.io/v1\\nkind: SecretProviderClass\\nmetadata:\\n  name: eshop-azure-keyvault\\nspec:\\n  provider: azure\\n  parameters:\\n    usePodIdentity: \\"false\\"\\n    useVMManagedIdentity: \\"false\\"   \\n    clientID: \\"${MANAGED_IDENTITY_CLIENT_ID}\\"\\n    keyvaultName: \\"${AKV_NAME}\\"\\n    cloudName: \\"\\"\\n    objects:  |\\n      array:\\n        - |\\n          objectName: mssql-password\\n          objectType: secret\\n          objectVersion: \\"\\"\\n        - |\\n          objectName: mssql-connection-catalog\\n          objectType: secret\\n          objectVersion: \\"\\"\\n        - |\\n          objectName: mssql-connection-identity\\n          objectType: secret\\n          objectVersion: \\"\\"\\n    tenantId: \\"${TENANT_ID}\\"\\n  secretObjects:\\n  - secretName: eshop-secrets\\n    type: Opaque\\n    data:\\n      - objectName: mssql-password\\n        key: mssql-password\\n      - objectName: mssql-connection-catalog\\n        key: mssql-connection-catalog\\n      - objectName: mssql-connection-identity\\n        key: mssql-connection-identity\\nEOF\\n```\\n\\nFinally, lets grant the Azure Managed Identity permissions to retrieve secrets from the Azure Key Vault.\\n\\n```bash\\naz keyvault set-policy \\\\\\n  --name $AKV_NAME \\\\\\n  --secret-permissions get \\\\\\n  --spn $MANAGED_IDENTITY_CLIENT_ID\\n```\\n\\n## Re-package deployments\\n\\nUpdate your database deployment to load environment variables from our ConfigMap, attach the PVC and SecretProviderClass as volumes, mount the volumes into the Pod, and use the ServiceAccount to retrieve secrets.\\n\\nAdditionally, you may notice the database Pod is set to use `fsGroup:10001` as part of the `securityContext`. This is required as the MSSQL container runs using a non-root account called `mssql` and this account has the proper permissions to read/write data at the `/var/opt/mssql` mount path.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: db\\n  labels:\\n    app: db\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: db\\n  template:\\n    metadata:\\n      labels:\\n        app: db\\n    spec:\\n      securityContext:\\n        fsGroup: 10001\\n      serviceAccountName: ${SERVICE_ACCOUNT_NAME}\\n      containers:\\n        - name: db\\n          image: mcr.microsoft.com/mssql/server:2019-latest\\n          ports:\\n            - containerPort: 1433\\n          envFrom:\\n            - configMapRef:\\n                name: mssql-settings\\n          env:\\n            - name: MSSQL_SA_PASSWORD\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-password\\n          resources: {}\\n          volumeMounts:\\n            - name: mssqldb\\n              mountPath: /var/opt/mssql\\n            - name: eshop-secrets\\n              mountPath: \\"/mnt/secrets-store\\"\\n              readOnly: true\\n      volumes:\\n        - name: mssqldb\\n          persistentVolumeClaim:\\n            claimName: mssql-data\\n        - name: eshop-secrets\\n          csi:\\n            driver: secrets-store.csi.k8s.io\\n            readOnly: true\\n            volumeAttributes:\\n              secretProviderClass: eshop-azure-keyvault\\nEOF\\n```\\n\\nWe\'ll update the API and Web deployments in a similar way.\\n\\n```bash\\n# Set the image tag\\nIMAGE_TAG=<YOUR_IMAGE_TAG>\\n\\n# API deployment\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: api\\n  labels:\\n    app: api\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: api\\n  template:\\n    metadata:\\n      labels:\\n        app: api\\n    spec:\\n      serviceAccount: ${SERVICE_ACCOUNT_NAME}\\n      containers:\\n        - name: api\\n          image: ${ACR_NAME}.azurecr.io/api:${IMAGE_TAG}\\n          ports:\\n            - containerPort: 80\\n          envFrom:\\n            - configMapRef:\\n                name: aspnet-settings\\n          env:\\n            - name: ConnectionStrings__CatalogConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-catalog\\n            - name: ConnectionStrings__IdentityConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-identity\\n          resources: {}\\n          volumeMounts:\\n            - name: aspnet\\n              mountPath: ~/.aspnet/https:/root/.aspnet/https:ro\\n            - name: eshop-secrets\\n              mountPath: \\"/mnt/secrets-store\\"\\n              readOnly: true\\n      volumes:\\n        - name: aspnet\\n          persistentVolumeClaim:\\n            claimName: aspnet-data\\n        - name: eshop-secrets\\n          csi:\\n            driver: secrets-store.csi.k8s.io\\n            readOnly: true\\n            volumeAttributes:\\n                secretProviderClass: eshop-azure-keyvault\\nEOF\\n\\n## Web deployment\\nkubectl apply -f - <<EOF\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: web\\n  labels:\\n    app: web\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: web\\n  template:\\n    metadata:\\n      labels:\\n        app: web\\n    spec:\\n      serviceAccount: ${SERVICE_ACCOUNT_NAME}\\n      containers:\\n        - name: web\\n          image: ${ACR_NAME}.azurecr.io/web:${IMAGE_TAG}\\n          ports:\\n            - containerPort: 80\\n          envFrom:\\n            - configMapRef:\\n                name: aspnet-settings\\n          env:\\n            - name: ConnectionStrings__CatalogConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-catalog\\n            - name: ConnectionStrings__IdentityConnection\\n              valueFrom:\\n                secretKeyRef:\\n                  name: eshop-secrets\\n                  key: mssql-connection-identity\\n          resources: {}\\n          volumeMounts:\\n            - name: aspnet\\n              mountPath: ~/.aspnet/https:/root/.aspnet/https:ro\\n            - name: eshop-secrets\\n              mountPath: \\"/mnt/secrets-store\\"\\n              readOnly: true\\n      volumes:\\n        - name: aspnet\\n          persistentVolumeClaim:\\n            claimName: aspnet-data\\n        - name: eshop-secrets\\n          csi:\\n            driver: secrets-store.csi.k8s.io\\n            readOnly: true\\n            volumeAttributes:\\n                secretProviderClass: eshop-azure-keyvault\\nEOF\\n```\\n\\nIf all went well with your deployment updates, you should be able to browse to your website and buy some merchandise again \ud83e\udd73\\n\\n```bash\\necho \\"http://$(kubectl get service web -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\')\\"\\n```\\n\\n## Conclusion\\n\\nAlthough there is no visible changes on with our website, we\'ve made a ton of changes on the Kubernetes backend to make this application much more secure and resilient.\\n\\nWe used a combination of Kubernetes resources and AKS-specific features to achieve our goal of securing our secrets and ensuring data is not lost on container crashes and restarts.\\n\\nTo learn more about the components we leveraged here today, checkout the resources and additional tutorials listed below. \\n\\nYou can also find manifests with all the changes made in today\'s post in the [Azure-Samples/eShopOnAKS](https://github.com/Azure-Samples/eShopOnAKS/tree/week3/day2) repository.\\n\\nSee you in the next post!\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Quickstart: Deploy a SQL Server container with Azure Kubernetes Services (AKS)](https://learn.microsoft.com/sql/linux/quickstart-sql-server-containers-kubernetes?WT.mc_id=containers-84290-pauyu&view=sql-server-ver16)\\n* [Secrets Store CSI Driver](https://secrets-store-csi-driver.sigs.k8s.io/)\\n* [Azure Key Vault Provider for Secrets Store CSI Driver](https://azure.github.io/secrets-store-csi-driver-provider-azure/docs/)\\n* [Azure/azure-workload-identity](https://github.com/Azure/azure-workload-identity)\\n* [Azure AD Workload Identity](https://azure.github.io/azure-workload-identity/docs/introduction.html)\\n* [Tutorial: Use a workload identity with an application on Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/aks/learn/tutorial-kubernetes-workload-identity?WT.mc_id=containers-84290-pauyu)"},{"id":"bring-your-app-day-3","metadata":{"permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-3","source":"@site/blog-cnny/2023-02-08/index.md","title":"3-3. Bringing Your Application to Kubernetes - Opening your Application with Ingress","description":"Expose your web application on Azure Kubernetes Service with ease using the Web Application Routing add-on. Benefit from automatic installation of a NGINX Ingress Controller, integration with Azure DNS for custom domains, and secure TLS with Azure Key Vault. Follow our step-by-step guide to enhance the accessibility and security of your web application.","date":"2023-02-08T00:00:00.000Z","formattedDate":"February 8, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"ingress","permalink":"/Cloud-Native/cnny-2023/tags/ingress"},{"label":"nginx-ingress-controller","permalink":"/Cloud-Native/cnny-2023/tags/nginx-ingress-controller"},{"label":"azure-dns","permalink":"/Cloud-Native/cnny-2023/tags/azure-dns"},{"label":"azure-key-vault","permalink":"/Cloud-Native/cnny-2023/tags/azure-key-vault"}],"readingTime":9.835,"hasTruncateMarker":false,"authors":[{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"}],"frontMatter":{"slug":"bring-your-app-day-3","title":"3-3. Bringing Your Application to Kubernetes - Opening your Application with Ingress","authors":["paul"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","configmaps","persistent-volumes","secrets","azure-files","azure-key-vault","azure-workload-identity","best-practices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-13.png","description":"Expose your web application on Azure Kubernetes Service with ease using the Web Application Routing add-on. Benefit from automatic installation of a NGINX Ingress Controller, integration with Azure DNS for custom domains, and secure TLS with Azure Key Vault. Follow our step-by-step guide to enhance the accessibility and security of your web application.","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","ingress","nginx-ingress-controller","azure-dns","azure-key-vault"]},"unlisted":false,"prevItem":{"title":"3-2. Bringing Your Application to Kubernetes - Adapting Storage, Secrets, and Configuration","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-2"},"nextItem":{"title":"3-4. Bringing Your Application to Kubernetes - Debugging and Instrumentation","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-4"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-3\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"3-3. Bringing Your Application to Kubernetes - Opening your Application with Ingress\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Expose your web application on Azure Kubernetes Service with ease using the Web Application Routing add-on. Benefit from automatic installation of a NGINX Ingress Controller, integration with Azure DNS for custom domains, and secure TLS with Azure Key Vault. Follow our step-by-step guide to enhance the accessibility and security of your web application.\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-13.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@pauldotyu\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-3\\" />\\n</head>\\n\\nWelcome to `Day 3 of Week 3` of #CloudNativeNewYear!\\n\\nThe theme for this week is Bringing Your Application to Kubernetes. Yesterday we added configuration, secrets, and storage to our app. Today we\'ll explore how to expose the eShopOnWeb app so that customers can reach it over the internet using a custom domain name and TLS.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Friday, February 10th at 11 AM PST\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week3-demo).  Join us Friday, February 10th and bring your questions!\\n\\n:::\\n\\n## What We\'ll Cover\\n\\n* Gather requirements\\n* Generate TLS certificate and store in Azure Key Vault\\n* Implement custom DNS using Azure DNS\\n* Enable Web Application Routing add-on for AKS\\n* Implement Ingress for the web application\\n* Conclusion\\n* Resources\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n## Gather requirements\\n\\nCurrently, our eShopOnWeb app has three Kubernetes services deployed:\\n\\n1. `db` exposed internally via `ClusterIP`\\n1. `api` exposed externally via `LoadBalancer`\\n1. `web` exposed externally via `LoadBalancer`\\n\\nAs mentioned in [my post last week](../2023-01-31/index.md), Services allow applications to communicate with each other using DNS names. Kubernetes has service discovery capabilities built-in that allows Pods to resolve Services simply by using their names.\\n\\nIn the case of our `api` and `web` deployments, they can simply reach the database by calling its name. The service type of `ClusterIP` for the `db` can remain as-is since it only needs to be accessed by the `api` and `web` apps.\\n\\nOn the other hand, `api` and `web` both need to be accessed over the public internet. Currently, these services are using service type `LoadBalancer` which tells AKS to provision an Azure Load Balancer with a public IP address. No one is going to remember the IP addresses, so we need to make the app more accessible by adding a custom domain name and securing it with a TLS certificate.\\n\\nHere\'s what we\'re going to need:\\n\\n* Custom domain name for our app\\n* TLS certificate for the custom domain name\\n* Routing rule to ensure requests with `/api/` in the URL is routed to the backend REST API\\n* Routing rule to ensure requests without `/api/` in the URL is routing to the web UI\\n\\nJust like last week, we will use the [Web Application Routing](https://learn.microsoft.com/azure/aks/web-app-routing?WT.mc_id=containers-84290-pauyu&tabs=without-osm) add-on for AKS. But this time, we\'ll integrate it with Azure DNS and Azure Key Vault to satisfy all of our requirements above.\\n\\n:::info\\n\\nAt the time of this writing the add-on is still in Public Preview\\n\\n:::\\n\\n## Generate TLS certificate and store in Azure Key Vault\\n\\nWe deployed an Azure Key Vault [yesterday](../2023-02-07/index.md) to store secrets. We\'ll use it again to store a TLS certificate too.\\n\\nLet\'s create and export a self-signed certificate for the custom domain.\\n\\n```bash\\nDNS_NAME=eshoponweb$RANDOM.com\\nopenssl req -new -x509 -nodes -out web-tls.crt -keyout web-tls.key -subj \\"/CN=${DNS_NAME}\\" -addext \\"subjectAltName=DNS:${DNS_NAME}\\"\\nopenssl pkcs12 -export -in web-tls.crt -inkey web-tls.key -out web-tls.pfx -password pass:\\n```\\n\\n:::info\\n\\nFor learning purposes we\'ll use a self-signed certificate and a fake custom domain name.\\n\\nTo browse to the site using the fake domain, we\'ll mimic a DNS lookup by adding an entry to your host file which maps the public IP address assigned to the ingress controller to the custom domain.\\n\\nIn a production scenario, you will need to have a real domain delegated to Azure DNS and a valid TLS certificate for the domain.\\n\\n:::\\n\\nGrab your Azure Key Vault name and set the value in a variable for later use.\\n\\n```bash\\nRESOURCE_GROUP=cnny-week3\\n\\nAKV_NAME=$(az resource list \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --resource-type Microsoft.KeyVault/vaults \\\\\\n  --query \\"[0].name\\" -o tsv)\\n```\\n\\nGrant yourself permissions to `get`, `list`, and `import` certificates.\\n\\n```bash\\nMY_USER_NAME=$(az account show --query user.name -o tsv)\\nMY_USER_OBJECT_ID=$(az ad user show --id $MY_USER_NAME --query id -o tsv)\\n\\naz keyvault set-policy \\\\\\n  --name $AKV_NAME \\\\\\n  --object-id $MY_USER_OBJECT_ID \\\\\\n  --certificate-permissions get list import\\n```\\n\\nUpload the TLS certificate to Azure Key Vault and grab its certificate URI.\\n\\n```bash\\nWEB_TLS_CERT_ID=$(az keyvault certificate import \\\\\\n  --vault-name $AKV_NAME \\\\\\n  --name web-tls \\\\\\n  --file web-tls.pfx \\\\\\n  --query id \\\\\\n  --output tsv)\\n```\\n\\n## Implement custom DNS with Azure DNS\\n\\nCreate a custom domain for our application and grab its Azure resource id.\\n\\n```bash\\nDNS_ZONE_ID=$(az network dns zone create \\\\\\n  --name $DNS_NAME \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --query id \\\\\\n  --output tsv)\\n```\\n\\n## Enable Web Application Routing add-on for AKS\\n\\nAs we enable the Web Application Routing add-on, we\'ll also pass in the Azure DNS Zone resource id which triggers the installation of the [`external-dns` controller](https://learn.microsoft.com/azure/aks/web-app-routing?WT.mc_id=containers-84290-pauyu&tabs=without-osm#web-application-routing-add-on-overview:~:text=external%2Ddns%20controller%3A%20Watches%20for%20Kubernetes%20Ingress%20resources%20and%20creates%20DNS%20A%20records%20in%20the%20cluster%2Dspecific%20DNS%20zone.%20Note%20that%20this%20is%20only%20deployed%20when%20you%20pass%20in%20the%20%2D%2Ddns%2Dzone%2Dresource%2Did%20argument.) in your Kubernetes cluster. This controller will be able to write Azure DNS zone entries on your behalf as you deploy Ingress manifests.\\n\\n```bash\\nAKS_NAME=$(az resource list \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --resource-type Microsoft.ContainerService/managedClusters \\\\\\n  --query \\"[0].name\\" -o tsv)\\n\\naz aks enable-addons \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --addons web_application_routing \\\\\\n  --dns-zone-resource-id=$DNS_ZONE_ID \\\\\\n  --enable-secret-rotation\\n```\\n\\nThe add-on will also deploy a new Azure Managed Identity which is used by the `external-dns` controller when writing Azure DNS zone entries. Currently, it does not have permission to do that, so let\'s grant it permission.\\n\\n```bash\\n# This is where resources are automatically deployed by AKS\\nNODE_RESOURCE_GROUP=$(az aks show \\\\\\n  --name $AKS_NAME \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --query nodeResourceGroup -o tsv)\\n\\n# This is the managed identity created by the Web Application Routing add-on\\nMANAGED_IDENTTIY_OBJECT_ID=$(az resource show \\\\\\n  --name webapprouting-${AKS_NAME} \\\\\\n  --resource-group $NODE_RESOURCE_GROUP \\\\\\n  --resource-type Microsoft.ManagedIdentity/userAssignedIdentities \\\\\\n  --query properties.principalId \\\\\\n  --output tsv)\\n\\n# Grant the managed identity permissions to write DNS entries\\naz role assignment create \\\\\\n  --role \\"DNS Zone Contributor\\" \\\\\\n  --assignee $MANAGED_IDENTTIY_OBJECT_ID \\\\\\n  --scope $DNS_ZONE_ID\\n```\\n\\nThe Azure Managed Identity will also be used to retrieve and rotate TLS certificates from Azure Key Vault. So we\'ll need to grant it permission for that too.\\n\\n```bash\\naz keyvault set-policy \\\\\\n  --name $AKV_NAME \\\\\\n  --object-id $MANAGED_IDENTTIY_OBJECT_ID \\\\\\n  --secret-permissions get \\\\\\n  --certificate-permissions get\\n```\\n\\n## Implement Ingress for the web application\\n\\nBefore we create a new Ingress manifest, let\'s update the existing services to use `ClusterIP` instead of `LoadBalancer`. With an Ingress in place, there is no reason why we need the Service resources to be accessible from outside the cluster. The new Ingress will be the only entrypoint for external users.\\n\\nWe can use the `kubectl patch` command to update the services\\n\\n```bash\\nkubectl patch service api -p \'{\\"spec\\": {\\"type\\": \\"ClusterIP\\"}}\'\\nkubectl patch service web -p \'{\\"spec\\": {\\"type\\": \\"ClusterIP\\"}}\'\\n```\\n\\nDeploy a new Ingress to place in front of the `web` Service. Notice there is a special `annotations` entry for `kubernetes.azure.com/tls-cert-keyvault-uri` which points back to our self-signed certificate that was uploaded to Azure Key Vault.\\n\\n```bash\\nkubectl apply -f - <<EOF\\napiVersion: networking.k8s.io/v1\\nkind: Ingress\\nmetadata:\\n  annotations:\\n    kubernetes.azure.com/tls-cert-keyvault-uri: ${WEB_TLS_CERT_ID}\\n  name: web\\nspec:\\n  ingressClassName: webapprouting.kubernetes.azure.com\\n  rules:\\n  - host: ${DNS_NAME}\\n    http:\\n      paths:\\n      - backend:\\n          service:\\n            name: web\\n            port:\\n              number: 80\\n        path: /\\n        pathType: Prefix\\n      - backend:\\n          service:\\n            name: api\\n            port:\\n              number: 80\\n        path: /api\\n        pathType: Prefix\\n  tls:\\n  - hosts:\\n    - ${DNS_NAME}\\n    secretName: web-tls\\nEOF\\n```\\n\\nIn our manifest above, we\'ve also configured the Ingress route the traffic to either the `web` or `api` services based on the URL path requested. If the request URL includes `/api`/ then it will send traffic to the `api` backend service. Otherwise, it will send traffic to the `web` service.\\n\\nWithin a few minutes, the `external-dns` controller will add an `A` record to Azure DNS which points to the Ingress resource\'s public IP. With the custom domain in place, we can simply browse using this domain name.\\n\\n:::info\\n\\nAs mentioned above, since this is not a real domain name, we need to modify our host file to make it seem like our custom domain is resolving to the Ingress\' public IP address.\\n\\nTo get the ingress public IP, run the following:\\n\\n```bash\\n# Get the IP\\nkubectl get ingress web -o jsonpath=\\"{.status.loadBalancer.ingress[0].ip}\\"\\n\\n# Get the hostname\\nkubectl get ingress web -o jsonpath=\\"{.spec.tls[0].hosts[0]}\\"\\n```\\n\\nNext, open your host file and add an entry using the format `<YOUR_PUBLIC_IP> <YOUR_CUSTOM_DOMAIN>`. Below is an example of what it should look like.\\n\\n```text\\n20.237.116.224 eshoponweb11265.com\\n```\\n\\nSee this [doc](https://linuxize.com/post/how-to-edit-your-hosts-file/) for more info on how to do this.\\n\\n:::\\n\\nWhen browsing to the website, you may be presented with a warning about the connection not being private. This is due to the fact that we are using a self-signed certificate. This is expected, so go ahead and proceed anyway to load up the page.\\n\\n### Why is the Admin page broken?\\n\\nIf you log in using the `admin@microsoft.com` account and browse to the **Admin** page, you\'ll notice no products are loaded on the page.\\n\\nThis is because the admin page is built using Blazor and compiled as a WebAssembly application that runs in your browser. When the application was compiled, it packed the `appsettings.Development.json` file as an embedded resource. This file contains the base URL for the public API and it currently points to `https://localhost:5099`. Now that we have a domain name, we can update the base URL and point it to our custom domain.\\n\\nFrom the root of the `eShopOnWeb` repo, update the configuration file using a [`sed` command](https://www.geeksforgeeks.org/sed-command-in-linux-unix-with-examples/).\\n\\n```bash\\nsed -i -e \\"s/localhost:5099/${DNS_NAME}/g\\" ./src/BlazorAdmin/wwwroot/appsettings.Development.json\\n```\\n\\nRebuild and push the container to Azure Container Registry.\\n\\n```bash\\n# Grab the name of your Azure Container Registry\\nACR_NAME=$(az resource list \\\\\\n  --resource-group $RESOURCE_GROUP \\\\\\n  --resource-type Microsoft.ContainerRegistry/registries \\\\\\n  --query \\"[0].name\\" -o tsv)\\n\\n# Invoke a build and publish job\\naz acr build \\\\\\n  --registry $ACR_NAME \\\\\\n  --image $ACR_NAME.azurecr.io/web:v0.1.0 \\\\\\n  --file ./src/Web/Dockerfile .\\n```\\n\\nOnce the container build has completed, we can issue a `kubectl patch` command to quickly update the `web` deployment to test our change.\\n\\n```bash\\nkubectl patch deployment web -p \\"$(cat <<EOF\\n{\\n  \\"spec\\": {\\n    \\"template\\": {\\n      \\"spec\\": {\\n        \\"containers\\": [\\n          {\\n            \\"name\\": \\"web\\",\\n            \\"image\\": \\"${ACR_NAME}.azurecr.io/web:v0.1.0\\"\\n          }\\n        ]\\n      }\\n    }\\n  }\\n}\\nEOF\\n)\\"\\n```\\n\\nIf all went well, you will be able to browse the admin page again and confirm product data is being loaded \ud83e\udd73\\n\\n## Conclusion\\n\\nThe Web Application Routing add-on for AKS aims to streamline the process of exposing it to the public using the open-source [NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/). With the add-on being managed by Azure, it natively integrates with other Azure services like Azure DNS and eliminates the need to manually create DNS entries. It can also integrate with Azure Key Vault to automatically pull in TLS certificates and rotate them as needed to further reduce operational overhead.\\n\\nWe are one step closer to production and in the upcoming posts we\'ll further operationalize and secure our deployment, so stay tuned!\\n\\nIn the meantime, check out the resources listed below for further reading.\\n\\nYou can also find manifests with all the changes made in today\'s post in the [Azure-Samples/eShopOnAKS](https://github.com/Azure-Samples/eShopOnAKS/tree/week3/day3) repository.\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Web Application Routing (Preview)](https://learn.microsoft.com/azure/aks/web-app-routing?WT.mc_id=containers-84290-pauyu&tabs=without-osm)\\n* [Web Application Routing on AKS](https://dev.to/azure/web-application-routing-on-aks-58ap)\\n* [Lab: Web Application Routing with AKS](https://aka.ms/aks-webapp-routing-lab)\\n* [NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/)\\n* [What is Azure DNS?](https://learn.microsoft.com/azure/dns/dns-overview?WT.mc_id=containers-84290-pauyu)"},{"id":"bring-your-app-day-4","metadata":{"permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-4","source":"@site/blog-cnny/2023-02-09/index.md","title":"3-4. Bringing Your Application to Kubernetes - Debugging and Instrumentation","description":"Using Bridge to Kubernetes to debug your application.","date":"2023-02-09T00:00:00.000Z","formattedDate":"February 9, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":8.955,"hasTruncateMarker":false,"authors":[{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"}],"frontMatter":{"slug":"bring-your-app-day-4","title":"3-4. Bringing Your Application to Kubernetes - Debugging and Instrumentation","authors":["steven"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["pods","deployments","kubernetes","aks","container-apps","cloud-native","github-actions","ci-cd"],"image":"https://azure.github.io/Cloud-Native/img/og/30-14.png","description":"Using Bridge to Kubernetes to debug your application.","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"3-3. Bringing Your Application to Kubernetes - Opening your Application with Ingress","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-3"},"nextItem":{"title":"3-5. Bringing Your Application to Kubernetes - CI/CD Secure Supply Chain","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-5"}},"content":"<head>\\n  <meta name=\\"twitter:url\\"\\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-4\\" />\\n  <meta name=\\"twitter:title\\"\\n    content=\\"3-4. Bringing Your Application to Kubernetes - Debugging and Instrumentation\\" />\\n  <meta name=\\"twitter:description\\"\\n    content=\\"Using Bridge to Kubernetes to debug your application.\\" />\\n  <meta name=\\"twitter:image\\"\\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-14.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\"\\n    content=\\"@stevenmurawski\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" />\\n  <link rel=\\"canonical\\"\\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-4\\" />\\n</head>\\n\\nWelcome to `Day 4 of Week 3` of #CloudNativeNewYear!\\n\\nThe theme for this week is Bringing Your Application to Kubernetes. Yesterday we exposed the eShopOnWeb app so that customers can reach it over the internet using a custom domain name and TLS. Today we\'ll explore the topic of debugging and instrumentation.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Friday, February 10th at 11 AM PST\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week3-demo).  Join us Friday, February 10th and bring your questions!\\n\\n:::\\n\\n## What We\'ll Cover\\n * Debugging\\n * Bridge To Kubernetes\\n * Instrumentation\\n * Resources: For self-study!\\n\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n## Debugging\\n\\nDebugging applications in a Kubernetes cluster can be challenging for several reasons:\\n\\n* **Complexity:** Kubernetes is a complex system with many moving parts, including pods, nodes, services, and config maps, all of which can interact in unexpected ways and cause issues.\\n* **Distributed Environment:** Applications running in a Kubernetes cluster are often distributed across multiple nodes, which makes it harder to determine the root cause of an issue.\\n* **Logging and Monitoring:** Debugging an application in a Kubernetes cluster requires access to logs and performance metrics, which can be difficult to obtain in a large and dynamic environment.\\n* **Resource Management:** Kubernetes manages resources such as CPU and memory, which can impact the performance and behavior of applications. Debugging resource-related issues requires a deep understanding of the Kubernetes resource model and the underlying infrastructure.\\n* **Dynamic Nature:** Kubernetes is designed to be dynamic, with the ability to add and remove resources as needed. This dynamic nature can make it difficult to reproduce issues and debug problems.\\n\\nHowever, there are many tools and practices that can help make debugging applications in a Kubernetes cluster easier, such as using centralized logging, monitoring, and tracing solutions, and following best practices for managing resources and deployment configurations.\\n\\nThere\'s also another great tool in our toolbox - [Bridge to Kubernetes](https://learn.microsoft.com/visualstudio/bridge/overview-bridge-to-kubernetes?WT.mc_id=containers-84290-stmuraws).\\n\\n## Bridge to Kubernetes\\n\\nBridge to Kubernetes is a great tool for microservice development and debugging applications without having to locally replicate all the required microservices.\\n\\nBridge to Kubernetes works with [Visual Studio](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.mindaro&WT.mc_id=containers-84290-stmuraws) or [Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=mindaro.mindaro&WT.mc_id=containers-84290-stmuraws).\\n\\nWe\'ll walk through using it with Visual Studio Code.\\n\\n### Connecting Bridge to Kubernetes to Our Cluster\\n\\n#### Ensure your AKS cluster is the default for `kubectl`\\n\\nIf you\'ve recently spun up a new AKS cluster or you have been working with a different cluster, you may need to change what cluster credentials you have configured.\\n\\nIf it\'s a new cluster, we can use:\\n\\n```shell\\nRESOURCE_GROUP=<YOUR RESOURCE GROUP NAME>\\nCLUSTER_NAME=<YOUR AKS CLUSTER NAME>\\naz aks get-credentials az aks get-credentials --resource-group $RESOURCE_GROUP --name $CLUSTER_NAME\\n```\\n\\n#### Open the command palette \\n\\nOpen the command palette and find `Bridge to Kubernetes: Configure`.  You may need to start typing the name to get it to show up.\\n\\n![The command palette for Visual Studio Code is open and the first item is Bridge to Kubernetes: Configure](../../static/img/cnny23/1-configure-bridge-to-kubernetes.png)\\n\\n#### Pick the service you want to debug\\n\\nBridge to Kubernetes will redirect a service for you.  Pick the service you want to redirect, in this case we\'ll pick `web`.\\n\\n![Selecting the `web` service to redirect in Visual Studio Code](../../static/img/cnny23/2-configure-bridge-to-kubernetes.png)\\n\\n#### Identify the port your application runs on\\n\\nNext, we\'ll be prompted to identify what port our application will run on locally.  For this application it\'ll be 5001, but that\'s just specific to this application (and the default for ASP.NET 7, I believe).\\n\\n![Setting port 5001 as the port to redirect to the `web` Kubernetes service in Visual Studio Code](../../static/img/cnny23/3-configure-bridge-to-kubernetes.png)\\n\\n#### Pick a debug configuration to extend\\n\\nBridge to Kubernetes has a couple of ways to run - it can inject it\'s setup and teardown to your existing debug configurations.  We\'ll pick `.NET Core Launch (web)`.\\n\\n![Telling Bridge to Kubernetes to use the .NET Core Launch (web) debug configuration in Visual Studio Code](../../static/img/cnny23/4-configure-bridge-to-kubernetes.png)\\n\\n#### Forward Traffic for All Requests\\n\\nThe last prompt you\'ll get in the configuration is about how you want Bridge to Kubernetes to handle re-routing traffic.  The default is that all requests into the service will get your local version.  \\n\\nYou can also redirect specific traffic.  Bridge to Kubernetes will set up a subdomain and route specific traffic to your local service, while allowing other traffic to the deployed service.\\n\\n![Allowing the launch of Endpoint Manager on Windows](../../static/img/cnny23/5-configure-bridge-to-kubernetes.png)\\n\\n### Using Bridge to Kubernetes to Debug Our Service\\n\\nNow that we\'ve configured Bridge to Kubernetes, we see that tasks and a new launch configuration have been added.\\n\\nAdded to `.vscode/tasks.json`:\\n\\n```yml\\n        {\\n            \\"label\\": \\"bridge-to-kubernetes.resource\\",\\n            \\"type\\": \\"bridge-to-kubernetes.resource\\",\\n            \\"resource\\": \\"web\\",\\n            \\"resourceType\\": \\"service\\",\\n            \\"ports\\": [\\n                5001\\n            ],\\n            \\"targetCluster\\": \\"aks1\\",\\n            \\"targetNamespace\\": \\"default\\",\\n            \\"useKubernetesServiceEnvironmentVariables\\": false\\n        },\\n        {\\n            \\"label\\": \\"bridge-to-kubernetes.compound\\",\\n            \\"dependsOn\\": [\\n                \\"bridge-to-kubernetes.resource\\",\\n                \\"build\\"\\n            ],\\n            \\"dependsOrder\\": \\"sequence\\"\\n        }\\n```\\n\\nAnd added to `.vscode/launch.json`:\\n\\n```yml\\n{\\n        \\"name\\": \\".NET Core Launch (web) with Kubernetes\\",\\n        \\"type\\": \\"coreclr\\",\\n        \\"request\\": \\"launch\\",\\n        \\"preLaunchTask\\": \\"bridge-to-kubernetes.compound\\",\\n        \\"program\\": \\"${workspaceFolder}/src/Web/bin/Debug/net7.0/Web.dll\\",\\n        \\"args\\": [],\\n        \\"cwd\\": \\"${workspaceFolder}/src/Web\\",\\n        \\"stopAtEntry\\": false,\\n        \\"env\\": {\\n            \\"ASPNETCORE_ENVIRONMENT\\": \\"Development\\",\\n            \\"ASPNETCORE_URLS\\": \\"http://+:5001\\"\\n        },\\n        \\"sourceFileMap\\": {\\n            \\"/Views\\": \\"${workspaceFolder}/Views\\"\\n        }\\n    }\\n```\\n\\n#### Launch the debug configuration\\n\\nWe can start the process with the `.NET Core Launch (web) with Kubernetes` launch configuration in the `Debug` pane in Visual Studio Code.\\n\\n![Launch the `.NET Core Launch (web) with Kubernetes` from the Debug pane in Visual Studio Code](../../static/img/cnny23/1-debug-with-bridge-to-kubernetes.png)\\n\\n\\n#### Enable the Endpoint Manager\\n\\nPart of this process includes a local service to help manage the traffic routing and your hosts file.  This will require admin or `sudo` privileges.  On Windows, you\'ll get a prompt like:\\n\\n![Prompt to launch the endpoint manager.](../../static/img/cnny23/2-debug-with-bridge-to-kubernetes.png)\\n\\n#### Access your Kubernetes cluster \\"locally\\"\\n\\nBridge to Kubernetes will set up a tunnel (thanks to port forwarding) to your local workstation and create local endpoints for the other Kubernetes hosted services in your cluster, as well as pretending to be a pod in that cluster (for the application you are debugging).\\n\\n![Output from Bridge To Kubernetes setup task.](../../static/img/cnny23/3-debug-with-bridge-to-kubernetes.png)\\n\\nAfter making the connection to your Kubernetes cluster, the launch configuration will continue. In this case, we\'ll make a debug build of the application and attach the debugger.  (This process may cause the terminal in VS Code to scroll with build output. You can find the Bridge to Kubernetes output with the local IP addresses and ports in the Output pane for Bridge to Kubernetes.)\\n\\nYou can set breakpoints, use your debug console, set watches, run tests against your local version of the service.\\n\\n#### Exploring the Running Application Environment\\n\\nOne of the cool things that Bridge to Kubernetes does for our debugging experience is bring the environment configuration that our deployed pod would inherit.  When we launch our app, it\'ll see configuration and secrets that we\'d expect our pod to be running with.  \\n\\nTo test this, we\'ll set a breakpoint in our application\'s start up to see what SQL Server is being used.  We\'ll set a breakpoint at `src/Infrastructure/Dependencies.cs` on line 32.\\n\\nThen, we will start debugging the application with Bridge to Kubernetes.  When it hits the breakpoint, we\'ll open the Debug pane and type `configuration.GetConnectionString(\\"CatalogConnection\\")`.\\n\\nWhen we run locally (not with Bridge to Kubernetes), we\'d see:\\n\\n```\\nconfiguration.GetConnectionString(\\"CatalogConnection\\")\\n \\"Server=(localdb)\\\\\\\\mssqllocaldb;Integrated Security=true;Initial Catalog=Microsoft.eShopOnWeb.CatalogDb;\\"\\n```\\n\\nBut, with Bridge to Kubernetes we see something more like (yours will vary based on the password ):\\n\\n```\\nconfiguration.GetConnectionString(\\"CatalogConnection\\")\\n \\"Server=db;Database=Microsoft.eShopOnWeb.CatalogDb;User Id=sa;Password=*****************;TrustServerCertificate=True;\\"\\n```\\n\\n![Debugging our local application connected to Kubernetes.](../../static/img/cnny23/5-debug-with-bridge-to-kubernetes.png)\\n\\nWe can see that the database server configured is based on our `db` service and the password is pulled from our secret in Azure KeyVault (via AKS).\\n\\nThis helps us run our local application just like it was actually in our cluster.\\n\\n### Going Further\\n\\nBridge to Kubernetes also supports more advanced scenarios and, as you need to start routing traffic around inside your cluster, may require you to modify your application to pass along a `kubernetes-route-as` header to help ensure that traffic for your debugging workloads is properly handled.  The docs go into much greater detail about that.\\n\\n## Instrumentation\\n\\nNow that we\'ve figured out our debugging story, we\'ll need to ensure that we have the right context clues to find where we need to debug or to give us a better idea of how well our microservices are running.\\n\\n### Logging and Tracing\\n\\nLogging and tracing become even more critical in Kubernetes, where your application could be running in a number of pods across different nodes. When you have an issue, in addition to the normal application data, you\'ll want to know what pod and what node had the issue, what the state of those resources were (were you resource constrained or were shared resources unavailable?), and if autoscaling is enabled, you\'ll want to know if a scale event has been triggered. There are a multitude of other concerns based on your application and the environment you maintain.\\n\\nGiven these informational needs, it\'s crucial to revisit your existing logging and instrumentation. Most frameworks and languages have extensible logging, tracing, and instrumentation libraries that you can iteratively add information to, such as pod and node states, and ensuring that requests can be traced across your microservices. This will pay you back time and time again when you have to troubleshoot issues in your existing environment.\\n\\n### Centralized Logging\\n\\nTo enhance the troubleshooting process further, it\'s important to implement centralized logging to consolidate logs from all your microservices into a single location. This makes it easier to search and analyze logs when you\'re troubleshooting an issue. \\n\\n### Automated Alerting\\n\\nAdditionally, implementing automated alerting, such as sending notifications when specific conditions occur in the logs, can help you detect issues before they escalate.\\n\\n### End to end Visibility\\n\\nEnd-to-end visibility is also essential in understanding the flow of requests and responses between microservices in a distributed system. With end-to-end visibility, you can quickly identify bottlenecks and slowdowns in the system, helping you to resolve issues more efficiently.\\n\\n## Resources\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::\\n\\n* [Use Bridge to Kubernetes in VS Code](https://learn.microsoft.com/visualstudio/bridge/bridge-to-kubernetes-vs-code?WT.mc_id=containers-84290-stmuraws)\\n* [Bridge to Kubernetes Visual Studio Extension](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.mindaro&WT.mc_id=containers-84290-stmuraws) \\n* [Bridge to Kubernetes Visual Studio Code Extension](https://marketplace.visualstudio.com/items?itemName=mindaro.mindaro&WT.mc_id=containers-84290-stmuraws).\\n\\n* [Kubernetes monitoring and logging](https://learn.microsoft.com/azure/architecture/aws-professional/eks-to-aks/monitoring?WT.mc_id=containers-84290-stmuraws)\\n* [Monitor a microservices architecture in Azure Kubernetes Service (AKS)](https://learn.microsoft.com/azure/architecture/microservices/logging-monitoring?WT.mc_id=containers-84290-stmuraws)"},{"id":"bring-your-app-day-5","metadata":{"permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-5","source":"@site/blog-cnny/2023-02-10/index.md","title":"3-5. Bringing Your Application to Kubernetes - CI/CD Secure Supply Chain","description":"In this article, you\'ll learn how to use Notary, an open-source project hosted by the Cloud Native Computing Foundation (CNCF) to digitally sign container images stored on Azure Container Registry.","date":"2023-02-10T00:00:00.000Z","formattedDate":"February 10, 2023","tags":[{"label":"cloud-native-new-year","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native-new-year"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"aks","permalink":"/Cloud-Native/cnny-2023/tags/aks"},{"label":"kubernetes","permalink":"/Cloud-Native/cnny-2023/tags/kubernetes"},{"label":"secure-supply-chain","permalink":"/Cloud-Native/cnny-2023/tags/secure-supply-chain"},{"label":"notary","permalink":"/Cloud-Native/cnny-2023/tags/notary"},{"label":"notation","permalink":"/Cloud-Native/cnny-2023/tags/notation"},{"label":"azure-key-vault","permalink":"/Cloud-Native/cnny-2023/tags/azure-key-vault"}],"readingTime":5.735,"hasTruncateMarker":false,"authors":[{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"}],"frontMatter":{"slug":"bring-your-app-day-5","title":"3-5. Bringing Your Application to Kubernetes - CI/CD Secure Supply Chain","authors":["josh"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloudnative","azure","kubernetes","azure-key-vault","github-actions","secure-supply-chain","notary","notation"],"image":"https://azure.github.io/Cloud-Native/img/og/30-15.png","description":"In this article, you\'ll learn how to use Notary, an open-source project hosted by the Cloud Native Computing Foundation (CNCF) to digitally sign container images stored on Azure Container Registry.","tags":["cloud-native-new-year","azure-kubernetes-service","aks","kubernetes","secure-supply-chain","notary","notation","azure-key-vault"]},"unlisted":false,"prevItem":{"title":"3-4. Bringing Your Application to Kubernetes - Debugging and Instrumentation","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-4"},"nextItem":{"title":"4-1. Serverless Container Options","permalink":"/Cloud-Native/cnny-2023/serverless-containers"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-5\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"3-5. Bringing Your Application to Kubernetes - CI/CD Secure Supply Chain\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"In this article, you\'ll learn how to use Notary, an open-source project hosted by the Cloud Native Computing Foundation (CNCF) to digitally sign container images stored on Azure Container Registry.\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-15.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@joshduffney\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-5\\" />\\n</head>\\n\\nWelcome to `Day 5 of Week 3` of #CloudNativeNewYear!\\n\\nThe theme for this week is Bringing Your Application to Kubernetes. Yesterday we talked about debugging and instrumenting our application. Today we\'ll explore the topic of container image signing and secure supply chain.\\n\\n:::tip Ask the Experts Thursday, February 9th at 9 AM PST\\n\\n[Watch our Q&A with Experts from the Azure Kubernetes Service product team!](https://aka.ms/cnny/watch-ate)\\n\\n:::\\n\\n:::tip Friday, February 10th at 11 AM PST\\n\\nWatch the recorded demo and conversation about this week\'s topics\\\\.\\n\\n[We were live on YouTube walking through today\'s (and the rest of this week\'s) demos](https://aka.ms/cnny/week3-demo).  Join us Friday, February 10th and bring your questions!\\n\\n:::\\n\\n## What We\'ll Cover\\n * Introduction\\n * Prerequisites\\n * Create a digital signing certificate\\n * Generate an Azure Container Registry Token\\n * Set up Notation\\n * Install the Notation Azure Key Vault Plugin\\n * Add the signing Certificate to Notation\\n * Sign Container Images\\n * Conclusion\\n\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n## Introduction\\n\\nThe secure supply chain is a crucial aspect of software development, delivery, and deployment, and digital signing plays a critical role in this process. \\n\\nBy using digital signatures to verify the authenticity and integrity of container images, organizations can improve the security of your software supply chain and reduce the risk of security breaches and data compromise.\\n\\nIn this article, you\'ll learn how to use Notary, an open-source project hosted by the Cloud Native Computing Foundation (CNCF) to digitally sign container images stored on Azure Container Registry.\\n\\n## Prerequisites\\n\\nTo follow along, you\'ll need an instance of:\\n- [Azure Container Registry](https://learn.microsoft.com/azure/container-registry/)\\n- [Azure Key Vault](https://learn.microsoft.com/azure/key-vault/)\\n\\n\\n## Create a digital signing certificate\\n\\nA digital signing certificate is a certificate that is used to digitally sign and verify the authenticity and integrity of digital artifacts. Such documents, software, and of course container images.  \\n\\nBefore you can implement digital signatures, you must first create a digital signing certificate. \\n\\nRun the following command to generate the certificate:\\n\\n1. Create the policy file\\n\\n    ```bash\\n    cat <<EOF > ./my_policy.json\\n    {\\n        \\"issuerParameters\\": {\\n            \\"certificateTransparency\\": null,\\n            \\"name\\": \\"Self\\"\\n        },\\n        \\"x509CertificateProperties\\": {\\n            \\"ekus\\": [\\n                \\"1.3.6.1.5.5.7.3.3\\"\\n            ],\\n            \\"key_usage\\": [\\n                \\"digitalSignature\\"\\n            ],\\n            \\"subject\\": \\"CN=${keySubjectName}\\",\\n            \\"validityInMonths\\": 12\\n        }\\n    }\\n    EOF\\n    ```\\n\\n    The _ekus_ and _key usage_ of this certificate policy dictate that the certificate can only be used for digital signatures.\\n\\n2. Create the certificate in Azure Key Vault\\n\\n    ```bash\\n    az keyvault certificate create --name $keyName --vault-name $keyVaultName --policy @my_policy.json\\n    ```\\n\\n    Replace `$keyName` and `$keyVaultName` with your desired certificate name and Azure Key Vault instance name.\\n\\n## Generate a Azure Container Registry token\\n\\nAzure Container Registry tokens are used to grant access to the contents of the registry. Tokens can be used for a variety of things such as pulling images, pushing images, or managing the registry.\\n\\nAs part of the container image signing workflow, you\'ll need a token to authenticate the Notation CLI with your Azure Container Registry.\\n\\nRun the following command to generate an ACR token:\\n\\n```bash\\naz acr token create \\\\\\n  --name $tokenName \\\\\\n  --registry $registry \\\\\\n  --scope-map _repositories_admin \\\\\\n  --query \'credentials.passwords[0].value\' \\\\\\n  --only-show-errors \\\\\\n  --output tsv\\n```\\n\\nReplace `$tokenName` with your name for the ACR token and `$registry` with the name of your ACR instance.\\n\\n## Setup Notation\\n\\nNotation is the command-line interface for the CNCF Notary project. You\'ll use it to digitally sign the _api_ and _web_ container images for the eShopOnWeb application.\\n\\nRun the following commands to download and install the NotationCli:\\n\\n1. Open a terminal or command prompt window\\n2. Download the Notary notation release\\n\\n    ```bash\\n    curl -Lo notation.tar.gz https://github.com/notaryproject/notation/releases/download/v1.0.0-rc.1/notation_1.0.0-rc.1_linux_amd64.tar.gz > /dev/null 2>&1\\n    ```\\n\\n    If you\'re not using Linux, you can find the releases [here](https://github.com/notaryproject/notation/releases).\\n\\n3. Extract the contents of the `notation.tar.gz`\\n    \\n    ```bash\\n    tar xvzf notation.tar.gz > /dev/null 2>&1\\n    ```\\n\\n4. Copy the notation binary to the $HOME/bin directory\\n\\n    ```bash\\n    cp ./notation $HOME/bin\\n    ```\\n\\n5. Add the $HOME/bin directory to the PATH environment variable\\n\\n    ```bash\\n    export PATH=\\"$HOME/bin:$PATH\\"\\n    ```\\n\\n6. Remove the downloaded files\\n\\n    ```bash\\n    rm notation.tar.gz LICENSE\\n    ```\\n\\n7. Check the notation version\\n\\n    ```bash\\n    notation --version\\n    ```\\n\\n## Install the Notation Azure Key Vault plugin\\n\\nBy design the NotationCli supports plugins that extend its digital signing capabilities to remote registries. And in order to sign your container images stored in Azure Container Registry, you\'ll need to install the Azure Key Vault plugin for Notation.\\n\\nRun the following commands to install the `azure-kv` plugin:\\n\\n1. Download the plugin\\n\\n    ```bash\\n    curl -Lo notation-azure-kv.tar.gz \\\\\\n        https://github.com/Azure/notation-azure-kv/releases/download/v0.5.0-rc.1/notation-azure-kv_0.5.0-rc.1_linux_amd64.tar.gz > /dev/null 2>&1\\n    ```\\n\\n    Non-Linux releases can be found [here](https://github.com/Azure/notation-azure-kv/releases/).\\n\\n2. Extract to the plugin directory & delete download files\\n\\n    ```bash\\n    tar xvzf notation-azure-kv.tar.gz -C ~/.config/notation/plugins/azure-kv notation-azure-kv > /dev/null 2>&\\n\\n    rm -rf notation-azure-kv.tar.gz\\n    ```\\n\\n3. Verify the plugin was installed \\n\\n    ```bash\\n    notation plugin ls\\n    ```\\n\\n## Add the signing certificate to Notation\\n\\nNow that you have Notation and the Azure Key Vault plugin installed, add the certificate\'s keyId created above to Notation. \\n\\n1. Get the Certificate Key ID from Azure Key Vault\\n\\n    ```bash\\n    az keyvault certificate show \\\\\\n      --vault-name $keyVaultName \\\\\\n      --name $keyName \\\\\\n      --query \\"kid\\" --only-show-errors --output tsv\\n    ```\\n      \\n   Replace `$keyVaultName` and `$keyName` with the appropriate information.\\n\\n2. Add the Key ID to KMS using Notation\\n\\n    ```bash\\n    notation key add --plugin azure-kv --id $keyID $keyName\\n    ```\\n\\n3. Check the key list\\n\\n    ```bash\\n    notation key ls\\n    ```\\n\\n## Sign Container Images\\n\\nAt this point, all that\'s left is to sign the container images.\\n\\nRun the `notation sign` command to sign the api and web container images:\\n\\n```bash\\nnotation sign $registry.azurecr.io/web:$tag \\\\\\n  --username $tokenName \\\\\\n  --password $tokenPassword\\n\\nnotation sign $registry.azurecr.io/api:$tag \\\\\\n  --username $tokenName \\\\\\n  --password $tokenPassword\\n```\\n\\nReplace `$registry`, `$tag`, `$tokenName`, and `$tokenPassword` with the appropriate values. To improve security, use a SHA hash for the tag.\\n\\n> *NOTE*: If you didn\'t take note of the token password, you can rerun the `az acr token create` command to generate a new password.\\n\\n## Conclusion\\n\\nDigital signing plays a critical role in ensuring the security of software supply chains. \\n\\nBy signing software components, organizations can verify the authenticity and integrity of software, helping to prevent unauthorized modifications, tampering, and malware. \\n\\nAnd if you want to take digital signing to a whole new level by using them to prevent the deployment of unsigned container images, check out the [Ratify](https://github.com/deislabs/ratify) project on GitHub!\\n\\n:::tip Take the Cloud Skills Challenge!\\n\\n[Enroll](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356) in the Cloud Skills Challenge! \\n\\nDon\'t miss out on this opportunity to level up your skills and stay ahead of the curve in the world of cloud native. \\n:::"},{"id":"serverless-containers","metadata":{"permalink":"/Cloud-Native/cnny-2023/serverless-containers","source":"@site/blog-cnny/2023-02-13/30days.md","title":"4-1. Serverless Container Options","description":"Explore serverless container options for development - including managed options like AKS and ACA","date":"2023-02-13T00:00:00.000Z","formattedDate":"February 13, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":6.82,"hasTruncateMarker":false,"authors":[{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"}],"frontMatter":{"slug":"serverless-containers","title":"4-1. Serverless Container Options","authors":["nitya"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["serverless","containers","decision-tree","aks","kubernetes","container-apps"],"image":"https://azure.github.io/Cloud-Native/img/og/30-16.png","description":"Explore serverless container options for development - including managed options like AKS and ACA","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"3-5. Bringing Your Application to Kubernetes - CI/CD Secure Supply Chain","permalink":"/Cloud-Native/cnny-2023/bring-your-app-day-5"},"nextItem":{"title":"4-2. Jumpstart your applications with Draft","permalink":"/Cloud-Native/cnny-2023/building-with-draft"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/serverless-containers\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Serverless Container Options For Azure\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Explore serverless container options for development - including managed options like AKS and ACA\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-16.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@nitya\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@nitya\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/serverless-containers\\" />\\n</head>\\n\\nWelcome to `Week 4` of #CloudNativeNewYear!\\n\\nThis week we\'ll _go further with Cloud-native_ by exploring advanced topics and best practices for the Cloud-native practitioner. We\'ll start with an exploration of _Serverless Container Options_  - ranging from managed services to Azure Kubernetes Service (AKS) and Azure Container Apps (ACA), to options that allow more granular control!\\n\\n## What We\'ll Cover\\n * The Azure Compute Landscape\\n * Serverless Compute on Azure\\n * Comparing Container Options On Azure\\n * Other Considerations\\n * Exercise: Try this yourself!\\n * Resources: For self-study!\\n\\n![](./../../static/img/og/30-16.png)\\n\\n---\\n\\nWe started this series with an introduction to core concepts:\\n * In [Containers 101](/cnny-2023/containers-101), we learned **why containerization matters**. Think portability, isolation, scalability, resource-efficiency and cost-effectiveness. _But not all apps can be containerized._\\n * In [Kubernetes 101](/cnny-2023/Kubernetes-101), we learned **how orchestration works**. Think systems to automate container deployment, scaling, and management. _But using Kubernetes directly can be complex_.\\n * In [Exploring Cloud Native Options](/cnny-2023/explore-options) we asked the real questions: **can we containerize - and should we?**. The first depends on app characteristics, the second on your requirements.\\n \\nFor example: \\n * _Can we containerize?_ The answer might be no if your app has system or OS dependencies, requires access to low-level hardware, or maintains complex state across sessions.\\n * _Should we containerize?_ The answer might be yes if your app is microservices-based, is stateless by default, requires portability, or is a legaacy app that can benefit from container isolation.\\n\\nAs with every technology adoption decision process, there are no clear yes/no answers - just _tradeoffs_ that you need to evaluate based on your **architecture** and **application requirements**. In today\'s post, we try to look at this from two main perspectives:\\n 1. _Should you go serverless?_ Think: managed services that let you focus on app, not infra.\\n 2. _What Azure Compute should I use?_ Think: best fit for my architecture & technology choices.\\n\\n\\n## Azure Compute Landscape\\n\\nLet\'s answer the second question first by exploring all [**available compute options on Azure**](https://learn.microsoft.com/azure/architecture/guide/technology-choices/compute-decision-tree?WT.mc_id=javascript-84290-ninarasi). The illustrated decision-flow below is my favorite ways to navigate the choices, with questions like:\\n * Are you migrating an existing app or building a new one?\\n * Can you app be containerized?\\n * Does it use a specific technology (Spring Boot, Red Hat Openshift)?\\n * Do you need access to the Kubernetes API?\\n * What characterizes the workload? (event-driven, web app, microservices etc.)\\n\\nRead the docs to understand how your choices can be influenced by the _hosting model_ (IaaS, PaaS, FaaS), supported _features_ (Networking, DevOps, Scalability, Availability, Security), _architectural styles_ (Microservices, Event-driven, High-Performance Compute, Task Automation,Web-Queue Worker) etc. \\n\\n![Compute Choices](https://learn.microsoft.com/azure/architecture/guide/technology-choices/images/compute-choices.png)\\n\\nNow that we know _all_ available compute options, let\'s address the second question: _why go serverless?_ and what are my serverless compute options on Azure?\\n\\n## Azure Serverless Compute\\n\\nServerless gets defined many ways, but from a compute perspective, we can focus on a few key characteristics that are key to influencing this decision:\\n\\n * **managed services** - focus on application, let cloud provider handle infrastructure.\\n * **pay for what you use** - get cost-effective resource utilization, flexible pricing options.\\n * **autoscaling on demand** - take advantage of built-in features like KEDA-compliant triggers.\\n * **use preferred languages** - write code in Java, JS, C#, Python etc. (specifics based on service)\\n * **cloud-native architectures** - can support event-driven solutions, APIs, Microservices, DevOps!\\n\\nSo what are some of the key options for [**Serverless Compute on Azure**](https://azure.microsoft.com/solutions/serverless/#solutions?WT.mc_id=javascript-84290-ninarasi)? The article dives into serverless support for _fully-managed end-to-end serverless solutions_ with comprehensive support for DevOps, DevTools, AI/ML, Database, Storage, Monitoring and Analytics integrations. But we\'ll just focus on the **4 categories of applications** when we look at Compute!\\n\\n 1. **Serverless Containerized Microservices** _using [Azure Container Apps](https://azure.microsoft.com/en-us/services/container-apps/?WT.mc_id=javascript-84290-ninarasi)_. Code in your preferred language, exploit full Dapr support, scale easily with any KEDA-compliant trigger.\\n 2. **Serverless Application Environments** _using [Azure App Service](https://azure.microsoft.com/products/app-service/?WT.mc_id=javascript-84290-ninarasi)_. Suitable for hosting monolithic apps (vs. microservices) in a managed service, with built-in support for on-demand scaling.\\n 3. **Serverless Kubernetes** _using [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/products/kubernetes-service/?WT.mc_id=javascript-84290-ninarasi)_. Spin up pods inside container instances and deploy Kubernetes-based applications with built-in KEDA-compliant autoscaling.\\n 4. **Serverless Functions** _using [Azure Functions](https://azure.microsoft.com/products/functions/?WT.mc_id=javascript-84290-ninarasi)_. Execute \\"code at the granularity of functions\\" in your preferred language, and scale on demand with event-driven compute.\\n\\nWe\'ll talk about these, and other compute comparisons, at the end of the article. But let\'s start with the core option you might choose if you want a managed serverless compute solution with built-in features for delivering containerized microservices at scale. Hello, **Azure Container Apps!**.\\n\\n## Azure Container Apps\\n\\n[Azure Container Apps (ACA)](https://learn.microsoft.com/azure/container-apps/?WT.mc_id=javascript-84290-ninarasi) became generally available in May 2022 - providing customers with the ability to run **microservices and containerized applications on a serverless, consumption-based platform**. The figure below showcases the different types of applications that can be built with ACA. Note that it comes with built-in KEDA-compliant autoscaling triggers, and other auto-scale criteria that may be better-suited to the type of application you are building.\\n\\n![About ACA](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/401522iACA9C8FFC49FE161/image-size/large?v=v2&px=999)\\n\\nSo far in the series, we\'ve put the spotlight on Azure Kubernetes Service (AKS) - so you\'re probably asking yourself: _How does ACA compare to AKS?_. We\'re glad you asked. Check out our _[Go Cloud-native with Azure Container Apps](https://azure.github.io/Cloud-Native/blog/zero2hero-aca-01)_ post from the #ServerlessSeptember series last year for a deeper-dive, or review the figure below for the main comparison points. \\n\\nThe key takeaway is this. Azure Container Apps (ACA) **also runs on Kubernetes** but abstracts away its complexity in a _managed service offering_ that lets you get productive quickly without requiring detailed knowledge of Kubernetes workings or APIs. However, if you **want full access and control over the Kubernetes API** then go with Azure Kubernetes Service (AKS) instead.\\n\\n![Comparison](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/401287i073CFBD50CB3A0B9/image-size/large?v=v2&px=999&WT.mc_id=javascript-99907-cxa)\\n\\n\\n## Other Container Options\\n\\nAzure Container Apps is the preferred **Platform As a Service (PaaS)** option for a fully-managed serverless solution on Azure that is purpose-built for cloud-native microservices-based application workloads. But - there are other options that may be suitable for your specific needs, from a requirements and tradeoffs perspective. Let\'s review them quickly:\\n\\n 1. **[Azure Functions](https://learn.microsoft.com/azure/azure-functions/functions-overview?WT.mc_id=javascript-84290-ninarasi)** is the serverless _Functions-as-a-Service_ (FaaS) option, as opposed to ACA which supports a PaaS approach. It\'s optimized for running event-driven applications built at the granularity of _ephemeral functions_ that can be deployed as code or containers.\\n 2. **[Azure App Service](https://learn.microsoft.com/azure/app-service/?WT.mc_id=javascript-84290-ninarasi)** provides fully managed hosting for web applications that may be deployed using code or containers. It can be integrated with other services including Azure Container Apps and Azure Functions. It\'s optimized for deploying traditional web apps.\\n 3. **[Azure Kubernetes Service](https://learn.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=javascript-84290-ninarasi)** provides a fully managed Kubernetes option capable of running any Kubernetes workload, with  direct access to the Kubernetes API.\\n 4. **[Azure Container Instances](https://learn.microsoft.com/azure/container-instances/?WT.mc_id=javascript-84290-ninarasi)** provides a _single pod_ of Hyper-V isolated containers on demand, making them more of a low-level \\"building block\\" option compared to ACA.\\n\\nBased on the **technology choices you made for application development** you may also have more specialized options you want to consider. For instance:\\n\\n 1. **[Azure Spring Apps](https://learn.microsoft.com/azure/spring-apps/overview?WT.mc_id=javascript-84290-ninarasi)** is ideal if you\'re running Spring Boot or Spring Cloud workloads on Azure,\\n 2. **[Azure Red Hat OpenShift](https://learn.microsoft.com/azure/openshift/intro-openshift?WT.mc_id=javascript-84290-ninarasi)** is ideal for integrated Kubernetes-powered OpenShift on Azure.\\n 3. **[Azure Confidential Computing](https://learn.microsoft.com/azure/confidential-computing/choose-confidential-containers-offerings)** is ideal if you have data/code integrity and confidentiality needs.\\n 4. **[Kubernetes At The Edge](https://learn.microsoft.com/azure/architecture/operator-guides/aks/choose-kubernetes-edge-compute-option)** is ideal for bare-metal options that extend compute to edge devices.\\n\\nThis is just the tip of the iceberg in your decision-making journey - but hopefully, it gave you a good sense of the options and criteria that influences your final choices. Let\'s wrap this up with a look at self-study resources for skilling up further.\\n\\n## Exercise\\n\\nWant to get hands on learning related to these technologies?\\n\\n:::tip TAKE THE CLOUD SKILLS CHALLENGE\\n[Register today](https://learn.microsoft.com/training/challenges?id=a0e385b9-f970-4182-b2e2-3b4619b6c356&WT.mc_id=javascript-84290-ninarasi) and level up your skills by completing free learning modules, while competing with your peers for a place on the leaderboards!\\n:::\\n\\n## Resources\\n\\n * [Choose an Azure compute service](https://learn.microsoft.com/azure/architecture/guide/technology-choices/compute-decision-tree?WT.mc_id=javascript-84290-ninarasi)\\n * [Serverless On Azure](https://azure.microsoft.com/solutions/serverless/#solutions?WT.mc_id=javascript-84290-ninarasi)\\n * [Go Cloud-native with Azure Container Apps](https://azure.github.io/Cloud-Native/blog/zero2hero-aca-01?WT.mc_id=javascript-84290-ninarasi)\\n * [Comparing Container Apps with other Azure container options](https://learn.microsoft.com/azure/container-apps/compare-options?WT.mc_id=javascript-84290-ninarasi)"},{"id":"building-with-draft","metadata":{"permalink":"/Cloud-Native/cnny-2023/building-with-draft","source":"@site/blog-cnny/2023-02-14/building-with-draft.md","title":"4-2. Jumpstart your applications with Draft","description":"Jump start your Kubernetes experience with Draft","date":"2023-02-14T00:00:00.000Z","formattedDate":"February 14, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":2.76,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://github.com/CSKIMM.png","key":"cory"}],"frontMatter":{"slug":"building-with-draft","title":"4-2. Jumpstart your applications with Draft","authors":["cory"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloud-native","containers","decision-tree","kubernetes","serverless","microservices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-17.png","description":"Jump start your Kubernetes experience with Draft","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"4-1. Serverless Container Options","permalink":"/Cloud-Native/cnny-2023/serverless-containers"},"nextItem":{"title":"4-3. Windows Containers","permalink":"/Cloud-Native/cnny-2023/windows-containers"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/building-with-draft\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Jumpstart your applications with Draft\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Jump start your Kubernetes experience with Draft\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-17.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@cksimming\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/building-with-draft\\" />\\n</head>\\n\\nIt\'s the final week of #CloudNativeNewYear! This week we\'ll go further with Cloud-native by exploring advanced topics and best practices for the Cloud-native practitioner. In today\'s post, we will introduce you to the basics of the open-source project Draft and how it can be used to easily create and deploy applications to Kubernetes. \\n\\n:::tip It\'s not too late to sign up for and complete the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n\\n:::\\n\\n---\\n\\n## What We\'ll Cover\\n* What is Draft? \\n* Draft basics\\n* Demo: Developing to AKS with Draft\\n* Resources\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n--- \\n## What is Draft? \\n\\n[Draft](https://github.com/azure/draft) is an open-source tool that can be used to streamline the development and deployment of applications on Kubernetes clusters. It provides a simple and easy-to-use workflow for creating and deploying applications, making it easier for developers to focus on writing code and building features, rather than worrying about the underlying infrastructure. This is great for users who are just getting started with Kubernetes, or those who are just looking to simplify their experience.\\n\\n:::info New to Kubernetes?\\n\\nCatch [A Quickstart Guide to Kubernetes Concepts](https://info.microsoft.com/ww-ondemand-a-quickstart-guide-to-kubernetes-concepts.html?lcid=en-us) on demand, now!\\n\\n:::\\n---\\n## Draft basics\\n\\nDraft streamlines Kubernetes development by taking a non-containerized application and generating the Dockerfiles, K8s manifests, Helm charts, and other artifacts associated with a containerized application. Draft can also create a GitHub Action workflow file to quickly build and deploy your application onto any Kubernetes cluster.\\n\\n1.\\t**\'draft create\'\':** Create a new Draft project by simply running the \'draft create\' command - this command will walk you through a series of questions on your application specification (such as the application language) and create a Dockerfile, Helm char, and Kubernetes \\n2.\\t**\'draft generate-workflow\'\':** Automatically build out a GitHub Action using the \'draft generate-workflow\' command\\n3.\\t**\'draft setup-gh\'\':** If you are using Azure, use this command to automate the GitHub OIDC set up process to ensure that you will be able to deploy your application using your GitHub Action. \\n\\nAt this point, you will have all the files needed to deploy your app onto a Kubernetes cluster (we told you it was easy!).\\n\\nYou can also use the **\'draft info\'** command if you are looking for information on supported languages and deployment types. Let\'s see it in action, shall we? \\n\\n---\\n# Developing to AKS with Draft\\n\\nIn this Microsoft Reactor session below, we\'ll briefly introduce Kubernetes and the Azure Kubernetes Service (AKS) and then demo how enable your applications for Kubernetes using the open-source tool Draft. We\'ll show how Draft can help you create the boilerplate code to containerize your applications and add routing and scaling behaviours. \\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/watch?v=XDm2dqxGcvo\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe> \\n---\\n##Conclusion\\n\\nOverall, Draft simplifies the process of building, deploying, and managing applications on Kubernetes, and can make the overall journey from [code to Kubernetes](https://techcommunity.microsoft.com/t5/apps-on-azure-blog/code-to-cloud-with-azure-kubernetes-service-aks/ba-p/3669916_) significantly easier. \\n\\n___\\n\\n## Resources\\n* **LAST WEEK** for the [Cloud Skills Challenge](https://aka.ms/Challenge)\\n* **Learning Resources**: [#30DaysOfCloudNative Collection](https://aka.ms/CNNY/collection)\\n* **Podcast:** [Containerize apps to AKS with Draft](https://www.youtube.com/watch?v=3RIulCcDet0)\\n* **Project:** [Get started with Draft](https://github.com/azure/draft)\\n\\n---"},{"id":"windows-containers","metadata":{"permalink":"/Cloud-Native/cnny-2023/windows-containers","source":"@site/blog-cnny/2023-02-15/index.md","title":"4-3. Windows Containers","description":"Let\'s learn about Windows containers!","date":"2023-02-15T00:00:00.000Z","formattedDate":"February 15, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"containers","permalink":"/Cloud-Native/cnny-2023/tags/containers"},{"label":"windows","permalink":"/Cloud-Native/cnny-2023/tags/windows"}],"readingTime":6.265,"hasTruncateMarker":false,"authors":[{"name":"Vinicius Apolinario","title":"Senior Cloud Advocate","url":"https://github.com/vrapolinario","imageURL":"https://github.com/vrapolinario.png","key":"vinicius"}],"frontMatter":{"slug":"windows-containers","title":"4-3. Windows Containers","authors":["vinicius"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["containers","windows","aks","kubernetes"],"image":"https://azure.github.io/Cloud-Native/img/og/30-18.png","description":"Let\'s learn about Windows containers!","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service","containers","windows"]},"unlisted":false,"prevItem":{"title":"4-2. Jumpstart your applications with Draft","permalink":"/Cloud-Native/cnny-2023/building-with-draft"},"nextItem":{"title":"4-4. Azure Kubernetes Services Add-ons and Extensions","permalink":"/Cloud-Native/cnny-2023/aks-extensions-addons"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/windows-containers\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Windows Containers\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"Let\'s learn about Windows containers!\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-18.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@vrapolinario\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/windows-containers\\" />\\n</head>\\n\\nWelcome to `Day 3 of Week 4` of #CloudNativeNewYear!\\n\\nThe theme for this week is going further with Cloud Native. Yesterday we talked about using Draft to accelerate your Kubernetes adoption. Today we\'ll explore the topic of Windows containers.\\n\\n## What We\'ll Cover\\n * Introduction\\n * Windows containers overview\\n * Windows base container images\\n * Isolation\\n * Exercise: Try this yourself!\\n * Resources: For self-study!\\n\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n## Introduction\\n\\nWindows containers were launched along with Windows Server 2016, and have evolved since. In its latest release, Windows Server 2022, Windows containers have reached a great level of maturity and allow for customers to run production grade workloads.\\n\\nWhile suitable for new developments, Windows containers also provide developers and operations with a different approach than Linux containers. It allows for existing Windows applications to be containerized with little or no code changes. It also allows for professionals that are more comfortable with the Windows platform and OS, to leverage their skill set, while taking advantage of the containers platform.\\n\\n## Windows container overview\\n\\nIn essence, Windows containers are very similar to Linux. Since Windows containers use the same foundation of Docker containers, you can expect that the same architecture applies - with the specific notes of the Windows OS. For example, when running a Windows container via Docker, you use the same commands, such as docker run. To pull a container image, you can use docker pull, just like on Linux. However, to run a Windows container, you also need a Windows container host. This requirement is there because, as you might remember, a container shares the OS kernel with its container host.\\n\\nOn Kubernetes, Windows containers are supported since Windows Server 2019. Just like with Docker, you can manage Windows containers like any other resource on the Kubernetes ecosystem. A Windows node can be part of a Kubernetes cluster, allowing you to run Windows container based applications on services like Azure Kubernetes Service. To deploy an Windows application to a Windows pod in Kubernetes, you can author a YAML specification much like you would for Linux. The main difference is that you would point to an image that runs on Windows, and you need to specify a node selection tag to indicate said pod needs to run on a Windows node.\\n\\n## Windows base container images\\n\\nOn Windows containers, you will always use a base container image provided by Microsoft. This base container image contains the OS binaries for the container to run. This image can be as large as 3GB+, or small as ~300MB. The difference in the size is a consequence of the APIs and components available in each Windows container base container image. There are primarily, three images: Nano Server, Server Core, and Server. \\n\\nNano Server is the smallest image, ranging around 300MB. It\'s a base container image for new developments and cloud-native scenarios. Applications need to target Nano Server as the Windows OS, so not all frameworks will work. For example, .Net works on Nano Server, but .Net Framework doesn\'t. Other third-party frameworks also work on Nano Server, such as Apache, NodeJS, Phyton, Tomcat, Java runtime, JBoss, Redis, among others.\\n\\nServer Core is a much larger base container image, ranging around 1.25GB. It\'s larger size is compensated by it\'s application compatibility. Simply put, any application that meets the requirements to be run on a Windows container, can be containerized with this image.\\n\\nThe Server image builds on the Server Core one. It ranges around 3.1GB and has even greater application compatibility than the Server Core image. In addition to the traditional Windows APIs and components, this image allows for scenarios such as Machine Learning via DirectX with GPU access.\\n\\nThe best image for your scenario is dependent on the requirements your application has on the Windows OS inside a container. However, there are some scenarios that are not supported at all on Windows containers - such as GUI or RDP dependent applications, some Windows Server infrastructure roles, such as Active Directory, among others.\\n\\n## Isolation\\n\\nWhen running containers, the kernel of the container host is shared with the containers running on it. While extremely convenient, this poses a potential risk for multi-tenant scenarios. If one container is compromised and has access to the host, it could potentially compromise other containers in the same system.\\n\\nFor enterprise customers running on-premises (or even in the cloud), this can be mitigated by using a VM as a container host and considering the VM itself a security boundary. However, if multiple workloads from different tenants need to share the same host, Windows containers offer another option: Hyper-V isolation. While the name Hyper-V is associated with VMs, its virtualization capabilities extend to other services, including containers. Hyper-V isolated containers run on a purpose built, extremely small, highly performant VM. However, you manage a container running with Hyper-V isolation the same way you do with a process isolated one. In fact, the only notable difference is that you need to append the `--isolation=hyperv` tag to the `docker run` command.\\n\\n## Exercise\\n\\nHere are a few examples of how to use Windows containers:\\n\\n### Run Windows containers via Docker on your machine\\n\\nTo pull a Windows base container image:\\n\\n```powershell\\ndocker pull mcr.microsoft.com/windows/servercore:ltsc2022\\n```\\n\\nTo run a basic IIS container:\\n```powershell\\n#This command will pull and start a IIS container. You can access it from http://<your local IP>:8080\\ndocker run -d -p 8080:80 mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2022\\n```\\n\\nRun the same IIS container with Hyper-V isolation\\n\\n```powershell\\n#This command will pull and start a IIS container. You can access it from http://<your local IP>:8080\\ndocker run -d -p 8080:80 --isolation=hyperv mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2022\\n```\\n\\nTo run a Windows container interactively:\\n\\n```powershell\\ndocker run -it mcr.microsoft.com/windows/servercore:ltsc2022 powershell\\n```\\n\\n### Run Windows containers on Kubernetes\\n\\nTo prepare an AKS cluster for Windows containers:\\nNote: Replace the values on the example below with the ones from your environment.\\n\\n```azurecli\\necho \\"Please enter the username to use as administrator credentials for Windows Server nodes on your cluster: \\" && read WINDOWS_USERNAME\\naz aks create \\\\\\n    --resource-group myResourceGroup \\\\\\n    --name myAKSCluster \\\\\\n    --node-count 2 \\\\\\n    --generate-ssh-keys \\\\\\n    --windows-admin-username $WINDOWS_USERNAME \\\\\\n    --vm-set-type VirtualMachineScaleSets \\\\\\n    --network-plugin azure\\n```\\n\\nTo add a Windows node pool for Windows containers:\\n\\n```azurecli\\naz aks nodepool add \\\\\\n    --resource-group myResourceGroup \\\\\\n    --cluster-name myAKSCluster \\\\\\n    --os-type Windows \\\\\\n    --name npwin \\\\\\n    --node-count 1\\n```\\n\\nDeploy a sample ASP.Net application to the AKS cluster above using the YAML file below:\\n\\n```yml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: sample\\n  labels:\\n    app: sample\\nspec:\\n  replicas: 1\\n  template:\\n    metadata:\\n      name: sample\\n      labels:\\n        app: sample\\n    spec:\\n      nodeSelector:\\n        \\"kubernetes.io/os\\": windows\\n      containers:\\n      - name: sample\\n        image: mcr.microsoft.com/dotnet/framework/samples:aspnetapp\\n        resources:\\n          limits:\\n            cpu: 1\\n            memory: 800M\\n        ports:\\n          - containerPort: 80\\n  selector:\\n    matchLabels:\\n      app: sample\\n---\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: sample\\nspec:\\n  type: LoadBalancer\\n  ports:\\n  - protocol: TCP\\n    port: 80\\n  selector:\\n    app: sample\\n```\\n\\nSave the file above and run the command below on your Kubernetes cluster:\\n\\n```powershell\\nkubectl apply -f <filename> .\\n```\\n\\nOnce deployed, you can access the application by getting the IP address of your service:\\n\\n```powershell\\nkubectl get service\\n```\\n\\n## Resources\\n\\n:::tip It\'s not too late to sign up for and complete the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n\\n:::\\n\\n* [Windows containers documentation](https://learn.microsoft.com/virtualization/windowscontainers/?WT.mc_id=containers-84290-viniap)\\n* [Run Windows containers on AKS](https://learn.microsoft.com/azure/aks/learn/quick-windows-container-deploy-cli?WT.mc_id=containers-84290-viniap)"},{"id":"aks-extensions-addons","metadata":{"permalink":"/Cloud-Native/cnny-2023/aks-extensions-addons","source":"@site/blog-cnny/2023-02-16/index.md","title":"4-4. Azure Kubernetes Services Add-ons and Extensions","description":"In this article we are going to learn about the extensions and add-ons available to AKS - Azure Kubernetes Services","date":"2023-02-16T00:00:00.000Z","formattedDate":"February 16, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"},{"label":"containers","permalink":"/Cloud-Native/cnny-2023/tags/containers"},{"label":"addons","permalink":"/Cloud-Native/cnny-2023/tags/addons"},{"label":"extensions","permalink":"/Cloud-Native/cnny-2023/tags/extensions"}],"readingTime":3.38,"hasTruncateMarker":false,"authors":[{"name":"Jorge Arteiro","title":"Senior Cloud Advocate","url":"https://github.com/jorgearteiro","imageURL":"https://github.com/jorgearteiro.png","key":"jorge"}],"frontMatter":{"slug":"aks-extensions-addons","title":"4-4. Azure Kubernetes Services Add-ons and Extensions","authors":["jorge"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["containers","aks","kubernetes","extensions","addons"],"image":"https://azure.github.io/Cloud-Native/img/og/30-19.png","description":"In this article we are going to learn about the extensions and add-ons available to AKS - Azure Kubernetes Services","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service","containers","addons","extensions"]},"unlisted":false,"prevItem":{"title":"4-3. Windows Containers","permalink":"/Cloud-Native/cnny-2023/windows-containers"},"nextItem":{"title":"4-5. Cloud Native New Year Wrap Up","permalink":"/Cloud-Native/cnny-2023/cnny-wrap-up"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/aks-extensions-addons\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Azure Kubernetes Services Add-ons and Extensions\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"In this article we are going to learn about the extensions and addons available to AKS - Azure Kubernetes Services\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-19.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@jorgearteiro\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/aks-extensions-addons\\" />\\n</head>\\n\\nWelcome to `Day 4 of Week 4` of #CloudNativeNewYear!\\n\\nThe theme for this week is going further with Cloud Native. Yesterday we talked about Windows Containers. Today we\'ll explore addons and extensions available to Azure Kubernetes Services (AKS).\\n\\n## What We\'ll Cover\\n * Introduction\\n * Add-ons\\n * Extensions\\n * Add-ons vs Extensions\\n * Resources\\n\\n\x3c!-- ************************************* --\x3e\\n\x3c!--  AUTHORS: ONLY UPDATE BELOW THIS LINE --\x3e\\n\x3c!-- ************************************* --\x3e\\n\\n## Introduction\\n\\nAzure Kubernetes Service (AKS) is a fully managed container orchestration service that makes it easy to deploy and manage containerized applications on Azure. AKS offers a number of features and capabilities, including the ability to extend its supported functionality through the use of add-ons and extensions.\\n\\nThere are also integrations available from [open-source projects and third parties](https://learn.microsoft.com/azure/aks/integrations?WT.mc_id=containers-84290-joarteir#open-source-and-third-party-integrations), but they are not covered by the [AKS support policy](https://learn.microsoft.com/azure/aks/support-policies?WT.mc_id=containers-84290-joarteir).\\n\\n\\n## Add-ons\\n\\nAdd-ons provide a supported way to extend AKS. Installation, configuration and lifecycle are managed by AKS following [pre-determine updates rules](https://learn.microsoft.com/azure/aks/integrations?WT.mc_id=containers-84290-joarteir#add-ons).\\n\\nAs an example, let\'s enable Container Insights with the monitoring addon. on an existing AKS cluster using `az aks enable-addons --addons` CLI command  \\n\\n```azurecli\\naz aks enable-addons \\\\\\n  --name MyManagedCluster \\\\\\n  --resource-group MyResourceGroup \\\\\\n  --addons monitoring\\n```\\n\\nor you can use `az aks create --enable-addons` when creating new clusters\\n```azurecli\\naz aks create \\\\\\n  --name MyManagedCluster \\\\\\n  --resource-group MyResourceGroup \\\\\\n  --enable-addons monitoring\\n```\\n\\nThe current available add-ons are:\\n\\n1.\\t**http_application_routing** - Configure ingress with automatic public DNS name creation. Only recommended for development.\\n2.\\t**monitoring** - Container Insights monitoring.\\n3.\\t**virtual-node** - CNCF virtual nodes open source project.\\n4.\\t**azure-policy** - Azure Policy for AKS.\\n5.\\t**ingress-appgw** - Application Gateway Ingress Controller (AGIC).\\n6.\\t**open-service-mesh** - CNCF Open Service Mesh project.\\n7.\\t**azure-keyvault-secrets-provider** - Azure Key Vault Secrets Provider for Secret Store CSI Driver.\\n8.\\t**web_application_routing** - Managed NGINX ingress Controller.\\n9.\\t**keda** - CNCF Event-driven autoscaling project.\\n\\nFor more details, get the updated [list of AKS Add-ons here](https://learn.microsoft.com/azure/aks/integrations?WT.mc_id=containers-84290-joarteir#available-add-ons)\\n\\n\\n## Extensions\\n\\nCluster Extensions uses Helm charts and integrates with Azure Resource Manager (ARM) to provide installation and lifecycle management of capabilities on top of AKS. \\n\\nExtensions can be auto upgraded using minor versions, but it requires extra management and configuration. Using Scope parameter, it can be installed on the whole cluster or per namespace.\\n\\nAKS Extensions requires an Azure CLI extension to be installed. To add or update this CLI extension use the following commands:\\n```azurecli\\naz extension add --name k8s-extension\\n```\\nand to update an existing extension\\n```azurecli\\naz extension update --name k8s-extension\\n```\\n\\nThere are only 3 available extensions:\\n1.\\t**Dapr** - CNCF Dapr project.\\n2.\\t**Azure ML** - Integrate Azure Machine Learning with AKS to train, inference and manage ML models.\\n3.\\t**Flux (GitOps)** - CNCF Flux project integrated with AKS to enable cluster configuration and application deployment using GitOps.\\n\\nAs an example, you can install Azure ML using the following command:\\n```azurecli\\naz k8s-extension create \\\\\\n  --name aml-compute --extension-type Microsoft.AzureML.Kubernetes \\\\\\n  --scope cluster --cluster-name <clusterName> \\\\\\n  --resource-group <resourceGroupName> \\\\\\n  --cluster-type managedClusters \\\\\\n  --configuration-settings enableInference=True allowInsecureConnections=True\\n```\\n\\nFor more details, get the updated [list of AKS Extensions here](https://learn.microsoft.com/azure/aks/cluster-extensions?tabs=azure-cli&WT.mc_id=containers-84290-joarteir#currently-available-extensions)\\n\\n\\n## Add-ons vs Extensions\\n\\nAKS Add-ons brings an advantage of been fully managed by AKS itself, and AKS Extensions are more flexible and configurable but requires extra level of management. \\n\\nAdd-ons are part of the AKS resource provider in the Azure API, and AKS Extensions are a separate resource provider on the Azure API.\\n\\n\\n## Resources\\n\\n:::tip It\'s not too late to sign up for and complete the [Cloud Skills Challenge](https://aka.ms/CNNY/Challenge)!\\n\\n:::\\n\\n* [Add-ons, Extensions, and other integrations with AKS](https://learn.microsoft.com/azure/aks/integrations?WT.mc_id=containers-84290-joarteir)\\n* [Available Add-ons on AKS](https://learn.microsoft.com/azure/aks/integrations#available-add-ons?WT.mc_id=containers-84290-joarteir)\\n* [Available Extensions on AKS](https://learn.microsoft.com/azure/aks/cluster-extensions?tabs=azure-cli&WT.mc_id=containers-84290-joarteir#currently-available-extensions)\\n* [Open source and third-party integrations](https://learn.microsoft.com/azure/aks/integrations?WT.mc_id=containers-84290-joarteir#open-source-and-third-party-integrations)\\n* [CNCF Dapr project](https://dapr.io/) \\n* [CNCF Flux project](https://fluxcd.io/)\\n* [CNCF KEDA project](https://keda.sh/)"},{"id":"cnny-wrap-up","metadata":{"permalink":"/Cloud-Native/cnny-2023/cnny-wrap-up","source":"@site/blog-cnny/2023-02-17/cnny-wrap-up.md","title":"4-5. Cloud Native New Year Wrap Up","description":"A review of all the great things we have learned during CNNY and how to keep the learning journey going!","date":"2023-02-17T00:00:00.000Z","formattedDate":"February 17, 2023","tags":[{"label":"cloud-native","permalink":"/Cloud-Native/cnny-2023/tags/cloud-native"},{"label":"30daysofcloudnative","permalink":"/Cloud-Native/cnny-2023/tags/30-daysofcloudnative"},{"label":"zero-to-hero","permalink":"/Cloud-Native/cnny-2023/tags/zero-to-hero"},{"label":"ask-the-expert","permalink":"/Cloud-Native/cnny-2023/tags/ask-the-expert"},{"label":"azure-kubernetes-service","permalink":"/Cloud-Native/cnny-2023/tags/azure-kubernetes-service"}],"readingTime":5.04,"hasTruncateMarker":false,"authors":[{"name":"Cory Skimming","title":"Sr. Product Marketing Manager","url":"https://twitter.com/cskimming","imageURL":"https://github.com/CSKIMM.png","key":"cory"},{"name":"Steven Murawski","title":"Principal Cloud Advocate","url":"https://github.com/smurawski","imageURL":"https://github.com/smurawski.png","key":"steven"},{"name":"Paul Yu","title":"Senior Cloud Advocate","url":"https://github.com/pauldotyu","imageURL":"https://github.com/pauldotyu.png","key":"paul"},{"name":"Josh Duffney","title":"Cloud-Native Advocate @Microsoft","url":"https://github.com/duffney","imageURL":"https://github.com/duffney.png","key":"josh"},{"name":"Nitya Narasimhan","title":"Senior Cloud Advocate, Illustrator","url":"https://github.com/nitya","imageURL":"https://github.com/nitya.png","key":"nitya"},{"name":"Vinicius Apolinario","title":"Senior Cloud Advocate","url":"https://github.com/vrapolinario","imageURL":"https://github.com/vrapolinario.png","key":"vinicius"},{"name":"Jorge Arteiro","title":"Senior Cloud Advocate","url":"https://github.com/jorgearteiro","imageURL":"https://github.com/jorgearteiro.png","key":"jorge"},{"name":"Devanshi Joshi","title":"Product Marketing Manager","url":"https://github.com/devanshidiaries","imageURL":"https://github.com/devanshidiaries.png","key":"devanshi"}],"frontMatter":{"slug":"cnny-wrap-up","title":"4-5. Cloud Native New Year Wrap Up","authors":["cory","steven","paul","josh","nitya","vinicius","jorge","devanshi"],"draft":false,"hide_table_of_contents":false,"toc_min_heading_level":2,"toc_max_heading_level":3,"keywords":["cloud-native","containers","decision-tree","kubernetes","serverless","microservices"],"image":"https://azure.github.io/Cloud-Native/img/og/30-20.png","description":"A review of all the great things we have learned during CNNY and how to keep the learning journey going!","tags":["cloud-native","30daysofcloudnative","zero-to-hero","ask-the-expert","azure-kubernetes-service"]},"unlisted":false,"prevItem":{"title":"4-4. Azure Kubernetes Services Add-ons and Extensions","permalink":"/Cloud-Native/cnny-2023/aks-extensions-addons"}},"content":"<head>\\n  <meta name=\\"twitter:url\\" \\n    content=\\"https://azure.github.io/Cloud-Native/cnny-2023/cnny-wrap-up\\" />\\n  <meta name=\\"twitter:title\\" \\n    content=\\"Cloud Native New Year Wrap Up\\" />\\n  <meta name=\\"twitter:description\\" \\n    content=\\"A review of all the great things we have learned during CNNY and how to keep the learning journey going!\\" />\\n  <meta name=\\"twitter:image\\" \\n    content=\\"https://azure.github.io/Cloud-Native/img/og/30-20.png\\" />\\n  <meta name=\\"twitter:card\\" content=\\"summary_large_image\\" />\\n  <meta name=\\"twitter:creator\\" \\n    content=\\"@cskimm\\" />\\n  <meta name=\\"twitter:site\\" content=\\"@AzureAdvocates\\" /> \\n  <link rel=\\"canonical\\" \\n    href=\\"https://azure.github.io/Cloud-Native/cnny-2023/cnny-wrap-up\\" />\\n</head>\\n\\nAnd that\'s a wrap on the inaugural #CloudNativeNewYear! Thank you for joining us to kick off the new year with this learning journey into cloud-native! In this final post of the 2023 celebration of all things cloud-native, we\'ll do two things:\\n\\n* **Look Back** - with a quick retrospective of what was covered.\\n* **Look Ahead** - with resources and suggestions for how you can continue your skilling journey!\\n\\nWe appreciate your time and attention and we hope you found this curated learning valuable. Feedback and suggestions are always welcome. From our entire team, we wish you good luck with the learning journey - now go build some apps and share your knowledge! \ud83c\udf89\\n\\n![](./../../static/img/cnny23/hero-banner.png)\\n\\n---\\n\\n## What We\'ll Cover\\n* Cloud-native fundamentals\\n* Kubernetes fundamentals\\n* Bringing your applications to Kubernetes\\n* Go further with cloud-native\\n* Resources to keep the celebration going!\\n\\n--- \\n## Week 1: Cloud-native Fundamentals\\n\\nIn Week 1, we took a tour through the fundamentals of cloud-native technologies, including a walkthrough of the core concepts of containers, microservices, and Kubernetes. \\n\\n* Jan 23 - **[Cloud-native Fundamentals](https://azure.github.io/Cloud-Native/cnny-2023/cloud-native-fundamentals)**: The answers to life and all the universe - what is cloud-native? What makes an application cloud-native? What are the benefits? (yes, we all know it\'s 42, but hey, gotta start somewhere!)\\n* Jan 24 - **[Containers 101](https://azure.github.io/Cloud-Native/cnny-2023/containers-101)**: Containers are an essential component of cloud-native development. In this intro post, we cover how containers work and why they have become so popular. \\n* Jan 25 - **[Kubernetes 101](https://azure.github.io/Cloud-Native/cnny-2023/Kubernetes-101)**: Kuber-what-now? Learn the basics of Kubernetes and how it enables us to deploy and manage our applications effectively and consistently.\\n\\n:::info  A QUICKSTART GUIDE TO KUBERNETES CONCEPTS\\n\\nMissed it Live? Tune in to [A Quickstart Guide to Kubernetes Concepts](https://info.microsoft.com/ww-ondemand-a-quickstart-guide-to-kubernetes-concepts.html?lcid=en-us) on demand, now!\\n\\n:::\\n\\n* Jan 26 - **[Microservices 101](https://azure.github.io/Cloud-Native/cnny-2023/microservices-101)**: What is a microservices architecture and how can we go about designing one? \\n* Jan 27 - **[Exploring your Cloud Native Options](https://azure.github.io/Cloud-Native/cnny-2023/explore-options)**: *Cloud-native*, while catchy, can be a very broad term. What technologies should you use? Learn some basic guidelines for when it is optimal to use different technologies for your project. \\n\\n\\n---\\n## Week 2: Kubernetes Fundamentals\\n\\nIn Week 2, we took a deeper dive into the Fundamentals of Kubernetes. The posts and live demo from this week took us through how to build a simple application on Kubernetes, covering everything from deployment to networking and scaling. Note: for our samples and demo we have used Azure Kubernetes Service, but the principles apply to any Kubernetes!\\n\\n* Jan 30 - **[Pods and Deployments](https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-1)**: how to use pods and deployments in Kubernetes. \\n* Jan 31 - **[Services and Ingress](https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-2)**: how to use services and ingress and a walk through the steps of making our containers accessible internally and externally!\\n* Feb 1 - **[ConfigMaps and Secrets](https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-3)**: how to of passing configuration and secrets to our applications in Kubernetes with ConfigMaps and Secrets.\\n* Feb 2 - **[Volumes, Mounts, and Claims](https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-4)**: how to use persistent storage on Kubernetes (and ensure your data can survive container restarts!).\\n* Feb 3 - **[Scaling Pods and Nodes](https://azure.github.io/Cloud-Native/cnny-2023/fundamentals-day-5)**: how to scale pods and nodes in our Kubernetes cluster.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/mLm9uskCrq0\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n\\n:::info  ASK THE EXPERTS: AZURE KUBERNETES SERVICE\\n\\nMissed it Live? Tune in to [Ask the Expert with Azure Kubernetes Service](https://learn.microsoft.com/en-us/shows/ask-the-expert/cloud-native-new-year-azure-kubernetes-service) on demand, now!\\n\\n:::\\n\\n---\\n## Week 3: Bringing your applications to Kubernetes\\n\\nSo, you have learned how to build an application on Kubernetes. What about your existing applications? In Week 3, we explored how to take an existing application and set it up to run in Kubernetes:  \\n\\n* Feb 6 - **[CI/CD](https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-1)**: learn how to get an existing application running in Kubernetes with a full pipeline in GitHub Actions.\\n* Feb 7 - **[Adapting Storage, Secrets, and Configuration](https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-2)**: how to evaluate our sample application\'s configuration, storage, and networking requirements and implement using Kubernetes.\\n* Feb 8 - **[Opening your Application with Ingress](https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-3)**: how to expose the eShopOnWeb app so that customers can reach it over the internet using a custom domain name and TLS.\\n* Feb 9 - **[Debugging and Instrumentation](https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-4)**: how to debug and instrument your application now that it is on Kubernetes. \\n* Feb 10 - **[CI/CD Secure Supply Chain](https://azure.github.io/Cloud-Native/cnny-2023/bring-your-app-day-5)**: now that we have set up our application on Kubernetes, let\'s talk about container image signing and how to set up a secure supply change.\\n\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/CMZ0XudQ4HA\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer;  clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowfullscreen></iframe>\\n\\n---\\n## Week 4: Go *Further* with Cloud-Native\\n\\nThis week we have gone further with Cloud-native by exploring advanced topics and best practices for the Cloud-native practitioner.\\n\\n* Feb 13 - **[Serverless Container Options](https://azure.github.io/Cloud-Native/cnny-2023/serverless-containers)**: explore if you should go serverless, when that is a great option, and what your serverless compute options are on Azure.\\n* Feb 14 - **[Jumpstart your applications with Draft](https://azure.github.io/Cloud-Native/cnny-2023/building-with-draft)**: learn the basics of the open-source project Draft and how it can be used to easily create and deploy applications to Kubernetes.\\n* Feb 15 - **[Windows Containers](https://azure.github.io/Cloud-Native/cnny-2023/windows-containers)**: learn how you can use Windows containers on Kubernetes. \\n* Feb 16 - **[Azure Kubernetes Service Add-ons and Extensions](https://azure.github.io/Cloud-Native/cnny-2023/aks-extensions-addons)**: explore add-ons and extensions available to Azure Kubernetes Service (AKS).\\n\\nAnd today, February 17th, with this one post to rule (er, collect) them all! \\n___\\n\\n## Keep the Learning Going! \\n\\nLearning is great, so why stop here? We have a host of great resources and samples for you to continue your cloud-native journey with Azure below: \\n\\n* **Learning Paths:** [Cloud Native New Year Learning Path Collection](https://learn.microsoft.com/users/nityan/collections/xz6ehr3z7o7e1q?WT.mc_id=javascript-84290-ninarasi)\\n* **Samples:** [Azure Samples on GitHub](https://github.com/Azure-Samples)\\n* **Hacks:** [What the Hack](https://microsoft.github.io/WhatTheHack/)\\n* **eBook:** [Cloud Native Infrastructure with Azure](https://azure.microsoft.com/resources/cloud-native-infrastructure-with-microsoft-azure/?WT.mc_id=javascript-84290-ninarasi)\\n* **eBook:** [Cloud-native Architecture Mapbook](https://azure.microsoft.com/resources/azure-cloud-native-architecture-mapbook/?WT.mc_id=javascript-84290-ninarasi)\\n\\n\\n---"}]}')}}]);